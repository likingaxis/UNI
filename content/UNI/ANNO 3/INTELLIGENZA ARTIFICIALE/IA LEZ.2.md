
## DEFINIZIONE DI AGENTE

- Un **agente** √® una **IA incarnata** in un ambiente, capace di **percepire, ragionare e agire autonomamente** in modo **razionale** per raggiungere i suoi obiettivi.
- **IA** √® il campo di studio (la disciplina)  
- **Agente** √® l‚Äôunit√† operativa che incarna una IA in un ambiente.

- *Agente=Software*
# ü§ñ DIFFERENZA TRA UN SOFTWARE TRADIZIONALE E UN SOFTWARE AI

Un **software tradizionale** lavora in isolamento: riceve input predefiniti e produce output prevedibili.  
Un **software di tipo AI**, invece, **lavora in un ambiente**, percepisce segnali esterni, **decide autonomamente** e **agisce** in base alle condizioni che rileva.  
√à un sistema dinamico, pi√π simile a un **sistema operativo intelligente** che non a un semplice programma.

- L‚Äô**agente AI** non pu√≤ sapere in anticipo le domande o gli stimoli che ricever√†.
    
- Pu√≤ disporre di:
    
    - **Effettori** ‚Üí componenti che gli permettono di compiere azioni fisiche o logiche.
        
    - **Sensori** ‚Üí apparati che gli consentono di percepire e riconoscere l‚Äôambiente.
### üîÅ Ciclo dell‚Äôagente

![[Pasted image 20251013185628.png]]

1. **Percepire** una situazione tramite i sensori.
    
2. **Decidere** cosa fare in base alle proprie conoscenze e percezioni passate.
    
3. **Agire** sull‚Äôambiente con gli effettori.
    
4. **Aggiornarsi** in base alle conseguenze dell‚Äôazione.
    

Gli agenti hanno **obiettivi** e una **percezione parziale del mondo**:  
l‚Äôambiente interno che rappresentano **non √® una copia perfetta del mondo reale**, ma una **versione astratta e dinamica**, arricchita solo quando nuove informazioni diventano necessarie.

---

# üß© PERCEZIONI E AZIONI

- **Percezione:** l‚Äôinput proveniente dai sensori.
    
- **Sequenza percettiva:** la storia completa di tutte le percezioni avute fino a un certo momento.
    
- L‚Äô**azione** √® sempre conseguente a una percezione: ogni nuova percezione genera una nuova decisione e quindi una nuova azione.

---
# üß† AGENTI RAZIONALI

Un **agente razionale** √® un‚Äôentit√† che interagisce con l‚Äôambiente in modo efficace, compiendo **le azioni giuste** per ottenere una **sequenza di stati desiderabile**.

> üí° **Un agente intelligente = un agente razionale**  
> In Intelligenza Artificiale, un agente √® intelligente quando agisce in modo razionale rispetto ai propri obiettivi e alle informazioni di cui dispone.

L‚Äôobiettivo non √® ‚Äúpensare come un umano‚Äù, ma **compiere scelte ottimali** rispetto alle percezioni e alle conoscenze attuali.

---

## üîπ Definizione di razionalit√†

La razionalit√† di un agente dipende da:

- la **misura di prestazione** (quanto le sue azioni portano al successo),
    
- le **conoscenze pregresse** dell‚Äôambiente,
    
- le **percezioni presenti e passate**,
    
- le **capacit√† operative** dell‚Äôagente.
    

Per ogni sequenza percettiva, un agente razionale sceglie **l‚Äôazione che massimizza il valore atteso della misura di prestazione**, considerando ci√≤ che sa e ci√≤ che ha percepito in passato.

---

## ‚öñÔ∏è Criterio di valutazione oggettivo

Per stabilire se un agente √® razionale, serve una **misura di prestazione esterna**, definita dal progettista, che descriva come vogliamo che il mondo evolva dopo le sue azioni.  
La razionalit√† quindi non √® assoluta, ma **relativa al contesto e al problema**.

---

## üî∏ Razionalit√† ‚â† Onniscienza

L‚Äôagente razionale **non √® perfetto**: non conosce tutto e non prevede tutto.  
Conta solo che agisca **nel modo migliore possibile** con le informazioni che ha.  
Se non sa, pu√≤ **esplorare** o **acquisire nuove informazioni** per migliorarsi.

---

## üîπ Razionalit√† e apprendimento

Raramente un agente dispone di tutte le conoscenze in anticipo.  
Per questo deve **imparare dall‚Äôesperienza**, modificando il proprio comportamento in base a **percezioni passate**, **feedback** e **errori**.  
Pi√π apprende, pi√π diventa razionale e quindi intelligente.

---

# üßç‚Äç‚ôÇÔ∏è AGENTI AUTONOMI

Un agente √® **autonomo** nella misura in cui il suo comportamento dipende **dalla propria esperienza**.  
Un agente che agisce solo secondo regole predefinite (**built-in**) √® rigido e poco flessibile.  
Deve invece **adattarsi** e migliorare nel tempo, pur rimanendo **controllabile e collaborativo**.

---

# üåç AMBIENTE E CODIFICA PEAS

Un ambiente √® descritto dal modello **PEAS**, che identifica gli elementi chiave del problema dell‚Äôagente:

|Lettera|Significato|Descrizione|
|---|---|---|
|**P**|Performance|Misura di successo dell‚Äôagente (obiettivi)|
|**E**|Environment|Descrizione dell‚Äôambiente operativo|
|**A**|Actuators|Attuatori: componenti per agire|
|**S**|Sensors|Sensori: componenti per percepire|

---

## üöñ Esempio ‚Äî Agente "Guidatore di Taxi"

| **Prestazioni** | Arrivare a destinazione in sicurezza, rispettando le regole, minimizzando tempi e consumi, garantendo comfort. |  
| **Ambiente** | Strada, traffico, pedoni, clienti, segnali stradali. |  
| **Attuatori** | Sterzo, acceleratore, freni, clacson, schermo, voce sintetica. |  
| **Sensori** | Telecamere, GPS, sonar, tachimetro, microfono, sensori di motore. |

---

# ‚öñÔ∏è PROPRIET√Ä DELL‚ÄôAMBIENTE

Un ambiente pu√≤ avere diverse caratteristiche:

|Propriet√†|Descrizione|
|---|---|
|**Completamente / Parzialmente osservabile**|L‚Äôagente percepisce tutto ci√≤ che serve oppure solo una parte (limitazioni sensoriali).|
|**Agente singolo / multi-agente**|In un ambiente multi-agente gli altri agenti possono essere cooperativi o competitivi.|
|**Deterministico / Stocastico / Non deterministico**|Deterministico ‚Üí stato futuro certo.  <br>Stocastico ‚Üí esiste una probabilit√† di transizione.  <br>Non deterministico ‚Üí esiti possibili equiprobabili o non noti.|
|**Episodico / Sequenziale**|Episodico ‚Üí le decisioni sono indipendenti (es. riconoscimento immagini).  <br>Sequenziale ‚Üí ogni decisione influenza le successive (es. guida autonoma).|
|**Statico / Dinamico / Semi-dinamico**|Statico ‚Üí l‚Äôambiente non cambia mentre l‚Äôagente decide, probabilmente perch√© effettua le scelte in maniera molto rapida.  <br>Dinamico ‚Üí l‚Äôambiente cambia mentre l‚Äôagente agisce (es. taxi autonomo).  <br>Semi-dinamico ‚Üí ambiente stabile ma la valutazione cambia (es. scacchi con timer).|
|**Discreto / Continuo**|Discreto ‚Üí numero finito di stati o azioni (esame a scelta multipla).  <br>Continuo ‚Üí stati e tempi variano nel continuo (es. guida).|
|**Noto / Ignoto**|Noto ‚Üí l‚Äôagente conosce l‚Äôambiente.  <br>Ignoto ‚Üí deve esplorare e apprendere.|

> Gli ambienti reali sono di solito: **parzialmente osservabili, stocastici, sequenziali, dinamici, continui, multi-agente e ignoti.**
---

**CHIEDI A LEZIONE SI INTENDE SIMULARE PER VELOCIZZARE O ASTRARRE IL VERO E PROPRIO AMBIENTE IN MODO CHE SIA COMPATIBILE CON QUEL DETERMINATO AGENTE?**
# üßÆ COME AUTOMATIZZARE UN AMBIENTE

Un **simulatore di ambienti** √® un software che:

- genera stimoli per gli agenti,
    
- raccoglie le azioni in risposta,
    
- aggiorna lo stato dell‚Äôambiente,
    
- pu√≤ attivare processi secondari,
    
- valuta la prestazione degli agenti.

Serve per **testare e addestrare** gli agenti in modo controllato.

### üî∏ Ambiente reale vs simulato

- L‚Äô**ambiente reale** √® il mondo fisico o operativo in cui l‚Äôagente percepisce e agisce concretamente (es. un‚Äôauto autonoma).
    
- L‚Äô**ambiente simulato** √® costruito ad hoc per l‚Äôaddestramento: consente di provare azioni e imparare senza rischi.  
    ‚Üí In genere si addestra in un **ambiente virtuale**, poi si trasferisce il comportamento nel **mondo reale**.
    

---

# üß† STRUTTURA DELL‚ÄôAGENTE

> **Agente = Architettura + Programma**

- **Architettura:** la parte fisica o software che esegue le operazioni (hardware, sensori, processi).
    
- **Programma agente:** l‚Äôalgoritmo che decide quale azione intraprendere in base alle percezioni.
    

üëâ L‚Äôarchitettura √® il **corpo**, il programma √® la **mente** dell‚Äôagente.

Un **agente** pu√≤ essere visto come una **funzione matematica** che:
$$Ag : P^* \rightarrow A$$
dove:
- $P^*$ = insieme di tutte le possibili sequenze di percezioni,
    
- $A$= insieme delle azioni possibili.

> In parole semplici:  
> **un agente √® una funzione che prende in input le percezioni e restituisce in output un‚Äôazione.**
> 
> Quindi, una **funzione agente** riceve una percezione (o una sequenza percettiva), decide, e **manda in output un‚Äôazione** in risposta.

---

## üìò Funzionamento generale
```scss
memoria ‚Üê aggiorna(memoria, percezione) 
azione ‚Üê scegli_azione_migliore(memoria) 
memoria ‚Üê aggiorna(memoria, azione) 
restituisci(azione)
```

Ogni agente, indipendentemente dalla sua architettura, pu√≤ **migliorare nel tempo attraverso l‚Äôapprendimento**, diventando progressivamente pi√π razionale e adattivo.

## DIVERSI TIPI DI AGENTE
- studiare le funzioni degli agenti!
- AGENTE BASATO SU TABELLA
	- AGENTE REATTIVO SEMPLICE, DI CUI UN ESEMPIO AGENTE BASATO SU TABELLA?
	- IL PUZZO DEL WUMPUS
- AGENTI BASATI SU MODELLO 
	- molto piu complessi, non scrivi solo una tabella con match della regola e match condizionale
	- devo avere la memorizzazione del modello(ovvero, prendere i dettagli essenziali di un certo oggetto e codificarli in dati comprensibili)
	- lo scopo viene definito dall'azione, devi fare l'azione e basta
- AGENTE CON OBIETTIVO
	- un agente ancora pi√∫ complesso ragiona ponendosi degli obiettivi
	- un goal non e per forza la soluzione migliore possibile ma cio che ci direziona verso una soluzione valida e accettabile
- utility e il goal?
	- utility e una autovalutazione dell'agente
ENUMERATI E NON VALUTATI
- AGENTI CON VALUTAZIONE DI UTILIT√Ä
	- valutazione da parte dell'ambiente
- AGENTI CHE APPRENDONO
	- dentro performance element abbiamo state world and utility
	- il performance element quando lavora non si addestra subito, bensi una volta accumulati gli addestramenti viene interrotto il performance element e viene sostituito da una nuova versione addestrata dai feedback ricevuti
		- ambiente simulato a volte usato nel batch learning
### IMPLICAZIONI COMPUTAZIONALI
- rappresentazioni
- funzioni principale degli agenti
- sborra
## TIPI DI RAPPRESENTAZIONE
- ATOMICA
- FATTORIZZATAf
- STRUTTURATA
## Pattern linguistici via machine learning con encoder e decoders per NL
- meccanismo di encoding che ci porta ad avere per ogni d appartenente a D d freccia sopra appartenente a R con 256 che fa encoding e cardinalita di D circa 250k
- con una certa probabilita abbiamo il decoding in teoria
- si chiamano LANGUAGE MODEL perche forniscono un modello stocastico che predice la transizione successiva ovvero la parola che va detta dopo
### DESIDERATA DI UN AGENTE
