{"ALTRO/COSA-FARE-SE-TI-SENTI-IL-CERVELLO-ANNEBBIATO":{"slug":"ALTRO/COSA-FARE-SE-TI-SENTI-IL-CERVELLO-ANNEBBIATO","filePath":"ALTRO/COSA FARE SE TI SENTI IL CERVELLO ANNEBBIATO.md","title":"COSA FARE SE TI SENTI IL CERVELLO ANNEBBIATO","links":[],"tags":[],"content":"Sensazioni come quella di ‚Äúnebbia mentale‚Äù, difficolt√† di concentrazione o lentezza nel ragionamento possono essere collegate a postura, respirazione superficiale, mancanza di movimento e stress. Ti propongo una routine quotidiana semplice di 10-15 minuti che combina:\n\n\nStretching posturale\n\n\nMovimenti di mobilit√† spinale\n\n\nTecniche di respirazione profonda\n\n\nAttivazione cerebrale e focus\n\n\nüîÅ Routine consigliata (10-15 minuti totali)\n\nüßç‚Äç‚ôÇÔ∏è 1. Reset posturale in piedi (1-2 min)\nObiettivo: rilasciare tensioni e ritrovare l‚Äôallineamento naturale.\n\n\nIn piedi, piedi larghi quanto le anche.\n\n\nGinocchia morbide, spalle rilassate.\n\n\nInspira profondamente, porta le braccia in alto.\n\n\nEspira e lascia scendere le braccia, come se lasciassi andare un peso.\n\n\nRipeti 5-6 volte.\n\n\n\nüßò‚Äç‚ôÇÔ∏è 2. Stretching per la colonna vertebrale (4 min)\nA. Gatto‚Äìmucca (1 min)\nIn quadrupedia (mani sotto spalle, ginocchia sotto fianchi):\n\n\nInspira, inarca la schiena e solleva il mento (mucca).\n\n\nEspira, incurva la schiena e guarda verso l‚Äôombelico (gatto).\nRipeti per 1 minuto.\n\n\nB. Torsioni da seduto (1 min)\nSeduto a gambe incrociate o su una sedia:\n\n\nRuota il busto verso destra appoggiando la mano sinistra sul ginocchio destro e la destra dietro la schiena.\n\n\nMantieni 30 secondi e cambia lato.\n\n\nC. Stretching del collo e trapezi (2 min)\n\n\nInclina la testa lateralmente, spalla opposta ben gi√π (30 sec per lato).\n\n\nRotazioni lente del collo, senza forzare (1 min totale).\n\n\n\nüß† 3. Respirazione ossigenante (3 min)\nTecnica 4-7-8 semplificata:\n\n\nInspira dal naso per 4 secondi.\n\n\nTrattieni 2-3 secondi (se ti √® comodo).\n\n\nEspira lentamente dalla bocca per 6-8 secondi. Fai 6 cicli.\n‚ö†Ô∏è Questa respirazione attiva il parasimpatico e aumenta l‚Äôossigenazione cerebrale.\n\n\n\nüß†üí° 4. ‚ÄúBrain activation‚Äù (3-4 min)\nA. Tapotement craniale (1 min)\nCon le punte delle dita, tamburella delicatamente tutta la testa, stimolando la circolazione.\nB. Cross crawl (2 min)\nDa in piedi:\n\n\nTocca il ginocchio sinistro con la mano destra sollevandolo.\n\n\nPoi tocca il ginocchio destro con la mano sinistra.\n\n\nAlterna, come una marcia ritmica. Attiva entrambi gli emisferi cerebrali.\n\n\nC. Sguardo alternato (30 sec)\n\n\nSenza muovere la testa, guarda alternativamente a destra e sinistra.\n\n\nPoi in alto e in basso.\n\n\nAiuta l‚Äôequilibrio visivo e neurologico.\n\n\n\n‚úÖ Suggerimenti extra:\n\n\nFallo al mattino o prima di studiare.\n\n\nAggiungi pause brevi ogni ora per ripetere solo respirazione e stretching del collo.\n\n\nEvita di stare curvo: usa un supporto lombare o stai seduto sul bordo della sedia per mantenere la colonna attiva.\n\n\nSe uno ha poco tempo\nSappi che in realt√† c‚Äô√® sempre tempo per tutto ma questa potrebbe essere una lista ‚Äúridotta‚Äù con gli esercizi essenziali\n‚ö°Ô∏è Mini-routine da 2-3 minuti (versione ‚Äúveloce ma potente‚Äù)\n‚è±Ô∏è 1. Gatto-Mucca (1 minuto)\nMobilit√† spinale rapida = scarichi tensioni su schiena e cervicale.\n\nIn quadrupedia, 6-10 ripetizioni lente e ampie.\n\n‚è±Ô∏è 2. Stretching del collo (1 minuto)\nScioglie subito le tensioni che impastano la testa e la concentrazione.\n\nInclina la testa a destra, mantieni 15-20 sec, poi sinistra.\nRuota lentamente il capo da un lato all‚Äôaltro per 20-30 sec.\n\n‚è±Ô∏è 3. Respirazione 4-7-8 semplificata (1 minuto)\nCalma il sistema nervoso e ossigena rapidamente il cervello.\n\n4 secondi inspiro ‚Äì 2-3 secondi pausa ‚Äì 6-8 secondi espiro.\nFai 4 cicli.\n\n\nüöÄ Extra (facoltativi ma top, se hai 30 sec in pi√π):\n\n\nCross Crawl (30 sec): attiva emisferi cerebrali e migliora il focus.\n\n\nTapotement craniale (30 sec): stimola circolazione e ‚Äúsveglia‚Äù la mente.****\n\n"},"ALTRO/IDEA-RICETTE":{"slug":"ALTRO/IDEA-RICETTE","filePath":"ALTRO/IDEA RICETTE.md","title":"IDEA RICETTE","links":[],"tags":[],"content":"focaccia odio amore\nyoutube.com/shorts/ZRY436p2-14\nCosa vi servir√†:\n400g farina Manitoba con almeno 12g proteine (io ho usato la marca Caputo)\n280g acqua a temperatura ambiente / leggermente tiepida\n2g lievito di birra essiccato (o 6g lievito fresco in panetto)\n20g olio evo\n8g sale fino per stendere e decorare: olio, sale grosso e rosmarino a piacere"},"ALTRO/LISTA/ATTRAZZIONI-DISNEYLAND-TAGLIATE":{"slug":"ALTRO/LISTA/ATTRAZZIONI-DISNEYLAND-TAGLIATE","filePath":"ALTRO/LISTA/ATTRAZZIONI DISNEYLAND TAGLIATE.md","title":"ATTRAZZIONI DISNEYLAND TAGLIATE","links":[],"tags":[],"content":"Castello di Aurora\nwww.disneylandparis.com/it-it/attrazioni/parco-disneyland/sleeping-beauty-castle/\nTopolino e la sua Orchestra FilarMagica\nwww.disneylandparis.com/it-it/attrazioni/parco-disneyland/discoveryland-theatre/\nAlice‚Äôs Curious Labyrinth\nwww.disneylandparis.com/it-it/attrazioni/parco-disneyland/alices-curious-labyrinth/\nAutopia, presentato da Avis\nwww.disneylandparis.com/it-it/attrazioni/parco-disneyland/autopia/\nBuzz Lightyear Laser Blast\nwww.disneylandparis.com/it-it/attrazioni/parco-disneyland/buzz-lightyear-laser-blast/\nPirates of the Caribbean\nwww.disneylandparis.com/it-it/attrazioni/parco-disneyland/pirates-of-the-caribbean/\nIt‚Äôs a small world\nwww.disneylandparis.com/it-it/attrazioni/parco-disneyland/its-a-small-world/\nStar Wars Hyperspace Mountain\nwww.disneylandparis.com/it-it/attrazioni/parco-disneyland/hyper-space-mountain/\nStar Tours: l‚ÄôAvventura continua\nwww.disneylandparis.com/it-it/attrazioni/parco-disneyland/star-tours-the-aventures-continue/\nDumbo the Flying Elephant\nwww.disneylandparis.com/it-it/attrazioni/parco-disneyland/dumbo-the-flying-elephant/\nPeter Pan‚Äôs Flight\nwww.disneylandparis.com/it-it/attrazioni/parco-disneyland/peter-pans-flight/\nDiscovery Arcade\nwww.disneylandparis.com/it-it/attrazioni/parco-disneyland/discovery-arcade/\nCasey Jr. ‚Äì le Petit Train du Cirque\nwww.disneylandparis.com/it-it/attrazioni/parco-disneyland/casey-jr-le-petit-train-du-cirque/\nBlanche-Neige et les Sept Nains¬Æ\nwww.disneylandparis.com/it-it/attrazioni/parco-disneyland/blanche-neige-et-les-sept-nains/\nLe Passage Enchant√© d‚ÄôAladdin\nwww.disneylandparis.com/it-it/attrazioni/parco-disneyland/le-passage-enchante-daladdin/\nSTUDIOS\nFrozen: Un Invito Musicale\nwww.disneylandparis.com/it-it/intrattenimento/parco-walt-disney-studios/animation-celebration-frozen-un-invito-musicale/\nMomento musicale con Minnie\nwww.disneylandparis.com/it-it/intrattenimento/parco-walt-disney-studios/minnie-musical-moment/\nRatatouille : L‚ÄôAventure Totalement Toqu√©e de R√©my‚Äã ‚Äã\nwww.disneylandparis.com/it-it/attrazioni/parco-walt-disney-studios/ratatouille-the-adventure/\nCars ROAD TRIP\nwww.disneylandparis.com/it-it/attrazioni/parco-walt-disney-studios/cars-road-trip/\nLes Tapis Volants - Flying Carpets Over Agrabah¬Æ\nwww.disneylandparis.com/it-it/attrazioni/parco-walt-disney-studios/flying-carpets-over-agrabah/\nCars Quatre Roues Rallye\nwww.disneylandparis.com/it-it/attrazioni/parco-walt-disney-studios/cars-quatre-roues-rallye/"},"ALTRO/LISTA/FILM-E-SERIE-DA-FINIRE":{"slug":"ALTRO/LISTA/FILM-E-SERIE-DA-FINIRE","filePath":"ALTRO/LISTA/FILM E SERIE DA FINIRE.md","title":"FILM E SERIE DA FINIRE","links":["ALTRO/LISTA/FILM","ALTRO/LISTA/GIOCHI","ALTRO/LISTA/SERIE-TV"],"tags":[],"content":"FILM\nGIOCHI\nSERIE-TV"},"ALTRO/LISTA/FILM":{"slug":"ALTRO/LISTA/FILM","filePath":"ALTRO/LISTA/FILM.md","title":"FILM","links":[],"tags":[],"content":"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTitoloImmagineStar WarsWhiplash"},"ALTRO/LISTA/GIOCHI":{"slug":"ALTRO/LISTA/GIOCHI","filePath":"ALTRO/LISTA/GIOCHI.md","title":"GIOCHI","links":[],"tags":[],"content":"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHalo: The Master Chief CollectionIndiana Jones and the Great CircleSplit FictionGod of WarCyberpunk DLCKakarotGhost of TsushimaOutlawsGTA IVLego Star WarsHigh on life"},"ALTRO/LISTA/PROBABILIT√Ä":{"slug":"ALTRO/LISTA/PROBABILIT√Ä","filePath":"ALTRO/LISTA/PROBABILIT√Ä.md","title":"PROBABILIT√Ä","links":[],"tags":[],"content":"invia i primi due esercizi con questo prompt e allegando il pdf\nSei uno studente universitario svolgi il seguente esercizio in modo completo, fornendo tutti i passaggi necessari per arrivare alla soluzione. Per ogni passaggio, spiega brevemente cosa si sta facendo e perch√©. Se si tratta di un calcolo complesso, suddividi ulteriormente i passaggi per rendere tutto pi√π comprensibile e lascia i numeri in frazioni senza scrivere con la , . Inoltre  fallo basandoti su questo pdf di soluzioni degli scorsi esami forniti dall‚Äôinsegnante\nper l‚Äôesercizio 4 D7 invia questo\nSei uno studente universitario svolgi il seguente esercizio in modo completo, fornendo tutti i passaggi necessari per arrivare alla soluzione. Per ogni passaggio, spiega brevemente cosa si sta facendo e perch√©. Se si tratta di un calcolo complesso, suddividi ulteriormente i passaggi per rendere tutto pi√π comprensibile e lascia i numeri in frazioni senza scrivere con la , . Inoltre fallo basandoti su questo pdf di soluzioni degli scorsi esami forniti dall‚Äôinsegnante, contando che l‚Äôinsegnante di solito lo risolve con un integrale questo esercizio\nper gli altri usa i prompt di prima"},"ALTRO/LISTA/SERIE-TV":{"slug":"ALTRO/LISTA/SERIE-TV","filePath":"ALTRO/LISTA/SERIE-TV.md","title":"SERIE-TV","links":[],"tags":[],"content":"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTitoloImmagineBreaking BadThe Big Bang TheoryMr. RobotIl Signore degli AnelliThe Last of Us"},"ALTRO/LISTA/parigi-itinerario":{"slug":"ALTRO/LISTA/parigi-itinerario","filePath":"ALTRO/LISTA/parigi itinerario.md","title":"parigi itinerario","links":[],"tags":[],"content":"giorno 1\n\narrivo per le 9:10\nmetro ‚Üí hotel 10:30\nsistemiamo le cose bla bla bla\neiffel towers\narco di trionfo\n\n\ngiorno 2\n\npiazza bastiglia\nnotre dame\nsaint chappelle\nmuseo louvre\ncentre pompidu\ngarnier capelli palazzo\n\n\ngiorno 3 disneyland paris üè∞üê≠üé†üéÜ‚ú®\napre alle ore 9:30\nchiude alle 21\n\n\n                  \n                  controllare se vale la pena andare a entrambi i parchi \n                  \n                \n\ngiorno 4\n\nzona montre matre\n\nbasilica\ngiardini\n\n\ngalleria la fayette\nmuro di ti amo\nmulin rouge (da fuori ovviamente)\nsacro cuore\nmuseo dorsay\ntorre eiffel buietto\n\ngiorno 5\n\ncatacombe parigi\niniziamo a partire alle 14(anche prima)\nvolo alle 16:10\n"},"ALTRO/ONE-PIECE-EPISODI":{"slug":"ALTRO/ONE-PIECE-EPISODI","filePath":"ALTRO/ONE PIECE EPISODI.md","title":"ONE PIECE EPISODI","links":[],"tags":[],"content":"\nLISTA DI EPISODI DI ONE PIECE EPISODI-CAPITOLO\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n#TitleCorresponding  Chapters1I‚Äôm Luffy! The Man Who Will Become the Pirate King!22Enter The Great Swordsman! Pirate Hunter Roronoa Zoro!3 | 4 | 53Morgan vs. Luffy! Who‚Äôs This Mysterious Beautiful Young Girl?5 | 6 | 74Luffy‚Äôs Past! The Red-Haired Shanks Appears!1 | 85Fear, Mysterious Power! Pirate Clown Captain Buggy!8 | 9 | 10 | 116Desperate Situation! Beast Tamer Mohji vs. Luffy!11 | 12 | 13 | 14 | 157Grand Duel! Zoro the Swordsman vs. Cabaji the Acrobat!15 | 16 | 17 | 188Who Will Win? Showdown Between the True Powers of the Devil Fruit!19 | 20 | 219Honorable Liar? Captain Usopp23 | 2410The World‚Äôs Strongest Weirdo! Jango the Hypnotist!24 | 25 | 2611Revealing the Conspiracy! The Pirate Caretaker, Captain Kuro!26 | 2712Battle! The Black Cat Pirate Crew. Battle on the Slope!28 | 29 | 3013The Terrifying Duo! Nyaban Brothers vs. Zoro30 | 31 | 3214Luffy‚Äôs Revival! Kaya-ojousama‚Äôs Life and Death Confrontation33 | 3415Defeat Kuro! Usopp‚Äôs Tear-filled Determination!35 | 36 | 3716Protect Kaya! Usopp Pirate Gang Takes Action!38 | 3917Completely Infuriated! Kuro vs. Luffy, Final Battle!39 | 40 | 4118You Are a Special Animal! Gaimon and His Bizarre Friends22 | 4219The Past of the Three Swords! The Promise Between Zoro and Kuina!5 | 4220The Famous Cook! Sanji of the Floating Restaurant42 | 4321An Unexpected Guest! Sanji‚Äôs Food and Gin‚Äôs Grace44 | 4522The Greatest Pirate Fleet: Captain Don Krieg46 | 4723Protect Baratie! The Great Pirate: Zeff the Red Leg48 | 4924Hawk Eyes Mihawk! Swordsman Zoro Falls into the Sea!50 | 51 | 5225The Emerge of the Superb Kicking Skill: Sanji vs. the Iron Wall Pearl53 | 54 | 5526Zeff and Sanji‚Äôs Dream: The Sea of Dreams - All Blue56 | 57 | 58 | 5927The Coldhearted Devil-man: Gin, The Pirate Fleet Battle Commander59 | 60 | 61 | 6228I Won‚Äôt Die! Conclusion: Luffy vs. Krieg62 | 63 | 6429Outcome of a Deadly Battle! The Spear Inside!65 | 6630Departure! Sea Chef and Luffy Travel Together!67 | 6831The Most Wicked Man of East Blue, Fishman Pirate Arlong69 | 70 | 7132The Witch of Cocoyashi Village, Arlong‚Äôs Female Officer70 | 71 | 72 | 7333Usopp‚Äôs Death?! Luffy - Yet To Land?73 | 74 | 7534Reunited! Usopp Tells Nami‚Äôs True Story75 | 76 | 7735The Hidden Past! Female Fighter Bellemere!77 | 7836Survive! The Mother Bellemere and Nami‚Äôs Family!78 | 79 | 8037Luffy Stands Up! End of a Broken Promise!80 | 8138Luffy in Trouble! Fishmen vs. Luffy Pirates!82 | 83 | 8439Luffy Drowning! Zoro vs. Octopus Hatchan!84 | 85 | 8640Proud, Tall Warriors! Dramatic Battle of Sanji and Usopp!86 | 87 | 8841Luffy‚Äôs Best! Nami‚Äôs Courage and the Straw Hat88 | 89 | 9042Bursting Out! Fishman Arlong, Fearsome Attack From The Sea!90 | 91 | 9243The End of the Fishman Empire! Nami is my Friend!92 | 93 | 9444Setting off with a Smile! Farewell my Hometown, Cocoyashi Village!9545Bounty! Straw Hat Luffy Becomes World Famous!9646Following the Straw Hat! Little Buggy‚Äôs Big Adventure35 | 37 | 39 | 40 | 42 | 43 | 46 | 47 | 48 | 50 | 51 | 53 | 5447You‚Äôve Been Waiting For It! The Return of Captain Buggy!36 | 55 | 57 | 58 | 59 | 60 | 62 | 63 | 65 | 66 | 67 | 68 | 71 | 72 | 73 | 74 | 7548The Town of the Beginning and the End - Arrival at Loguetown96 | 97 | 9849Sandai Kitetsu and Yubashiri! Zoro‚Äôs New Swords, and the Female Sergeant Major9750Usopp vs. Daddy The Father! Showdown at High Noon!Filler51A Burning Culinary Battle? Sanji vs. The Gorgeous ChefFiller52Buggy‚Äôs Revenge! The Man who Smiles at the Execution Platform!98 | 9953The Legend Has Begun! Head to the Grand Line10054Foreboding of a New Adventure! The Puzzling Girl, Apis10155The Holy Beast! Apis‚Äô Secret and the Legendary Island10156Erik‚Äôs Raid! Great Escape from Gunkan Island!Filler57Lone Island in a Distant Sea! The Legendary Lost IslandFiller58Duel in the Ruins! Strained Zoro vs. ErikFiller59Luffy, Completely Surrounded! Admiral Nelson‚Äôs Secret PlanFiller60Those Who Soar in the Open Skies! Revival of the 1000 Year LegendFiller61Angry Finale! Cross the Red Line!10162The First Obstacle? Giant Whale Laboon Appears102 | 10363A Man‚Äôs Promise, Luffy and the Whale Vow to Meet Again103 | 104 | 10564A Pirate-Loving Town? Arrival at Whiskey Peak106 | 10765Exploding Sant≈çry≈´! Zoro vs. Baroque Works!107 | 108 | 109 | 11066A Serious Fight! Luffy vs. Zoro: the Baffling Duel!110 | 111 | 11267Deliver Princess Vivi! Luffy Pirates Depart113 | 11468Try Hard, Koby! Diary of Koby-Meppo‚Äôs Marine Struggles83 | 85 | 87 | 93 | 95 | 99 | 101 | 102 | 104 | 106 | 108 | 110 | 112 | 11369Koby-Meppo‚Äôs Determination! Vice Admiral Garp‚Äôs Fatherly Pride114 | 116 | 118 | 11970Prehistoric Island! The Shadow Lurking in Little Garden!115 | 116 | 11771Humongous Battle! The Giants Dorry and Brogy!116 | 11872Luffy‚Äôs Anger! A Dirty Trick in a Sacred Battle117 | 118 | 11973Brogy Wails in Victory! Elbaf‚Äôs Judgement119 | 12074The Devil‚Äôs Candle! Tears of Regret and Tears of Anger121 | 12275Luffy Attacked by Magic! Colors Trap123 | 12476Critical Counterattack! Usopp‚Äôs Quick Wit and Kaenboshi!124 | 125 | 12677Farewell to the Giants‚Äô Island! On to Alabasta127 | 128 | 12978Nami is Sick? Beyond the Snow that Falls on the Ocean!129 | 130 | 13179Ambush! The Bliking and Wapol the Blik128 | 131 | 13280A Doctorless Island? Adventure in the Country Without a Name!132 | 133 | 13481Ya Happy? The Doctor who is Called a Witch!134 | 135 | 13682Dalton‚Äôs Resolve! Wapol‚Äôs Forces Land136 | 137 | 13883Island that Lives in Snow! Ascend The Drum Rockies!138 | 13984The Blue-Nosed Reindeer! Chopper‚Äôs Secret139 | 14085Dream of the Outcasts! The Quack Doctor Hiluluk140 | 141 | 142 | 14386Hiluluk‚Äôs Cherry Blossoms and Inherited Will141 | 143 | 144 | 14587Against Wapol‚Äôs Army Corps! The Abilities of the Baku Baku no Mi!145 | 146 | 147 | 14888Zoan Type Devil‚Äôs Fruit! Chopper‚Äôs Seven-Level Transformation147 | 148 | 149 | 15089When the Kingdom‚Äôs Rule is Over! The Flag of Conviction Lasts Forever150 | 151 | 15290Hiluluk‚Äôs Cherry Blossoms! Miracle of the Drum Rockies152 | 15391Farewell, Drum Island! I‚Äôm Going Out to Sea!142 | 154 | 15592The Hero of Alabasta and the Ballerina on Deck155 | 156 | 15793Coming to the Desert Kingdom! The Rain-Calling Powder and the Rebel Army15894Reunion of the Powerful! His Name is Fire Fist Ace157 | 15895Ace and Luffy! Warm Memories and Brotherly Bonds15996The Green City, Erumalu and the Kung Fu Dugongs159 | 160 | 16197Adventure in the Country of Sand! The Demons that Live in the Scorching Earth16298Here Come the Desert Pirates! The Men who Live Free16299Spirit of the Fakes! Heart of the Rebel Army, KamyuFiller100Rebel Warrior Kohza! The Dream Sworn to Vivi!163 | 164101Heat Haze Duel! Ace vs. Scorpion Man159102Ruins and Lost Ones! Vivi, Comrades, and the Shape of a CountryFiller103At Spiders Cafe - The Enemy Ringleaders Meet at 8 o‚Äôclock160 | 161 | 162 | 163 | 164 | 165104Luffy vs. Vivi! A Tearful Vow for Comrades165 | 166105The Alabasta War Front! City of Dreams, Rainbase167 | 168106Trap in a Desperate Situation! Breaking Into Rain Dinners169 | 170107Operation Utopia Commences! The Wave of Rebellion Begins to Move171 | 172108The Fearsome Bananawani and Mr. Prince172 | 173 | 174109The Key to Turning the Tide and a Great Escape! Doru Doru Ball!175 | 176110Merciless Fight to the Death! Luffy vs. Crocodile176 | 177 | 178111The Miracle Sprint! Alabasta the Animal Land179 | 180112Rebel Army vs. Royal Army! The Battle will be in Alubarna!180 | 181 | 182 | 183113Alubarna is Crying! Fierce Fight of Captain Carue!182 | 183 | 184114Swear on Your Crewmate‚Äôs Dream! Battle at Molehill 4th Avenue184 | 185 | 186115Today‚Äôs Grand Performance! Mane Mane Montage!186 | 187 | 188116Transforming Into Nami! Bon Kurei‚Äôs Hard-Hitting Ballet Kenpo188 | 189 | 190117Nami‚Äôs Whirlwind Warning! Clima Tact Explosion190 | 191 | 192118Secret of the Royal Family! The Ancient Weapon, Pluton192 | 193119Essence of a Mighty Sword! The Power to Cut Steel and the Breath of All Things194 | 195120The Battle is Over! Kohza Flies the White Flag196 | 197121Vivi‚Äôs Voice Goes Unheard! A Hero Descends!198 | 199122Sand Crocodile and Water Luffy! Death Match: Round 2200 | 201123Smells Like Croc! Run to the Tomb of the Royal Family, Luffy!202 | 203124The Nightmare Draws Near! Secret Base of the Suna Suna Clan204 | 205125Magnificent Wings! My Name is Pell, Guardian Spirit of the Kingdom206 | 207 | 208126I Will Surpass You! Rain Falls on Alabasta!208 | 209 | 210127A Farewell to Arms! Pirates and a Little Justice211 | 212128The Pirates‚Äô Banquet and Operation Escape Alabasta!213 | 214129Everything Began that Day! Vivi Tells of her Adventures!215 | 216130Beware her Scent! The Seventh One is Nico Robin!217 | 218131The First Patient! Anecdote of the Rumble BallFiller132The Navigator‚Äôs Mutiny! For an Unwavering Dream!Filler133Inherited Recipe! Sanji the Curry Iron ChefFiller134I‚Äôll Make it Bloom! Manly Usopp‚Äôs Eight-Shaku BallFiller135Infamous Pirate Hunter! The Wandering Swordsman, Zoro!Filler136Zenny Lives on Goat Island and There‚Äôs a Pirate Ship on his Mountain!Filler137How‚Äôs That for Profit? Money Lender Zenny‚Äôs Ambition!Filler138Where the Island‚Äôs Treasure Lies! Zenny Pirates Full Charge!Filler139Legend of the Rainbow Mist! Ruluka Island and the Old Man Henzo!Filler140Inhabitants of Neverland! The Pumpkin Pirates!Filler141A Longing for Home! The Inescapable Pirate Graveyard!Filler142Frantic Struggle! Wetton‚Äôs Plans and the Rainbow Tower!Filler143And Then the Legend Begins! To the End of the Rainbow!218144The Log is Taken! Salvage King, Masira!218 | 219 | 220145Monsters Appear! Don‚Äôt Touch the Whitebeard Pirates221146Stop Dreaming! The City of Ridicule, Mock Town!222 | 223 | 224147The Pirate‚Äôs Summit! The Man who Talks of Dreams and the King of Underwater Exploration225 | 226148The Legendary Family! ‚ÄòLiar Noland‚Äô227 | 228149Hard Turn to the Clouds! Find the Southbird!229 | 230150Dreams Don‚Äôt Come True!? Bellamy vs. The Saruyama Alliance231 | 232151The Hundred-Million Man! The World‚Äôs Highest Authority and the Pirate Blackbeard232 | 233 | 234152Sail into the Sky! Ride the Knock-Up Stream235 | 236153This is the Sea of the Sky! The Knight of the Sky and Heaven‚Äôs Gate237 | 238154Godland Skypiea! The Angels Of the Cloud Beach239 | 240155Sacred Ground! The Island Where God Resides and Heaven‚Äôs Judgement!241156Criminals Already!? Skypiea‚Äôs Upholders of the Law242157Can we Escape!? God‚Äôs Ordeals are Set in Motion!243158Trap on Lovely Street! Almighty God Enel244159Go Forth, Little Crow! To the Sacrificial Altar245160Survival Rate: 10%! Priest Satori with the Power of Mantra!246 | 247161Peril of the Ordeal of Balls! Fight to the Death in the Lost Forest247162Chopper‚Äôs in Danger! Former God vs. Priest Shura248 | 249163Ever Mysterious! Ordeal of String and Ordeal of Love!?249 | 250164Light the Fire of Shandia! Wiper the Warrior251165Floating Land of Gold, Jaya! To God‚Äôs Shrine!252166Eve of Gold Festival! Feelings Toward ‚ÄòVearth‚Äô!253167God Enel Appears!! Aubade to the Survivors254168The Python Strikes! The Survival Game Begins255 | 256169The Life-Threatening Reject! War Demon Wiper‚Äôs Resolve256 | 257 | 258170Fierce Sky Battle! Pirate Zoro vs. Fighter Braham258 | 259171Howling Burn Bazooka!! Luffy vs. War Demon Wiper260 | 261172Ordeal of Swamp! Chopper vs. Priest Gedatsu!!261 | 262 | 263173The Invincible Ability! Enel‚Äôs True Nature Revealed263 | 264174The Vanished City! The Magnificent Ruins of Shandora!!263 | 264 | 265 | 266 | 268 | 272175Chance of Survival: 0%!! Chopper vs. Priest Ohm266 | 267176Climb Giant Jack!! Showdown in the Upper Ruins268 | 15 | 269177Ultimate Test of the Ordeal of Iron! The White-Barbed Death Match!!270 | 271178Gushing Blade Attack! Zoro vs. Priest Ohm!!271 | 272179The Upper Ruins Crumble! The Quintet Finale!!272 | 273180Battle in the Ancient Ruins! God Enel‚Äôs Desire!!274 | 275181Ambitions of Fairy Vearth - The Ark, Maxim!!275 | 276 | 277182Finally Clashing! Pirate Luffy vs. God Enel!!276 | 277 | 278 | 279183Maxim Rises! The Start of Deathpiea!!280 | 281184Luffy‚Äôs Fall! God‚Äôs Judgement and Nami‚Äôs Desire!!282 | 283185Two People Awaken! A Rescue in Front of Burning Love!!283 | 284186Capriccio to Destruction! The Impending Doom of Sky Island!!284 | 285 | 286187Guidance from the Sound of a Bell! The Great Warrior and Tales of an Explorer286 | 287 | 288188Released from Disgrace! The Tears of the Great Warrior!!289 | 290 | 291189Eternal Friendship! The Bell of Oath Echoes Throughout the Giant Ocean!!291 | 292 | 293190The Destruction of Angel Island! Terror of The Descending Raigou!!294 | 295191Chop Down Giant Jack! The Last Hope of Escaping295 | 296 | 297192The Miracle in God‚Äôs Country! A Love Song Heard by Angels297 | 298193The War Draws to a Close! Ringing Far and Wide, the Proud Fantasia299 | 300194I Have Come Here! The Weaving of the Poneglyphs301195Now Heading Towards the Blue Sea!! Memories of an Interwoven Finale302 | 303196Emergency Official Announcement! Notorious Pirate Ship Infiltration!Filler197Sanji the Cook! Showing His Real Worth at the Marine Dining-room!Filler198Zoro‚Äôs imprisonment and Chopper‚Äôs Emergency Operation!Filler199The Search of the Approaching Marines! The Second Person Who Was Captured!Filler200Luffy and Sanji‚Äôs Desperate Decision! Large Rescue Maneuvers!Filler201Hot Blood Special Unit Participation! Bridge Offensive and Defensive Battle!Filler202Smash the Barricade! The Going Merry is Recovered!Filler203The Missing pirate Ship! 2nd Round Assault on the Fortress303204The Gold Recovery Plan and the Waver Recovery Plan!Filler205Catch Them All in One Net! Johnathan‚Äôs Secret Scheme!Filler206So Long, Marine Base! The Final Battle for FreedomFiller207Big Adventure in Long Ring Long Land303 | 304 | 305208The Foxy Pirate Crew and the Davy Back!305 | 306209Round 1! One Lap of the Donut Race306 | 307210Foxy the Silver Fox! A Violent Interference308 | 309211Round 2! Shoot into the Groggy Ring!310 | 311212Rapid-Fire Red Cards! Groggy Ring312 | 313213Round 3! Round and Round Roller Race!Filler214Burning Roller Race! Dash into the Final Round!313215The Screaming Speed Serve! Pirate Dodgeball!Filler216Final Match on the Edge! Dharma has Fallen!313217Captain Confrontation! The Last Fight: Combat!313 | 314218Full Power Noro Noro Beam vs. The Invulnerable Luffy315 | 316219Heroic Fierce Combat! The Fateful Last Battle317 | 318220You Lost Your Memory? It Was Taken? Who Are You?Filler221The Mysterious Boy With the Whistle and Robin‚Äôs Guess!Filler222Get Back Your Memories! Landing on the Island!Filler223Zoro Sharpens His Fangs! A Fight With a Wild Beast!Filler224The Memory Thief‚Äôs Final Counterattack Shows His True Nature!Filler225The Man of Pride! Foxy the Silver Fox303226The Nigh Invincible Man? And a Very Dangerous Man!318227Marine High Admiral Aokiji! The Threat of the Greatest Power319 | 320228Rubber and Ice One-On-One Fight! Luffy vs. Aokiji!320 | 321 | 322229Running Sea Train! The City of Water, Water 7322 | 323 | 324230The Adventure in the City of Water! Aim for the Giant Shipyard323 | 324 | 325231The Franky Family and Iceburg!325 | 326232Galley-La Company! The Magnificent Dock #1326 | 327233The Pirate Kidnapping Incident and the Pirate Ship Waits for Death!328 | 329234Rescuing a Crewmate! The Raid on the Franky House329 | 330 | 331235Quarrel in the Moonlight! The Pirate Ship Trembles in Sadness331 | 332236Luffy vs. Usopp! The Spirit of the Clashing Men332 | 333237The City of Water is Shaking! Iceburg was Targeted!334 | 335238Rubberman vs. Fire-Breathing Cyborg335 | 336 | 337239The Criminals are the Straw Hat Pirates? The Bodyguards of Water 7337 | 338 | 339240An Eternal Farewell? Nico Robin, The Woman Who Bears Darkness339 | 340241Catch Robin! The Determination of the Straw Hat Pirates340 | 341 | 342242The Signal is the Explosion! CP9 Starts to Move340 | 341 | 342243CP9 Unmasked! Their Shocking True Faces343 | 344 | 345244The Secret Bond! Franky and Iceburg346245Come Back, Robin! The Confrontation with CP9347 | 348246Destruction of the Straw Hat Pirates? The Terror of the Model Leopard!349 | 350247The Man who is Loved by his Ship! Usopp‚Äôs Tears!350 | 351 | 352248Franky‚Äôs Past! The Day the Sea Train Ran352 | 353 | 354249Spandam‚Äôs Conspiracy! The Day the Sea Train Shook353 | 355 | 356250The End of the Legendary Man! The Day the Sea Train Cried356 | 357 | 358251The Truth Behind the Betrayal! Robin‚Äôs Sorrowful Decision!358 | 359252The Steam Whistle Separates the Crew! The Sea Train Begins to Run360 | 361253Sanji Breaks In! The Sea Train Battle in the Storm!361 | 362254The Shout of Nami‚Äôs Soul! The Return of the Straw Hat!363 | 364 | 365255Another Sea Train! Rocket Man Sortie364 | 365256Rescue our Friends! The Oath that Links the Enemies358 | 366257Smash the Wave! Luffy and Zoro, The Strongest Combo!366 | 367258A Man of Mystery Appears!? His Name is Sogeking!368 | 369259Cook Confrontation! Sanji vs. Ramen Kenpo369 | 370260Duel on the Roof! Franky vs. Nero!370 | 371 | 372261Crash! Demon-Cutting Zoro vs. Ship-Cutting T-Bone!371 | 372 | 373262Robin Struggles! Sogeking‚Äôs Clever Scheme!!373 | 374263The Judiciary Island! The Full Picture of Enies Lobby!374 | 375264Operation Disembarkation Commences! The Straw Hat Crew Rushes In!375 | 376265Luffy Charges In! Great Decisive Battle on the Judiciary Island!!376 | 377 | 388266Battle with the Giants! Open the Second Door!378 | 379267The Means of Escaping is Opened! Fly through the Sky, Rocketman!379 | 380268Catch Up with Luffy! The Straw Hat Pirates‚Äô All-Out War381 | 382269Robin was Betrayed! The Expectations of the World Government!382 | 383270Give Robin Back! Luffy vs. Blueno!383 | 384271Don‚Äôt Stop! Raise the Signal Fire of a Counterattack!384 | 385272Luffy is in Sight! Gather at the Courthouse Plaza385 | 386 | 387273All for the Sake of Protecting My Friends! Gear Second in Motion387 | 388274Answer Us, Robin! The Outcries of the Straw Hat Crew!!389 | 390275Robin‚Äôs Past! The Girl who was Called a Demon!391 | 392276The Fated Parent and Child! The Mother‚Äôs Name is Olvia!393 | 394 | 395277Tragedy of Ohara! Fear of Buster Call!395 | 396 | 397278Say You Want to Live! We are Friends!!397 | 398279Jump Into the Falls! Luffy‚Äôs Feelings!!Filler280A Man‚Äôs Way of Life! Zoro‚Äôs Techniques, Usopp‚Äôs DreamFiller281Tears Which Weaved the Bond of Friendship! Nami‚Äôs World MapFiller282Separation Refines a Man! Sanji and ChopperFiller283All for my Friends‚Äô Sake! The Darkness Within Robin!Filler284The Blueprints Aren‚Äôt Passed! Franky‚Äôs Decision399 | 400285Retrieve the 5 Keys! The Straw Hat Crew vs. CP9400286Power of the Devil Fruit! Kaku and Jabra Transform401 | 402287Even if I Die, I Won‚Äôt Kick you! Sanji‚Äôs Manly Chivalry402 | 403288The Silent Owl‚Äôs Miscalculation! My Cola is the Water of Life403 | 404289Zoro‚Äôs New Technique Explodes! The Katana‚Äôs Name is Sogeking?405 | 406290Uncontrollable! Chopper‚Äôs Forbidden Rumble406 | 407291Boss Luffy Returns! A Dream or Reality Lottery TroubleFiller292The Great Mochimaki Race to the Castle! Conspiracy of the Red NoseFiller293Bubble User Kalifa! Nami Draws Near to the Soap‚Äôs Trap407 | 408294The Resounding Bad News! The Buster Call is Invoked4092955 Namis? Counterattack with the Mirage!410 | 411296Nami‚Äôs Determination! Shoot the Rampaging Chopper!411 | 412297Hunter Sanji Appears? Elegy to the Lying Wolf413 | 414298The Scorching Kick! Full Course of Sanji‚Äôs Footwork414 | 415 | 416299The Drawn Sword‚Äôs Fierce Attack! Zoro vs. Kaku Powerful Slash Showdown416 | 417300Zoro the Fierce God! The Incarnation of Asura Revealed by His Soul417 | 418301Spandam‚Äôs Shock! A Hero Stands on the Tower of Justice419 | 420302Robin‚Äôs Liberation! Luffy vs. Lucci: Peak of the Decisive Battle420303The Criminal is Boss Luffy? Chase the Vanished Great Sakura TreeFiller304If I Can‚Äôt Win, I Can‚Äôt Protect Anyone! Gear Third Activates421305The Terrifying Past! Dark Justice and Rob Lucci422306A Phantom Mermaid is Here? Within Fading Consciousness423 | 424307The Island Sinking in Gunfire! Franky‚Äôs Outcry of Regret424 | 425308Wait for Luffy! Fight to the Death on the Bridge of Hesitation!425 | 426309Feelings Put Into Fists! Luffy‚Äôs Full-Power Gatling426 | 427310A Friend Approaches from the Sea! The Straw Hat Crew‚Äôs Strongest Bonds428311Everyone Escapes! The Path to Victory is for the Pirates429312Thank You Merry! The Sea of Separation in the Snow430313The Disturbance of Peace! The Vice-Admiral with the Fist of Love431314The Strongest Family Lineage? Luffy‚Äôs Father Revealed!432315Its Name is The New World! The Whereabouts of the Great Grand Line!433316Shanks Moves! Ceremony to the Rampaging Age433 | 434 | 435317The Girl Searching for the Yagara! Great Investigation in the Water Metropolis!Filler318The Mother is Strong! Zoro‚Äôs Slapstick Housework HelpFiller319Sanji Crashes! The Mysterious Old Man and Intense Cooking435320Everyone‚Äôs Finally Wanted! The Crew of Over Six Hundred Million!358 | 435321The King of Beasts that will Cross the Ocean! The Dream Ship‚Äôs Magnificent Completion!436322Goodbye my Lovable Followers! Franky Departs437323Departure from the Water City! The Distinction of a Man, Usopp‚Äôs Duel438324Circling Bounties! The Hometowns Dance as the Ship Advances!439 | 440325The Most Evil Ability! Blackbeard‚Äôs Darkness Attacks Ace434 | 440 | 441326Mysterious Party of Pirates! The Sunny and a Dangerous Trap442327Sunny in a Pinch! Roar, Secret Superspeed MechaFiller328The Dream Sinking in the New World! The Pirate of Despair, PuzzleFiller329The Assassins Attack! The Great Battle Above the Ice BeginsFiller330The Hard Fights of the Straw Hat Crew! The Pirate Soul Banking it All on the Flag!Filler331Hot Full Throttle! The Twins‚Äô Magnetic Power Draws NearFiller332The Great Chaos Mansion! The Angry Don and the Imprisoned CrewFiller333The Phoenix Returns! The Dream of the Pirate Flag Sworn to a FriendFiller334The Super Final Atsu Atsu Battle! Luffy vs. the Scortching DonFiller335Waiting in the New World! Farewell to the Courageous PiratesFiller336Chopper Man Departs! Protect the TV Station by the ShoreFiller337Venture Into the Devil‚Äôs Sea! The Mysterious Skeleton Floating Through the Fog442338The Delight of Having Met People! The Gentleman Skeleton‚Äôs True Colors443339One Phenomenon After Another! Disembarking at Thriller Bark443 | 444340The Man Called a Genius! Hogback Appears!445 | 446341Nami in Big Trouble! The Zombie Mansion and the Invisible Man446 | 447342Mystery of the Zombies! Hogback‚Äôs Nightmarish Research Laboratory447 | 448 | 449343His Name is Moriah! Trap of the Great Shadow-Stealing Pirate448 | 449344Feast of the Zombie Song! The Bell of the Night Raid is a Sound of Darkness449 | 450345Filled with Animals!? Perona‚Äôs Wonder Garden451346Disappearing Straw Hat Crew! The Mysterious Swordsman Appears!452347Leftover Chivalry! The Traitorous Zombie who Protects Nami453348Coming from the Sky! That Man is the ‚ÄúHumming‚Äù Swordsman!454349Luffy in an Emergency! The Living Place of the Strongest Shadow!455350The Warrior Called a Demon!! The Time of Oars‚Äô Resurrection456351Awakening After 500 Years!! Oars Revives!!457352Conviction Strong Enough to Beg for One‚Äôs Life!! Brook Protects his Afro458353A Man‚Äôs Oath Never Dies!! To the Friend who Waits Under a Far-Away Sky458 | 459354We will Definitely Meet Again!! Brook and the Cape of the Promise459355Food, Nami and Shadows!! Luffy‚Äôs Angry Counterattack460356Usopp the Strongest? Leave the Negatives to Me461357Sudden Death of the General Zombies!! Oars in an Adventurous Mood!!462358Sanji, the Knight of Flames!! Kick Down the False Ceremony463 | 464359Perverted Connection? Sanji‚Äôs Stolen Dream463 | 464360Saving Hero! The Enemy is the Invincible Princess465361Perona‚Äôs Terror!! The U in Uso is the U in Usopp466362Slashes Dancing on the Roof! Finale - Zoro vs. Ryuma466 | 467363Chopper‚Äôs Rage!! Hogback‚Äôs Demonic Medical Practice468364Oars Roars!! Come Out Straw Hat Crew469365The Enemy is Luffy!! The Strongest Zombie vs. the Straw Hat Crew470366Defeat Absalom!! Nami‚Äôs Lightning Attack of Friendship!!471367One Down!! Sure Kill Straw Hat Docking?472368Soundless Invasion!! The Mysterious Visitor: Kuma the Tyrant473369Oars Plus Moriah - The Greatest Combination of Brains and Brawn474370A Secret Strategy to Turn the Tables - Nightmare Luffy Appears475 | 476371The Straw Hat Crew Annihilated - Full-Throttle Kage Kage Abilities476 | 477372The Battle for Superiority Starts! - Luffy vs. Luffy478 | 479373The Conclusion Arrives! - Deliver the Finishing Blow480 | 481374The Bodies Vanish! - The Morning Sun Pierces Through the Nightmare Island!481 | 482375The Endless Crisis! Orders to Obliterate the Straw Hat Crew483376Kuma‚Äôs Nikyu Nikyu Power That Deflect Everything484377My Crewmate‚Äôs Pain is My Pain, Zoro Fights Prepared to Die485378Promise on a Day Long Ago - The Pirate‚Äôs Song and a Tiny Whale486379Brook‚Äôs Past - Sad Farewell to the Cheerful Friend487380Bink‚Äôs Sake - The Song that Connects the Past and Present487 | 488381A New Crewmate! - The Musician ‚ÄúHumming Brook‚Äù489 | 490382Noro Noro Menace - Return of Foxy the Silver FoxFiller383The Great Treasure Contest! Collapse! Spa IslandFiller384Brook‚Äôs Hard Struggle - The Difficult Path to Becoming a True Crewmate?Filler385Arriving at Halfway Through the Grand Line! The Red Line490386Hatred of the Straw Hat Crew - Enter Iron Mask Duval490 | 491387The Fated Reunion! Save the Imprisoned Fishman492 | 493388Tragedy! The Truth of the Unmasked Duval493 | 494389Explosion! The Sunny‚Äôs Super Secret Weapon: Gaon Cannon494 | 495390Landing to Get to Fishman Island - The Sabaody Archipelago496391Tyranny! The Rulers of Sabaody, the Celestial Dragons497392New Rivals Gather! The 11 Supernovas498393The Target is Keimi!! The Kidnappers‚Äô Evil Draws Near499394Rescue Keimi - The Dark History of the Archipelago500395Time Limit - The Human Auction Begins501396The Exploding Fist! Destroy the Auction502397Huge Panic! Struggle in the Auction Hall503398Admiral Kizaru Moves! The Sabaody Archipelago in Chaos504399Break Through the Encirclement! Marines vs. Three Captains505 | 506400Roger and Rayleigh - The Pirate King and His Right Hand506 | 507401Impossible to Avoid!? Admiral Kizaru‚Äôs Speed of Light Kick!!507 | 508402Overwhelming! The Marine Combat Weapon Pacifista509 | 510403Another Strong Enemy Appears! Broadaxe-Wielding Sentomaru510 | 511404Admiral Kizaru‚Äôs Fierce Attack - The Straw Hat Crew‚Äôs Desperate Situation!511 | 512405Disappearing Crew - The Final Day of the Straw Hat Crew513406Special Historical Arc - Boss Luffy Appears AgainFiller407Special Historical Arc - Destroy! Thriller Company‚Äôs TrapFiller408Landing! No-Boys-Allowed Island Amazon Lily514409Hurry! Back to the Crew - Adventure on the Isle of Women515410Everyone‚Äôs Drunk on Love! Pirate Empress Hancock516411The Secret Hidden on Their Backs - Luffy Encounters the Snake Princess517412The Heartless Judgment! Marguerite Turned to Stone!!518413Luffy‚Äôs Hard Trial! The Power of the Snake Sisters‚Äô Haki!!519414Battle with Full-Powered Abilities!! Gomu Gomu vs. Hebi Hebi520415Hancock‚Äôs Confession - The Sisters‚Äô Disgusting Past521416Rescue Ace! The New Destination is the Great Prison522417Love is a Hurricane! Hancock in Love522 | 523418The Crewmates‚Äô Whereabouts - Weather Science and Karakuri Island523419The Crewmates‚Äô Whereabouts - The Island of Giant Birds and the Pink Paradise!523 | 524420The Crewmates‚Äô Whereabouts - The Bridge that Connects Islands and Man-Eating Plants524421The Crewmates‚Äô Whereabouts - The Negative Princess and the Devil King!524422A Life-threatening Break-in! The Underwater Prison Impel Down!525 | 526423Reunion in Hell!? The User of the Bara Bara No Mi!526424Break through Crimson Hell! Buggys great Uproar Plan527425The Prison‚Äôs strongest Man! Introduction of the Poison-Man Magellan528 | 530426Movie-connected Special: The ‚ÄòGold Lion‚Äôs‚Äô Ambition Moves ForwardFiller427Movie-connected Special: ‚ÄòLittle East Blue‚Äô is TargetedFiller428Movie-connected Special: The Amigo Pirate Crew‚Äôs Vicious AssaultFiller429Movie-connected Special: The Decisive Battle! Luffy vs. LargoFiller430The Imprisoned Royal Shichibukai! Jinbe, Knight of the Sea528 | 529431The Trap of Chief Guard Saldeath - Level 3 Starvation Hell530432The Liberated Swan! Reunion! Bon Kurei530 | 531433Chief Warden Magellan Moves - The Net to Trap Straw Hat Is Complete!532434Preparations for War! A Decisive Battle in Level 4 - Blazing Hell533435Magellan‚Äôs Strength! Bon Kurei Flees Before His Enemy533 | 534436The Fight Finished! Luffy‚Äôs Final Life Risking Attack535437Because He‚Äôs My Friend - Bon Kurei‚Äôs Do-or-Die Rescue535 | 536438Paradise in Hell - Impel Down Level 5.5536 | 537439Luffy‚Äôs Treatment Begins - Iva‚Äôs Miraculous Power!!537 | 538440Believe in Miracles! Bon Kurei Cheers From His Heart538 | 539441Luffy Revives! Iva-san‚Äôs Jailbreak Plan Begins!!539442Ace‚Äôs Convoy Starts - The Offense and Defense of the Lowest Level, Level 6!540443The Strongest Team is Formed - Shake Impel Down to it‚Äôs Core!540 | 541444Even More Chaos! Blackbeard Teach Invades541 | 542445A Dangerous Meeting! Blackbeard and Shiliew of the Rain542 | 543446His Spirit Won‚Äôt Break! Hannyabal Goes All Out543 | 544447The Jet Pistol of Rage - Luffy vs. Blackbeard544448Stop Magellan! Iva-san Unleashes His Secret Attack545449Magellan‚Äôs Clever Scheme! The Jailbreak Plan is Obstructed545 | 546450The Jailbreak Team Driven Into a Corner - Forbidden Move ‚ÄòVenom Demon‚Äô546 | 547451Cause the Last Miracle - Breaking Through the Gate of Justice548452The Destination is Marine Headquarters - The Ship Sets Out to Rescue Ace!549453The Crewmates‚Äô Whereabouts - Weatheria Report and Cyborg Animals555 | 556 | 548 | 549454The Crewmates‚Äô Whereabouts - Giant Bird Chicks and a Pink Showdown543 | 544 | 552 | 554455The Crewmates‚Äô Whereabouts - The Revolutionary Army and the Forest of Gluttony‚Äôs Trap!545 | 546 | 550 | 551456The Crewmates‚Äô Whereabouts - The Giant Gravestone and Panties of Gratitude557 | 558 | 559 | 560457Special Retrospective Before Marineford - The Siblings‚Äô Vow!Filler458Special Retrospective Before Marineford - Assemble! The Three AdmiralsFiller459The Time of the Decisive Battle Draws Near! The Marine‚Äôs Strongest Battle Formation is Ready!549 | 550 | 551460An Enormous Fleet Appears - Invasion! The Whitebeard Pirates551461The Beginning of the Battle! Ace and Whitebeard‚Äôs Past551 | 552462The Power to Destroy the World! The Gura Gura no Mi‚Äôs Ability552 | 553463Burn Everything to Ash! Admiral Akainu‚Äôs Power553 | 554464The Devil‚Äôs Descendant! Little Oars Jr. Dashes Off!554 | 555465Only the Winner is Justice - Put Into Motion! Sengoku‚Äôs Plan!556466The Straw Hat Team Arrives ‚Äì The Battlefield Grows More Intense557467I‚Äôll Save You Even If I Die - Luffy vs. The Marines, The Battle Starts558468Consecutive Battles! Devil Fruit User Army vs. Devil Fruit User Army559469Kuma Causes Disaster ‚Äì Iva-san‚Äôs Angry Attack560470Master Swordsman Mihawk - The Black Sword‚Äôs Slash Draws Near Luffy561471The Extermination Operation Begins - The Might of the Pacifista Army562472Akainu‚Äôs Plot! Whitebeard Entrapped563473The Encirclement Walls Activated! The Whitebeard Pirates Driven Into a Corner!!564474The Order to Perform the Execution is Given - Break Through the Encircling Wall!565475Rush Into the Final Phase! Whitebeard‚Äôs Maneuver to Turn the Tides566476Luffy‚Äôs Strength is Exhausted! All-Out War in the Oris Plaza!!567477Power that Reduces One‚Äôs Life - Tension Hormones Return568478For a Promise!!Luffy and Koby Clash!569479In Front of the Execution Platform! The Path to Ace is Opened!!570 | 571480The Path they Each Chose - Luffy vs. Garp!571481Ace Freed! Whitebeard‚Äôs Final Captain‚Äôs Order!572482The Power that Burns Even Fire - Akainu‚Äôs Ruthless Pursuit573483Searching for an Answer - Fire Fist Ace Dies on the Battlefield574484Marine Headquarters Collapses! Whitebeard‚Äôs Silent Rage!574 | 575 | 576485Settling the Score - Whitebeard vs. The Blackbeard Pirates576486The Start of the Show - Blackbeard‚Äôs Plot Revealed577487Akainu‚Äôs Tenacity! The Fist of Magma Attacks Luffy578488A Desperate Cry - Seconds of Valor that Change Destiny579489Enter Shanks! The Ultimate War Ends at Last580490Powerful Independent Rivals! The Beginning of the ‚ÄúNew Era‚Äù!581491Arrival at the Island of Women - Cruel Reality Tortures Luffy581 | 582492The Strongest Tag-Team! Luffy and Toriko‚Äôs Hard Struggle!Filler493Luffy and Ace - The Story of the Brothers‚Äô Meeting!582 | 583494Enter Sabo! The Boy From Grey Terminal583 | 584495I Won‚Äôt Run - Ace‚Äôs Desperate Rescue Operation584496Someday to the Sea! The Three Brat‚Äôs Sake Cups of Oath!585497Leaving the Dadan Family!? The Secret Base is Complete!585498Apprentice Luffy!? The Man who Fought the Pirate King!584 | 585499The Battle Against the Big Tiger! Who Will Be the Captain?!Filler500Stolen Freedom! The Nobles‚Äô Trap Draws Near the Three Brothers585 | 586501The Flames Are Lit - The Gray Terminal‚Äôs Crisis586 | 587502Where Is Freedom? The Boy‚Äôs Sad Departure587 | 588503I‚Äôm Counting On You! A Letter From a Brother!588 | 589504To Fulfill the Promise - Separate Departures!1 | 589505I Want to See Them! Luffy‚Äôs Tearful Scream590506The Straw Hat Crew Shocked! The Bad News is ReceivedFiller507Reunion with Dark King Rayleigh - It‚Äôs Time For Luffy‚Äôs Decision591508Back to the Captain - Jailbreak from Sky Island and the Incident on the Winter Island592509Contact! The Great Swordsman Mihawk - Zoro‚Äôs Struggle of Willpower592510Sanji‚Äôs Suffering - The Queen Returns to His Kingdom!591 | 593511An Unexpected Return! Luffy, to Marineford!594512Delivered to the Crew - The Big News Comes Through!593 | 594513The Pirates Move Out! The Earth Shattering New World595514Live Through Hell - Sanji‚Äôs Fight with Men at Stake595 | 596515I‚Äôll Get Stronger and Stronger! Zoro‚Äôs Vow to his Captain596 | 597516Luffy‚Äôs Training Begins. See You 2 Years later, At The Promised Place597517The New Chapter Begins. Regroup, Straw Hat Pirates!598518A Hair-Trigger! Luffy vs. Fake Luffy598 | 599519The Marines Move Out, Target the Straw Hat Crew!599 | 600520Massive Gathering, Threat of the Fake Straw Hats!600521The Battle Begins! The Results of Training!601522Everyone‚Äôs Reunited! Luffy Sets Sail for the New World!602523A Shocking Revelation - The Man Who Protected the Sunny!603 | 604524Undersea Struggle, The Demon of the Deep Appears!604 | 605525Disaster in the Deep Sea, The Straw Hat Crew Gets Lost!605 | 606526Undersea Volcanic Eruption! Sailing To Fishman Island606 | 607527Landing at Fishman Island, The Lovely Mermaids!607 | 608528Eruption of Excitement! Sanji‚Äôs Crisis of Life!609529Fishman Island Collapses?! Shirley‚Äôs Prediction!610530The King of Fishman Island, Sea God Neptune!611531Ryugu Palace! Led By The Shark That Was Saved!612532The Coward Crybaby! Hard-Shell Tower‚Äôs Mermaid Princess613533Emergency Situation! Ryuugu Palace Held Captive614534Ryuugu Palace Shaking! Shirahoshi and the Kidnapping614 | 615535Hody‚Äôs Attack! The Beginning of his Vengeful Plan!616536Decisive Battle at Ryugu Palace! Zoro vs. Hody617537Protect Shirahoshi! Decken‚Äôs Pursuit618538The Crew is Defeated!? Hody Controls Ryuugu Palace619539Revived Fate! Nami and the Fishman Pirates620540Hero of the Slave Liberation - Adventurer Tiger621 | 622541Kizaru Appears! A Trap Aimed at Tiger620 | 621 | 622542Team Formation! Save ChopperFiller543The Hero‚Äôs Last Moments! The Impact of Tiger‚Äôs Truth623544The Pirates Split - Jinbe vs. Arlong623 | 624545Fishman Island is Shaking! The Landing of a Celestial Dragon624 | 625546Unexpected Disaster! An Assassin‚Äôs Bullet Shuts the Future625 | 626547Back to the Present! Hody Begins to Move627548The Kingdom is Shaking! Instruction for Neptune‚Äôs Execution628549A Crack Arises! Luffy vs. Jinbe629550Hody‚Äôs Accident - The Evil Drug‚Äôs True Power!629 | 630551The Decisive Battle Begins at Gyoncorde Plaza!631552Shocking Confession - The Truth about Otohime‚Äôs Assassination632553Shirahoshi‚Äôs Tears! Finally, Luffy‚Äôs Appearance!633554Big Clash! Straw Hat Pirates vs. 100,000 Opponents634555Explosive Move! Zoro and Sanji Sally Forth!634 | 635556First Showing! Sunny‚Äôs Secret Weapons!634 | 635 | 636557Iron Pirate! Entry of Franky Shogun636558Noah Approaching! The Crisis of Fishman Island‚Äôs Destruction!636 | 637559Hurry Up, Luffy! Shirahoshi‚Äôs Desperate Situation638560Beginning of the Battle! Luffy vs. Hody!639561Battle Royal! The Group vs. the New Fishman Pirates!640562Luffy is Defeated!? The Hour of Hody‚Äôs Revenge641563Shocking Truth! Hody‚Äôs True Identity!642 | 643 | 644564To Zero! Passionate Desire to Luffy!642 | 644565Luffy‚Äôs Whole Body Blow! Red Hawk Explosion643 | 644 | 645566Final Conclusion! Hody‚Äôs Final Battle645 | 646567Stop Noah! Elephant Gatling of Desperation!645 | 647568To the Future! The Path Towards the Sun!648569Revealed Secret - The Truth of Ancient Weapons649570The Crew Is Surprised! The New Marine Fleet Admiral!650571I Love Sweets! The Yonko Big Mom651572Grim Prospects! A Trap that Waits in the New World652573Finally Setting Sail! Goodbye Fishman Island653574To the New World! Aim for the Strongest Sea654 | 655575Z‚Äôs Ambition Arc - The Little Giant Lily!Filler576Z‚Äôs Ambition Arc - Introduction of the Mystery of the Strongest Army Corps!Filler577Z‚Äôs Ambition Arc - A Desperate Big Escape Strategy!Filler578Z‚Äôs Ambition Arc - Luffy vs. Shuzo!Filler579Landing! The Burning Island, Punk Hazard655580A Scorching Battle! Luffy vs. the Giant Dragon!655 | 656581The Crew is Confused! The Shocking Beheaded Samurai Appears!656 | 657 | 658582Surprise! The Secret of the Island is Finally Revealed .657 | 658583Save the Children! Start of a Gang Fight!658 | 659584A Duel of Swordplay! Brook and the Mysterious Samurai Torso659585Shichibukai! Trafalgar Law660586A Big Pinch! Luffy Sinks Into The Cold Lake661587Clash! Law vs. Vice Admiral Smoker662 | 663588Reunion after Two Years! Luffy and Law662 | 663589Worst of the World - The Scary Scientist Caesar664590History‚Äôs Strongest Collaboration vs. Glutton of the SeaFiller591Chopper Enraged - Master‚Äôs Tyrannical Experiments665592Gang Obliteration! Legendary Hitman Attack!666593Save Nami! Luffy‚Äôs Snow Mountain Battle667594Formation! The Pirate Alliance Luffy-Law!668595Capture Master - The Pirate Alliance‚Äôs Operation Begins!669596On the Verge of Annihilation - The Monster of Death Flies in670597Big Battle - Caesar Activates his True Ability!671 | 672598The Samurai Who Cuts Fire! Foxfire Kin‚Äôemon!672599Shock! The Identity of the Mysterious Man Vergo!673600Protect the Children! Master‚Äôs Evil Hands Close in674601New World‚Äôs Severe Earthquake - Caesar‚Äôs Nightmare Experiment675602History‚Äôs Worst Slaughter Weapon! Shinokuni676603The Counterattack Begins! Luffy and Law‚Äôs Great Escape677604The Aim is Building R! The Pirate Alliance‚Äôs Great Assault!678 | 679605Tashigi‚Äôs Tears - G-5‚Äôs Suicidal Breakthrough Strategy679606Vice Admiral‚Äôs Betrayal! ‚ÄòDemon Bamboo‚Äô Vergo680607Incandescent Fierce Battle - Luffy vs. Caesar681608The Mastermind in the Shadows! Doflamingo Moves!682609Luffy‚Äôs Freezing to Death!? The Terrifying Snow Woman, Monet!683610Fist Fight! Two Vice Admirals Fight684611The Small Dragon! Momonosuke Revealed685612Deadly Combat in Snowstorm - The Straw Hats vs. the Snow Woman686613Secret Technique Blasts! Zoro‚Äôs Strongest One-Sword Style!687614I‚Äôll Protect My Friends! Mocha‚Äôs Desperate Escape688615Brownbeard‚Äôs Bitterness! Luffy‚Äôs Angry Attack689616Shocking Conclusion! Smoker vs. Vergo!690 | 693617Caesar Defeated! The Strongest Grizzly Magnum691 | 692618Invasion! The Assassin From Dressrosa692619Rampage! The Invincible Franky Shogun693 | 694620Desperate Situation! Punk Hazard‚Äôs Big Explosion694621Capture Caesar - General Cannon Blasts695622Emotional Meeting! Momonosuke and Kin‚Äôemon696623Regretful Departure - Leaving Punk Hazard!697624G-5‚Äôs Annihilation! Doflamingo Assaults!698625Tension! Aokiji vs. Doflamingo698 | 699626Caesar has Disappeared! The Pirate Alliance Sallies699627Luffy Dies in the Sea!? The Collapse of the Pirate AllianceFiller628Big Reversal! Luffy‚Äôs Explosive Fist of FuryFiller629Violent Shock! Earth-shaking Big NewsFiller630Adventure! The Country of Love and Passion, Dressrosa701631Swirling Madness - Corrida Colosseum701 | 702632Dangerous Love - Dancing Girl Violet702 | 703633The Most Powerful Unknown Warrior! Lucy Appears703 | 704634The Pirate Prince Cavendish704 | 705 | 706635The Fated Reunion - Bellamy the Hyena705 | 706636Supernova! Bartolomeo the Cannibal706 | 707637Rivalry of Warriors! B Block on Fire!707 | 708638One-hit Knockout! The Astounding King Punch709639Fighting Fish Attack! Break through the Iron Bridge of Death710640Adventure! The Island of Fairies, Green Bit710 | 711 | 712641The Unknown World - Tontatta Kingdom711 | 712642Scheme of the Century - Doflamingo Gets Moving706 | 711 | 712643Heaven and Earth Shakes! The True Power of Admiral Fujitora713 | 714644An Angry Blow! The Giant vs. Lucy714645The Destructive Cannon Explodes! A Close Call for Lucy715646The Legendary Pirate - Don Chinjao!716647Light and Shadow - The Darkness Lurking in Dressrosa!717648Sortie - The Legendary Hero, Usoland718 | 726649The Fierce Battle‚Äôs Conclusion! Lucy VS Chinjao!718 | 719650Luffy and the Fated Gladiator Rebecca720651Protect her ‚Äòtil the End! Rebecca and the Toy Soldier721652Final Battleground - D Block Battle Begins722653Decisive Battle! Jora vs. Straw Hat Crew722 | 723654Blade of Beauty! Cavendish of the White Horse706 | 723655The Great Clash! Sanji VS. Doflamingo724656Rebecca‚Äôs Sword of Death! Backwater Sword Dance725657The Unluckiest Fighters! Logan vs. Rebecca725 | 726 | 727 | 731658Shock! The Toy Soldier‚Äôs True Identity!726659A Chilling Past! The Secret Behind Dressrosa727660Nightmare! That One Tragic Evening in Dressrosa728661Shichibukai Confrontation - Law vs. Doflamingo728 | 729662Two Great Forces Face-off! Straw Hat and the Heavenly Demon730663Luffy, Startled ‚Äî The Man Who Will Inherit Ace‚Äôs Will731664Start Operation SOP ‚Äî Usoland Charges732665Hot Emotions - Rebecca vs. Suleiman733666Winner Decided!? The End to the D-Block Bash734667The Admiral‚Äôs Decision ‚Äî Fujitora vs. Doflamingo735668The Final Round Begins ‚Äî Diamante the Hero Takes the Stage736669The Castle Moves! Elite Officer Pica Emerges736 | 737670Dragon Claw Explosion! Lucy‚Äôs Threatening Blow!736 | 737 | 738671Defeat Sugar - The Dwarf Soldiers Charge In!738 | 739672The Last Light ‚Äì The Secret of Our Captain!739 | 740673The Rupture Human ‚Äì Gladius‚Äô Big Explosion!740674Liar Usoland on the Run!741675A Fated Meeting ‚Äì Kyros and King Riku741 | 742676Operation Failed! Hero Usoland Dies!?742677The Legend is Back! Kyros‚Äô All-out Blow743678Fire Fist Explosion! The Power of the Revived Mera Mera no Mi744679Gallant Appearance ‚Äì Revolutionary Army Chief of Staff Sabo744 | 745680The Devil‚Äôs Trap ‚Äì Dressrosa Annihilation Plan745681The 500 Million Man ‚Äì The Target is Usoland!746682Breaking through Enemy Lines - Luffy and Zoro Launch the Counter-Attack746 | 747683With a Rumbling of the Ground - The God of Destruction, Giant Pica Descends747684Gathering into a Powerful Front! Luffy and a Group of Brutal Warriors!748685Great Advance! Luffy Army vs. Pica!749 | 750686A Shocking Confession! Law‚Äôs Soul-burning Vow!749 | 750687A Big Clash! Chief of Staff Sabo vs. Admiral Fujitora750 | 751688A Desperate Situation - Luffy Gets Caught in a Trap!751 | 752689Great Escape! Luffy‚Äôs Miraculous Elephant Gun!752690A United Front ‚Äì Luffy‚Äôs Breakthrough to Victory752 | 753691The Second Samurai ‚Äì Evening Shower Kanjuro Appears753 | 754 | 755692The Struggle with Pica ‚Äì Zoro‚Äôs One Finishing Move754 | 755693Princess of Little People ‚Äì The Imprisoned Mansherry755694Invulnerable! The Terrifying Headcracker Doll Army756695Life-Risking! Luffy is the Trump Card to Victory756 | 757696A Tearful Reunion ‚Äì Rebecca and Kyros!757 | 758697One Shot One Kill - The Man Who Will Save Dressrosa758698Anger Explosion - Luffy and Law‚Äôs Ultimate Secret Plan759699Noble Family - Doflamingo‚Äôs True Identity!760700Ultimate Power - The Secret of the Ope Ope no Mi!761701Sad Memories - Law the Boy from the White City!762702Celestial Dragon! Doffy‚Äôs Sublime Past763703A Difficult Path ‚Äì Law and Corazon‚Äôs Life Journey764704Time Draws Near! Seize the Ope Ope no Mi!765705A Moment of Resolution - Corazon‚Äôs Parting Smile!766706Go, Law - The Kind-hearted Man‚Äôs Final Battle!767707To Freedom! Law Unleashes the Injection Shot768708Heated Battle - Law vs. Doflamingo769 | 770709A Decisive Battle Against the Executives - Proud Hajrudin769 | 770710Battle of Love - Navy Leader Sai vs. Baby 5769 | 771711A Man‚Äôs Pride - Bellamy‚Äôs Last Assault!769 | 770 | 771 | 772 | 780712Storm and Stress - Hakuba vs. Dellinger772 | 773713Bari-Bari - Homage God Fist Strikes!773714The Healing Princess ‚Äì Save Mansherry!774 | 779715Showdown Between Men ‚Äì Senor‚Äôs Requiem of Love775 | 779716Stardust of Death ‚Äì Diamante‚Äôs Storm of Fierce Attacks775 | 776717Trueno Bastardo! Kyros‚Äô Blow of Anger!776 | 777718Moving Across the Ground! The Giant Statue Pica‚Äôs Surprise Maneuver!777 | 778719Aerial Battle - Zoro‚Äôs Deadly Secret Technique Explodes!778720See ya Later! Bellamy‚Äôs Farewell Blow!779721Law Dies - Luffy‚Äôs Fierce Assault of Anger!780722A Blade of Tenacity! The Gamma Knife Counterattack!781723Haki Clash - Luffy vs. Doflamingo781 | 782724Impossible to Attack - Trebol‚Äôs Shocking Secret782 | 783725Anger Erupts! I Will Take Everything upon Myself!783726Gear Fourth! The Miraculous Boundman!784727Great Counterattack! Doflamingo‚Äôs Awakening!785728Luffy! The All-Out Leo Bazooka!785 | 786729Kaen Ryuo - Protect Luffy‚Äôs Life786 | 787730Tears of Miracles! Mansherry‚Äôs Fight!‚Äú787 | 788731As Long as We Breathe! Stop the Deadly Birdcage!788 | 789732Dead or Alive! A Fateful Countdown!789733Attack on a Celestial! Luffy‚Äôs King Kong Gun of Anger!790734To Be Free! Dressrosa‚Äôs Delight!791735The Unheard-of! Admiral Fujitora‚Äôs Surprising Decision!792736Sending a Shock Wave! The Worst Generation Goes Into Action!793737The Birth of the Legend! The Adventures of the Revolutionary Warrior Sabo!794738The Brothers‚Äô Bond! The Untold Story Behind Luffy and Sabo‚Äôs Reunion!794 | 795739The Strongest Creature! One of the Four Emperors - Kaido, King of the Beasts!795740Fujitora Takes Action! The Complete Siege of the Straw Hats!796741A State of Emergency! Rebecca Is Kidnapped!796 | 797742The Bond Between Father and Daughter! Kyros and Rebecca!797 | 798743Manly Spirit! Luffy vs. Fujitora in a Head-to-Head Clash798 | 799744No Way Out! Admiral Fujitora‚Äôs Ruthless Pursuit!799745Exchanging the Sons‚Äô Cups! Straw Hat Grand Fleet!800746Clash of the Mightiest ‚Äì Raging Monsters of the New World801747The Silver Fortress ‚Äì The Great Adventures of Luffy and Bart802748An Underground Labyrinth ‚Äì Luffy vs Mine Cart ManFiller749The Sword Technique Heats Up! Law and Zoro Finally Appear!Filler750A Desperate Situation - Luffy Fights a Battle in Extreme HeatFiller751The Start of a New Adventure - Arrival at the Mysterious Island, ‚ÄòZou‚Äô!802752The New Shichibukai - Son of the Legendary Whitebeard Arrives802 | 803753A Deadly Elephant Climb - A Great Adventure on the Back of the Giant Elephant!803 | 804754Battle Starts! Luffy vs. the Mink Tribe!805755Garchu! The Straw Hat Crew Reunites806756The Counterattack Begins! The Curly Hat Pirates moves out!807757An Incoming Threat - Jack of the Beasts Pirates!807 | 808758Ruler of Day - Enter Duke Inuarashi!808 | 809759Ruler of Night - Nekomamushi Appears809 | 810760Destruction of the Capital - Curly Hat Pirates Arrive on Land!808 | 809 | 810761Race Against Time - The Bond of the Minks and the Crew!810762The Rascal Returns Home - Yonko Big Mom‚Äôs Assassin811 | 812763The Truth Behind His Disappearance - Sanji‚Äôs Shocking Invitation812 | 813764To My Buds! Sanji‚Äôs Farewell Note!813 | 814765Let‚Äôs Go See Master Nekomamushi814 | 815766Luffy‚Äôs Decision - Sanji on the Brink of Quitting!815767A Volatile Situation - The Dog and the Cat and the Samurai!816768The Third One! Raizo of the Mist, the Ninja, Appears!817769A Red Stone! A Guide to the One Piece817 | 818770The Secret of the Wano Kingdom ‚Äì The Kozuki Clan and the Poneglyph818771A Man‚Äôs Vow ‚Äì Luffy and Kozuki Momonosuke819772The Legendary Journey! The Dog and the Cat and the Pirate King!819 | 820773Returning Nightmare - Assault of the Invulnerable Jack820 | 821774Defensive Battle of Zou - Luffy and Zunisha!821775Save the Giant Elephant - The Straw Hats Rescue Operation!Filler776Descending the Elephant ‚Äì Setting Sail for Sanji‚Äôs Retrieval!822777To the Reverie - Princess Vivi and Princess Shirahoshi823778To the Reverie - Rebecca and the Sakura Kingdom823779Kaido Returns - The Worst Generation Threatened!824780A Hungry Front - Luffy and the Marine Rookies!Filler781The Persistent Trio ‚Äì The Great Pursuit for the Straw Hats!Filler782Fist of the Devil ‚Äì Showdown! Luffy vs. GrantFiller783Sanji‚Äôs Homecoming! Into Big Mom‚Äôs Territory!824 | 8257840 and 4 ‚Äì A Confrontation with Germa 66!825 | 826785The Deadly Poison Crisis ‚Äì Luffy and Reiju!826 | 827786Totto Land! One of the Yonko ‚ÄúBig Mom‚Äù Appears827787The Yonko‚Äôs Daughter ‚Äì Sanji‚Äôs Fianc√©e ‚ÄúPudding‚Äù828788A Massive Attack! Mom‚Äôs Hunger Pangs828 | 829789The Capital Crumbles!? Big Mom and Jinbe829790The Yonko‚Äôs Castle ‚Äì Arrival on Whole Cake Island830791The Forest of Sweets! Luffy vs. Luffy831792Mom‚Äôs Assassin - Luffy and the Seducing Woods!831 | 832793The Seafaring Nation ‚Äì Judge the King of Germa832 | 833794A Showdown Between Father and Son ‚Äì Judge vs. Sanji833 | 834795Great Ambition ‚Äì Big Mom and Caesar834796Kingdom of Souls ‚Äì Mom‚Äôs Fearsome Power!835797A Top Executive! One of the Three Commanders ‚ÄúCracker‚Äù Appears835 | 836798An Enemy With 800 Million Bounty ‚Äì Luffy vs. Thousand Arms Cracker836 | 837799Full Force Showdown ‚Äì Gear Fourth vs. Bisu Bisu Ability837 | 8388001 and 2 ‚Äì Assemble! The Vinsmoke Family838 | 839801The Benefactor‚Äôs Life! Sanji and Owner Zeff!839802An Angry Sanji! The Secret of Germa 66!839 | 840803The Past that He Let Go of! Vinsmoke Sanji!840804To East Blue - Sanji‚Äôs Decision to Set Sail841805A Battle of Limits - Luffy and the Infinite Biscuits!841 | 842806Power of Fullness - New Gear Fourth Tankman!842 | 843807Saddest Duel - Luffy vs. Sanji Part 1843808Saddest Duel - Luffy vs. Sanji Part 2843 | 844809A Storm of Revenge! An Enraged Army Comes to Attack!845810The End of the Adventure - Sanji‚Äôs Resolute Proposal845811I‚Äôll Wait Here - Luffy vs. the Enraged Army846812Infiltration Inside the Castle - Steal the Road Poneglyph846 | 847813Face-to-face - Luffy and Big Mom847 | 848814Shout of the Soul - Brook and Pedro‚Äôs Lightning Operation848 | 849815Farewell ‚Äì Pudding‚Äôs Tears of Resolve848 | 849816Fate of the Left Eye ‚Äì Pedro vs Baron Tamago850817Moist Cigarette! The Night Before Sanji‚Äôs Wedding!850 | 851818The Undaunted Soul - Brook vs. Big Mom851819Sora‚Äôs Wish! Germa‚Äôs Failure - Sanji!852820Sanji is Back - Luffy‚Äôs Great Flat-out Run Counterattack852 | 853821The Chateau in Turmoil! Luffy, to the Rendezvous!853 | 854822The Decision to Part! Sanji and the Straw Hat Bento854823The Yonko Rolls Over - The Great Brook Rescue Mission!855824The Rendezvous! Luffy, a One-on-One at His Limit!855 | 856825Liar - Luffy and Sanji856826Sanji Returns ‚Äì Crash It! The Tea Party from Hell857827A Secret Meeting! Luffy vs. The Fire Tank Pirates857 | 858828The Deadly Pact! Luffy &amp; Bege‚Äôs Allied Forces858 | 859829Luffy‚Äôs Secret Plan ‚Äì Just Before the Curtain Rises! The Conspired Wedding Ceremony859 | 860830Family Gathering ‚Äì The Curtain Rises! The Tea Party from Hell860831The Pretend Couple! Enter Sanji ‚ô° Pudding861832The Kiss of Death! The Yonko Assassination Plan Begins!862833Offering up a Sake Cup! Chivalrous Jinbe repays his debt!863834The plan failed!? Big Mom Pirates Counterattack!864835Run Sanji! SOS Germa 66!865836The Mystery of Mama - The Island of Giants and the Little Beast866837Mama‚Äôs Birthday - The Day that Carmel has disappeared867838Launchers Explosion! Big Mom Assassination Moment868839Evil Army - Transformation! Germa 66868 | 869840Cutting the Father-Son Relationship! Sanji and Judge!869 | 870841Tea Party Escape - Luffy VS Big Mom870 | 871842Execution Starts - Luffy Allied Army Annihilation !?871 | 872843The Castle Collapsed - Straw Hat Pirates Begins Great Escape872 | 873844The Spear of Elbaf - Onslaught! The Flying Big Mom873 | 874845Pudding‚Äôs Resolve Blazes - The Seducing Woods874846The Thunder‚Äôs Counterattack - Nami and the Stormy Zeus875847A Coincidental Reunion - Sanji and the Evil Pudding in Love875 | 876848Protecting the Sunny - Fierce Battle! Chopper and Brook876 | 877849Before the Dawn - Guardians Leader Pedro877 | 878850I Will Definitely Return! Luffy‚Äôs Life-Risking Departure878851The Man with a Bounty of Billion - The Strongest Sweet Commander, Katakuri879852A Hard Battle Starts - Luffy vs. Katakuri879 | 880853The Green Room - An Invincible Helmsman, Jinbe880 | 881854The Menacing Mogura ‚Äì Luffy‚Äôs Silent Battle881 | 882855End of Death Battle!? Katakuri‚Äôs Rage Awakens882 | 883856The Forbidden Secret! Katakuri‚Äôs Merienda!883857Luffy‚Äôs Counterattack - Invincible Katakuri‚Äôs Weakness884858Crisis Again! Gear 4 vs Muso Donuts884 | 885859The Rebellious Daughter, Chiffon - Sanji‚Äôs Big Plan for Transporting the Cake885 | 886860A Man‚Äôs Way of Life - Bege and Luffy‚Äôs Determination as Captains886 | 887861The Cake Sank?! Sanji and Bege‚Äôs Getaway Battle!887 | 888862Sulong - Carrot‚Äôs Mysterious Great Transformation888 | 889863Break Through - Straw Hat Crew‚Äôs Great Naval Battle!889 | 890864Finally Clash - Yonko VS Straw Hat Crew890865Dark King‚Äôs Direct Precepts! The Battle Against Katakuri Turns Around!890 | 891 | 894866Finally He Returns - Sanji, the Man Who‚Äôll Stop the Yonko891 | 892867Lurking in the Darkness - Assassin Attacks Luffy!892 | 893868A Man‚Äôs Resolution - Katakuri‚Äôs Life Risking Great Match893 | 894869Wake Up - To Cross Over the Strongest Kenbunshoku894870A God Speed Fist - New Gear 4 Activation!895871Finally Concluded - An Outcome of the Fierce Battle with Katakuri896 | 902872A Desperate Situation - The Iron-Tight Entrapment of Luffy!897873Pulling Back from the Brink - The Formidable Reinforcements Germa!898874The Last Hope - The Sun Pirates Emerge899875A Fascinating Taste - Sanji‚Äôs Cake of Happiness900876The Man of Humanity and Justice! Jimbei, a Desperate Massive Ocean Current901877Time for Farewell! Pudding‚Äôs One Last Request!902878The World in Shock! The Fifth Emperor of the Sea Arrives!903879To the Levely! Gathering of the Straw Hat Allies!903880Sabo Goes into Action - All the Captains of the Revolutionary Army Appear!904881The Next Move - New Obsessive Fleet Admiral Sakazuki905882The Summit War - Pirate King‚Äôs Inherited Will905883One Step Ahead of the Dream - Shirahoshi‚Äôs Path to the Sun!905884I Want to See Them - Vivi and Rebecca‚Äôs Feelings906885Darkness of the Holy Land - The Mysterious Giant Straw Hat864 | 865 | 866 | 868 | 870 | 871 | 888 | 903 | 904 | 906886The Uproarious Holy Land - Princess Shirahoshi is being targeted!907887On the Verge - The Two Yonko Targeting Luffy907888Sabo Gets Angry - Tragedy of the Revolutionary Army Officer Kuma908889Finally, It Starts - The Conspiracy-filled Levely!908890Marco! The Keeper of Whitebeard‚Äôs Last Memento909891Climbing Up a Waterfall! A Great Journey Through the Land of Wano‚Äôs Sea Zone!910892Wano Country! To the Land of Samurai where Cherry Blossoms Flutter909 | 910893Otama Appears! Luffy vs. Kaido‚Äôs Army!910 | 911894He‚Äôll Come! The Legend of Ace in the Land of Wano911 | 912895Special Edition! - The Strongest Bounty Hunter CiderFiller896Special Editon! - Luffy Vs Carbonic Acid KingFiller897Save O-Tama! Straw Hat, Bounding through the Wasteland!912898Headliner! The Magician Basil Hawkins Enters the Scene!913899Confirmed Defeat! The Assault of the Strawman!913 | 915900The Greatest Day! O-Tama‚Äôs First Oshiruko!914901Entering Enemy Territory! The Protagonists Spread into the Town of Bakura!914 | 915902The Yokozuna Appears - The Invincible Urashima Goes After O-Kiku!915 | 916903Sumo Battle - Straw Hat VS The Strongest Yokozuna!916904Luffy‚Äôs Intense Anger! Save O-Tama from the Crisis!916 | 917905Fighting for Otama! Fight against Holdem!917906Strike - The Magician and the Surgeon of Death!91890720th Anniversary! - Special Romance DawnFiller908Arrival of the Treasure Ship - Luffy-tarou Returns the Favor!918 | 919909A Mysterious Gravestone - Reunion at the Oden Castle Ruins!919910The Legendary Samurai - A Man that Roger Favoured!920911Defeat the Emperor - The Secret Raid Plan Starts920 | 921912The Strongest Man - Pillar of the Bandits, Shutenmaru!921 | 922913Everyone‚Äôs Annihilated - Kaido‚Äôs Bolo Breath of Rage!922914Finally Clashing - The Ferocious Luffy vs. Kaido922 | 923915Destructive! One Shot, One Kill - Thunder Bagua!923 | 924916Life in Hell! Luffy‚Äôs Place of Humiliation924917The Holy Land in Tumult - The Yonko Blackbeard Laughts Boldly925918Start of the Action - The Great Plan to Overthrow Kaido925 | 926919Great Riot! Prisoner Luffy and Kid!926920Great Reputation! Sanji‚Äôs Specialty Soba!927 | 928921Magnificent - The Most Beautiful Woman of Wano, Komurasaki927 | 928922A Tale of Chivalry! Zoro and Tonoyasu‚Äôs Little Trip!928 | 929923A State of Emergency - Big Mom Closes in!928 | 929 | 930924The Capital in an Uproar! Another Assassin Targets Sanji!930925Great Success - Justice of O-Soba Mask!931926Desperate Situation - The Threatful Orochi Oniwabanshu931 | 932927A State of Chaos - Fearsome Snake Shogun Orochi932 | 933928The Flower Falls! The Final Moment of the Most Beautiful Woman in Wano Country933929Conciliation of Prisoners - Luffy and Grandpa Hyo!934930All-Star! Queen the Plague Appears!934 | 935931Climb - Luffy‚Äôs Fleeing Play!935 | 936932Dead or Alive - Queen‚Äôs Sumo Inferno936933Gyukimaru! Zoro Fights a Duel on Oihagi Bridge937934Great Reversal - Santoryu Beyond the Deadline !937 | 938935Amazement of Zoro - True Identity of the Mysterious Beauty938 | 939936Approach - Ryuo, the Haki of Wano Country939 | 940937A Lame Yasu - The Star of Ebisu Town940938Meet Easily - Identity of Ushimitsu Kozo941939Malediction - Departure in Song of Tonoyasu941 | 942940Cruelty - The Reality of SMILE Devil Fruit!942 | 943941Toko‚Äôs Tears - Orochi‚Äôs Painful Bullets!943942The Straw Hats Intrudes! Uproar! A Fierce Battle at the Execution Room944943Luffy‚Äôs Determination - Breakthrough the Grand Sumo‚Äôs Hell!944 | 945944The Coming of the Storm! Big Mom‚Äôs Great Rampage!945945A Grudge Over Oshiruko - Luffy Gets into a Desperate Situation946946Stop the Emperor of the Sea! Queen‚Äôs Secret Plan!947947Brutal Ammunition! The Plague Rounds Aim at Luffy!947 | 948948Start Fighting Back! Luffy and the Red Scabbard Samurai!948 | 949949We‚Äôre Here to Win! Luffy‚Äôs Desperate Scream!949950The Warriors‚Äô Dreams - Takeover of Udon950951Orochi‚Äôs Pursuers! Ninja Army Corps vs. Zoro950 | 951952Tensions on Onigashima! Encounter?! The Two Emperors951 | 952953Hiyori‚Äôs Confession! Reunion on Oihagi Bridge952 | 953954Its Name is Enma! Oden‚Äôs Meito!953955A New Alliance?! Kaido‚Äôs Army Great Assemble954956Decisive Battle Draws Near! The Straw Hat Crew Ready for Battle955957Big News! The Warlords Attack Incident956958The Legendary Battle! Garp and Roger957959The Promised Port! Wano Country Arc Act 3 Opening958 | 959960The Best Samurai in Wano Country! Kozuki Oden Appears959 | 960961Tearful Apprentice - Oden and Kin‚Äôemon961 | 962962Moving Fate Drift Ashore! Whitebeard Pirates!962 | 963963Oden‚Äôs Determination! Whitebeard‚Äôs Trials!963 | 964964Whitebeard‚Äôs Little Brother! Oden‚Äôs Great Adventure!964 | 965965Blades Crossed! Roger and Whitebeard!965 | 966966Roger‚Äôs Wish! A New Adventure Begins!966967The Bet of a Lifetime! Roger‚Äôs Adventure966 | 967968The Pirate King is Born - Arriving at the Last Island!967969To the Land of Wano! The Roger Pirates Disband!968970Sad News - The Opening of the Great Pirate Era968 | 969971Raid! Oden and the Nine Red Scabbards969 | 970972The Moment of Conclusion! Oden vs. Kaido!970 | 971973Sentenced to Boil - Oden‚Äôs Deadly Hour971974I‚Äôm Oden, and I Was Born to Boil972975The Burning Castle! The Fate of the Kozuki Clan!972 | 973976Back to the Present! Beyond 20 Years973 | 974977Pirates at Sea! Raid! Onward to Onigashima974978The Worst Generation Charges in! The Battle of the Stormy Sea975979Strong Luck!? Leader Kin‚Äôemon‚Äôs Plan975 | 976980Promise of Tears! The Kidnapped Momonosuke976981A New Companion! Knight of the Sea Jinbe!977982Kaido‚Äôs Trump Card - Introducing the Tobi Roppo977 | 978983The Seriousness of the Samurai! The Crew Lands on Onigashima977 | 978984Luffy Goes Out of Control?! Sneaking into Kaido‚Äôs Banquet979985Feelings Toward O-tama - Luffy‚Äôs Furious Blow979 | 980986Fighting Music! The Ability to Attack Luffy!980987The Failing Dream? The Plot to Lure Sanji!981988Arrival of Reinforcements! Captain of the Whitebeard Pirates!981 | 982989Oath of Man! Fierce Battle of the Brachiotank982990Thunder Bagua! The Appearance of Kaido‚Äôs Son983991Enemy or Ally? Luffy and Yamato!983 | 984992I Want to Become Oden - Yamato‚Äôs Desire984993Explosive?! The Handcuffs that Shackle Yamato‚Äôs Freedom!985994The Scabbards Face-off - Kikunojo vs. Kanjuro985 | 986995Raid! Inheriting the Will of Oden986996Onigashima in Tumult- Luffy‚Äôs All-Out War Begins987997Moonlight Battle - Berserker ‚ÄúSulong‚Äù987 | 988998The Rebellion of Zeus?! Nami‚Äôs Desperate Situation!988999I‚Äôll Protect You - Chance Encounter Yamato and Momonosuke9891000Overwhelming Strength! The Straw Hat Pirates Gather989 | 9901001A Dangerous Invitation! Plan to Eradicate Queen9901002A New Connection! Nami and Ulti!9911003A Heroic Blade! The Red Scabbards vs. Kaido, Again Once More991 | 9921004An Inherited Technique - Unleashing Oden‚Äôs Secret Swordplay9921005The Power of Ice Oni! A New Version of the Excite Bullets9931006I Won‚Äôt Forgive You! Chopper‚Äôs Determination!993 | 9941007Zoro‚Äôs Pursuit! Ice Oni Tag9941008Nami‚Äôs Surrender?! Ulti‚Äôs Wild Headbutt9951009Sasaki‚Äôs Onslaught - Armored Division vs. Yamato995 | 9961010Eliminate the Ice Oni - Chopper‚Äôs Fire Trick!996 | 9971011It‚Äôs Not Okay!! The Spider That Lures Sanji9971012A Comeback Move! Marco The Phoenix‚Äôs Flame9981013Yamato‚Äôs Past ‚Äì The Man Aiming for an Emperor‚Äôs Head998 | 9991014Marco‚Äôs Tears! The Bond of the Whitebeard Pirates999 | 10001015Straw Hat Luffy - The Man Who Will Become the Pirate King10001016The Battle of the Monsters! The Three Stubborn Captains10011017A Barrage of Powerful Techniques! The Fierce Attacks of the Worst Generation!1001 | 10021018Kaido Laughs! Four Emperors vs. New Generation!10031019Otama‚Äôs Secret Plan! Great Operation Kibi Dango10041020Sanji‚Äôs Scream! An SOS Echoes Over the Island1004 | 10051021Spank Strikes! Sanji‚Äôs Woman-trouble!1005 | 10061022No Regrets - The Student and Teacher Bond Between Luffy and the Boss10061023Preparations OK! Chopperphage Nebulizer10071024Oden Appears! The Confused Hearts of the Red Scabbards!1007 | 10081025Annihilation of the Worst Generation!? The Powerful Techniques of the Four Emperors!1008 | 10091026The Supernovas Counterattack! The Four Emperors‚Äôs Disassembly Operation10091027Protect Luffy! Zoro and Law‚Äôs Sword Technique10101028Beyond the Four Emperors - Luffy‚Äôs Iron Fist Counterattack1010 | 10111029A Faint Memory - Luffy and Red-Haired‚Äôs Daughter UtaFiller1030The Oath of the New Era! Luffy and UtaFiller1031Nami‚Äôs Screams - The Desperate Death Race!10111032The Dawn of the Land of Wano - The All-Out Battle Heats Up!10121033Settled! Luffy‚Äôs Accelerating Fist of the Supreme King1012 | 10131034Luffy Defeated! The Straw Hats in Jeopardy?!1013 | 10141035The Beasts Trample Down! The End of the Kozuki Family!10141036Fight Against the Dark Night! The Commander-in-Chief of the Land of Wano Sounds Off!10151037Believe in Luffy! The Alliance‚Äôs Counterattack Begins!1015 | 10161038Nami‚Äôs Lethal Attack! O-Tama‚Äôs Desperate Challenge!1016 | 10171039A Dramatic Increase of Allies! Straw Hats Fight Back!1017 | 10181040The Pride of a Helmsman - The Enraged Jinbe!10181041Great Battle of Monsters! Yamato and Franky10191042The Predator‚Äôs Trap - Black Maria‚Äôs Seduction1019 | 10201043Slash the Nightmare - Brook‚Äôs Sword of Ice!1020 | 10211044Clutch! A Demon Incarnate, Robin!10211045A Spell! Kid and Zoro Facing Threats!10221046Taking a Chance! Both Wings Go into Battle!1022 | 10231047Ascend to the Dawn! A Pink Dragon Gets Agitated1023 | 10241048For the Future! Yamato and the Great Swordsmen‚Äôs Pledge10241049Luffy Soars! Revenge Against the King of the Beasts10251050Two Dragons Face Off! Momonosuke‚Äôs Determination!1025 | 10261051A Legend All Over Again! Luffy‚Äôs Fist Roars in the Sky1026 |10271052The Situation Has Grown Tense! The End of Onigashima!1027 | 10281053Sanji‚Äôs Mutation ? The Two Arms in Crisis!10281054Death to Your Partner! Killer‚Äôs Deadly Gamble!10291055A Shadowy Figure Pulls the Strings! Onigashima in Flames1029 | 10301056A Countercharge! Law and Kid‚Äôs Return-Attack Combination1030 | 10311057For Luffy - Sanji and Zoro‚Äôs Oath10311058The Onslaught of Kazenbo - Orochi‚Äôs Evil Clutches Close in10321059Zoro‚Äôs Hardship - A Monster! King the Wildfire1032 | 10331060Secrets of Enma! The Cursed Sword Entrusted to Zoro1033 | 10341061Attack of the Devil! Sanji VS Queen1034 | 10351062King of Hell Three Sword Style - Zoro vs. King1035 | 10361063Luffy Accelerates! The Turning Point of a New Era!10361064Shuron Hakke! A Lawless Dragon Approaches Luffy!10371065The Destruction of the Alliance?! Fire up, the Will of the New Generation!10381066Here Comes Main Act! Powerful Techniques of Shockwave and Magnetism10391067Towards A New Era! Conclusion! The Brats‚Äô Resolution10401068Moon Princess Echoes! The Final Phase of Wano Country!10411069There is Only One Winner - Luffy vs. Kaidou1041 | 10421070Luffy Defeated?! The Determination of the Left Behind10431071Luffy‚Äôs Peak - Attained! Gear 510441072The Ridiculous Power! Gear 5 in Full Play1045 | 10461073No Escape! Inferno on Onigashima!10461074Believe in Momo - Luffy‚Äôs Final Big Move10471075Twenty Years of Prayer! Reclaim Wano Country10481076The World That Luffy Wants!10491077Closing the Curtain! Winner - Straw Hat Luffy!10501078He Returns! The Shogun of Wano Country, Kozuki Momonosuke10511079The Morning Comes! Luffy and the Others Rest!10521080A Celebration Banquet! The New Emperors of the Sea!10531081The World Burns! The Navy Admiral Attack!873 | 875 | 10541082The Coming of the New Era! The Red-Haired‚Äôs Imperial Rage10551083The World That Moves On! A New Organization, Cross Guild10561084Time to Depart - Wano Country and the Straw HatsFiller1085The Last Curtain! Luffy and Momonosuke‚Äôs Vow10571086A New Emperor! Buggy the Star Clown!10581087The War on the Island of Women! A Case Involving Koby the Hero10591088Luffy‚Äôs Dream1058 | 1059 | 10601089Entering a New Chapter! Luffy and Sabo‚Äôs Paths!1060 | 10611090A New Island! Future Island Egghead10611091Brimming with the Future! An Adventure on the Island of Science!10621092Bonney‚Äôs Lamentation! Darkness Lurking on the Future Island1062 | 10631093The Winner Takes All! Law vs. Blackbeard!1062 | 1063 | 10641094The Mystery Deepens! Egghead Labophase1064 | 10651095The Brain of a Genius - Six Vegapunks!10651096A Forbidden Piece of History! A Theory Concerning a Kingdom10661097The Will of Ohara! The Inherited Research1066 | 10671098The Eccentric Dream of a Genius!1067 | 10681099Preparations for Interception! Rob Lucci Strikes!1068 | 10691100Unprecedented Power! Luffy vs Lucci!10691101The Strongest Form of Humanity! The Seraphim‚Äôs Abilities!10701102Sinister Schemes! The Operation to Escape Egghead1070 | 10711103Turn Back My Father! Bonney‚Äôs Futile Wish!1071 | 10721104A Desperate Situation! The Seraphim‚Äôs All-out Attack!1072 | 10731105A Beautiful Act of Treason! The Spy, Stussy10731106Trouble Occurs! Seek Dr. Vegapunk!10741107A Shudder! The Evil Hand Creeping Up on the Laboratory1074 | 10751108Incomprehensible! The Seraphim‚Äôs Rebellion!1075 | 1076 | 10771109A Tough Decision! An Unusual United Front!10761110Survive! Deadly Combat with the Strongest Form of Humanity!10771111The Second Ohara! The Mastermind‚Äôs Ambition!10781112Clash! Shanks vs. Eustass Kid!10791113Run, Koby! A Desperate Escape Strategy10801114For the Beloved Pupil - The Fist of Vice Admiral Garp!1073 | 1080 | 1081"},"ALTRO/PIANO-STUDI-MANOLO":{"slug":"ALTRO/PIANO-STUDI-MANOLO","filePath":"ALTRO/PIANO STUDI MANOLO.md","title":"PIANO STUDI MANOLO","links":[],"tags":[],"content":"‚úÖ FASE 1: Consolidamento Basi\nüìÖ Dal 22 maggio al 13 giugno\nüóìÔ∏è Giorni di studio: Luned√¨, Marted√¨, Mercoled√¨, Gioved√¨\nüéØ Obiettivo: ricostruire le fondamenta aritmetiche e algebriche\nSettimana 1 (22-23-27-28 maggio)\n\n\nInsiemi numerici: naturali (‚Ñï), interi (‚Ñ§), razionali (‚Ñö), reali (‚Ñù)\n\n\nOperazioni fondamentali: addizione, sottrazione, moltiplicazione, divisione\n\n\nPropriet√† delle operazioni: associativa, commutativa, distributiva\n\n\nPotenze e radici: propriet√† e operazioni\n\n\nSettimana 2 (29 maggio ‚Äì 3-4-5 giugno)\n\n\nFrazioni: semplificazione, operazioni, conversione tra frazioni e decimali\n\n\nPercentuali: calcolo di aumenti, diminuzioni, sconti\n\n\nRipasso generale + esercizi guidati\n\n\nSettimana 3 (9-10-11-12 giugno)\n\n\nApprofondimento personalizzato sugli argomenti pi√π ostici\n\n\nMini test finale sui contenuti della fase 1\n\n\n\n‚úÖ FASE 2: Algebra e Risoluzione\nüìÖ Dal 16 al 27 giugno\nüéØ Obiettivo: padroneggiare espressioni algebriche, equazioni e sistemi\nSettimana 4 (16-17-18-19 giugno)\n\n\nMonomi e polinomi: definizione e operazioni\n\n\nProdotti notevoli: quadrato di binomio, binomi coniugati\n\n\nScomposizione: raccoglimento, prodotti notevoli, Ruffini\n\n\nFrazioni algebriche: semplificazione e operazioni\n\n\nSettimana 5 (23-24-25-26 giugno)\n\n\nEquazioni di primo grado\n\n\nEquazioni di secondo grado con discriminante\n\n\nDisequazioni di primo e secondo grado\n\n\nSistemi lineari: sostituzione, confronto, riduzione\n\n\n27 giugno (venerd√¨)\n\nGiornata di esercitazioni e riepilogo\n\n\n‚úÖ FASE 3: Funzioni e Analisi\nüìÖ Dal 30 giugno al 18 luglio\nüéØ Obiettivo: acquisire familiarit√† con le funzioni e le basi del calcolo\nSettimana 6 (30 giugno ‚Äì 1-2-3 luglio)\n\n\nConcetto di funzione: dominio, codominio, immagine\n\n\nFunzioni lineari, quadratiche, esponenziali, logaritmiche\n\n\nPropriet√† delle funzioni: iniettivit√†, suriettivit√†, biiettivit√†\n\n\nComposizione e funzione inversa\n\n\nSettimana 7 (7-8-9-10 luglio)\n\n\nConcetto intuitivo di limite\n\n\nContinuit√†: significato base\n\n\nDerivata: significato geometrico\n\n\nRegole base della derivazione\n\n\nSettimana 8 (14-15-16-17 luglio)\n\n\nRipasso completo di funzioni e analisi\n\n\nEsercizi guidati e applicazioni economiche base\n\n\n\n‚úÖ FASE 4: Trigonometria + Ripasso\nüìÖ Dal 21 luglio al 1 agosto\nüéØ Obiettivo: chiudere il programma e fissare i concetti con esercitazioni\nSettimana 9 (21-22-23-24 luglio)\n\n\nAngoli: gradi e radianti\n\n\nFunzioni goniometriche: seno, coseno, tangente\n\n\nIdentit√† fondamentali: addizione, sottrazione, duplicazione\n\n\nRisoluzione di triangoli rettangoli e generici\n\n\nSettimana 10 (28-29-30-31 luglio)\n\n\nRipasso generale con focus sulle aree critiche\n\n\nEsercitazioni miste e simulazioni\n\n\nGiorno jolly per recuperi o rafforzamento individuale\n\n\n1 agosto (venerd√¨)\n\nTest finale o grande ripasso collettivo\n"},"ALTRO/scheda-palestra-aurora/ALLENAMENTO-AURORA":{"slug":"ALTRO/scheda-palestra-aurora/ALLENAMENTO-AURORA","filePath":"ALTRO/scheda palestra aurora/ALLENAMENTO AURORA.md","title":"ALLENAMENTO AURORA","links":[],"tags":[],"content":"Pausa tra gli esercizi: 30-45 secondi per aumentare l‚Äôintensit√†.\nPausa tra i circuiti: 1 minuto.\nTip: fai esercizi piano, concentrati sul farlo bene e se non riesci con i pesi fai senza\nAllenamento 1: Parte superiore del corpo\nFocus: Petto, Schiena, Spalle, Braccia.\nEsercizi:\n\n\nFlessioni (Push-ups)\n3 serie da 10-12 ripetizioni\nSe troppo difficile, appoggia le ginocchia a terra.\n\n\nRematore con manubri (Manubri da 2 kg)\n3 serie da 12-15 ripetizioni\nInclinati in avanti e porta i manubri verso il busto.\n\n\nArnold Press (Spalle, manubri da 2 kg)\n3 serie da 12-15 ripetizioni\nRuota i polsi mentre sollevi i manubri verso l‚Äôalto.\n\n\nCurl per bicipiti (Manubri da 2 kg)\n3 serie da 12-15 ripetizioni\nSollevare i manubri mantenendo i gomiti fermi vicino al corpo.\n\n\nEstensioni tricipiti dietro la testa (Manubri da 2 kg)\n3 serie da 12-15 ripetizioni\nSolleva il manubrio sopra la testa e abbassa l‚Äôavambraccio.\n\n\nPlank\n3 serie da 30-40 secondi\nMantieni il corpo in posizione dritta su avambracci e punte dei piedi.\n\n\nCircuito consigliato:\nEsegui i primi 5 esercizi in superserie (un esercizio dopo l‚Äôaltro) con pause di 30-45 secondi tra gli esercizi.\nRipeti il circuito per 3 giri totali.\n\nAllenamento 2: Parte inferiore del corpo e core\nFocus: Gambe, Glutei, Core.\nEsercizi:\n\n\nSquat a corpo libero\n3 serie da 12-15 ripetizioni\nMantieni la schiena dritta e spingi con i talloni.\n\n\nAffondi in avanti (con manubri da 2 kg se possibile)\n3 serie da 10-12 ripetizioni per gamba\nFai un passo in avanti e abbassa il corpo fino a che la gamba posteriore quasi tocca il pavimento.\n\n\nStacchi rumeni (con manubri da 2 kg)\n3 serie da 12-15 ripetizioni\nTieni i manubri davanti al corpo e abbassali mantenendo la schiena dritta.\n\n\nPonte per i glutei\n3 serie da 15-20 ripetizioni\nSdraiati sulla schiena e solleva i fianchi mantenendo i piedi a terra.\n\n\nMountain Climbers\n3 serie da 30 secondi\nAlterna velocemente le ginocchia verso il petto.\n\n\nCrunch addominali\n3 serie da 15-20 ripetizioni\nSolleva la parte superiore del corpo contraendo gli addominali.\n\n\nCircuito consigliato:\nEsegui i primi 5 esercizi in superserie con pause di 30-45 secondi tra gli esercizi.\nRipeti il circuito per 3 giri totali.\n\nSuggerimenti:\n\nPausa breve: Mantieni pause brevi (30-45 secondi) tra gli esercizi per aumentare l‚Äôintensit√†.\nProgressione: Se gli esercizi risultano troppo semplici, aumenta le ripetizioni o riduci i tempi di riposo.\nStretching finale: Concludi ogni sessione con 5-10 minuti di stretching, concentrandoti sui muscoli lavorati.\n"},"UNI/ANNO-1/ANALISI-1/ANALISI-1-INDICE":{"slug":"UNI/ANNO-1/ANALISI-1/ANALISI-1-INDICE","filePath":"UNI/ANNO 1/ANALISI 1/ANALISI 1 INDICE.md","title":"ANALISI 1 INDICE","links":["UNI/ANNO-1/ANALISI-1/SCALETTA","UNI/ANNO-1/ANALISI-1/LIMITI-NOTEVOLI","UNI/ANNO-1/ANALISI-1/STUDIO-DI-FUNZIONE"],"tags":[],"content":"SCALETTA\nSCALETTA\nLIMITI CONSIGLI\nLIMITI NOTEVOLI\nSTUDIO DI FUNZIONE\nSTUDIO DI FUNZIONE\nDIMOSTRAZIONI\nTABELLINE\n"},"UNI/ANNO-1/ANALISI-1/COSE-DA-SAPERE-DI-ANALISI-IMPORTANTISSIME":{"slug":"UNI/ANNO-1/ANALISI-1/COSE-DA-SAPERE-DI-ANALISI-IMPORTANTISSIME","filePath":"UNI/ANNO 1/ANALISI 1/COSE DA SAPERE DI ANALISI IMPORTANTISSIME.md","title":"COSE DA SAPERE DI ANALISI IMPORTANTISSIME","links":[],"tags":[],"content":"GENERALI\ntrigonometria splittingz\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFormulaEspressione\\sin(\\alpha + \\beta)\\sin \\alpha \\cos \\beta + \\cos \\alpha \\sin \\beta\\sin(\\alpha - \\beta)\\sin \\alpha \\cos \\beta - \\cos \\alpha \\sin \\beta\\cos(\\alpha + \\beta)\\cos \\alpha \\cos \\beta - \\sin \\alpha \\sin \\beta\\cos(\\alpha - \\beta)\\cos \\alpha \\cos \\beta + \\sin \\alpha \\sin \\beta\\tan(\\alpha + \\beta)\\frac{\\tan \\alpha + \\tan \\beta}{1 - \\tan \\alpha \\cdot \\tan \\beta}\\tan(\\alpha - \\beta)\\frac{\\tan \\alpha - \\tan \\beta}{1 + \\tan \\alpha \\cdot \\tan \\beta}\\sin^2 x + \\cos^2 x1\nTABELLA SUPERTRIGONOMETRICA\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGradiRadianti\\sin(\\theta)\\cos(\\theta)\\tan(\\theta)0¬∞001030¬∞\\frac{\\pi}{6}\\frac{1}{2}\\frac{\\sqrt{3}}{2}\\frac{1}{\\sqrt{3}}45¬∞\\frac{\\pi}{4}\\frac{\\sqrt{2}}{2}\\frac{\\sqrt{2}}{2}160¬∞\\frac{\\pi}{3}\\frac{\\sqrt{3}}{2}\\frac{1}{2}\\sqrt{3}90¬∞\\frac{\\pi}{2}10non definita120¬∞\\frac{2\\pi}{3}\\frac{\\sqrt{3}}{2}-\\frac{1}{2}-\\sqrt{3}135¬∞\\frac{3\\pi}{4}\\frac{\\sqrt{2}}{2}-\\frac{\\sqrt{2}}{2}-1150¬∞\\frac{5\\pi}{6}\\frac{1}{2}-\\frac{\\sqrt{3}}{2}-\\frac{1}{\\sqrt{3}}180¬∞\\pi0-10210¬∞\\frac{7\\pi}{6}-\\frac{1}{2}-\\frac{\\sqrt{3}}{2}\\frac{1}{\\sqrt{3}}225¬∞\\frac{5\\pi}{4}-\\frac{\\sqrt{2}}{2}-\\frac{\\sqrt{2}}{2}1240¬∞\\frac{4\\pi}{3}-\\frac{\\sqrt{3}}{2}-\\frac{1}{2}\\sqrt{3}270¬∞\\frac{3\\pi}{2}-10non definita300¬∞\\frac{5\\pi}{3}-\\frac{\\sqrt{3}}{2}\\frac{1}{2}-\\sqrt{3}315¬∞\\frac{7\\pi}{4}-\\frac{\\sqrt{2}}{2}\\frac{\\sqrt{2}}{2}-1330¬∞\\frac{11\\pi}{6}-\\frac{1}{2}\\frac{\\sqrt{3}}{2}-\\frac{1}{\\sqrt{3}}360¬∞2\\pi010\nnelle funzioni dispari se hai un meno dentro l‚Äôargomento puoi portarlo fuori\nDISEQUAZIONI\nLIMITI\nDERIVATE\nINTEGRALI\nse uno ha \\int{\\frac{1}{a^2+cx^2} dx} pu√≤ risolverlo come \\frac{a}{c}*arctan(\\frac{x}{c})\nmodi per integrare\n\nfratti semplici\n\nricordare la formula ris+\\frac{res}{den}\n\n\nsostituzione\nper parti\n"},"UNI/ANNO-1/ANALISI-1/FERMAT":{"slug":"UNI/ANNO-1/ANALISI-1/FERMAT","filePath":"UNI/ANNO 1/ANALISI 1/FERMAT.md","title":"FERMAT","links":[],"tags":[],"content":"\nse hai un intorno (a, b)\nse hai un punto x_0 di minimo relativo o massimo relativo \\in (a,b) che √© derivabile in base alla funzione\nse calcoli il rapporto incrementale ti vengono due risultati uno minore di 0 e uno maggiore di 0 automaticamente con la permanenza del segno ti viene 0 quindi √® un punto stazionario ovvero un punto che ha angolatura 0\nnon puoi prendere in considerazione i punti angolosi o roba non derivabile pure se sono minimi relativi o massimi relativi\n"},"UNI/ANNO-1/ANALISI-1/LIMITI-NOTEVOLI":{"slug":"UNI/ANNO-1/ANALISI-1/LIMITI-NOTEVOLI","filePath":"UNI/ANNO 1/ANALISI 1/LIMITI NOTEVOLI.md","title":"LIMITI NOTEVOLI","links":[],"tags":[],"content":"Anche le versioni inverse di questi limiti sono indifferenti\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\na quanto tende?formularisultato0\\dfrac{sin(x)}{x}10\\dfrac{tan(x)}{x}10\\dfrac{arcsin(x)}{x}10\\dfrac{arctan(x)}{x}1\\pi\\dfrac{sin(x)}{x-\\pi}-10\\dfrac{1-cos(x)}{x}00\\dfrac{1-cos(x)}{x^2}\\dfrac{1}{2}0\\dfrac{sin(x)-tan(x)}{x^3}\\dfrac{1}{2}\\infty(1+\\dfrac{a}{x})^x\\epsilon^a0(1+x)^\\dfrac{1}{x}\\epsilon0\\dfrac{a^x-1}{x}ln(a)0\\dfrac{(1+x)^a-1}{x}a0\\dfrac{\\epsilon^x-1}{x}10\\dfrac{ln(1+x)}{x}1\nTEOREMA DEL RAPPORTO\nIl teorema del rapporto si svolge quando non sai cosa fare, questo √® uno schema di esempio\n"},"UNI/ANNO-1/ANALISI-1/NEPERO":{"slug":"UNI/ANNO-1/ANALISI-1/NEPERO","filePath":"UNI/ANNO 1/ANALISI 1/NEPERO.md","title":"NEPERO","links":[],"tags":[],"content":"(1+1/n)^n che tende a infinito\nE‚Äô uguale a il numero di nepero  ed e‚Äô\n\nconvergente perche‚Äô vale solo e\ncrescente si verifica facendo l‚Äôinduzione del successivo maggiore del precedente\nlimitata superiormente ponendo la funzione minore di x dove x e‚Äô 3 ovvero il maggiorante\n"},"UNI/ANNO-1/ANALISI-1/SCALETTA":{"slug":"UNI/ANNO-1/ANALISI-1/SCALETTA","filePath":"UNI/ANNO 1/ANALISI 1/SCALETTA.md","title":"SCALETTA","links":[],"tags":[],"content":"FINE LEZIONI\nmanca esattamente = date(2024-06-14) - date(today) per il 14/06/2024\ndall‚Äôesame manca esattamente = date(2024-06-25) - date(today) per il 25/06/2024**\nDIMOSTRZIONI:\nIHIHIHIH\nBASI:¬†\n\n Semplificazioni¬†\n Fattoriali¬†\n Sistemi¬†\n binomi¬†\n Frazioni¬†\n Logaritmi¬†\n modulo¬†\n Esponenziale¬†\n Potenze¬†\n tabelline¬†\n Radici¬†\n trigonometria¬†\n Funzioni¬†\n Equazioni/dis\n\nDisequazioni:¬†\n\n\n SIN, COS, TAN‚Ä¶, LOG, ESP, MODULO, POTENZA, RADICI¬†\n\n\n QUAD DI UN BINOMIO, CUBO DI BINOMIO, SOMM*DIFF, DIFF DI CUBI, RACCOGLIMENTI, RACCOGLIMENTO PARZIALE, TRINOMIO SPECIALE¬†\n\n\n FRATTE, PARABOLE, parabola cubica, SISTEMI\n\n\nLimiti:¬†\n\n Sostituzione\n Forme Indet\n Limiti notevoli\n Hopital\n Successioni\n Teorema degli zeri\n Funz continue\n Nepero\n Destro e sinistro\n Confronto\n\nDerivate:¬†al 10/05/2024 manca = date(2024-05-10) - date(today)\n\n Derivate notevoli\n Formule\n Hopital\n Fermat\n\nIntegrali:¬†20/05/2024 manca = date(2024-05-20) - date(today)\n\n Primitiva\n Definiti/indefiniti\n Per sostituzione e per parti\n Integrali fratti\n Integrale improprio\n Confronto\n Equi asintotica\n Taylor\n\nStudio funzione(lez.14)¬†\n\n\n Dominio¬†\n\n\n Continuit√† e Simmetrie e segno(se chiesto)¬†\n\n\n Limiti agli estremi di D e asintoti¬†\n\n\n Derivata prima,\n\n\n Crescenza decrescenza\n\n\n Massimo e minimo (rel e ass)\n\n\n Derivata seconda se richiesto\n\n\n Convessit√† concavit√†\n\n\n Punti di flesso¬†\n\n\nN. complessi e serie numeriche:¬†\n\n\n Serie numeriche,¬† geometriche, telescopiche, armonica,radice, rapporto, confronto e confronto asintotico e confronto integrale¬†\n\n\n Somma cartesiana, somma prodotto coniugato e modulo, divisione, forma esponenziale, formula di eulero, potenze, radici n-esime¬†\n\n\n Calcolo differenziale\n\n"},"UNI/ANNO-1/ANALISI-1/STUDIO-DI-FUNZIONE":{"slug":"UNI/ANNO-1/ANALISI-1/STUDIO-DI-FUNZIONE","filePath":"UNI/ANNO 1/ANALISI 1/STUDIO DI FUNZIONE.md","title":"STUDIO DI FUNZIONE","links":[],"tags":[],"content":""},"UNI/ANNO-1/ANALISI-1/TEOREMI":{"slug":"UNI/ANNO-1/ANALISI-1/TEOREMI","filePath":"UNI/ANNO 1/ANALISI 1/TEOREMI.md","title":"TEOREMI","links":["TEOREMA-DEGLI-ZERI"],"tags":[],"content":"I PI√ô IMPORTANTI\nTEOREMA DEGLI ZERI\nteorema di fermat\nbolzano\nweirestrass\nlimiti di successioni e sottosuccessiobi\nteorema ponte\nproblema di lagrange\ncauchy\nhopiyal\npolinomio di taylor e o piccolo\nderime ribout\ncalcolo fondamentale integrali\nteorema degli integrali fratti\nteorema del confronto\nconfronto asintotico\nle serie tra cui leibniz"},"UNI/ANNO-1/ANALISI-1/Taylor-svolgimenti":{"slug":"UNI/ANNO-1/ANALISI-1/Taylor-svolgimenti","filePath":"UNI/ANNO 1/ANALISI 1/Taylor svolgimenti.md","title":"Taylor svolgimenti","links":[],"tags":[],"content":"\n\n  \n  \n    \n      @font-face {\n        font-family: Excalifont;\n        src: url(data:font/woff2;base64,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);\n          }\n    \n    \n            \n          \n        \n  \n  Espansione con tangente\nCOME TROVARE IL TAYLOR DI QUALCOSA\n\n  \n  \n    \n      @font-face {\n        font-family: Excalifont;\n        src: url(data:font/woff2;base64,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);\n          }\n    \n    \n            \n          \n        \n  \n  FAI DERIVATA FINO ALLA TUA TPOI APPLICHI LA FORMULA DOVE LA K RAPPRESENTAIL NUMERO DI DERIVAZIONE"},"UNI/ANNO-1/ANALISI-1/WEIRESTRASS-BOLZANUNGZ":{"slug":"UNI/ANNO-1/ANALISI-1/WEIRESTRASS-BOLZANUNGZ","filePath":"UNI/ANNO 1/ANALISI 1/WEIRESTRASS BOLZANUNGZ.md","title":"WEIRESTRASS BOLZANUNGZ","links":[],"tags":[],"content":"se hai una successione limitata allora esiste una sottosuccessione che √® convergente\nTEOREMA SOLO DI DIRE STRAITS FORWARS\nhai una funzione che √® in un insieme limitato [a,b]  esisteranno un x_{min} e un x_{max} che sono \\in [a,b] che chiuderanno la nostra funzione come un paninetto del subway surfers\n\n\nse f √® continua in [a,b] per il teorema dei valori intermedi e di weersausts f assume tutti i valori compresi tra il valore maxximus e il valore minimus tipo il seno\n\nXMAX BUON NATALE DEFINIZIONE DIMOSTRATA\nvogliamo dimostrare l‚Äôesistenza di una x che ritorna il max della funzione\ndiciamo che la nostra M √® uguale al sup di una funzione definita in [a,b]\nla nostra M pu√≤ avere 2 valori:\n\n+\\infty vuol dire che tu hai una qualsiasi x_n che √® sempre maggiore di una qualsiasi n che hai appartenente ai naturali positivi come un cane che si rincorre la coda\nR continuare pois\n"},"UNI/ANNO-1/ANNO-1-INDICE":{"slug":"UNI/ANNO-1/ANNO-1-INDICE","filePath":"UNI/ANNO 1/ANNO 1 INDICE.md","title":"ANNO 1 INDICE","links":["ciao/content/","UNI/ANNO-1/ANALISI-1/ANALISI-1-INDICE","UNI/ANNO-1/PROGRAMMAZIONE/Programmazione-INDICE","UNI/ANNO-1/DISCRETA/Discreta-INDICE","UNI/ANNO-1/LOGICA/Logica-INDICE","UNI/ANNO-1/ARCHITETTURA/Architettura-INDICE","UNI/ANNO-1/GEOMETRIA/GEOMETRIA-INDICE"],"tags":[],"content":"home\nAnalisiüìà\necco qua:ANALISI 1 INDICE\n\nriassunti‚ùå\nesercizi‚ùå\n\nProgrammazioneüíª\neccoci qua:Programmazione INDICE\n\nriassunti ‚úÖ\nesercizi ‚ùå\n\nDiscreta üßÆ\neccoci qua:Discreta INDICE\n\nriassunti‚ùå\nesercizi ‚ùå\n\nLogica e Reti Logicheüß†\neccolo qui:Logica INDICE\n\nriassunti ‚úÖ\nesercizi ‚ùå\n\nArchitettura dei sistemi di elaborazioneüéõ\neccolo qua:Architettura INDICE\n\nriassunti ‚úÖ\nesercizi ‚úÖ\n\nGeometria üìê\nesercizi meccanici:GEOMETRIA INDICE\n\nriassunti‚ùå\nesercizi ‚úÖ\n"},"UNI/ANNO-1/ARCHITETTURA/Architettura-INDICE":{"slug":"UNI/ANNO-1/ARCHITETTURA/Architettura-INDICE","filePath":"UNI/ANNO 1/ARCHITETTURA/Architettura INDICE.md","title":"Architettura INDICE","links":["UNI/ANNO-1/ARCHITETTURA/ESERCIZI/ESERCIZI-ARM","ciao/content/UNI/ANNO-1/ARCHITETTURA/LISTA-ARGOMENTI","UNI/ANNO-1/ARCHITETTURA/LEZIONI/1.INTRODUZIONE","UNI/ANNO-1/ARCHITETTURA/LEZIONI/2.Organizzazione-sistemi-di-calcolo","UNI/ANNO-1/ARCHITETTURA/LEZIONI/3.Le-memorie","UNI/ANNO-1/ARCHITETTURA/LEZIONI/4.Input-Output","UNI/ANNO-1/ARCHITETTURA/LEZIONI/5.Algebra-Booleana","UNI/ANNO-1/ARCHITETTURA/LEZIONI/6.Livello-Logico-Digitale","UNI/ANNO-1/ARCHITETTURA/LEZIONI/7.Livello-logico-digitale(2)","UNI/ANNO-1/ARCHITETTURA/LEZIONI/8.Architettura-ARM","UNI/ANNO-1/ARCHITETTURA/LEZIONI/9.PROGRAMMARE-IN-ARM","UNI/ANNO-1/ARCHITETTURA/LEZIONI/10.Micro-architettura-e-Macro-architettura","UNI/ANNO-1/ARCHITETTURA/LEZIONI/11.-MACRO-ARCHITETTURA-+-Linguaggio-assemblativo","UNI/ANNO-1/ARCHITETTURA/LEZIONI/12.-Architetture-per-il-calcolo-parallelo(parte-1)","UNI/ANNO-1/ARCHITETTURA/LEZIONI/13.-Architetture-per-il-calcolo-parallelo(parte-2)","UNI/ANNO-1/ARCHITETTURA/LEZIONI/14.sistemi-operativi","UNI/ANNO-1/ARCHITETTURA/ESERCIZI/HAMMING-CODE"],"tags":[],"content":"# ARRIVARE 15 MINUTI PRIMA\n\nsistemi di numerazioni ed algebra di boole\nsistemi digitali e codifica\narchitettura ARM\nprogrammazione in ARM\nB√∂hm-Jacopini dice che posso non scrivere porcherie e che posso scrivere cose strutturate, in modo strutturato\ntipo di architettura:ARM7\nLISTA ARGOMENTI\n\n\n\n                  \n                  # 1.INTRODUZIONE\n                  \n                \n\nargomenti\n\ndominio digitale e analogico\nlinguaggi, livelli e macchine virtuali\nevoluzione delle architetture di computer\ntipologie di computer\nstoria della famiglia intel\nunit√† metriche\n\n\n\n\n\n                  \n                  # 2.Organizzazione sistemi di calcolo\n                  \n                \n\nargomenti\n\nprocessori\nmemoria principale\n\n\n\n\n\n                  \n                  # 3.Le memorie\n                  \n                \n\nargomenti\n\ngerarchie delle memorie\nhard disk e supporti di memoria\n\n\n\n\n\n                  \n                  # 4.Input-Output\n                  \n                \n\nargomenti:\n\nmobo\nbus, tipologie ed evoluzioni\ninput-output\ncaratteri\n\n\n\n\n\n                  \n                  # 5.Algebra Booleana\n                  \n                \n\n\nAlgebra di Boole\nPorte logiche\n\n\n\n\n\n                  \n                  # 6.Livello Logico Digitale\n                  \n                \n\n\nflip flop, latch e varie porte logiche\n\n\n\n\n\n                  \n                  # 7.Livello logico digitale(2)\n                  \n                \n\n\nvarie cpu partendo dal pentium fino all‚Äôi7\nvari microcontrollori\n\n\n\n\n\n                  \n                  # 8.Architettura ARM\n                  \n                \n\n\nintroduzione all‚Äôargomento\nspiegazione di registri, indirizzamenti e shift\nvarie istruzioni in ARM\n\n\n\n\n\n                  \n                  # 9.PROGRAMMARE IN ARM\n                  \n                \n\n\nguida sulla programmazione\nschemi DNS ecc‚Ä¶\n\n\n\n\n\n                  \n                  # 10.Micro-architettura e Macro-architettura\n                  \n                \n\n\nsezione dedicata alla micro architettura che √® un livello dell‚Äôarchitettura\nprima parte della macro architettura\n\n\n\n\n\n                  \n                  # 11. MACRO ARCHITETTURA + Linguaggio assemblativo\n                  \n                \n\n\nseconda parte della macro architettura\nlinguaggio assemblativo il livello 4\n\n\n\n\n\n                  \n                  # 12. Architetture per il calcolo parallelo(parte 1)\n                  \n                \n\n\nsoluzioni per eseguire calcoli in modo parallelo\n\n\n\n\n\n                  \n                  # 13. Architetture per il calcolo parallelo(parte 2)\n                  \n                \n\n\n\n                  \n                  # 14.sistemi operativi\n                  \n                \n\npaging memorie e scheduling\n\n\n\n\n                  \n                  # lista di esercizi \n                  \n                \n\nHAMMING CODE\nESERCIZI ARM\n\n"},"UNI/ANNO-1/ARCHITETTURA/ESERCIZI/ESERCIZI-ARM":{"slug":"UNI/ANNO-1/ARCHITETTURA/ESERCIZI/ESERCIZI-ARM","filePath":"UNI/ANNO 1/ARCHITETTURA/ESERCIZI/ESERCIZI ARM.md","title":"ESERCIZI ARM","links":["UNI/ANNO-1/ARCHITETTURA/ESERCIZI/ESERCIZI-ARM"],"tags":[],"content":"lista di esercizi in arm\nclicca qui per quelli del simonetta\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCondizioneDescrizioneFlag CoinvoltiEQEqual (Uguale)Z=1NENot Equal (Non uguale)Z=0CS/HSCarry Set/Unsigned Higher or SameC=1CC/LOCarry Clear/Unsigned LowerC=0MIMinus/NegativeN=1PLPlus/Positive or ZeroN=0VSOverflow SetV=1VCOverflow ClearV=0HIUnsigned HigherC=1 &amp; Z=0LSUnsigned Lower or SameC=0 or Z=1GESigned Greater Than or EqualN=VLTSigned Less ThanN‚â†VGTSigned Greater ThanZ=0 &amp; N=VLESigned Less Than or EqualZ=1 or N‚â†V\nEsercizi nostri\nn.1(nostro)\n\n\n                  \n                  Scrivi un programma che scambia i valori di due registri. \n                  \n                \n\nMOV R0,#10\nMOV R1,#5\nMOV R2,R0\nMOV R0,R1\nMOV R1,R2\nMOV R3,#0\n\n\nn.2(nostro)\nAddizione di Numeri:\n\n\n                  \n                  Scrivi un programma che somma due numeri e salva il risultato in un altro registro. \n                  \n                \n\nMOV R1,#10\nMOV R2,#5\nADD R0,R1,R2\n\n\nn.3(nostro)\n\n\n                  \n                  Scrivi un programma che usa un&#039;istruzione di salto per bypassare alcune operazioni. \n                  \n                \n\nMOV R1,#1\nMOV R2,#1\nCMP R1,R2\nBNE skip  //Branch if Not Equal\nMOV R3,#9\nskip:\nMOV R3,#6\n\n\nn.4(nostro)\n\n\n                  \n                  Scrivi un programma che confronta due numeri e, se il primo numero √® maggiore del secondo, somma un terzo numero al primo. Altrimenti, sottrai il terzo numero dal secondo. \n                  \n                \n\nMOV R0,#1\nMOV R1,#2\nMOV R3,#10\nCMP R0,R1\nBGT somma //Branch if Greater than\nSUB R1,R3\nB skipsom\nsomma:\nADD R0,R3\nskipsom:\nMOV R4,#5\n\n\nn.5(nostro)\n\n\n                  \n                  Scrivi un programma che confronta due numeri e, se il primo numero √® minore o uguale al secondo, moltiplica il primo numero per un fattore specificato. Altrimenti, somma una costante al secondo numero. \n                  \n                \n\nMOV R0,#3\nMOV R1,#2\nMOV R3,#2\nCMP R0,R1\nBLE skip     // Branch if less or equal\nADD R1,R1,R3\nB skimul\nskip:\nMUL R0,R0,R3\nskimul:\n// continuo condizione\n\n\nn.6(nostro)\n\n\n                  \n                  Scrivi un programma che sottrae il secondo numero dal primo e, se il risultato √® negativo, moltiplica il secondo numero per un fattore specificato. Se il risultato √® positivo o zero, incrementa il primo numero di una costante. \n                  \n                \n\nMOV R0,#1\nMOV R1,#2\nMOV R3,#0\nMOV R5,#5\nSUB R4,R0,R1\nCMP R3,R4\nBGT skip   //maggiore Greater Than (se 0 √® maggiore di R0-R1 skip)\nADD R0,#1\nB nomult\nskip:\nMUL R1,R5\nnomult:\n\n\nn.7(nostro)\n\n\n                  \n                  Scrivi un loop che decrementa un registro finch√© non raggiunge zero. \n                  \n                \n\nMOV R0,#3\nwhile:\nCMP R0,#0\nBLE skip   // branch if LESS or EQUAL R0&lt;=0\nSUB R0,R0,#1\nB while\nskip:\n\n\nn.8(nostro)\n\n\n                  \n                  Creare un programma che confronta due numeri memorizzati nei registri R0 e R1. A seconda del risultato del confronto, il programma eseguir√† diverse operazioni aritmetiche: Se R0 √® maggiore di R1, incrementare R2. Se R0 √® uguale a R1, decrementare R2. Se R0 √® non uguale a R1, moltiplicare R2 per 2. Se R0 √® minore di R1, dividere R2 per 2 (per semplicit√†, assumiamo una divisione intera). \n                  \n                \n\nEsercizi Simonetta\nn.1(libro)\n\n\n                  \n                  creare un esercizio che faccia la divisione senza usare la divisione in ARM \n                  \n                \n\nMOV R1, #10\nMOV R2, #5\nMOV R3, #0\nWHILE:\nCMP R1,R2\nBLT continua\nSUB R1,R2\nADD R3,#1\nB WHILE\ncontinua:\n\n\nn.2(libro)\n\n\n                  \n                  creare un esercizio che faccia la moltiplicazione senza usare la MUL in ARM \n                  \n                \n\nMOV R1, #10\nMOV R2, #5\nMOV R3,#0\nWHILE:\nCMP R2,#0\nBEQ continua\nADD R3,R3, R1\nSUB R2,#1\nB WHILE\ncontinua:\n\n\nn.3(libro)\n\n\n                  \n                  creare un esercizio che faccia la potenza senza la potenza \n                  \n                \n\nMOV R1, #0\nMOV R2, #0\nMOV R0,R1\nCMP R1,#0\nBEQ case0\nCMP R2,#0\nBEQ case1\nWHILE:\nCMP R2,#1\nBLT continua\nMUL R0,R0,R1\nSUB R2,#1\nB WHILE\ncase0:\nCMP R2,#0\nBEQ case3\nMOV R0,#0\ncase3:\nMVN R0,#0\nB continua\ncase1:\nMOV R0,#1\ncontinua:\n\n\nn.4(libro)\n\n\n                  \n                  creare un esercizio che fa una somma degli elementi di un array \n                  \n                \n\n.data  // entriamo nella sezione di data dove li creiamo\narray: .word 3,4,5,6   // ci creiamo un array con il nome che ci pare poi con .word per creare delle\nword\n.global _start //tipo il main  \n_start:      // tipo il main\nLDR R0,=array     // facciamo una load in R0 della nostra struttura dell&#039;array\nLDR R2,[R0]       // facciamo una load del primo elemento di R0 in R2 per salvarcelo\nMOV R4,#0         // creiamo il nostro registro che salver√† la somma\nCMP R2,#0         // compare per verificare se il primo elemento √® minore a zero, pk lo prevede la\npre cond\nBLT fine   \t\t  // branch a etichetta fine\n//LSL R3,R2,#4     // per salvarci l&#039;ultimo offset dell&#039;array in R3 facciamo uno shift a sinistra di 4\nposizioni??\nMOV R1,#0        // R1 sar√† il nostro offset\nwhile:\nLDR R2,[R0,R1]   // per scorrere stiamo dicendo che il nostro R2 √® la somma di R0+R1\nADD R4,R2        // salviamo in R4 R2\nADD R1,#4        // per andare ai numeri successivi sommiamo R1 con 4 N.B indirizzo di base non\ncambia l&#039;offset\nCMP R1,#12\t     // confronta il massimo valore possibile con l&#039;offset attuale per capire se deve\nfermarsi\nBLE while\nfine:\n\n"},"UNI/ANNO-1/ARCHITETTURA/ESERCIZI/HAMMING-CODE":{"slug":"UNI/ANNO-1/ARCHITETTURA/ESERCIZI/HAMMING-CODE","filePath":"UNI/ANNO 1/ARCHITETTURA/ESERCIZI/HAMMING CODE.md","title":"HAMMING CODE","links":[],"tags":[],"content":"A cosa serve?\nserve a rilevare e corregere errori in un alfabeto di bit\nCOME SI SVOLGE UN ESERCIZIO DI CORREZIONE DI HAMMING?\nFacciamo un esempio:\n"},"UNI/ANNO-1/ARCHITETTURA/ESONERO-PART2":{"slug":"UNI/ANNO-1/ARCHITETTURA/ESONERO-PART2","filePath":"UNI/ANNO 1/ARCHITETTURA/ESONERO PART2.md","title":"ESONERO PART2","links":[],"tags":[],"content":"PRATICA\n\nESERCIZIO SUGLI INDIRIZZAMENTI(73)\nEsercizio dei processi e il carico della CPU(1)\nSISTEMI BATCH\n\nfirst come first\nshortest job first\nshortest remaining next\n\n\nINTERATTIVI\n\nround robin\nlotteria\nShortest process next\n\n\nREAL TIME\n\nSono soft e hard(sostenibilita del sistema) sono piu o meno rigidi\n\n\nRICHIESTE SU DISCO\n\nFirst come first served\nShortest seek first\nAscensore\n\n\nGESTIONE DELLA MEMORIA\n\nmemoria libera\n\nlista collegata\nbitmap\n\n\nbest fit\nfirst fit\nnext fit\nworst fit\n\n\nGESTIONE DELLE PAGINE\n\nottimo\nleast recently used\nnot recently used\nnot frequently used\nclock\nworking set\nwsclock\naging\nsecond chance\nfifo\n\n\n"},"UNI/ANNO-1/ARCHITETTURA/LEZIONI/1.INTRODUZIONE":{"slug":"UNI/ANNO-1/ARCHITETTURA/LEZIONI/1.INTRODUZIONE","filePath":"UNI/ANNO 1/ARCHITETTURA/LEZIONI/1.INTRODUZIONE.md","title":"1.INTRODUZIONE","links":["tags/pagina31"],"tags":["pagina31"],"content":"Argomenti\n\ndominio digitale e analogico\nlinguaggi, livelli e macchine virtuali\nevoluzione delle architetture di computer\ntipologie di computer\nstoria della famiglia intel\nunit√† metriche\n\nAnalogico\n\nle info intorno a noi sono analogiche, suoni, colori, tatto‚Ä¶\nle informazioni di memoria venivano memorizzate in modo analogico(vinile)\n\nDigitale\n\ninformazioni vengono codificate attraverso dei valori discreti\n\n\n\n                  \n                  i valori discreti possono dare gli stessi dati dei valori continui(analogici)? \n                  \n                \n\nteorema del campionamento\nquei campioni se vengono selezionati in un intervallo breve quando ricostruiamo il segnale non\nperdiamo informazioni, tipo il ping nei giochi\n\n\nConversioni tra domini\n\nIl computer √® una macchina elettronica digitale in grado di risolvere problemi attraverso un insieme di istruzioni assegnate (il programma)\n\nil calcolatore usa 0 e 1\nil calcolatore ha una cpu\n\nil problema della distanza concettuale\nil calcolatore √® composto da layer fino a quando non raggiunge un livello che √® comprensibile dall‚Äôessere umano\nmacchine e linguaggi via via pi√π sofisticati tra layer e layer\n\n\n\n                  \n                  Tip\n                  \n                \n\nL=linguaggio\nM=macchina\n\n\n\ntraduzione:\n\nun modo per eseguire un programma scritto in L1 √® sostituire ogni istruzione di L1 in L0 e viene definita traduzione\nil programma L1 √® tradotto nel linguaggio L0 e funziona esclusivamente su quella determinata M\nL1 pu√≤ essere eliminato una volta che viene tradotto in L0\n\n\ninterpretazione:\n\nquando hai un programma in L0 che accetta input da L1, le istruzioni verranno eseguite man mano e ci sar√† un interprete che le cambier√†\nL1 e L0 sono entrambi utili perch√© vengono usati allo stesso tempo\n\n\n\nLa Cipolla\nSi crea uno schema a cipolla con una gerarchia di linguaggi astratti e macchine virtuali corrispondenti\nogni programma del livello n deve essere tradotto per il livello n-1\n\nArchitettura multilivello attuale\n\nlinguaggi ad alto livello: c++, java ecc‚Ä¶\nlinguaggio assemblativo che usano i programmatori(assembly)\n√® un mix di istruzioni che vengono eseguite o dal microprogramma o dal sistema operativo, una sorta di ponte tra i due\nmicroprogramma, controlla le operazioni nel percorso dei dati e le interpreta\nmicro-architettura, la memoria locale √® fatta di collezioni di 8-32 registri, quest‚Äôultimi sono connessi all‚ÄôALU attraverso un percorso dati(data path)\nparte fisica, porte logiche e i registri(combo di porte logiche)\n\nLivelli 4 e 5 sono del programmatore\nlivelli da 0 a 3 pi√π linguaggio macchina\n\n\n\n                  \n                  cosa √® l&#039;ALU? \n                  \n                \n\nALU(arithmetic logic unit) esegue le operazioni aritmetiche e logiche\n\n\nDifferenza tra Hardware e Software\n\nHardware tangibile\nsoftware intangibile, astratto\n\nHw e Sw sono logicamente equivalenti qualsiasi operazione fatta dal software pu√≤ essere svolta dal‚ÄôHw e viceversa\nUn po‚Äô di storia:\n\n1940 i primi computer digitali con solo due livelli, ISA e livello logico digitale\n1951  si pass√≤ a computer a 3 livelli\n1960 invenzione sistema operativo un software in grado di gestire l‚Äôhardware\n1970 utilizzo di micro-codice permise la creazione di istruzioni pi√π efficienti per programmare\n\nLe varie generazioni di computer:\nComputer di generazione zero:\nerano meccanici come:\n\nla macchina di Pascal che svolgeva somme e sottrazioni\nmacchina di Leibniz che svolgeva moltiplicazioni e divisioni\nla macchina analitica di Babbage che legge e scrive dati nelle schede perforate tipo con delle matrici con fori attraverso un foto-diodo che con le luci indicava 0 e 1\nprimi computer a rel√® con mark 1 e mark 2, con i segnali elettrici che indicano 0 e 1\n\nPrima generazione:\n\nComputer Colossus utilizzato da turing a valvole termoioniche 1945\nMacchina di Von Neumann IAS ha una ALU che usa il registro accumulatore per fare le operazioni, memoria, CU(control unit), input e output\n\nSeconda generazione:\nUso di transistor digitali e non analogica\n\nTX-0 e PDP-1 sfruttavano i bus(insieme di linee condivise tra i vari componenti del calcolatore) tra transistor e bus abbiamo una vera e propria architettura ‚Äúmoderna‚Äù, con comunicazione multipla\nomnibus primo pc che usava il bus\n\nCosa √® il bus?\nti permette di far comunicare ogni componente direttamente da un‚Äôunico flusso\n\ncondividere un unico bus rende le macchine scalabili al posto di fare un intreccio.\nandiamo incontro al corto circuito perch√® bisogna sincronizzare le comunicazioni, se due componenti parlano allo stesso tempo si fotte tutto ESPLODEE AIUTOOOO!!!!!! perch√® si mixano delle tensioni diverse(concetto master-slave)\nTerza generazione:\n\ncircuiti integrati 1965-1980 ibm system/360, pdp-11\n\nQuarta generazione:\n\n(very large scale integration) 1980-? con tecnologia VLSI si stampano milioni di transistor su un singolo chip / IBM pc, apple Lisa intel 8080 8088 80386, arrivano alle case di tutti con floppy disk\n\nQuinta generazione:\n\ncomputer invisibili in elettrodomestici, orologi, carte di credito, giocattoli\n\nlegge di Moore\n\n\n                  \n                  Dice che il numero dei transistor nei componenti raddoppia ogni 18 mesi fino agli anni 2000 poi per problemi di surriscaldamento, consumi e altro non √® pi√π attuale questa legge \n                  \n                \n\n\n\n\n                  \n                  Per risolvere il problema si decise di fare pi√π core con architetture multi core pi√π cpu insieme, pi√π core ‚â† pi√π potenza perch√® dipende da come lo gestisce il SO e dalla sincronizzazione tra questi core \n                  \n                \n\ntipologie di computer\n\nComputer usa e getta: chip all‚Äôinterno di cartoline di auguri che hanno un basso costo chip RFID\nMicro-controllori: computer che non sono elaboratori(elettrodomestici, giocattoli)\nDispositivi mobili e da gioco: macchine con capacit√† grafiche e sonore, non espandibili e non programmabili dall‚Äôutente\nPersonal computer: macchine destinate all‚Äôinformatica individuale\nServer: computer potentissimi che si connettono alla rete con alta velocit√† e sono, mono o multi-processore dotate di hard disk capienti\nCluster: insieme di server connessi insieme da reti\nMainframe : computer un tempo super potente ormai obsoleto usato da banche e inail\n\nLa storia di intel\nNel 1968 costru√¨ il primo chip 4004 in silicio\nla frequenza non √® sempre indice di velocit√† soprattutto su architetture diverse.\nOgni chip ha una memoria, a che serve?\n√® una memoria molto veloce che memorizza elementi vicini ad uno specifico che ci serve cos√¨ da raggiungerlo in fretta, se ripeto un‚Äôistruzione e la ho nella memoria della cpu andr√† pi√π veloce\nuna memoria per ogni singolo core, una memoria per mettere d‚Äôaccordo tutti i core\npi√π potenza significa pi√π tensione e pi√π calore difficile da smaltire\nle unit√† metriche\nfoto delle unit√† metriche\nper i dati si usa base due\n1kb di memoria contiene 1024 Byte non 1000 Byte\n\nesercizi sul suo libro che si possono fare:\n\nesercizi sui sistemi di enumerazione\nalgebra di boole\nsistemi di emning bho\n\nStack pila architettura dei livelli\nlivello astratto hai una visione astratta attraverso una sintesi di quello che c‚Äô√® sotto, guidi la macchina con volante frizione ecc‚Ä¶ information hiding(interfaccia), quando applichi il metodo passi i parametri ma non vedi l‚Äôalgoritmo\npagina31"},"UNI/ANNO-1/ARCHITETTURA/LEZIONI/10.Micro-architettura-e-Macro-architettura":{"slug":"UNI/ANNO-1/ARCHITETTURA/LEZIONI/10.Micro-architettura-e-Macro-architettura","filePath":"UNI/ANNO 1/ARCHITETTURA/LEZIONI/10.Micro-architettura e Macro-architettura.md","title":"10.Micro-architettura e Macro-architettura","links":["UNI/ANNO-1/LOGICA/Logica-INDICE"],"tags":[],"content":"Il livello di Micro-architettura fornisce le risorse al livello ISA e si trova ad un livello pi√π alto di quello logico digitale, la micro-architettura svolge il compito di definire istruzioni per la gestione della CPU come istruzioni per la cache, gestione della memoria, operazioni matematiche(servendosi della ALU)\n\nEsistono diversi tipi di ISA su cui si collega il livello di micro architettura, noi a scopo didattico useremo un sottoinsieme della Java Virtual Machine IJVM\ne un microprogramma in una ROM\nil microprogramma si compone da microistruzioni con l‚Äôuso di variabili\n\nPC(Program Counter) contiene il riferimento della prossima microistruzione\nOPCODE √® il codice identificativo del tipo di microistruzione\nci sono anche gli operandi\n\nModello di esecuzione\nil modello √® il Fetch-Decode-Excecute\n\nFetch: carica dell‚Äôistruzione\nDecode: decodifica dell‚Äôistruzione\nExcecute: Esecuzione dell‚Äôistruzione\n\n\nIl Data Path\ndall‚Äôinglese Percorso Dati, √® quella parte della CPU che gestisce input, output, registri e ALU\n√® composto da:\n- registri(32 bit) che si relazionano e controllano la memoria(PC, MDR, MAR, MSR)\n\nci sono due bus B e C\nGli operandi della ALU sono A e B, B prende i dati dal BUS B invece A da un registro chiamato H che prende i dati dal bus C\ndopo l‚Äôoutput della ALU abbiamo uno shifter che pu√≤ fare le sue operazioni per modificare i dati\nci sono due tipi di segnali di controllo uno dove la scrittura avviene sul Bus B e l‚Äôaltro dove il Buc C scrive nel registro\n\n\nI registri:\n\nMAR memory address register\nMDR Memory Data Register\nMBR Memory Byte Register √® un registro che salva man mano l‚Äôesecuzione delle istruzioni che si trovano nella memoria centrale\nSP Stack Pointer, √® un puntatore che punta all‚Äôindirizzo dello stack\nLocal Variable(LV) riferimento delle Variabili locali all‚Äôinterno dello stack\nConstant pool(CPP) raccolta di costanti con numeri e stringhe\nTop word on the stack(TOS)\nOp Code register(OPC):Registro temporaneo che tiene l‚Äôultima istruzione prima di eseguire un Branch\nHolgind(H) riceve i dati dal Bus C e invia i dati all‚Äôoperando A\n\nALU(Aritmetic Logic Unit)\nLa ALU ha sei linee di controllo(modi per svolgere operazioni con operandi)\n\nF0 e F1 permettono di distinguere l‚Äôoperazione\nENx abilita la determinata variabile A o B\nINVA sottrae la variabile A\nINC incrementa\n\n\nFormato delle microistruzioni\nda cosa sono fatte le microistruzioni che controllano il microprocessore?\nle microistruzioni hanno delle funzioni di base che permettono di facilitare il lavoro in un microprogramma:\n\nADDR questa funzione ci permette di ricevere l‚Äôindirizzo della potenziale successiva istruzione\nJAM determina in base a quale criterio va selezionata la prossima istruzione\nALU sceglie cosa far fare alla ALU\nC comunica quali registri sono sul bus C\nMem seleziona eventuali funzioni da svolgere sulla memoria\nB comunica quali registri sono sul bus B\n\n\nESEMPIO DI MICROARCHITETTURA LA MIC-1\nla micro architettura, oltre ad avere le cose trattate prima, ha una memoria di controllo e un decoder:\n\nmemoria di controllo: memorizza le microistruzioni da eseguire\ndecoder: decodifica partendo da un OPCODE il tipo di istruzione da eseguire\nall‚Äôinterno della microarchitettura mic-1 le istruzioni presenti nella memoria centrale vengono eseguite nell‚Äôordine in cui vengono memorizzate(a meno che ci siano salti)\nogni microistruzione definisce quale microistruzione dover eseguire successivamente\nla memoria di controllo ha un indirizzo program counter(MPC) e uno IR(MIR)\n\n\nIl funzionamento del Mic-1\nil Mic-1 funziona scandito da un clock ogni ciclo di clock inizia con un fronte in discesa(1 a 0)\nil MIR viene caricato dalla parola indirizzata dal MPC dopo aver finito questa cosa il data path una volta iniziato il suo ciclo si prepara ad inviare attraverso il bus B e il registro H l‚Äôinvio degli operandi per far eseguire il calcolo alla ALU oltre a l‚Äôinvio della funzione richiesta dopo che la ALU ha fatto il suo calcolo manda sul bus C il risultato e una volta raggiunto il fronte in salita i registri vengono caricati sul fronte di salita vengono aggiornati anche i bit di stato N e Z\n\nEsempio di ISA:IJVM\nLo STACK\n√à una struttura dati utilizzata dalla IJVM √® una parte della memoria dove ogni dato viene impilato e possono essere inseriti o prelevati solo sulla sua cima, √® di tipo LIFO(last in first out)\novvero l‚Äôultimo da inserire √® il primo ad uscire\npu√≤ essere usato per salvare variabili locali per procedure(procedure), passaggio di parametri o tenere operandi per fare espressioni aritmetiche\ncon lo stack ci si possono fare due operazioni:\n\nPush: scrittura sulla parte sopra dello stack\nPop: estrazione del dato sopra lo stack(lettura)\n\n\n\nnulla\npush j\npush k\npop k\npop j\nesempi di stack con utilizzo di SP e LV\n\nun esempio di utilizzo di SP e LV √® per fare una operazione di pop dove abbiamo bisogno sia di uno che dell‚Äôaltro per ritagliare quel pezzo \n\nMemoria del IJVM\noltre allo stack la IJVM usa altre quattro aree della memoria\n\nCPP(constant pool) dove ci sono tutte le costanti\nBlocco delle variabili locali, dove vengono salvate le variabili dei metodi ‚Äúfunzioni‚Äù\nStack degli operandi\nArea dei metodi, dove ci sono tutte le funzioni del programma\nle istruzioni della ijvm\n\n\nIL LIVELLO DI MACROARCHITETTURA\nil livello di macro architettura riguarda proprio il livello ISA, rappresenta il livello di interfaccia tra il software e l‚Äôhardware,\ncreazione immagine slide num 23\nLIVELLO ISA overview\nIl livello ISA si compone:\nL‚ÄôISA si compone da:\n\nil modello di memoria(come √® fatta la memoria)\ni registri\ntipi di dati utilizzabili\ntutte le istruzioni\nDal livello ISA non √® possibile conoscere il funzionamento della microarchitettura, infatti L‚ÄôISA definisce ‚Äúcosa‚Äù fa una CPU, ma non il ‚Äúcome‚Äù viene fatto specificatamente a livello fisico e logico.\nil livello ISA deve essere retrocompatibile ovvero deve essere in grado di far girare vecchi programmi\nsi divide in 2 modalit√†:\nmodalit√† kernel per eseguire le istruzioni e il SO\nmodalit√† utente per eseguire i programmi dell‚Äôutente\n\nI modelli di memoria\n√® il modo in cui viene suddivisa la gestione della memoria attraverso dei raggruppamenti a 4(32 bit) o 8(64 bit)\nle parole possono esser storate in modo allineato o no\n\ni processori al livello ISA possono avere istruzioni e dati su livelli separati oppure in modo lineare\nI registri\n\nalcuni registri dei livelli sotto a quello ISA non sono leggibili superiormente(tipo TOS e MAR)\nci sono due tipi di registri al livello ISA:\nspecializzati: Program Counter, Stack pointer e quelli visibili in modalit√† kernel(controllo della cache, della memoria, dei dispositivi di I/O e altra roba hardware)\nuso generale: sono utilizzati per memorizzare risultati temporanei delle variabili locali\nc‚Äô√® il registro dei flag(program status word) √® un registro che si interfaccia sia in modalit√† utente che in modalit√†  kernel e sono i seguenti flag:\nN, se il risultato √® negativo si asserisce\nZ, se il risultato √® zero si asserisce\nV, se c‚Äô√® un risultato che genera overflow si asserisce\nC, asserito quando il risultato causa un riporto sul bit significativo\nA, Asserito quando c‚Äô√® un riporto oltre il terzo bit\nP, Asserito quando il risultato √® pari\n\nCome funziona il livello ISA su un core i7\nquesto ISA √® retrocompatibile fino al 8086 e 8088(altre versioni di processori)\nnel corso di questi processori ci sono stati forti cambiamenti di bus indirizzi, di tipi di architettura e di nuove istruzioni.\nIl momento pi√π importante √® avvenuto quando il bus √® stato ampliato a 64 bit creando cos√¨ le architetture x86-64\nCome opera un core i7?\nci sono tre modi in cui opera:\n\nmodalit√† reale: si comporta come un vecchio microprocessore 8088 ma se vengono eseguite istruzioni con errori va in blocco\nmodalit√† virtuale: permette l‚Äôesecuzione di programmi basati su 8088 in modo pi√π protetto e controllato da un vero SO\nmodalit√† protetta: si comporta come un vero e proprio i7(ovvero s√© stesso)\nla memoria √® suddivisa in segmenti da 64kb\n\nChe registri ha in pi√π il Core i7?\nha 4 registri a 32 bit di uso generale(quelli arm ne hanno tipo 15)\n\nEAX, operazioni aritmetiche\nEBX, puntatore a indirizzi di memoria\nECX, puntatore usato per quando si svolgono dei cicli\nEDX, usato per svolgere moltiplicazioni e divisioni usando i prodotti e dividendi insieme a EAX\ntutti questi registri possono essere a 8 o a 16 bit(Extended)\nci sono altri 4 registri a 32 bit che hanno delle caratteristiche specifiche:\nESI e EDI: vengono usati per fare operazioni e trasferimenti su stringhe\nEBP: punta la base dello stack(tipo LV)\nESP: puntatore allo stack(TIPO SP)\nCi sono i registri segmento(tutti a 16 bit) consentono la compatibilit√† con i registri di segmento usati soprattutto in passato con l‚Äô8088\nregistro EIP ovvero PC esteso a 16 bit\nEFLAGS la PSW(program status word) i bit di flag estesi a 16 bit\n\n\nI tipi di dato\ni tipi di dato sono:\n\nnumerici\ninteri\nreali con virgola mobile\nbooleani true o false\nnon numerici tipo:\nASCII o UNICODE\nbitmap(mappa dei bit per le immagini)\npuntatori tipo PC\ni tipi di dato con segno supportano il complemento a dueLogica INDICE\nsi sposta la virgola seguendo la mantissa e l‚Äôesponente\n\nIstruzioni\nle istruzioni sono formate da codice operativo(OPCODE) e da indirizzi per gli operandi(non obbligatori)\n\nCriteri progettuali dei formati di istruzioni\nle istruzioni corte sono preferibili poich√©:\n\nhai programmi con meno istruzioni, pi√π piccoli\nmemorizzi una % pi√π elevata di istruzioni sulla cache\nminimizzarle troppo pu√≤ toglierne la comprensione in fase di decodifica\navere una memoria sufficiente per codificare adeguatamente tutte le istruzioni\ndefinire il numero di bit da utilizzare nell‚Äôindirizzamento di una memoria uno spazio di indirizzamento ampio allunga l‚Äôistruzione.\n\nFormati delle istruzioni del Core i7\nUna istruzione del Core i7 √® formata da:\n\n6 campi(un pezzo di memoria da riempire), di lunghezza variabile\nci sono 2 operandi di cui uno √® sempre un registro l‚Äôaltro pu√≤ anche essere una memoria\nMODE stabilisce la modalit√† di indirizzamento\nl‚Äôindirizzo di memoria dove c‚Äô√® un offset che consente un corretto indirizzamento\nSIB(Scale, Index, Base) √® un bit supplementare\n\n"},"UNI/ANNO-1/ARCHITETTURA/LEZIONI/11.-MACRO-ARCHITETTURA-+-Linguaggio-assemblativo":{"slug":"UNI/ANNO-1/ARCHITETTURA/LEZIONI/11.-MACRO-ARCHITETTURA-+-Linguaggio-assemblativo","filePath":"UNI/ANNO 1/ARCHITETTURA/LEZIONI/11. MACRO ARCHITETTURA + Linguaggio assemblativo.md","title":"11. MACRO ARCHITETTURA + Linguaggio assemblativo","links":["UNI/ANNO-1/ARCHITETTURA/LEZIONI/10.Micro-architettura-e-Macro-architettura"],"tags":[],"content":"MACRO ARCHITETTURA\nModalit√† di indirizzamento\nconosciamo 8 tipi di indirizzamento:\n\nImmediato: Quando il valore dell‚Äôoperando √® direttamente nell‚Äôistruzioni  tipo #5\nDiretto: Quando nell‚Äôistruzione scrivi l‚Äôindirizzo completo dell‚Äôoperando tipo 0x005\nIndiretto: Quando fornisci l‚Äôindirizzo di memoria che contiene l‚Äôindirizzo effettivo dell‚Äôoperando\nA registro: Quando specifichi un Registro come operando\nIndiretto a registro: Quando tu metti un registro che contiene l‚Äôindirizzo dell‚Äôoperando\nIndicizzato: l‚Äôindirizzo √® dato da una costante pi√π il contenuto di un registro quindi tipo con l‚Äôoffset\nA registro base: Viene sommato anzich√® una costante un registro agli indirizzi\nStack: l‚Äôoperando √® sulla cima dello stack\n\nEsempio di somma di array e spostamento di array\nNoi vogliamo scorrere l‚Äôarray e per farlo prendiamo il registro di base e lo sommiamo di volta in volta di 4 byte, R2 ci servir√† per salvare l‚Äôattuale array cos√¨ da poterci poi sommare 4 per scorrere al successivo, R1 salver√† la somma degli elementi e R3 la prima posizione esterna cos√¨ da trovare la fine dell‚Äôarray\n\ncontinuo dell‚Äôesempio\n\n\nCodice auto-modificante\nCos√¨ si chiamano quei codici che nel corso dell‚Äôesecuzione si modificano ad esempio con dei loop\n\nsi pu√≤ notare come nella fase di codice rossa ci sia un add con un registro che cambia nel tempo\nIndirizzamento indicizzato\n√® un indirizzo dato da un indirizzo+ offset\nesempio:\nfa un and bit a bit tra gli array A e B e fa un or tra tutti i risultati\n(A[0] AND B[0]) OR (A[1] AND B[1] ) OR (A[2] AND B[2]) OR...\n\nR1 accumula l‚Äôor tra gli and\nR2 indica la posizione attuale dell‚Äôarray\nR3 indica la fine ovvero 4096 quindi 1025\nR4 usata come variabile d‚Äôappoggio per le AND\n\nINDIRIZZAMENTO INDICIZZATO ESTESO\nl‚Äôindirizzo di memoria √® calcolato sommando due registri:\n\nuno memorizza la base\nl‚Äôaltro l‚Äôindice\ninizializziamo R5 con A e R6 con B\n\nMOV R4,(R2+R5)\nAND R4,(R2+R6)\nSTACK\n^347d6f\ncosa da aggiungere:\nal top dello stack in una operazione aritmetica hai il secondo operando e sotto hai il primo operando\nNOTAZIONE POLACCA POSTFISSA\n√à un sistema per scrivere in modo differente espressioni matematiche senza l‚Äôuso di parentesi\nil segno v√† dopo che hai scritto i numeri che ne riguardano\n\nORTOGONALIT√Ä\nUn set di istruzioni √® caratterizzato principalmente da 2 cose:\n\ncodici operativi(OPCODE)\nmodalit√† di indirizzamento\nsi dice ortogonalit√† quando puoi usare tutte le modalit√† di indirizzamento viste in precedenza con tutti i codici operativi, ad esempio sul MUL devi usare per forza dei registri quindi non c‚Äô√® ortogonalit√†\nsu alcune architettura ad esempio quella Intel non √® possibile attuarla\nesempio instruction set ortogonale\n\nISTRUZIONE ORTOGONALE\nISTRUZIONE NON ORTOGONALE\nTIPI DI ISTRUZIONI\n(vedi prossime pagine per approfondimenti)\n\nUNARIE:\n\nAritmetiche: complemento, opposto, incremento, radice,‚Ä¶\nBit a bit: not, shift e rotation.\n\n\nBINARIE:\n\nAritmetiche e logiche\n\n\nTRASFERIMENTO DATI:\n\nDa registro/memoria a registro/memoria\n\n\nSELEZIONE E CONFRONTO\nITERAZIONE\nCHIAMATA DI UNA PROCEDURA\nINPUT/OUTPUT:\n\nPolling, interrupt, DMA\n\n\n\nESEMPIO DI ISTRUZIONE UNARIA\n\ncome viene applicato lo shift??\nscorrere k posizioni a sinistra o destra ad un numero X comporta una potenza  o una divisione\n2^k\nALTRE ISTRUZIONI UNARIE:\n\nCLR, fa il clear di un registro\nINC,  lo incrementa di 1\nNEG, lo trasforma in un numero negativo facendo il complemento a 2\nNOT, nega la variabile\nSQRT, radice quadrata\n\nOPERAZIONI BINARIE\nsi dividono in:\n\nLogiche:\n\nAND, OR, XOR, NAND, NOR\n\n\nAritmetiche:\n\nADD, MULT, DIV, e altre‚Ä¶\n\n\n\nISTRUZIONI DI SELEZIONE\nil modo migliore per scegliere cosa eseguire o meno √® attraverso l‚Äôuso di Branch e  Condizioni dove quest‚Äôultime vengono verificate attraverso la PSW(Program Status Word)\n\nISTRUZIONI DI TIPO ITERATIVO\nCi sono istruzioni che attraverso l‚Äôuso di etichette permettono di creare delle ripetizioni fino al verificarsi di determinate condizioni.\n\nISTRUZIONI DI I/O\nUn‚Äôoperazione di I/O √® una operazione che consiste nel trasferimento di dati in entrata o in uscita da un dispositivo periferico\nESISTONO 3 MODI DI FARE I/O:\n\ncon busy waiting: dove la CPU periodicamente interroga i dispositivi (polling) che rimanendo in attesa(busy waiting) che il dispositivo sia pronto al trasferimento\nI/O gestito con interruzioni: La CPU riceve richieste di trasferimento dai dispositivi attraverso un interrupt\nDMA(Direct Memory Access): La CPU avvia una operazione che viene gestita dal controllore DMA\n\nDMA\nLa CPU programma il controller DMA specificando:\n\nla dimensione che il trasferimento ha in byte\nil dispositivo che bisogna interrogare\nin quale zona di memoria bisogna prendere i dati attraverso un indirizzo\nIl controller gestisce l‚Äôoperazione da solo\nIl DMA pu√≤ gestire pi√π operazioni contemporaneamente\n\n\nIstruzioni del Intel Core i7\n\n\nCONTROLLO DEL FLUSSO\nci sono delle tecniche che pemettono di alterare l‚Äôesecuzione di un programma come:\n\nsalti con o senza condizione\nChiamata di procedure\nCoroutine\nTrap\nInterrupt\n\n\nProcedure\nuna procedura √® una serie di istruzioni(tipo una funzione)\nogni volta che ne viene chiamata una viene allocato sullo stack un nuovo frame dello stack che contiene i seguenti dati:\n\ni parametri in entrata e uscita\nle variabili locali\nl‚Äôindirizzo di rientro (return)\nun puntatore allo stack frame del chiamante\nSP punta alla cima dello stack invece BP alla base del frame creato\nl‚Äôaccesso a variabili locali e parametri avviene attraverso il BP+ un offset\nQuando la procedura termina il frame viene deallocato\nci sono un Master e uno Slave quando si avvia una procedura, la procedura √® lo slave che deve essere chiamata e il master √® colui che chiama questa procedura\n\nTrap\nLa trap √® una procedura atuomatica che si attiva quando avviene una eccezione durante l‚Äôesecuzione di un programma\nla gestione della trap √® affidata alla trap handler\nesempi di trap:\n\noverflow e underflow\nopcode non definito\nviolazione di protezione\ndivisione per zero\ntentativi di utilizzo di dispositivi inesistenti\n\nCOROUTINE\nUna coroutine √® una funzione speciale che pu√≤ essere interrotta e ripresa. A differenza di una funzione normale che inizia dall‚Äôinizio e corre fino al suo completamento quando viene chiamata, una coroutine pu√≤ iniziare la sua esecuzione, poi fermarsi (‚Äúsospendersi‚Äù) in un punto specifico, fare qualcos‚Äôaltro, e poi riprendere l‚Äôesecuzione esattamente da dove si era fermata.\nogni istruzione pu√≤ riprendersi RESUME sono usate per simulazioni parallele su singola CPU\nINTERRUPT\nSono eventi, spesso correlati con I/O, che cambiano il normale flusso di esecuzione.\nA differenza delle trap, sono asincroni e nascono all‚Äôesterno della CPU.\nLa gestione delle interruzioni √® affidata all‚Äôinterrupt handler e la routine di gestione dell‚Äôinterrupt √® chiamata ISR (Interrupt Service Routine)\nalla fine dell‚Äôinterrupt si deve riprendere quello che si stava facendo\nAzioni hardware di gestione dell‚Äôinterrupt\nquando avviene una interrupt vengono svolte delle azioni a livello hardware che sono le seguenti:\n\nil controller del dispositivo genera un interrupt\nquando la CPU √® pronta a ricevere l‚Äôinterrupt gli invia al controller del dispositivo una acknowledge\nquando il controller vede l‚Äôacknowledge risponde con un vettore interruzione identificativo per farsi riconoscere\nla CPU lo legge e se lo salva\nla CPU salva il PC Program counter e la PSW Program status Word sullo stack\nla CPU attraverso il vettore di interruzione capisce la prima istruzione e la mette nel PC\n\nAzioni software di gestione dell‚Äôinterrupt\nDopo aver settato a livello hardware tutte le componenti per gestire l‚Äôinterrupt, ora si passa all‚Äôesecuzione effettiva della routine di servizio:\n\nLa ISR salva sullo stack i registri della CPU per poterli ripristinare\nIndividua il numero esatto del device che ha generato l‚Äôinterruzione tramite la lettura di opportuni registri\nLegge tutte le informazioni relative all‚Äôinterruzione (es. codici di stato)\nGestisce eventuali errori di I/O\nEsegue tutto ci√≤ che √® previsto per la gestione dell‚Äôinterruzione\nSE NECESSARIO informa il device che l‚Äôinterruzione √® stata risolta\nRipristina tutti i registri salvati sullo stack\nEsegue un‚Äôistruzione di RETURN FROM INTERRUPT ripristinando lo stato della CPU precedente l‚Äôinterruzione\n\nQuando ci sono multipli interrupt entra in gioco la loro priorit√†\n\nI problemi di Intel Architecture-32\n\n√à una architettura di tipo CISC\nHa un tipo di indirizzamento a memoria questo vuole dire che molte operazioni e istruzioni nella CPU vengono fatte direttamente sulla memoria del computer piuttosto che tra i registri interni del processore.\nCi sono pochi registri e non regolari:\n\nper essere riordinate serve un hardware complesso\nil fatto che le istruzioni transitino sulla memoria crea delle dipendenze tra le istruzioni che vengono usate\nserve una Pipeline per gestire l‚Äôesecuzione di tutte le istruzioni obbligando una predizione dei salti precisa che per esserlo il codice deve essere eseguito prima che venga richiesto(esecuzione speculativa)\ni programmi sono limitati a 4GB disponendo di 32 bit\n\n\n\nARCHITETTURA IA-64\n√® una versione della IA-32 ma a 64 bit ma poco utilizzata perch√© il mercato server preferiva rimanere a 32 bit\nobiettivi della architettura in questione:\n\nal posto di compilare in modo approssimativo ed eseguire successivamente il codice si decise di fargli compilare il codice in modo pi√π esaustivo per poi fargli eseguire il codice in modo pi√π leggero\nil core i7 riordina le istruzioni, rinomina i registri e schedula le unit√† funzionali(tipo la ALU)\nper ottimizzare le performance si fecero delle implementazioni come:\nriduzione degli accessi in memoria\nscheduling delle istruzioni\nriduzione dei salti condizionati\ncaricamenti speculativi\n\nLINGUAGGIO ASSEMBLATIVO\n\nAssembler= traduttore\nAssembly= linguaggio usato\nINTRODUZIONE\nI livelli di micro e macro-architettura erano interpretati il livello assembly √® interamente tradotto.\nIl programma\ncolui che converte il programma sorgente in un programma destinazione √® detto traduttore (colui che traduce il codice in una roba che pu√≤ capire la macchina)\n\nMentre si esegue il programma oggetto(linguaggio che si avvicina alla macchina)\ni livelli di micro e macro architettura vengono usati per scambiare le informazioni adeguatamente\nINTRODUZIONE AL LINGUAGGIO ASSEMBLATIVO\nIl linguaggio sorgente √® una rappresentazione simbolica del linguaggio macchina\ni simboli mnemonici sono tipo ADD,SUB, MUL\nogni istruzione ha una corrispondenza in linguaggio macchina(binaria)\nil programmatore assembler ha accesso a tutte le risorse della macchina a differenza di linguaggi pi√π ad alto livello\nun programma √® scritto per una specifica famiglia di macchine\nassembler viene usato per creare programmi di ridotte dimensioni, che sfruttino la macchina al 100% e che siano veloci\nci sono dei comanti che usa l‚Äôassemblatore nel codice vengono chiamati pseudoistruzioni o direttive dell‚Äôassemblatore\nEsempi\nPer definire un nuovo simbolo pari al valore di una espressione(creare una costante)\nsi pu√≤ ad esempio fare BASE EQU 1000\noppure allocare 3 byte con dei valori fissati:\nTABLE DB 11,23,49\noppure fare un assemblaggio con condizioni\nWORDSIZE EQU 32\nIF WORDSIZE GT 32\nWSIZE DD 64\nELSE WSIZE DD 32\nENDIF\nLE MACROISTRUZIONI\nconsentono di creare delle istruzioni ripetibili vedi l‚Äôesempio e capisci subito\n\nPROCESSO DI ASSEMBLAGGIO\nc‚Äô√® sempre il solito problema dei salti che non possono essere previsti dall‚Äôassemblatore, ci sono perci√≤ due soluzioni\n\nleggere il programma due volte costruendo una tabella dei simboli, etichette e istruzioni che poi alla seconda esecuzione saranno gi√† presenti\nleggere il programma sorgente dopo averlo convertito in  un formato intermedio con una tabella intermedia salvata in memoria che poi viene precisata meglio al secondo passaggio\n\nPRIMO PASSAGGIO\nil primo passaggio costruisce la tabella dei simboli\nl‚Äôassembler usa la variabile ILC(instruction location counter) per memorizzare l‚Äôindirizzo dell‚Äôistruzione che sta assemblando\nun assembler usa 3 tabelle principalmente:\n\nSimboli\nPseudo istruzioni\ncodici operativi\n\nESEMPIO\n\nSECONDO PASSAGGIO\nDurante il secondo passaggio viene generato il vero e proprio codice oggetto\ngenerando anche le informazioni che user√† il linker per collegare tutte le istruzioni in un unico file\ndio cane!\nLa tabella dei simboli\nla tabella dei simboli raccoglie seguendo lo standard&lt;simbolo, valore&gt; accessibili tramite il simbolo\nesistono vari algoritmi per creare questa tabella\nUtilizzare una struttura  ordinata accedendovi in modo dinamico con costo O(log n)\nUsare una codifica hash che mappa ogni simbolo a determinati intervalli da 0 a k-1(O(1))\nLINKER E LOADER\ntutti i programmi hanno pi√π procedure e queste procedure vengono tradotte dall‚Äôassembler una alla volta salvando sul disco il risultato.\nl‚Äôoperazione di linking prende le procedure oggetto e unendole crea il programma\nprima di eseguirlo occorre caricare il programma in memoria centrale serve il loader\n\nLA STRUTTURA DI UN CODICE OGGETTO\nil codice oggetto √® il risultato della compilazione del codice sorgente\ned √® diviso in pi√π ‚Äústrati‚Äù\n\ncodice identificativo e lunghezze, contiene tutti i dati che si riferiscono a lunghezze e identificativi per trovare subito determinate linee di codice che servono per il linker per creare un programma singolo\nuno ‚Äústrato‚Äù dove vengono definite le variabili PUBLIC che possono essere usate su altri file o moduli\nuna lista intera di riferimenti esterni con funzioni esterne o variabili definite in altri moduli indicati con EXTERN\nora c‚Äô√® il vero e proprio codice dopo questa serie di variabili e informazioni questa parte contiene il vero e proprio codice tradotto in linguaggio macchina\npoi c‚Äô√® un dizionario di rilocazione che include indirizzi di memoria che devono essere sistemati o resettati\nidentificativo di fine modulo: alla fine del file oggetto viene identificata la fine del modulo con anche un checksum che √® una somma usata per trovare errori durante la lettura di un modulo\n\n"},"UNI/ANNO-1/ARCHITETTURA/LEZIONI/12.-Architetture-per-il-calcolo-parallelo(parte-1)":{"slug":"UNI/ANNO-1/ARCHITETTURA/LEZIONI/12.-Architetture-per-il-calcolo-parallelo(parte-1)","filePath":"UNI/ANNO 1/ARCHITETTURA/LEZIONI/12. Architetture per il calcolo parallelo(parte 1).md","title":"12. Architetture per il calcolo parallelo(parte 1)","links":[],"tags":[],"content":"INTRODUZIONE\nl‚Äôobiettivo principale dell‚Äôindustria dei computer √® sempre stata quella di voler aumentare le performance, in passato si faceva aumentando il clock ma poi divenne impossibile per un limite fisico ovvero che un segnale non pu√≤ essere pi√π veloce della velocit√† della luce e per problemi di gestione delle temperature.\nun computer con un clock a 1 THz deve essere pi√π piccolo di 100 \\mu m per dare abbastanza spazio al singolo ciclo di clock √® fattibile ma ci sono comunque limiti strutturali di dissipazione del calore\nuna soluzione a questo problema √© l‚Äôarchitettura parallela ovvero pi√π CPU che collaborano per il medesimo obiettivo\nClassificazione di Flynn\nci permette di classificare i tipi di architetture in base a flusso di istruzioni e flusso di dati\n\nClassificazione dei calcolatori\n\nARCHITETTURE PER IL CALCOLO PARALLELO\nIl parallelismo aiuta appunto a migliorare le performance con tecnologie come il pipelining e le architetture superscalari si pu√≤ arrivare ad un miglioramento dal 5 al 10.\nCon pi√π CPU si arriva a un miglioramento addirittura dal 50 al 100%\nesistono tre approcci riguardo queste architetture:\n\nData parallel computers(SIMD)\nMultiprocessors(MIMD)\nMulticomputers(MIMD)\n\nLe varie architetture\n\nParallelismo nel chip\nPu√≤ avvenire in 3 modi:\nparallelismo a livello di istruzioni\nmettere pi√π istruzioni per ogni ciclo di clock con due tipi di processori:\nSuperscalari: con pipeline e unit√† funzionali parallele\n\nProcessori VLIW con istruzioni lunghe che dividono il problema nelle varie componenti\n\nprima di iniziare il prossimo argomento farei uno specchietto che spiega cosa √® il thread\n\n\n                  \n                  Cosa √® il Thread? \n                  \n                \n\nIl Thread √® un‚Äôunit√† pi√π piccola del processo che pu√≤ essere eseguita indipendentemente e in modo concorrenziale\n\n\nMultithreading nel chip\nrisolve un problema di stallo della pipeline, ovvero quando una CPU tenta di accedere ad una informazione in memoria e non nella cache e perci√≤ per accedervi ha bisogno di tempo per caricarla prima di riprendere l‚Äôesecuzione.\ncome funziona lo stallo nella pipeline nello specifico:\nfacciamo finta di avere una CPU con una istruzione per ciclo di clock divisa a sua volta in 3 piccoli thread A,B e C che durante il primo ciclo si chiamano A1,B1,C1\nA2 nel secondo ciclo di clock ha bisogno di una info che non √® nella cache quindi entra in stallo e deve attendere 2 cicli prima di recuperarlo.\n\nle soluzioni come gi√† detto sono attraverso il multithreading\nil multithreading si divide in 3 approcci:\n\na grana fine\na grana grossa\ndi tipo simultaneo\n\nA GRANA FINE\nLe istruzioni dei singoli Thread sono eseguite a turno in un ciclo di clock in quei due ipotetici cicli di stallo di una singola istruzione vengono eseguite le altre istruzioni\nogni thread ha i suoi registri e la quantit√† dei thread viene definita in fase di progettazione del chip\nle situazioni di stallo non avvengono solo per situazioni di memoria ma anche altre\n\nA GRANA GROSSA\nIn quelli a grana grossa i thread vengono eseguiti fino al verificarsi di uno stallo, ogni volta che si verifica uno stallo viene perso un ciclo e si passa ad un thread successivo\nrichiede meno thread per mantenere occupata la CPU ed √® meno efficiente rispetto a quello a grana fine\n\nTIPO SIMULTANEO richiede Multithreading in CPU superscalari\nle cpu hanno pi√π unit√†(componenti) in parallelo quindi pi√π pipeline solo che c‚Äô√® un limite fisico di componenti e di dimensioni per cui la seguente tipologia non si pu√≤ migliorare\n\n\nCiascun thread emette due istruzioni per ciclo fintanto che pu√≤, altrimenti, non appena raggiunge uno stallo, viene emessa immediatamente un‚Äôistruzione del thread che segue affinch√© la CPU resti pienamente impegnata.\nimmagina che nella foto ci siano degli stalli ma che vengono subito riempiti da altri thread\nMULTIPROCESSORI IN UN SOLO CHIP\nCon il passare degli anni i transistor sono diventati sempre pi√π piccoli ed √® stato possibile aumentare il loro numero all‚Äôinterno di un chip.\nil clock non venne aumentato per i soliti motivi per tale ragione le industrie inserirono pi√π CPU(core) dentro lo stesso chip(die)\ni multiprocessori si dividono in 2:\nOMOGENEI\ncondividono stessa cache di primo e secondo livello e la memoria principale si dividono in altre due sotto categorie caratterizzate da due tecnologie differenti:\n\nETEROGENEI\nin quelli eterogenei ogni core ha uno specifico compito come ad esempio decoder, audio/video, cripto-processore e interfacce di rete.\nvengono dette system on a chip\nsfruttare questi chip prevede l‚Äôuso di algoritmi che hanno un uso in parallelo e sono molto complessi da realizzare\nper i chip multicore per farli comunicare tra loro viene usato un bus ma per i sistemi pi√π grandi ne serve pi√π di uno o ad anello, l‚Äôanello √® un sistema che fa comunicare i core tutti insieme collegandoli due a due formando un anello per poter trasmettere dei dati da core a core si usa un token che viene preso dalla singola cpu, quando lo prende pu√≤ trasferire le informazioni e una volta riposto il token qualche altra cpu pu√≤ prenderlo(tipo gioco delle sedie)\nil bus √® frutto dell‚Äôinterconnessione delle cpu quindi una cpu pu√≤ passare le informazioni tra le cpu\n\nChip-level multiprocessor\nSono come dei multiprocessori ma pi√π piccoli.\nPer quanto riguarda la progettazione software di essi non √® cos√¨ differente dai multiprocessori a bus.\nal posto di avere una cache per ogni CPU hanno delle cache in comune che per√≤ possono essere saturate.\nrispetto ai normali multiprocessori questi chip sono meno tolleranti ai malfunzionamenti\n(esempio di malfunzionamento:while all‚Äôinfinito che si interrompe)\nCo-processori\nSono processori che collaborano e che svolgono specifiche funzioni permettono il miglioramento del processore perch√® si prendono il compito di svolgere quelle determinate funzioni\nci sono diversi tipi di co processori:\n\ngrafici\nrete\ncrittoprocessori\n\nMIMD\npresa dalla classificazione di flyn sono i processori che lavorano con multiple istruzioni e dati multipli\nci sono 3 tipi di MIMD:\n1. MULTIPROCESSORI\n\nhanno una memoria condivisa e grazie a questo non serve installare un sistema operativo per ogni CPU, inoltre pu√≤ esserci una sola CPU che si occupa degli scambi I/O(multiprocessore asimmetrico) esistono due altri tipi di multiprocessori\n\nUMA(quando le parole vengono lette in memoria sempre alla stessa velocit√† Uniform Memory Access)\nNUMA(Non Uniform Memory Access)\napprofondiamo un attimo gli UMA.\nsi dividono in 5 tipi:\n\nARCHITETTURA UMA BASATI SU BUS\nQuesti processori lavorano su un singolo bus per collegarsi alla shared memory, per evitare intoppi √® sconsigliato l‚Äôutilizzo di troppe CPU\n\nUMA CON SINGOLO BUS E CACHE NELLA CPU\nogni CPU ha una sua piccola cache, oltre alla shared memory cos√¨ facendo si riducono dei tempi di attesa possono essere read only o READ/WRITE\n\nUMA CON SINGOLO BUS E CPU DI RAM\nle CPU oltre ad avere una cache(che ha poca memoria) hanno anche una ram dedicata(memoria privata) la shared memory serve viene usata solo per salvare le variabili globali a questo punto il compilatore deve spezzettare per bene il progetto per far si che venga gestito bene dalle varie CPU per scindere le variabili globali e locali\nUMA CON CROSSBAR SWITCH\nUtilizzare un solo bus √® un limite soprattutto su sistemi con pi√π di 64 CPU\nper fare pi√π parallelismi si usa la crossbar switch\n√® composta da un circuito chiamato commutatore √® una griglia che instrada il segnale azionando e spegnendo i vari connettori\nnella foto se c‚Äô√® il pallino nero significa che ad esempio 000 sta comunicando con 010 come una sorta di matrice/battaglia navale\nse la porta √® chiusa significa che il collegamento si instrader√† l√¨\nalla CPU non verr√† mai negata una connessione di cui ha bisogno perch√© si calcola il percorso migliore\nin qualsiasi momento una CPU pu√≤ comunicare con una memoria, l‚Äôimportante √® che non ci sia una sovrapposizione altrimenti, darebbe gli stessi problemi del bus singolo(tipo 100 che prova a parlare con la memoria 000 anche se 010 gi√† ci sta parlando)\nun altro problema √® il numero esagerato di incroci che bisogna fare in base al numero di memorie e di CPU che va in funzione di n^2 dove n √® il numero dei CPU e delle memorie\n\nUMA CON RETE DI COMMUTAZIONI I A PI√ô STADI\na quello precedente c‚Äôera un commutatore per ogni collegamento ora con questo a rete a pi√π stadi c‚Äô√® un collegamento che prevede 2 input e 2 output per ogni commutatore ci√≤ comporta un ottimizzazione del numero di commutatori.\nogni messaggio che viene scambiato tra i commutatori √® composto da\n\n\nPer n CPU e x\nmemorie \\dfrac{n}{2}\\log_2(x)\nun esempio √® la rete omega\n\nil funzionamento dell‚Äôindirizzamento avviene attraverso lo shuffle perfetto, i bit della memoria corrispondono al percorso da fare dove 0 sta per sali al commutatore e invece 1 sta per scendi\n\nnon tutte le CPU possono lavorare contemporaneamente ad esempio 000 deve usare per forza 1A e anche 100, insieme non possono lavorare perch√© usano gli stessi commutatori\ntutto ci√≤ si basa su un sistema interlacciato che tenta di ridurre al minimo al congestione, ovvero i percorsi minimi\nAPPROFONDIMENTO SUI MULTIPROCESSORI NUMA\nper connettere pi√π CPU insieme superando i limiti dei sistemi UMA entra in gioco NUMA ovvero Non Uniform Memory Access, quindi memorie che hanno tempo di accesso non uniforme\nle macchine NUMA hanno:\n\nun unico spazio di indirizzamento(TUTTO LO STACK degli indirizzamenti) che √® visibile a tutte le cpu\nper accedere a una memoria remota(lontana) usano istruzioni di LOAD e STORE\npi√π la memoria √® lontana(remota) e pi√π ci sar√† un accesso lento se invece √® locale l‚Äôaccesso sar√† veloce\nCi sono due tipi di macchine NUMA:\nNC-NUMA(No Cache Non Uniform Access)\nogni processore ha accesso diretto alla memoria principale del sistema ma non ha la cache\nil tempo di accesso √® noto\nCC-NUMA(Cache Coerent Non Uniform Memory Access)\nsono basati sulle directory-based multiprocessor e\nprevedono delle cache cos√¨ da ridurre i tempi di accesso ma ovviamente prevede l‚Äôuso di snooping con un database che tiene conto degli stati e degli indirizzi\n\n2.MULTICOMPUTER\nIl secondo progetto di architettura parallela prevede per ogni CPU una memoria privata, cio√® accessibile solo da essa e non dalle altre  tramite semplici istruzioni LOAD e STORE, ma cui nessun altra CPU pu√≤ accedere.\nProgrammare un multicomputer √® molto pi√π difficile che programmare un multiprocessore. D‚Äôaltra parte i multicomputer grandi sono molto pi√π semplici ed economici da costruire rispetto a multiprocessori con lo stesso numero di CPU.\n\n3. SISTEMI DISTRIBUITI\nsono computer che lavorano su aree geografiche estese come internet e i messaggi impiegano dai 10 ai 100 ms sono tipo i client e i server\n\nTIPI DI SISTEMI OPERATIVI MULTIPROCESSORE\nCi sono tre approcci per mettere sistemi operativi su multiprocessori:\n\nogni cpu ha un suo sistema operativo\nci sono multiprocessori master e slave\nmultiprocessori simmetrici\n\n1. SO per ogni CPU\nLa memoria √® divisa in pi√π partizioni ognuna con il suo SO di ogni CPU\nogni CPU lavora totalmente in modo indipendente e ci√≤ genera una scarsa condivisione delle risorse tra le varie CPU\n\n2. Multiprocessori Master-Slave\nsolo una CPU fa da SO e sfrutta le altre come Slave per√≤ il master diventa un collo di bottiglia, perch√© deve gestire tutte le chiamate di sistema.\n\n3. Multiprocessori simmetrici\nOgni CPU pu√≤ diventare Master prendendo il SO dalla memoria\nsolo che le CPU devono essere sincronizzate e bisogna evitare i deadlock(stalli)\nLa CPU che effettua una chiamata di sistema, effettua una trap al kernel(invio di un pacchetto al kernel che aspetta un riscontro) ed elabora la richiesta.\n\nSincronizzazione dei multiprocessori\nLe CPU di un multiprocessore hanno bisogno di sincronizzarsi dovendo proteggere i dati sensibili come database e kernel sfruttando il sistema mutex\n\n\n                  \n                  mutex \n                  \n                \n\n√® un meccanismo di sincronizzazione utilizzato nei sistemi multi-thread o multi-processo per\nimpedire che pi√π thread o processi accedano simultaneamente a una risorsa condivisa.\n\n\nse ad una CPU viene disabilitata la possibilit√† di attendere interrupt tutte le altre possono comunque farlo\nil TSL(Test Set Lock) all‚Äôinterno del mutex permette ad una parola in memoria di essere modificata e controllata con una sola operazione\nCon pi√π CPU il TSL blocca il bus cos√¨ che le altre CPU non vi accedono successivamente sblocca il bus\n\n\n                  \n                  cos&#039;√® il kernel? \n                  \n                \n\nIl kernel gestisce operazioni come la gestione della memoria, la gestione dei processi, la gestione\ndei dispositivi di input/output e la gestione delle interruzioni. √à essenziale per il funzionamento\ndi qualsiasi sistema operativo, poich√© fornisce l‚Äôinterfaccia tra il software delle applicazioni e\nl‚Äôhardware del computer.\n\n"},"UNI/ANNO-1/ARCHITETTURA/LEZIONI/13.-Architetture-per-il-calcolo-parallelo(parte-2)":{"slug":"UNI/ANNO-1/ARCHITETTURA/LEZIONI/13.-Architetture-per-il-calcolo-parallelo(parte-2)","filePath":"UNI/ANNO 1/ARCHITETTURA/LEZIONI/13. Architetture per il calcolo parallelo(parte 2).md","title":"13. Architetture per il calcolo parallelo(parte 2)","links":[],"tags":[],"content":"\n\n                  \n                  cosa √® lo scheduling? \n                  \n                \n\n√à la pianificazione e gestione delle risorse come attivit√†, processi e informazioni\nnel caso della CPU lo scheduler ad esempio mette in ordine i processi a seconda delle priorit√† mettendo una determinata capacit√† di risorse della CPU ad ogni processo a seconda delle loro necessit√† e priorit√†(ad esempio hai brave e discord aperto, lo scheduler dice alla CPU di dare il 30% delle risorse a brave e il 20% a discord), lo scheduler inoltre d√† un tot di tempo alla CPU per eseguire il processo\n\n\nScheduling dei multiprocessori\nLo scheduler pu√≤ essere mono-dimensionale o bi-dimensionale\nnel caso del mono-dimensionale hai solo una CPU quindi lo scheduler deve solo decidere quale processo avviare\ninvece nel caso bi-dimensionale lo scheduler deve decidere quale processo avviare e quale CPU utilizzare\nEsistono vari algoritmi di scheduling per ciascuna situazione:\n\n\ntimesharing\n\n\ncondivisione dello spazio\n\n\nschedulazione gang\n\n\npartiamo dal primo\nTIME SHARING\n√à utilizzato quando i processi sono indipendenti(non lavora con delle risorse che esegue un altro processo)\nl‚Äôalgoritmo usa un vettore che contiene tutti i processi che sono nello stato ‚Äúready‚Äù quindi sono pronti per partire, con diverse priorit√† di esecuzione\navendo un unica struttura dati  e dei processi indipendenti tutte le CPU sono perfettamente bilanciate e non ci sar√† mai una CPU oberata da lavoro mentre un‚Äôaltra √® inattiva come se fosse un sistema monoprocessore\nproblemi:\n\nse hai troppe CPU tutte vogliono accedere alla struttura dati(il vettore)\nquando una delle CPU deve fare un‚Äôoperazione di I/O che richiede del tempo, oltre ad essere innescato lo spin lock, avviene un cambio di contesto, ovvero la CPU deve passare dall‚Äôesecuzione del processo che stava eseguendo a un altro processo ad esempio di attesa dell‚ÄôI/O. Il problema √® quando tutti i processi entrano in questo stato e iniziano ad essere sovraccarichi di lavoro\n\n\n\n                  \n                  cosa √® lo spin lock \n                  \n                \n\n√à un meccanismo di protezione che aiuta la sincronizzazione tra le risorse delle CPU evitando che\nn CPU interagiscano con la stessa cosa. si divide in due stati:\n\nl‚Äôattesa(spin) √® quando la risorsa √® in attesa di avere interazioni\nil lock(il blocco della risorsa) √® quando la risorsa √® bloccata a tutte le altre CPU perch√© sta\navendo una interazione\n\n\n\n\nQuando una CPU ci mette troppo tempo e quindi termina il quantum di tempo dato dallo scheduler, la CPU quindi ancora deve rilasciare il lock, la CPU pu√≤ accedere un tempo extra quindi un extra quantum, questa operazione viene chiamata smart scheduling.\nL‚Äôaffinity scheduling fa eseguire il medesimo processo alla CPU che gi√† lo ha eseguito in passato cos√¨ da sfruttare i dati nella cache\nper creare questa affinit√† si utilizza un algoritmo di schedulazione a 2 livelli:\n\nscheduling ad alto livello, vengono messi i processi con elevata priorit√† e vengono assegnati alle CPU che in quel momento sono inutilizzate\nscheduling a basso livello, viene fatto uno scheduling assegnando il processo in base all‚Äôaffinit√† della cache e delle priorit√†, comportando un miglioramento delle performance generali\nquesta cosa d√† un carico equo alle CPU\nle liste di processi vengono usate meno perch√© alle CPU vengono assegnati compiti che gi√† conoscono\n\nSPACE SHARING SCHEDULING\nQuando ci sono correlazioni tra i vari processi si pu√≤ usare lo scheduling per condivisione di spazio\ncosa succede?\nil processo viene suddiviso in tanti piccoli thread e lo scheduler assegna n thread a n CPU.\nEssendo processi complementari lo scheduler avvier√† i processi una volta che ci saranno disponibili n CPU libere, quindi se il processo richiede 10 thread e ci sono 9 CPU disponibili lo scheduler non far√† eseguire nulla\nvantaggio:\nriduce gli overhead, perch√© le CPU sono libere di accedere alla memoria senza troppi conflitti\nproblema:\nquando le CPU non sono libere si perde tempo nell‚Äôattesa che si liberino\n\n\n                  \n                  overhead cosa √®? \n                  \n                \n\nQuelle risorse in pi√π all‚Äôinterno di un processo, ad esempio in un cambio di contesto in mezzo ai due processi c‚Äô√® il cambio stesso, quindi una risorsa in pi√π\n\n\n\nSCHEDULAZIONE GANG\nNasce dal bisogno di schedulare insieme risorse(spazio) e tempo\nsi compone in 3 passaggi:\n\nsi creano tanti piccoli gruppi di thread correlati chiamate unit√† o gang\ntutti i thread di una gang vengono eseguiti assieme su diverse CPU con il sistema di timesharing\ntutti i thread della gang iniziano e terminano assieme\nquesto sistema funziona perch√© ogni CPU √® scandita da un quanto ben definito e discreto, dopo che il quantum termina alle CPU viene fatta nuovamente l‚Äôoperazione di scheduling e se un thread si blocca, la sua CPU rimane inattiva fino allo fine del quanto\n\n\nTutti i thread vengono eseguiti contemporaneamente a seconda di uno scheduling fatto e in un determinato quantum di tempo.\nCi√≤ permette anche lo scambio di informazioni immediate tra le varie CPU di risorse necessarie e condivise\n\nMULTICOMPUTER\nOgni CPU del multicomputer si interfaccia con la sua memoria privata con LOAD e STORE ma per scambiare informazioni con altre CPU usano send receive attraverso rete di interconnessione\n\nuna CPU √® interessata ai dati di un‚Äôaltra CPU\ndopo aver scoperto quale CPU possiede i dati che le interessano le spedisce una richiesta di copia dei dati. Di norma questa operazione blocca la CPU finch√© la richiesta non viene soddisfatta.\nla richiesta arriva alla CPU 1, il suo software lo analizza e restituire i dati richiesti.  la CPU 0 riceve il messaggio di risposta, il suo software si sblocca e continua l‚Äôesecuzione.\n¬†I processori di comunicazione sono collegati tramite una rete ad alta velocit√†.\nquando un programma applicativo esegue una primitiva send il processore di comunicazione riceve una notifica e si incarica di trasmettere il blocco di dati dell‚Äôutente presso la macchina di destinazione (eventualmente dopo aver chiesto, e ricevuto, il permesso di farlo).\nun insieme di computer si dice Cluster\nI multicomputer sono facili da costruire perch√© il componente base √® un PC con una scheda di rete con alte performance.\n\nTOPOLOGIA\n√à il modo in cui vengono interconnessi i computer tra loro √® composto da:\n\nnodi, ovvero il computer stesso con CPU memoria e scheda di rete\nswitch(opzionale), ovvero il dispositivo di instradamento che consente lo scambio di pacchetti tra i dispositivi, √® opzionale poich√© i nodi possono essere connessi direttamente tra di loro senza uso di quest‚Äôultimi\nci sono diversi tipi di topologia:\n\n1. A stella\ni quadrati sono i computer che per comunicare tra loro usano uno switch di intermezzo che consente i trasferimenti\n\n3. Ad anello\nnon sono necessari switch poich√© ogni computer √® collegato con altri 2 e funziona attraverso un sistema di token che se viene preso da uno dei computer ha la possibilit√† di trasferire le informazioni tra i computer finch√© non lo posa\n\n4.A Griglia(grid) o (mesh)\n√® una piattaforma bidimensionale altamente scalabile dove il percorso pi√π lungo tra due nodi si chiama diametro e aumenta come la radice quadrata dei due nodi\n\n5. Doppio Toro\nGli switch sono pi√π interconnessi tra loro permettendo una miglior tolleranza e velocit√† di instradamento ma con un diametro inevitabilmente pi√π piccolo\n\n6. Cubo\nStruttura tridimensionale regolare\n\n7. Ipercubo Scalabile\nUn cubo di dimensione 4 √® ottenibile mettendo insieme due cubi di dimensione 3\n\nMolti computer paralleli usano questa topologia perch√© il suo diametro cresce linearmente con la sua dimensione: diametro = \\log_2 n nodi\nCLUSTER\nsono una serie di computer connessi assieme e si dividono in 2 tipi:\n\ncentralizzati: sono computer nella stessa stanza e sono uguali\ndecentralizzati: non sono nella stessa stanza e sono diversi\n\nSCHEMI DI SWITCHING\nNei multicomputer sono usati due tipi di schemi di switching.\n1. Store-and-forward packet switching\nOgni messaggio √® composto da pacchetti che a seconda delle sue priorit√†, peso ecc‚Ä¶ viene instradato e raggiunge il nodo destinatario. √à flessibile ed efficiente ma potrebbe verificarsi un aumento dei tempi di latenza nella fase di invio\n2. Circuit switching\nNel secondo caso vengono coinvolti degli switch che si scambiano il messaggio tra di loro partendo da un mittente fino a raggiungere lo switch vicino al destinatario, ci√≤ riduce la latenza perch√© gli Switch non devono salvare l‚Äôinformazione devono solo fare da ‚Äúripetitori‚Äù.\nQuesto sistema richiede una fase di inizializzazione che prende tempo, ma una volta terminata il processo √® velocissimo.\nUna variante √® il wormhole routing, spezza il pacchetto in sottopacchetti e permette a quest‚Äôultimi di iniziare il tragitto prima che sia stato inizializzato il collegamento.\nInterfacce di rete\nOgni Computer(Nodo) del Multicomputer ha almeno una scheda di rete e una memoria RAM, che serve per memorizzare i pacchetti che entrano ed escono dal nodo\nLa scheda di rete comprende RAM e DMA\nI DMA(Direct Memory Access) sono dei canali di trasferimento diretto dei dati senza uso della CPU\n\nSOFTWARE DI COMUNICAZIONE\nsi dividono in pi√π livelli\n\n1. Software di comunicazione di basso livello\nLe primitive send e receive possono essere bloccanti (sincrone) o non bloccanti (asincrone).\nL‚Äôeccessiva copia di pacchetti √® il nemico principale delle prestazioni dei multi computer (i pacchetti vengono copiati per varie ragione tra cui evitare perdita di dati, backup ecc..). Per evitare che ci√≤ accada alcuni multi computer accedono direttamente alla scheda di rete per ricevere o inviare dati. Se cos√¨ non fosse tutta l‚Äôoperazione di invio/ricezione dati sarebbe gestito dal sistema operativo che dovrebbe fare chiamate multiple di sistema per gestire il tutto, questo porta a creare molteplici copie dei pacchetti   durante il passaggio dati tra utente e kernel.   Problemi: difficile da programmare, rischi di sicurezza poich√© si accede direttamente alla scheda di rete, potrebbero esserci tanti processi sullo stesso nodo che vogliono spedire i pacchetti.\n2. Software di comunicazione a livello utente\nI processi sulle diverse CPU di un multicomputer comunicano attraverso lo scambio di messaggi usando Sender e Receiver\n\n\nSEND: Questa funzione invia un messaggio ad un processo identificato come destinazione (destination). Quando si chiama la funzione SEND, si specifica il destinatario del messaggio e un puntatore al messaggio stesso (message_pointer). Il chiamante, ovvero il processo che esegue la chiamata SEND, viene bloccato fino a quando il messaggio non viene effettivamente spedito. Questo significa che il processo chiamante rimane in sospeso fino a quando la CPU non ha completato l‚Äôinvio del messaggio alla destinazione.\n\n\nRECEIVE: Questa funzione √® chiamata da un processo che desidera ricevere un messaggio da un‚Äôaltra CPU. Quando si chiama la funzione RECEIVE, si specifica l‚Äôindirizzo su cui il processo ricevente √® in ascolto (address) e un puntatore al buffer in cui memorizzare il messaggio ricevuto (message_pointer). Il processo chiamante viene bloccato fino a quando non arriva un messaggio sulla porta specificata dall‚Äôindirizzo. Una volta ricevuto il messaggio, viene copiato nel buffer e il processo chiamante viene sbloccato, consentendogli di procedere con l‚Äôelaborazione.\nIn un multicomputer statico il numero di CPU √® noto a priori, quindi il campo address √® formato dall‚Äôidentificativo della CPU e dall‚Äôidentificativo del processo o della porta sulla CPU selezionata.\n\n\nCHIAMATE BLOCCANTI E NON BLOCCANTI\nLe primitive send e receive possono essere bloccanti (sincrone) o non bloccanti (asincrone).\n\nbloccanti significa che tu finch√® non termini di fare un‚Äôoperazione di send o receive non puoi fare altro\nnon bloccanti il contrario restituendo il controllo al chiamante subito dopo che ha fatto un‚Äôoperazione di send o receive, lo svantaggio √® che il mittente non sa quando il pacchetto √® stato inviato e inoltre non pu√≤ usare il flusso del buffer per inviare altri pacchetti mentre ne sta gi√† inviando uno\nCi sono 3 soluzioni a questo problema\n\n\nil Kernel copia il messaggio in un buffer interno\nil mittente riceve un interrupt cos√¨ che pu√≤ riutilizzare il buffer\nmentre il mittente manda un‚Äôaltro messaggio il buffer si sdoppia creando una sua copia ma mettendo la sua pagina in modalit√† read-only\n\nIl processo mittente pu√≤ eseguire quindi:\n\n\nuna spedizione bloccante e mantenere bloccata la CPU\n\n\nuna spedizione non bloccante con copia (la CPU spreca tempo solo per eseguire una copia)\n\n\nuna spedizione non bloccante con interrupt (programmazione difficile)\n\n\nuna spedizione non bloccante con copia su scrittura (la CPU spreca tempo anche per la copia di fine processo oltre le scritture richieste)\n\n\nIn un sistema multi-thread la prima √® la scelta migliore: mentre il thread che esegue la send √® bloccato, gli altri continuano a lavorare.\nIl processo destinatario pu√≤ utilizzare una receive non bloccante(non blocchi quello che fai ma fai una receive)\nuna receive bloccante comporta una attesa continua e non permette di svolgere altre operazioni nel mentre.\nL‚Äôarrivo di un messaggio pu√≤ essere gestito:\n\n\ntramite interrupt, ma sono difficili da programmare e molto lenti\n\n\nrichiamando una procedura poll(), si tratta di una procedura che viene chiamata per verificare se ci sono messaggi in attesa di essere letti\n\n\nattraverso la creazione automatica di un thread (chiamato thread pop-up) che finito il suo compito muore spontaneamente\n\n\nattraverso un interrupt che attiva nella ISR il codice di gestione (questo schema √® una versione ibrida dei precedenti che sfrutta l‚Äôidea di un thread pop-up senza creare alcun thread, migliorando cos√¨ le performance, e si chiama messaggi attivi)\n\n\n\nRemote Procedure Call (RPC)\nIl modello a scambio di messaggi √® molto conveniente per un sistema operativo multi computer ma soffre di un grave difetto ovvero tutti le comunicazioni (i programmi) utilizzano l‚ÄôI/O.\nCi sono due entit√† il chiamante e il chiamato, quando un processo su una macchina 1 ha bisogno di eseguire una procedura presente sulla macchina 2, la macchina 1 entra in attesa e la macchina 2 elabora la procedura, la macchina 1 invia delle info attraverso i parametri e la macchina 2 li invia a sua volta ritornando i risultati\nLa procedura chiamante √® il client e la procedura chiamata √® il server\nil programma client usa una procedura client stub per chiamare una procedura remota\nviceverda il chiamato ha il server stub\n\n\nil passo 1 √® la chiamata da parte del client del client stub, che √® una chiamata di procedura locale, con i parametri messi sullo stack nel modo consueto;\n\n\nil passo 2 consiste nell‚Äôimpacchettamento dei parametri in un messaggio e nell‚Äôeffettuare una chiamata di sistema per spedire il messaggio (impacchettare i parametri √® detto marshaling);\n\n\nnel passo 3, il kernel spedisce il messaggio dalla macchina client a quella server;\n\n\nnel passo 4 il kernel passa il pacchetto in arrivo al server stub;\n\n\nnel passo 5 il server stub chiama la procedura del server.¬†\n\n\nLa risposta effettua lo stesso cammino in direzione opposta.\nproblemi implementativi:\n\nparametri puntatore: il passaggio dei puntatori √® impossibile, perch√© il client ed il server hanno un diverso spazio degli indirizzi\nquando viene scambiato un array all‚Äôinterno dello stack(quindi nei parametri) che non ha una dimensione definita e ha un simbolo di fine conosciuto solo dal client, c‚Äô√® un errore di array indefinito esempio di simbolo: &quot;\\0&quot;\ntipi di dato: non √® sempre possibile dedurre i tipi dei parametri, nemmeno con una specifica normale, o dal codice stesso (funzioni polimorfe). Ad esempio la printf.\nvariabili globali: la procedura chiamante e quella chiamata non possono comunicare per mezzo di variabili globali in quanto non esiste un contesto comune.\n\n\nMemoria condivisa distribuita\n\n\n                  \n                  definizione di pagina \n                  \n                \n\nLa pagina √® una suddivisione di memoria su parti di dimensioni minori per ottimizzare le operazioni. L‚Äôoperazione di suddivisione si chiama paging\n\n\nBench√© RPC sia interessante, molti programmatori preferiscono un modello di memoria condivisa, e lo vorrebbero utilizzare anche su un multicomputer.\nVenne perci√≤ inventata questa DSM(Distributed Shared Memory) che prevede una memoria virtuale per ogni macchina con le proprie pagine e tabelle.\nQuando una CPU effettua una LOAD o una STORE su una pagina che non ha, avviene una trap al sistema operativo, che quindi, localizza la pagina, e chiede alla CPU che la possiede correntemente di invalidare la pagina, e spedirla sulla rete di interconnessione. Quando arriva, la pagina viene mappata e viene fatta ripartire l‚Äôistruzione che aveva provocato il fault; in effetti, il sistema operativo sta soddisfacendo i fault di pagina della RAM remota, invece che dal disco locale.\nLa differenza tra una vera memoria condivisa e DSM √® illustrata nella Figura. Nella (a) si vede un vero multiprocessore con memoria fisica condivisa implementata tramite hardware; nella (b) si vede DSM implementata dal sistema operativo; nella (c) troviamo DSM implementata da livelli superiori del software.\n\nScheduling\nIn un multiprocessore tutti i processi stanno nella stessa memoria. Quando una CPU finisce il suo task corrente esegue semplicemente un altro processo (tutti i processi posso essere candidati). Gli algoritmi di scheduling per il multi computer e il multi processore sono simili ma non tutti possono essere applicati ad entrambi. Ad esempio un algoritmo che NON FUNZIONA √® quello che prevede la lista centralizzata dei processi pronti ‚Äúready‚Äù perch√© avendo un multi computer non posso indirizzare adeguatamente i processi in modo sensato perch√© ciascun processo pu√≤ essere eseguito solo dalla CPU dove si trova in quel momento e quindi si crea un problema di bilanciamento. Una cosa importante dei multi computer √® che quando si crea un nuovo processo esso deve essere posizionato in modo efficiente per non creare troppa disparit√† nel carico di lavoro.\nBilanciamento del carico\nCi sono degli algoritmi che permettono la gestione dei vari processi dei singoli nodi(computer) visto che √® molto difficile controllarli.\nci sono diverse cose da notare per gestire questi algoritmi:\nIl fabbisogno di CPU, l‚Äôutilizzo di memoria e la quantit√† di comunicazione con ogni altro processo.¬†\nI possibili obiettivi sono: la minimizzazione dei cicli di CPU sprecati per la carenza di lavoro locale, la minimizzazione della larghezza di banda di comunicazione totale e condizioni eque per gli utenti e i processi.\nVIRTUALIZZAZIONE\n√à una tecnica che permette di creare pi√π computer virtuali all‚Äôinterno di un computer singolo e reale\nLa virtualizzazione introduce importanti vantaggi:\n\n\nforte isolamento tra le macchine (isolamento dei malfunzionamenti);\n\n\nminore spazio occupato;\n\n\nminore consumo;\n\n\nminore calore da dissipare;\n\n\nmaggiore manutenibilit√†;\n\n\npossibilit√† di creare dei checkpoint (punti di ripristino);\n\n\npossibilit√† di far girare applicazioni legacy su ambienti obsoleti;\n\n\npossibilit√† di effettuare test delle applicazioni su differenti sistemi operativi senza disporre dell‚Äôhardware fisico necessario.\n\n\nLa ‚Äúmodalit√† kernel‚Äù, anche conosciuta come ‚Äúmodalit√† privilegiata‚Äù o ‚Äúmodalit√† supervisore‚Äù, √® uno stato di funzionamento dei processori che consente l‚Äôesecuzione di istruzioni privilegiate e l‚Äôaccesso diretto a risorse hardware critici. In questo stato, il processore ha il massimo livello di controllo sul sistema e pu√≤ eseguire operazioni sensibili, come cambiare le impostazioni di configurazione hardware o gestire la memoria.\nNel contesto dei sistemi operativi, il kernel √® il nucleo centrale del sistema che gestisce le risorse hardware e fornisce servizi di base ai processi in esecuzione.\nQuando un sistema operativo esegue operazioni critiche o gestisce risorse hardware, spesso lo fa nella modalit√† kernel per garantire la sicurezza e l‚Äôintegrit√† del sistema.\nOgni CPU ha un insieme di istruzioni che si comportano in modo diverso quando vengono eseguite in modalit√† utente e kernel.\nQuando ci√≤ avviene le istruzioni sono dette sensibili mentre quelle istruzioni che posso eseguire solo in modalit√† kernel sono dette privilegiate e se le provo ad eseguire in una modalit√† non kernel ottengo una trap (procedura automatica che si attiva quando avviene un eccezione).\nUna macchina √® virtualizzabile solo se le istruzioni sensibili sono contenute in quelle privilegiate. Ad oggi la virtualizzazione √® stata introdotta direttamente sulle CPU commerciali col nome di SVM o VT.\nCI SONO DUE TIPI DI HYPERVISOR\nHYPERVISOR TIPO 1\nSi posiziona come un SO host in modalit√† kernel e sopra ad esso ci sono tutti i vari sistemi operativi come macchine virtuali che pensano di stare in modalit√† kernel ma in realt√† sono in modalit√† utente\nQuando il SO guest esegue una istruzione sensibile:\n\n\nse la CPU non ha la VT l‚Äôistruzione fallisce e il sistema operativo crasha;\n\n\naltrimenti avviene una trap nel kernel e l‚Äôhypervisor pu√≤ vedere se l‚Äôistruzione √® stata inviata da una VM del SO guest, in questo caso la esegue, o da un programma utente, in questo caso simula il comportamento dell‚Äôhardware reale.\n\n\n\n\nHYPERVISOR DI TIPO 2\n√à un software che viene eseguito sopra un SO Host.\nQuesto Hypervisor interpreta le istruzioni della VM e le traduce sul SO della macchina reale.\nUn esempio √® VMware ed √® eseguito come programma utente.\nQuesti hypervisor di tipo 2 sfruttano una tecnica di traduzione binaria, che gli permette di prendere i blocchi di istruzioni di base all‚Äôinterno di un codice e li traduce come ad esempio (JMP, CALL, TRAP..)\nTutte queste istruzioni vengono tradotte come una procedura VMware\nQuesti blocchi vengono messi nella cache virtuale di VMware e vengono eseguiti alla velocit√† della macchina fisica\nI DUE MESSI A CONFRONTO\nTutte le istruzioni sensibili che lavorano anche a livello kernel in un hypervisor di tipo 2 vengono emulate e quindi non vengono direttamente eseguite sul SO della macchina fisica.\nCon gli hypervisor di tipo 1 l‚Äôapproccio trap and emulate con gli hardware VT genera troppi trap e troppi overhead di gestione, invece la loro traduzione come nel hypervisor di tipo 2 √© pi√π efficiente\nalcuni di tipo 1 per√≤ eseguono lo stesso la traduzione binaria comportandosi come quelli di tipo 2\n\n\n                  \n                  differenza tra procedura e funzione \n                  \n                \n\nsono entrambi dei blocchi di istruzioni e la differenza √® che la funzione ti ritorna un valore invece la procedura non ritorna nulla\n\n\nParavirtualizzazione\nGli hypervisor tipo 1 e 2 funzionano senza modifiche al SO guest, ma con performance non eccellenti.\nUn diverso approccio prevede la modifica del codice sorgente del SO guest: invece di eseguire istruzioni sensibili si effettuano chiamate di procedure definite dall‚Äôhypervisor.\nQuindi l‚Äôhypervisor definisce una interfaccia, cio√® delle API (Application Program Interface), che i sistemi operativi guest possono attivare. Questo trasforma di fatto l‚Äôhypervisor in un microkernel e il SO guest modificato viene detto paravirtualizzato. Le performance ovviamente migliorano poich√© le trap si trasformano in system call."},"UNI/ANNO-1/ARCHITETTURA/LEZIONI/14.sistemi-operativi":{"slug":"UNI/ANNO-1/ARCHITETTURA/LEZIONI/14.sistemi-operativi","filePath":"UNI/ANNO 1/ARCHITETTURA/LEZIONI/14.sistemi operativi.md","title":"14.sistemi operativi","links":[],"tags":[],"content":"COSA √à UN SISTEMA OPERATIVO\n√à QUELLA PARTE SOFTWARE CHE PERMETTE DI GESTIRE L‚ÄôHARDWARE IN MODO PI√ô ASTRATTO E NON √à DA CONFONDERE CON LA GUI GRAPHIC USER INTERFACE CHE INVECE √à LA VERA E PROPRIA INTERFACCIA ED √à UN SOFTWARE SUL SO\nTHREAD VS PROCESSI\nIL PROGRAMMA PER ESSERE ESEGUITO √à DIVISO IN PROCESSI I PROCESSI SI POSSONO METTERE IN STATO DI PRONTO,ESECUZIONE,ATTESA. OGNI PROCESSO HA IL SUO STACK E OGNI PROCESSO PU√í ESSERE DIVISO IN MINI PROCESSI CHIAMATI THREAD\njob √® come se fosse il processo e i task vengono svolti dai thread\nSCHEDULING\n√à UN SISTEMA CHE GESTISCE IN BASE A DEI CRITERI I PROCESSI E I THREAD SPESSO CON UN ALGORITMO, COLUI CHE FA LE OPERAZIONI DI GESTIONE √à LO SCHEDULER\nUN ALGORITMO DI SCHEDULING SI DIVIDE PRIMA DI TUTTO IN\nPREEMPTIVE: in base a un quantum pu√≤ essere messo in fase di pre rilascio\nNON PREEMPTIVE: il processo una volta eseguito non viene bloccato\nCI SONO 3 SISTEMI:\nBATCH\nSistemi prevalenti non preemptive che non devono dare una risposta rapida a clienti in attesa\n\nFICFS(FIRST COME FIRST SERVED)\nSJF(SHORTEST JOB FIRST)\nSRTN(SHORTEST REMAINING TIME NEXT)\n\nINTERATTIVI\nESSENDO INTERATTIVI SONO PREEMPTIVE E DEVONO DARE UNA RISPOSTA IMMEDIATA CON PI√ô UTENTI IN ATTESA\n\nRR(ROUND ROBIN)\nSPN (SHORTEST PROCESS NEXT)\nPS(SCHEDULING CON PRIORIT√Ä)\nLOTTERIA\nFAIR SHARE\nGARANTITO\n\nREAL TIME\nTUTTI QUEI PROCESSI CHE DEVONO ESSERE ESTREMAMENTE RAPIDI\nHARD O SOFT SOFT POSSONO LEGGERMENTE RITARDARE\n\nSOSTENIBILIT√Ä con la sommatoria che va da 1 a m con ci/pi\n\nGESTIONE DELLA MEMORIA\nnell‚Äôambito della gestione della memoria trattiamo le seguenti componenti ram e disco rigido\nla ram √® limitata colui che la gestisce √® il gestore della memoria\npossono non essere astratte quindi la memoria √® cos√¨ com‚Äô√®\nSWAPPING\nogni processo √® una sua istanza che occupa tot spazio e una volta che non viene usato passa al disco rigido\nMEMORIA VIRTUALE\ndivisione in pagine della memoria con il paging, ogni processo pu√≤ essere eseguito senza che tutte le sue pagine stiano nella ram e quindi riduce di molto gli spazi\nha pi√π algoritmi swapping delle pagine avviene quando hai un page fault\n\nFIFO(FIRST IN FIRST OUT)\nLRU(LEAST RECENTLY USED)\nNFU(NOT FREQUENTLY USED)\nSC(SECOND CHANCE)\nNRU(NOT RECENTLY USED)\nAGING\nWSCLOCK\n"},"UNI/ANNO-1/ARCHITETTURA/LEZIONI/2.Organizzazione-sistemi-di-calcolo":{"slug":"UNI/ANNO-1/ARCHITETTURA/LEZIONI/2.Organizzazione-sistemi-di-calcolo","filePath":"UNI/ANNO 1/ARCHITETTURA/LEZIONI/2.Organizzazione sistemi di calcolo.md","title":"2.Organizzazione sistemi di calcolo","links":["UNI/ANNO-1/LOGICA/PARTE2LOGICA/Cap6-logica"],"tags":[],"content":"Sommario\n\nlibro:pag 35\nriassunto:inizio (1.2)\nPROCESSORI:\n\norganizzazione della cpu\nesecuzione dell‚Äôistruzione\nRISC vs CISC\nprincipi di progettazione dei calcolatori\nparallelismo a livello di istruzione\nparallelismo a livello di processore\n\n\nMEMORIA PRINCIPALE:\n\nBit.\nSistemi di numerazione\nindirizzi di memoria\nordinamento dei byte\ncodici di correzione di errore\nmemoria cache\n\n\n\nI PROCESSORI\nCPU\n\nLa CPU(Central Processing Unit) √® il cervello del computer e sfruttando anche il bus esegue le istruzioni nei programmi della memoria principale\n\ncosa contiene la cpu?\n\nCU, il vigile\nALU, serve per fare semplici calcoli e sfrutta i registri\nRegistri (piccole memorie ad alta velocit√†)\n\nNei registri della cpu abbiamo:\n\nprogram counter(PC)\n\n√® un puntatore che punta all‚Äôindirizzo nella memoria centrale dell‚Äôistruzione successiva\n\n\ninstruction register(IR)\n\ncontiene l‚Äôistruzione che si sta eseguendo della memoria centrale\n\n\n\n\n\n                  \n                  IR e PC prendono le informazioni dalla memoria centrale \n                  \n                \n\n\nbus √® una  collezione di cavi paralleli per trasferire indirizzi\nbus dati bus controllo bus indirizzi\ncome √® fatta la cpu?(Von Neumann)\n\nla CPU √® fatta dalle cose prima e da un data path\n\ncome funziona il data path?\n\nhai da 1 a 32 registri\nA e B salvano le informazioni di due registri e li passano all‚ÄôALU a cui fa l‚Äôoperazione e vanno in output e lo mette in un registro di output apposito che pu√≤ essere poi immagazzinato in un registro della CPU\n\noperazioni del data path:\n\nl‚ÄôALU oltre ad avere somme sottrazioni ecc‚Ä¶ ha anche altre istruzioni ad esempio:\n\nistruzione registro-memoria(se A non √® nel registro, non √® mai stata usata allora significa che bisogna caricare l‚Äôinformazione all‚Äôinterno del registro e poi vengono usate)\nistruzione register-register(se A √® gi√† nel registro non serve che venga caricato dalla memoria principale e viene direttamente usato)\n\n\n\n\n\n                  \n                  L&#039;ALU per fare delle operazioni sui dati li prende per forza dai registri \n                  \n                \n\nesempio:\n\nesecuzione delle istruzioni:\nSi pu√≤ chiamare anche fetch-decode-execute\nLa CPU esegue le istruzioni svolgendole in piccoli passi che principalmente si dividono cos√¨:\n\nprelevare dalla memoria centrale l‚Äôistruzione successiva(suggerita dal PC) e viene salvata nell‚ÄôIR\nAggiornamento del Program Counter con l‚Äôindirizzo dell‚Äôistruzione successiva\ncapire il tipo di istruzione\nse l‚Äôistruzione richiede dei dati in memoria(parola) determinare dove si trova questo dato\nse serve mettere il dato nel registro della CPU\neseguire l‚Äôistruzione\ntornare nel punto 1 cos√¨ che si ripeta tutto\n\nstrategie di progettazione della CPU\nabbiamo due filosofie:\n\nArchitetture CISC abbiamo una cpu che capisce delle istruzioni pi√π complesse senza l‚Äôuso di istruzioni di base che le compongono (lentamente)\nArchitettura RISC abbiamo una cpu che capisce poche e semplici istruzioni(pi√π veloci infatti basta un solo ciclo di data path!!)\n\n\n\n                  \n                   utilizzo di entrambe\n                  \n                \n\nintel a partire dal x486 fece un mix tra risc e cisc\n\n\nse vuoi progettare la tua cpu devi\n\nFar eseguire tutte le istruzioni direttamente dall‚Äôhardware, se hai istruzioni per le architetture CISC le dividi in piccole istruzioni primitive\nUtilizzo del parallelismo per eseguire pi√π istruzioni nello stesso tempo\nLe istruzioni devono essere facili da decodificare, con istruzioni regolari, di lunghezza fissa e con poche tipologie\nsolo le istruzioni LOAD E STORE hanno accesso alla memoria,LOAD preleva STORE salva\npi√π registri(almeno 35)=pi√π informazioni rapide da consultare\n\nPARALLELISMO\nIl clock √® il numero totale di cicli in un secondo, oggi abbiamo raggiunto un limite di clock, per aumentare la velocit√† delle istruzioni ci viene incontro il parallelismo che si divide in due tipi\ntipi di parallelismo:\n\na livello di istruzione\n\nquando esegui operazioni indipendenti, simultaneamente\n\n\na livello di processore\n\nquando pi√π CPU lavorano per risolvere lo stesso problema\n\n\n\nPrefetching\nI calcolatori sono stati progettati con la capacit√† di prendere le istruzioni in memoria prima che esse vengano eseguite nel buffer di prefetch.\nIn pratica il Prefetching era diviso in due parti\n\nprelievo dell‚Äôistruzione\nesecuzione dell‚Äôistruzione\n\n\n\n                  \n                  Fetch=prelievo di memoria \n                  \n                \n\nPipelining\n√® una strategia che divide un‚Äôistruzione in piccoli passaggi che vengono eseguite da unit√† hardware dedicate\n\nIl pipeline rende la latenza pi√π bilanciata\ncalcoli vari con MIPS T E s\nProcessori con pi√π pipeline\ncon il pipeline in base a quanto parallelismo faccio ottimizzo i tempi\nse hai due pipeline raddoppi la latenza di emissione\npoi si fecero pi√π processori con pi√π pipeline\n\n\nadd pass access page on obsidian\n\nArchitetture superscalari\nUtilizzare pi√π di due pipeline in parallelo comporterebbe un‚Äôaumento eccessivo dell‚Äôhardware perci√≤ si arriv√≤ a una soluzione differente\nOvvero quella di dividere lo stato 4(di esecuzione) in istruzioni che verranno eseguite contemporaneamente mentre prima venivano eseguite(le stesse istruzioni) contemporaneamente\novviamente s3 deve riuscire ad inviare contemporaneamente i dati a s4 in modo praticamente simultaneo\n\nParallelismo a livello di processore\nun aumento di processori comporta un fattore di miglioramento ma non troppo elevato, per ottenere un incremento di 50 100 bisogna progettare sistemi con molte cpu\nCi sono tre differenti approcci per il parallelismo a livello di processore:\nComputer con parallelismo sui dati\nFunziona basandosi sull‚Äôottimizzazione della gestione dei dati\nClassificazione di Flynn\n\n\nProcessori SIMD: sono costituiti da un vasto numero di processori identici che svolgono le stesse istruzioni su dati differenti(super computer vettoriali)\nProcessori vettoriali: esegue le stesse operazioni su 2 dati differenti (registri) con un unico sommatore\n\nmulti processori\nsegue la tecnica di mettere pi√π cpu che condividono una memoria in comune\ne che siano sincronizzati nel farlo e sono dette fortemente accoppiate (tightly coupled)\nsono senza memoria locale\n\nSono abbastanza irrealizzabili da fare perch√© uno dovrebbe collegare ogni CPU solo da una memoria condivisa, perci√≤ progettarono i multi computer\nmulti computer\nSe io mettessi una memoria locale per ogni CPU ottimizzo alcuni processi che possono svolgere singolarmente le CPU senza dover scrivere sempre tutto nella memoria condivisa\ncon memoria locale\n\nmemoria principale\n\nserve per memorizzare software e dati\nl‚Äôunit√† della memoria √® il bit una variabile che assume due stati\n\n\nsistemi di enumerazione\nServono per rappresentare i numeri\npossono essere scritte in diverse basi\nperch√© in base 16 vengono usate le lettere?\nperch√© venivano usati nella macchina da scrivere\nvedi gli appunti di logica sul binario Cap6-logica\n\nConversioni da altro a binario\nbase 4 prendi le informazioni in 2 blocchi\nbase 8 dividi in 3 blocchi\nbase 16 dividi in 4 blocchi\ne cos√¨ via\nindirizzi di memoria\nUna predefinita quantit√† di bit indica un indirizzo in una cella di memoria\n\nordinamento dei byte\ni byte in una parola possono essere scritte da sinistra a destra big endian o al contrario little endian\n\ncodici di correzione\nQuando le memorie dei calcolatori commettono degli errori per proteggersi da tali errori bisogna registrarli, le memorie usano dei codici di rilevazione e/o di correzione degli errori che si aggiungono alla normale informazione\nad esempio abbiamo n,m e r dove n=lunghezza della parola m=bit normali r=bit di controllo\nquesta si chiama (Codeword)\n\n\n                  \n                  parola=insieme di dati e informazioni in bit ad esempio \n                  \n                \n\nVedi il libro di esercizi su codice di hamming\nmemorie cache\nDevo leggere i dati dalla memoria principale ma √® un p√≤ lentina\nse usassi sempre la memoria principale si creerebbe del bottleneck\nsi decise di creare cos√¨ una memoria a tampone di poche dimensioni\ncon dei tempi di accesso veloci, dove vengono salvate le informazioni pi√π utilizzate.\nesempio:\nSto facendo un ordinamento se gli elementi me li trovo in memoria a tampone e non nella memoria principale gli step successivi saranno facilitati nel confrontare le informazioni\nQuando la CPU necessit√† di una determinata parola la cerca subito nella cache e poi la cerca in memoria centrale\nI principi\n\nprincipio di localit√† spaziale: dice che se hai usato una informazione A √® molto probabile che userai delle informazioni vicino ad A\nprincipio di localit√† temporale: temporalmente parlando se stai accedendo alle informazioni di A molto probabilmente nel corso del tempo userai cose nelle zone di A\n\n\n\n                  \n                  esempio stupido: \n                  \n                \n\nse stai vedendo una foto nella cartella comunioni probabilmente ne scorrerai un‚Äôaltra e\nprobabilmente rimarrai temporalmente nella cartella FOTO COMUNIONI\n\n\nGerarchie di memoria\nI processori pi√π recenti hanno diversi livelli di memoria che hanno dei compiti\n\nTipi di memoria\nsono banchi di diverse dimensioni\nhanno un indirizzamento di memoria e attraverso l‚Äôindirizzamento arriviamo al contenuto stesso.\nSi dividono in due tipi:\n\nSIMM: ha una riga di connettori su un solo lato\nDIMM: ha due righe di connettori(doppia faccia) e sono il doppio pi√π potenti delle SIMM\n\nriferimento libro: pag(51)\nriassunto:2 pag(14)\n"},"UNI/ANNO-1/ARCHITETTURA/LEZIONI/3.Le-memorie":{"slug":"UNI/ANNO-1/ARCHITETTURA/LEZIONI/3.Le-memorie","filePath":"UNI/ANNO 1/ARCHITETTURA/LEZIONI/3.Le memorie.md","title":"3.Le memorie","links":["UNI/ANNO-1/ARCHITETTURA/LEZIONI/2.Organizzazione-sistemi-di-calcolo"],"tags":[],"content":"argomenti:\n\nmemoria secondaria\nlibro(50)\nriassunto(2.14)\n\nGerarchie di memorie\npi√π la memoria √® grande pi√π ci metti tempo ad accedervi  e costa meno\nesempio:\n\nregistri della CPU sono pi√π veloci e meno capienti ma costano di pi√π\nnastri e dischi ottici sono pi√π capienti ma pi√π lenti per√≤ costano meno\nle varie memorie si possono mettere su una piramide dove pi√π vai in basso pi√π sono lente come accesso, pi√π capienti e meno costose, dove √® sottolineato in verde c‚Äô√® un gap\n\n\n\n\n                  \n                  Simonettata\n                  \n                \n\nla macchina non deve mai stare in attesa senn√≤ inefficiente\nquando andiamo dalla memoria centrale al disco meccanico c‚Äô√® ancora pi√π ritardo\nperch√® la testina dell‚Äôhard disk √® meccanica\ni dispositivi ottici potrebbero ESPLODERE nel tempo\n\n\ndischi magnetici\nSono uno o pi√π piatti di alluminio rivestiti da materiale magnetico.\nSi d√† una polarit√† a questi magneti con una carica elettrostatica dalla testina che corrispondono a (+/-) che poi letti dalla stessa testina corrispondono a  0 e 1\ntestina:si muove in modo longitudinale e copre tutta la superficie del disco che gira, la testina ha questo solenoide che permette di cambiare le particelle ferrose di una piccola porzione del disco che cambiano polarit√†\n\nla traccia\nla traccia √® la sequenza di bit che percorre il disco(quella in blu)\nle tracce sono divise in settori e tra i settori c‚Äô√® un gap di intersezione\npi√π la traccia √® vicino al centro pi√π √® densa di informazioni ma sempre con lo stesso numero di informazioni\n\n\nogni traccia √® formata da un preambolo che sincronizza le testine\nogni traccia ha un ECC che serve per il controllo degli errori e la correzione\n\n\nhard disk\nSfruttano pi√π dischi magnetici\nOgni disco ha diverse tracce e per le tracce parallele a tutti gli altri dischi si dice come la figura che forma, cilindro\nOgni disco ha la sua testina e ha un processore chiamato controller del disco che sincronizza i controlli dettati dal software\nci sono 3 tipi tempi:\n\nTempo di seek √® di circa 5/10 ms ed √® il tempo che impiega la testina per posizionarsi nella parte giusta\nLatenza rotazionale il disco deve girare per trovare l‚Äôinformazione giusta con rpm(rotazioni-per-minuto)con latenza tra 3-6 ms\ntempo di trasferimento tempo necessario per il passaggio dei dati al cervello della macchina con un tempo di 3,5/4 ¬µs(micro-secondi)\n\n\nI floppy disk\nsono piccoli ma contengono poca memoria\nsono tipo gli hard disk ma non sono immersi da un liquido e quindi le testine(punzone) che servono per leggerli toccano direttamente la superficie\nDischi IDE\nSu questi dischi il controllore non √® pi√π su una scheda separata ma su ogni testina.\nIl sistema operativo leggeva e scriveva dati sul disco e scriveva anche sul registro della CPU, invocando il BIOS nella ROM\nIDE si √® poi evoluto in EIDE che con uno schema di indirizzamento LBA(Logical Block Addressing) aument√≤ la capacit√† massima e la velocit√† di lettura sfruttando anche il parallelismo\nSCSI disk\nmeglio di quelli IDE perch√© il controllore permetteva di collegare fino a 7 dispositivi insieme\n(scanner, cd-rom, unit√† a nastro‚Ä¶)\nRAID\nDischi sempre pi√π grandi per tanti dati\navere un disco solo enorme SLED che tiene tutti i dati non √® il massimo,  si decise cos√¨ di farne tanti PICCOLINIIII\ne nacque cos√¨ l‚Äôidea del RAID ovvero quella di fare tanti dischi separati ma che poi il calcolatore li vede come un unico disco e distribuiscono i dati sulle diverse unit√† per permetterne una gestione parallela.\nSostituendo la scheda contenente il controllore del disco con un controllore di tipo RAID\nCi sono 5 livelli di RAID:\nRaid livello 0\ni dischi vengono usati per memorizzare le cose in ordine sequenziale applicando appunto il concetto di Round-Robin(riempio lo strip 0 poi strip 1 poi 2 e cos√¨ via‚Ä¶)\nAvendo le cose divise in 4 dischi puoi cercarle in parallelo e fare prima\nnon √® un vero RAID perch√© quando un disco si rompe non hai possibilit√† di recuperare i dati\n\nRaid livello 1\nha lo stesso concetto del raid 0 solo che in questo caso si crea una copia del disco nello stesso momento in cui si scrive su quello originale\nquali sono gli svantaggi? ci sono troppi dischi e la memoria si riduce\n\nRaid livello 2\nScomponi una parola distribuendola su ogni disco cos√¨ se hai un errore puoi scovarlo meglio con l‚Äôuso del codice di Hamming vedi:2.Organizzazione sistemi di calcolo\nad esempio nell‚Äôimmagine abbiamo 7 dischi,\nogni disco avr√† 1 bit della parola ma ogni 4 bit(nibble) ci saranno 3 bit di parit√† ovvero quei bit che con il codice di Hamming ci segnalano l‚Äôerrore\nproblema: tutti dischi devono essere gli stessi e devono essere sincronizzati e andare alla stessa velocit√†\n\nRaid livello 3\n√® simile al RAID 2 ma solo un disco √® dedicato ai bit di parit√†.\nOgni parola ha un bit di parit√† che spesso non √® sufficiente a risolvere l‚Äôerrore\n\nRaid livello 4\n√® come il raid 0 solo che ha un disco di parit√† che prende in considerazione tutti gli strip, quindi se un disco si guasta si pu√≤ riparare recuperando i byte dal disco di parit√†.\nHa prestazioni scarse e si pu√≤ creare un collo di bottiglia quando il disco di parit√† √® pieno\n\nRaid livello 5\n\nOgni disco ha una sezione dedicata alla parit√†\nil problema √® che per recuperare i dati ci metti troppo\nSSD\nSono basati su memoria flash non volatile(se spegni il pc le informazioni ci sono ancora)\nnon hanno elementi meccanici e costano di pi√π ma sono molto pi√π veloci dei normali dischi\nil principale guasto che pu√≤ avvenire √® che un transistor potrebbe rompersi e che pu√≤ rimanere o sempre spento o sempre acceso\nCD-ROM\nInventati dalla sony nel 1984\nsono dei dischi fatti di policarbonato con un alluminio riflettente, sopra questo materiale venivano creati dei solchi pit o venivano lasciati piatti land, questi funzionano come un vinile ovvero che un solco corrisponde a 1 e un land corrisponde a 0.\nPer essere rilevati questi solchi o colline venne usato un laser\ncd-rom vs magnetici\ncd rom tipo vinili in modo sequenziale\nmagnetici le informazioni sono sparse e a livello magnetico\n\nformato di memorizzazione:\nil cd rom ha per ogni simbolo(?) fa corrispondere ogni byte in  14 bit di cui 3 sono del codice di Hamming e due ne rimangono liberi\nogni 42 simboli hai un frame(588bit)\ne un sector ogni 98 frame\n\ni settori del cd rom\nle informazioni vengono memorizzate con o senza controllo di errore\nun settore contiene\nun preambolo(serve per dire che √® una nuova sequenza) da 12 byte fissi+4 byte che specificano il numero del settore(i settori sono numerati in ordine)\ne il modo, se stai usando o no la correzione di errore\nil modo 2 dove non sono attesi errori viene usato per musica e video\nPoi ci furono i CD-R registrabili, sono irreversibili dove i laser rompono il pigmento e corrispondono al pit\n\nCD-RW sono quelli riscrivibili\nvenivano utilizzate dei materiali per ripristinare lo stato iniziale del disco trasformare un pit in un land\nil laser ha 3 modalit√†\n\nbassa\n\nleggi lo stato del pigmento senza alterarlo\n\n\nmedia\n\nscioglie il materiale e lo ripristina allo stato naturale\n\n\nalta\n\nlo scioglie creando il pit\n\n\n\nDVD\nsono simili ai cd ma pi√π innovativi\n\nhanno pit pi√π piccoli\nspirale pi√π stretta\nlaser rosso\nmaggiore capacit√†\nmaggiore troughput (velocit√† di trasfermento)\nsi dividono in 4 formati:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nnr.side(dischi incollati)layer(due livelli)GB1single-sidedsingle-layer4.72single-sideddual-layer8.53double-sidedsingle-layer9.44double-sideddual-layer17\nconclusioni\nfinito a\npag(59)\nriassunto(22)"},"UNI/ANNO-1/ARCHITETTURA/LEZIONI/4.Input-Output":{"slug":"UNI/ANNO-1/ARCHITETTURA/LEZIONI/4.Input-Output","filePath":"UNI/ANNO 1/ARCHITETTURA/LEZIONI/4.Input-Output.md","title":"4.Input-Output","links":["tags/ASCII","tags/UNICODE","tags/UTF-8"],"tags":["ASCII","UNICODE","UTF-8"],"content":"argomenti:\n\nmobo\nbus, tipologie ed evoluzioni\ninput-output\ncaratteri\nlibro(58)\nriassunto(2.23)\n\nDispositivi del computer:\n\nLa scheda madre:\n\n√® la scheda principale e contiene CPU, gli slot per le RAM, i BUS di comunicazione e altri connettivi per I/O\n\n\n\n\nIl BUS:\n√® un sistema di comunicazione utilizzato per far comunicare tra loro i vari dispositivi di I/O( che hanno un loro controller personale che li interfaccia con esso)\nsi dividono in due tipi:\nseriali: hanno pochi cavi e con informazioni che vengono passate sequenzialmente\nparalleli: tanti cavi paralleli tra loro che consentono pi√π bit trasferiti allo stesso tempo\ncome sono fatti i bus interni?\nsono suddivisi in 3 parti:\n\nbus dati: trasmette le informazioni tra le componenti interne del computer(CPU, memoria‚Ä¶)\nbus di controllo: serve per sincronizzare lo scambio di dati con informazioni che sono ad esempio:\n\nil tipo di operazione(r/w)\ndimensione dei dati trasmessi\nrichiesta di interruzzione\n\n\nbus indirizzi: specifica l‚Äôindirizzo fisico dove i dati devono essere scritti o letti\n\n\nEsempio di lettura da disco:\n\n\n                  \n                  il programma deve ottenere dei dati da disco HDD cosa fa? \n                  \n                \n\n\nManda il comando dal suo controllore al controllore del disco\nNel disco eseguita l‚Äôoperazione di seek (posizionamento testina) cercando i dati\nLi restituisce al controllore in bit spezzandole in pi√π parole\nSe il controllore √® riuscito a leggere e a scrivere i dati in memoria senza l‚Äôaiuto della CPU ha effettuato un DMA(Direct memory access)\nSe il trasferimento √® completo avviene un interrupt che ferma il processo della CPU e fa\npartire l‚ÄôINTERRUPT SERVICE ROUTINE (ISR), controlla eventuali errori e informa il sistema\noperativo del trasferimento terminato con successo\n\n\n\nApprofondimento sul DMA\n\nPi√π dispositivi possono richiedere l‚Äôutilizzo del bus\nc‚Äô√® bisogno di qualcuno che gestisca gli accessi ad esso in base a delle priorit√† e si chiama arbitro del bus\nUn dispositivo richiede attraverso il suo controller di accedere al bus, il bus √® obbligato a farlo accedere subito, altrimenti ci sarebbe una perdita di dati, questa situazione genera un rallentamento dei cicli della CPU(cycle stealing)\nquando non c‚Äô√® nessun dispositivo I/O la CPU pu√≤ usare tutti i cicli del bus per fare le sue cosette\nBUS ISA:\ni bus ISA sono nel tempo diventati obsoleti poich√© i pc avevano bisogno di scambiare sempre pi√π informazioni\nla soluzione consiste nel migliorare i bus:\nEISA(con banda a 33,3 MB/s)\nPCI(528 MB/s)\nper rendere questi cambiamenti pi√π conosciuti Intel decise di pubblicare i brevetti di questi bus\n\n\n\n                  \n                  Simonettata\n                  \n                \n\ngli sviluppatori sono i carri trainanti di questi nuovi sistemi, se non ci sono\nsviluppatori non ci sono vendite\n\n\nComputer con due BUS\nPCI e ISA sono molto diversi tra loro\nsi invent√≤ un sistema che permetteva l‚Äôutilizzo di entrambi cos√¨ possono funzionare tutte le periferiche\nLa CPU √® collegata direttamente ad un suo bus dedicato ad alta velocit√†\nvengono utilizzati due ponti(bridge) per collegare questi due tipi di bus\n\nBus PCIe\nsfrutta una rete punto punto si aumentano le velocit√† di trasferimento fino a 17 GB/s\n\nDispositivi di input output\nle periferiche si dividono in 3 tipi:\n\ninput: tastiera, mouse e fotocamera\noutput: monitor, stampante e altoparlante\ninput e output: modem e hard disk\n\nTastiere\nquando viene premuto un tasto viene generato un interrupt che viene letto dal sistema operativo e corrisponde a un simbolo\n\nMonitor LCD\nQuesta tecnologia prima veniva usata solo sui portatili, ma ora viene usato su ogni schermo\nconsiste in un liquido che riflette come un cristallo la luce generata da un pannello illuminato che illuminer√† a seconda della refrazione un determinato colore\n\nRAM nella scheda video (VRAM)\nla VRAM memorizza le informazioni che vanno spalmate sullo schermo, i pixel\nquindi se abbiamo una risoluzione di 1920x1080 avremo 1920 pixel x 1080 pixel\nla bitmap √® una mappa di bit che vengono memorizzati dalla VRAM e che ci dicono le posizioni di quei bit\nimmagina che il monitor sia una matrice e che in base a riga e colonna tu devi distribuire dei bit che corrispondono a una informazione su schermo\nper collegare la GPU alla CPU usiamo un bus chiamato AGP oppure PCIe\nDispositivi di puntamento\n\nCome funziona il mouse?\nci sono 3 tipi di mouse\n\nmeccanico: dove c‚Äô√® una pallina che attraverso due resistenze permette il calcolo delle posizioni x e y\nottico: hai un led che ha una piccola fotocamera che rileva le imperfezioni della superficie e capisce gli spostamenti\nopto meccanico: hai una pallina e i movimenti della pallina vengono rilevai da un led ottico\n\nStampanti\nsono dispositivi di output che permettono di trasferire le informazioni su un supporto documenti elettronici\nsono di varie tecnologie:\n\na matrice (ha degli aghi che stampano in colonne o righe)\na getto d‚Äôinchiostro (con cartuccia con degli ugelli)\na laser(tamburo che si carica elettrostaticamente e viene colpito da un laser che scrive sul cilindro, dove √® stato scritto non √® pi√π elettrostatico passa sull‚Äôinchiostro dove non √® caricato e poi passa sul foglio)\ninchiostro solido\na getto di cera(usano inchiostri a cera su un nastro)\nsublimazione(da uno stato solido a gassoso senza passare per liquido, vaporizzazione dei colori )\ntermiche(piccoli aghi che disegnano su una carta termosensibile)\n\nStampanti a impatto a matrice\nContengono una matrice di punzoni elettromagnetici che scorre longitudinalmente mentre il foglio scorre sotto. Sono generalmente monocromatiche, lente, rumorose e di bassa qualit√† grafica. Si utilizzano generalmente per stampare su piccoli fogli o moduli prestampati.\nGetto di inchiostro\nTestina e foglio funzionano come sopra, l‚Äôinchiostro √® spruzzato da piccoli ugelli\nSono di due tipi:\n\npiezoelettriche: l‚Äôinchiostro viene spinto fuori a seconda della tensione elettrica\ntermiche: contengono una piccola resistenza elettrica dentro ogni ugello, la tensione scalda la resistenza che incrementa la pressione dell‚Äôinchiostro e lo spinge fuori l‚Äôugello. Economiche e silenziose, costo di manutenzione eccessivo\npoi scrivi\n\nLaser\nhanno un tamburo rotante che viene caricato elettricamente, un laser colpisce questo tamburo che girando attira la polvere della carica che perde e viene scaricata sul foglio\nApparati di telecomunicazioni\nogni casa che ha accesso a internet ha bisogno di connettersi attraverso una linea telefonica(senza contare la fibra),\nsolo che essa √® analogica ma a noi servono dei segnali digitali(bit)\nper fare ci√≤ utilizzeremo dei segnali portanti che oscillano tra 1kHz e 2kHz\nche ci permetteranno di definire gli 0 e gli 1(modulazione) con un margine d‚Äôerrore trascurabile\ni dispositivi che sfruttano il seguente sistema sono i modem\n\nCaratteristiche del modem:\nCi sono tre tipi di modulazione ovvero il modo di convertire una frequenza in bit\n\nModulazione di ampiezza(b): si utilizzano due valori standard che corrispondono a 0 e 1\nModulazione di frequenza(c): l‚Äôampiezza rimane costante ma cambia la portante in base a 0 o 1\nModulazione di fase(d): frequenza e ampiezza costanti ma cambia la portante ovvero la tensione\n\n\n\n\n                  \n                  Info\n                  \n                \n\nbitrate: numero di bit al secondo\nboudrate: numero di cambiamenti del segnale\n\n\nDSL Digital Subscriber Line\n√® una tecnologia che nasce da una limitazione del modem di 56 kbps dovuto al fatto che era in realt√† destinata solo a trasmissione vocale\nla pi√π utilizzata e conosciuta √® l‚ÄôADSL dove la A sta per Asymmetric\nil cavo che collega l‚Äôabbonato alla rete locale si chiama (cycle loop) e la velocit√† dipende dalla distanza di questo cavo\ncome funziona l‚ÄôADSL?\ni canali come vengono utilizzati?\n\ncanale 0: usato per le chiamate tradizionali Plain old telephone service POTS\n1-5: non vengono usati\n1 canale viene usato per upstream\n1 canale viene usato per il downstream\n248 per il trasferimento dati\ninformazioni:\nla adsl corrisponde a 250 modem\nsi chiama asincrona perch√© un provider di solito non d√† tutta la banda del download rispetto all‚Äôupload all‚Äôabbonato e quindi si crea un dislivello tra up e down\n\n\nLa codifica dei caratteri\nl‚Äôessere umano e la macchina per comunicare usano diversi standard:\n\nASCII\nUNICODE\nUTF-8\n\nASCII\nASCII\n√® pi√π usato e ogni carattere sono 7 bit in totale ci sono 128 caratteri\ni caratteri 00 e 1F sono i caratteri di controllo\nil problema del codice ASCII √® che non √® inclusivo con altre lingue e anche se hanno cercato di risolvere aggiungendo 1 bit in pi√π e quindi arrivare a 256 caratteri non √® stato comunque soddisfacente\n\n#UNICODE\nUNICODE\nquesto sistema nasce dai problemi del codice ASCII citato prima\nl‚Äôidea √® stata quella di assegnare a ogni carattere un valore a 16 bit unico\nchiamato code point che permetteva un‚Äôassegnazione di 65k caratteri\nUNICODE integrava i 256 caratteri nel suo codice cos√¨ da essere pi√π comune a tutti\n#UTF-8\nUTF-8\nUNICODE presto divent√≤ inutilizzabile poich√© 65k caratteri non erano sufficienti\nper questo venne invetato l‚Äôutf-8 Universal Character Set Transformation Format\nhanno lunghezza variabile da 4 a 8 byte e possono codificare circa 2 miliardi di caratteri\nUTF-8 viene utilizzato nel web e 1 byte √® destinato per i codici ASCII\ninformazioni da sapere:\n\nil primo byte di ogni carattere UTF-8 determina univocamente il numero di byte nel carattere.\ni byte successivi al primo in un carattere UTF-8 iniziano sempre con 10, cosa mai vera per il byte iniziale, rendendo il codice auto sincronizzante.\nin caso di errore di un qualche byte si pu√≤ comunque trovare il successivo basta trovare il 10\n\n\nconclusioni\nfinito a\npag(75)\nriassunto(finito il 2)"},"UNI/ANNO-1/ARCHITETTURA/LEZIONI/5.Algebra-Booleana":{"slug":"UNI/ANNO-1/ARCHITETTURA/LEZIONI/5.Algebra-Booleana","filePath":"UNI/ANNO 1/ARCHITETTURA/LEZIONI/5.Algebra Booleana.md","title":"5.Algebra Booleana","links":["UNI/ANNO-1/LOGICA/Logica-INDICE","UNI/ANNO-1/LOGICA/PARTE2LOGICA/Cap8-logica"],"tags":[],"content":"ARGOMENTI:\n\nAlgebra di Boole\nPorte logiche\n\nLivello Logico\nDi tutti i livelli della macchina quello che andremo ad approfondire oggi √® quello logico digitale\n\nAlgebra di Bool\nIdeata dal logico matematico George Bool, funziona con 0 e 1 oppure true e false e funziona con l‚Äôutilizzo di porte logiche che svolgono operazioni logiche\nDiversi tipi di funzioni che prevedono un output soltanto\nSono come delle scatole che ricevono un input e attraverso delle funzioni danno degli output che rispetto a n input sono (2^2)^n\n\n\n\nPropriet√† dell‚Äôalgebra di Boole\nVedere Logica INDICE\nOPERATORI UNIVERSALI\nattraverso la lezione Cap8-logica\nabbiamo visto che con CNF e DNF puoi trovare delle formule che ti permettono di tradurre qualsiasi tabella di verit√†\ncon le AND, OR e NOT\nsi pu√≤ fare la stessa cosa ma solo con NAND e NOR\n\nLe varie conversioni possibili:\n"},"UNI/ANNO-1/ARCHITETTURA/LEZIONI/6.Livello-Logico-Digitale":{"slug":"UNI/ANNO-1/ARCHITETTURA/LEZIONI/6.Livello-Logico-Digitale","filePath":"UNI/ANNO 1/ARCHITETTURA/LEZIONI/6.Livello Logico Digitale.md","title":"6.Livello Logico Digitale","links":["UNI/ANNO-1/LOGICA/PARTE2LOGICA/Cap9-logica","UNI/ANNO-1/ARCHITETTURA/LEZIONI/2.Organizzazione-sistemi-di-calcolo"],"tags":[],"content":"Argomenti:\nper qualsiasi cosa andare a: Cap9-logica\nci sono due tipi di circuiti\nCombinatori:\nCircuiti in cui semplicemente, output dipende da input\nSequenziali:\nCircuiti dove, output dipende da input oppure dai vari stati(Q) che pu√≤ avere il circuito\nlatch s-r\nhanno una uscita retro-azionata\n\nset: settarlo che vale 1\nreset: resettarlo a 0\nq √® lo stato in cui il latch pu√≤ esistere\nvedi appunti di logica:\n\nse S cambia q negata diventa 0 e q diventa 1\nse R diventa 1 S cambier√† altrimenti non cambia mai\nse sia s che r sono 1 diventa non deterministico\nSR-Latch clocked\n√® un sr latch che sfrutta il clock che ti permette di sincronizzare i circuiti\nD-latch\nrisolve l‚Äôambiguit√† del set reset, diventa deterministico\nnon pu√≤ pi√π esserci 1 e 1 insieme perch√© una √® la negata dell‚Äôaltra\nClock:\nClock √® un oggetto che genera un segnale alto o basso(impulso)\ncome ogni circuito √® soggetto a una latenza perch√© quando un segnale √® cambiato da una porta ci vuole un tempo fisico che √® al millisecondo ma comunque c‚Äô√® una latenza\n(tempo di refresh 5ms)\nFlip-Flop\n\n√® un evoluzione del D-latch Cap9-logica\npossiamo rappresentarlo con una onda quadra che segna 0 o 1(idealmente):\n\nlo stato del flip flop cambia durante la transizione del segnale in 2 modi:\n\nfronte in salita: da 0 a 1\nfronte in discesa: da 1 a 0\nNel flip-flop ci sono preset e clear che servono per forzare lo stato 1 o 0\nla transizione del dato avviene quando si ha un (level triggered) ovvero quando il segnale di clock √® alto e il master diventa 0 e lo slave diventa 1\nSi dice edge triggered perch√© pu√≤ reagire sia in un fronte in salita che un fronte in discesa\n\nGeneratore di impulsi(clock):\nsi collega ad esempio al flip-flop e serve per dare un clock che vada a un determinato periodo di oscillazione tra 0 e 1\n\nsfruttando la porta not e la porta and ti permette di generare periodicamente lo stesso dato a un determinato lasso di tempo\n\na √® l‚Äôinput\nb √® la negazione dell‚Äôinput ma ci mette un po‚Äô di tempo quando ci sono dei cambiamenti a cambiare\nc √® uguale ad a\nd prende il ritardo di c and b\n\nOrganizzazione della memoria\nI flip-flop memorizzano 1 bit se ne metto 8 insieme formano 1 byte da poter memorizzare\n\nLe celle di memoria:\nOgni cella ha un suo indirizzo soprattutto su memorie di grandi dimensioni.\nSu ogni cella possiamo eseguire operazioni di scrittura o lettura.\nesempio di cella a 12 bit:\n\ntu hai una memoria a 12 bit  costituita da 4 celle ciascuna memorizza una parola a 3 bit\npoi ci sono le rispettive uscite dei 3 input\n\nCs: Selezioni il chip cosa √®? chiedi al tutor\nindirizzi: il circuito seguente usa 2 bit per selezionare la cella(00,01,10,11) per selezionarlo usa il multiplexer\nOE: output enable serve per abilitare o meno(bho)\nReaD: se √® 0 abilita la scrittura se √® 1 abilita la lettura(bho)\n\n\nCome connettere pi√π uscite insieme?\nSe le metti in un unico filo si crea un corto circuito quindi sfruttiamo open collector o il buffer three state\nOPEN COLLECTOR:**\nC‚Äô√® una resistenza di pull-up che agisce come una porta or e che se almeno uno dei due input ha tensione bassa allora l‚Äôoutput dar√† L(low)\nBUFFER THREE STATE:**\nha uno stato in pi√π dei normali 0 e 1 ovvero quando hai una resistenza che √® al massimo della sua resistivit√† e impedenza\n\n\nChip di memoria\ni chip di memoria sono dei circuiti che memorizzano seguendo la logica seguita in precedenza e sono riusabili e espandibili.\na volte ragionano con logica positiva oppure al contrario con logica negativa\ni chip di memoria hanno dei segnali di controllo:\n\nCS chip select permette di selezionare il chip da attivare**\nWE write enable dice se deve leggere o scrivere**\nOE output enable fonde insieme i segnali di uscita**\n\nesempio di memoria di tipo (2^{11} \\times 2^{11})\n\n\nD serve per specificare l‚Äôoperazione che vogliamo fare lettura/scrittura\nSpecificare se vi state riferendo a una determinata riga e colonna mettendo true a RAS oppure a CAS\nRAS(row address strobe)\nCAS(column address strobe)\n√® pi√π lenta perch√© serve specificare riga e poi colonna, ma richiede meno pin rispetto a una memoria sequenziale\n\nmemoria volatile\nRAM\nci sono due tipi di RAM:\n\nstatiche: tengono l‚Äôinformazione finch√© sono alimentate, vengono caricate prima dell‚Äôesecuzione di un programma e funzionano tipo un flip-flop\ndinamiche: le dinamiche sono pi√π complesse usano un condensatore che si carica o scarica elettricamente, esso nel tempo perde la sua carica e quindi ciclicamente bisogna refresharlo, viene caricato anche nel mentre dell‚Äôesecuzione del programma, sono meno costose ma pi√π lente e possono essere:\n\nDRAM FPM (fast page mode)\nSDRAM un ibrido tra statico e dinamico\nSDRAM DDR(double data rate)raddoppia il tasso di trasferimento della SDRAM\n\n\n\nmemoria non volatile\nROM(Read Only Memory):\nsono memorie a sola lettura il cui contenuto non cambia e non sono volatili\nPROM:\nmemoria rom programmabile bruciando dei piccoli fusibili che fanno parte di un array che fa parte di una serie di righe e colonne.\nEPROM:\nsono anche cancellabili attraverso una luce ultravioletta che li mette tutti a 1\nEEPROM:\nfunziona come la EPROM. ma per modificarla basta un impulso elettrico\nMEMORIA FALSH:\n√â come la EEPROM ma la memoria flash √® cancellabile a blocchi e riscrivibile.\nChip della CPU\nil modo in cui comunica all‚Äôesterno √® attraverso i segnali e i pin\nci sono 3 tipi di chip:\n\nindirizzi\ndati\ncontrollo\ni pin della CPU sono connessi agli altri componenti con i 3 bus\nci sono 3 bus:\ncontrollo\nindirizzo\ndati\n\ni passaggi della CPU:\n\nmette sul bus indirizzi l‚Äôindirizzo dell‚Äôistruzione\nusa il bus di controllo per dire che vuole eseguire una lettura alla memoria\nla memoria risponde con la parola e con un segnale positivo che dice che l‚Äôoperazione √® andata bene\nla CPU riceve il segnale di controllo e si prepara per eseguire l‚Äôistruzione\n\n\n\n                  \n                  vedere fetch decode excecute \n                  \n                \n\n2.Organizzazione sistemi di calcolo\n\n\nI PIN della CPU\ni pin di indirizzamento e dei dati ci permettono di caprie se una CPU √® performante oppure no\n\ncon n pin dati pu√≤ leggere n-bit x clock\ncon m pin indirizzi pu√≤ indirizzare fino a 2^m indirizzi\nI pin di controllo possono essere raggruppati in diverse categorie:\ninterrupt: momento di fermo di tutti i processi per dare priorit√† a determinati processi come quelli di lettura e scrittura\ncontrollo del bus: controlla i segnali del bus selezionando le componenti\narbitraggio: specifica il tipo di segnale e serve per regolare il traffico del bus con priorit√†\ncoprocessore: semplifica le operazioni che dovrebbe fare la CPU\ni pin di stato: inviano o ricevono informazioni di stato\naltri pin servono per altre funzioni generiche\n\n\nBus del calcolatore\nquando si parla di dispositivi del calcolatore alcuni si dicono attivi e altri passivi:\n\nattivi o master, inviano le informazioni nel bus, hanno un bus driver per inviare il segnale\npassivi o slave, attendono le informazioni dal bus, hanno un bus receiver collegarsi con il bus\nquesti per evitare corti circuito nel bus usano il sistema buffer tri-state oppure il wired OR\n\nAmpiezza del bus\nil bus ha una determinata ampiezza questo significa che in un ciclo di clock posso passare determinate locazioni di memoria che vanno a 2^n, incremento dell‚Äôampiezza del bus di indirizzi porta un aumento delle informazioni ma anche un aumento dei costi, fili e connettori\nLarghezza di banda del bus\nper aumentare la larghezza di banda del bus si pu√≤:\n\nridurre il numero di operazioni in un ciclo di clock\n\nproblemi di retrocompatibilit√†\nproblemi di disallineamento(dispositivi che vanno a velocit√† differenti)\n\n\nincrementare ampiezza del bus dati\n\npu√≤ causare un rallentamento del sistema\n\n\n\nTemporizzazione del bus\n\nbus sincroni: le attivit√† del bus vengono scandite da un suo ciclo detto ciclo di bus dove ogni operazione richiede n cicli di clock\n\n\n\n                  \n                  cosa fa la CPU che vuole leggere da memoria? \n                  \n                \n\n\nLa CPU(master) pone l‚Äôindirizzo di memoria sull‚Äôaddress bus\nLe linee di indirizzo si stabilizzano su nuovi valori(DATA) e MREQ si asserisce dicendo che la richiesta di memoria √® disponibile per fare operazioni di scrittura e lettura e RD cambia per specificare se bisogna fare lettura e scrittura\nse la memoria impiega troppo tempo per rispondere asserisce WAIT per fargli fare altre cose nel frattempo\nappena la memoria √® pronta toglie WAIT\nla CPU legge i dati memorizzandoli in un registro\nuna volta finito nega MREQ e RD\n\n\n\n                  \n                  √® importante che i dati vengano messi sul bus prima che la CPU le legga \n                  \n                \n\n\n\n\nbus asincrono: si manifesta un handshake tra master e slave senza tenere conto dei tempi, il bus si adatta a seconda delle velocit√† dei dispositivi ma √® pi√π difficile da costruire\n\n\n\n                  \n                  esempio e informazioni del bus asincrono \n                  \n                \n\nogni operazione mette il tempo che gli serve e quando inizia MSYN si asserisce e quando finisce si nega SSYN\n\n\n\nArbitraggio del bus\nSe pi√π dispositivi vogliono utilizzare il bus abbiamo bisogno di un arbitro che le regolamenti dando diverse priorit√† ad ognuno.\n\n\n                  \n                  Noi abbiamo questa grande autostrada ma deve essere regolamentata e gestita. \n                  \n                \n\nl‚Äôarbitro pu√≤ essere decentralizzato o centralizzato.\nCentralizzato\n\nl‚Äôarbitro centralizzato √® integrato nel chip della CPU oppure √® separato, il problema √® che se si rompe √® un macello\n\nIl bus contiene una unica linea di richiesta or cablata(+input che convergono in un or)\n\nd√† priorit√† a quelli pi√π vicini all‚Äôarbitro(collegamento a festone)\n\n\nun altro tipo √® a due livelli, dando priorit√†, una componente fa richiesta a una delle priorit√† e viene accettata o meno\n\n\n\n\ndecentralizzato:\nIn quello decentralizzato non c‚Äô√® un arbitro e ogni dispositivo ha una sua priorit√†\nha pi√π linee di richiesta ciascuna ha assegnata una priorit√†.\nI componenti comunicano tra di loro per sincronizzarsi e spartirsi il bus\nMalus: tot dispositivi per tot livelli\nci sono tre linee:\n\nrichiesta del bus\nbusy\narbitraggio che serve per dare le informazioni per far sincronizzare i componenti\nil bus deve essere inattivo asserendo la variabile IN, se IN √® negata allora significa che la componente non pu√≤ diventare master negando la sua OUT(della componente)\n\n\n\n                  \n                  ESEMPIO \n                  \n                \n\nSe la prima componente trova IN asserito allora procede a fare quello che deve fare,\nmettendo OUT negata cos√¨ che le componenti successive trovano la in negata e non asserita\n\n\n\n\n\n                  \n                  Dalle\n                  \n                \n\n\n\n\nOperazioni del bus\nA volte pu√≤ essere utile trasferire pi√π parole in un unico trasferimento.\nAll‚Äôinizio della lettura del blocco il master del bus comunica allo slave quante parole deve trasferire in un lasso di tempo T1\nLo slave restituisce l‚Äôesatto numero di parole anche se ci mette cose a caso\nBLOCK, viene asserito per indicare che √® stato richiesto il trasferimento di un blocco.\n\nInterrupt Handling\n√à un segnale di interruzione che la CPU riceve una volta che un dispositivo ha finito\nLa CPU aspetta l‚Äôinterrupt(da una richiesta che ha fatto ad una componente) e nel frattempo fa altro(il pepe)\nper evitare 1 miliardo di interrupt contemporanei ci sar√† un arbitro che li gestisce\n8259A\n√® un esempio di un controllore degli interrupt\nci puoi collegare fino a 8 controllori\nquando uno o pi√π interrupt sono asseriti la variabile INT asserisce e asserisce anche il pin di interrupt sulla CPU la CPU successivamente quando √® pronta per gestire la interrupt invia un impulso su INTA confermando che √® pronta, successivamente l‚Äô8259A dir√† alla COU quale dispositivo ha causato questa interrupt attraverso un ciclo di bus speciale.\nLa CPU ha questo vettore con scritti tutti i dispositivi e cos√¨ capisce chi √® stato a causare l‚Äôinterrupt.\nL‚Äô8259A ha al suo interno vari registri che la CPU pu√≤ leggere e scrivere utilizzando i cicli di bus ordinari e i pin RD (ReaD), WR (WRite), CS (Chip Select) e A0(indirizzo della cella).\nuna volta che la CPU ha finito quello che doveva finire scrive un codice speciale nel registro che fa negare INT cos√¨ che sia pronto a futuri interrupt\n"},"UNI/ANNO-1/ARCHITETTURA/LEZIONI/7.Livello-logico-digitale(2)":{"slug":"UNI/ANNO-1/ARCHITETTURA/LEZIONI/7.Livello-logico-digitale(2)","filePath":"UNI/ANNO 1/ARCHITETTURA/LEZIONI/7.Livello logico digitale(2).md","title":"7.Livello logico digitale(2)","links":[],"tags":[],"content":"ARGOMENTI:\n\nesempi di cpu\nesempi di bus\ninterfacce\nil troughput pu√≤ essere una unit√† di misura per capire quanto √® veloce il processore\ne pu√≤ misurare ogni componente che svolge la funzione nella pipeline\n\nESEMPI DI CPU:\n\nPentium 4\n\n3.2 Ghz\n90nm\npu√≤ accedere a memorie a 64 bit ma i programmatori ci programmano sopra a 32 bit\nha 3 livelli di cache\n\n8kb di SRAM\nfino a 1mb\nda 2 MB\n\n\nVisto che ha due CPU potrebbe accadere un problema, se una modifica una parola nella sua cache locale, l‚Äôaltra CPU avr√† una versione vecchia della parola. perci√≤ avviene il processo di monitoraggio detto snooping che permette alla CPU di tenere traccia delle modifiche che ha fatto, quindi quando un‚Äôaltra CPU entra nel bus della memoria cercando qualcosa che ha gi√† modificato l‚Äôaltra CPU essa procede a inviarglielo aggiornato.\npipeline pi√π profonda\ndue unit√† ALU che che operano al doppio della frequenza di clock\nil problema delle CPU √® che ciucciano troppa energia, perci√≤ intel ha trovato un modo per metterle in idle e farle consumare meno energia.\n\nquesta tecnologia divide il funzionamento della cpu in 5 livelli da attivo a sonno profondo, pi√π vai verso il livello di sonno profondo pi√π perdi funzionalit√† come lo snooping e l‚Äôinterrupt handling, quando la CPU va in sonno profondo rimangono attivi solo il registro e la cache e la CPU attende un interrupt hardware per risvegliarsi\n\n\n\n\n\nPin e segnali del Pentium4\nLa cpu ha diversi pin(478) e sono spartiti a seconda di diversi compiti:\n\nalcuni per i segnali di I/O, wait, interrupt‚Ä¶\naltri per l‚Äôalimentazione a diversi voltaggi\naltri ancora per la massa\ne la intel si lascia qualche pin libero per un uso futuro\n\nI PIN DEL PENTIUM 4\nARBITRO DEL BUS\n\nBPRI# bus priority request\nBR0# bus request\nLOCK# la CPU chiede all‚Äôarbitro del bus per bloccarla e permetterne l‚Äôutilizzo solo della CPU\n\nPIN DI RICHIESTA\nSegnali scambiati con l‚Äôaddress bus e il bus di controllo\n\nA# trasferimento di bit di indirizzamento ha 36 bit di indirizzamento di cui 3 impostati a 0\nADS# Si asserisce se l‚Äôindirizzo inserito sul bus √® valido\nREQ# Specifica l‚Äôoperazione di lettura o scrittura\n\nPIN DI ERRORI\n\nMISC √® un segnale di errore generico che serve per segnalare se c‚Äô√® un errore\n\nPIN DI RISPOSTA\nSono dei pin che usa il bus slave per comunicare con il bus master\n\nRS# contiene il codice di stato, ovvero un codice che ti d√† lo stato corrente della CPU o del processo che sta eseguento\nTRDY# indica che lo slave √® pronto ad accettare dati dal master\nBNR# asserisce uno stato di attesa quando il dispositivo indirizzato non pu√≤ rispondere\n\nPIN DI DATI\n√à utilizzato per il trasferimento di dati\n\nD# trasferisce 8 byte nel bus\nDRDY# si asserisce quando D sta per trasferire i dati, cos√¨ che tutti gli altri componenti sono informati della cosa\nDBSY#  viene usato per comunicare a tutti i dispositivi che il bus √® occupato\n\nIL PIN DI RESET‚Äô#‚Äô\n\nViene usato per resettare la CPU in caso di problemi\n\n\n\n                  \n                  differenza tra bus di controllo e arbitro del bus \n                  \n                \n\nl‚Äôarbitro del bus si limita a gestire il traffico\nil bus di controllo invece gestisce tutto ci√≤ che riguarda le operazioni che svolge il bus come l‚Äôinvio o il ricevimento di dati, gestione degli indirizzi ecc..\n\n\n\nPipeline nel Pentium 4\nLe CPU sono pi√π veloci delle memorie centrali basate su DRAM e per questo √® essenziale ottimizzare la pipeline per ottenere il massimo troughput dalla memoria per evitare attese della CPU\n\n\n                  \n                  troughput : \n                  \n                \n\n(quantit√† di istruzioni in un determinato tempo)\n\n\nPer consentire l‚Äôuso della pipeline, le richieste di memoria del Pentium 4, chiamate transazioni, sono composte da sei stadi.\n\n\nFase di arbitraggio del bus;\n\n\nFase di richiesta;\n\n\nFase di segnalazione dell‚Äôerrore;\n\n\nFase di investigazione (snoop);\n\n\nFase di risposta;\n\n\nFase dei dati.\n\n\n\nIntel Core I7\n\n64 bit\n4 core\n45 nm\n3,2 GHz\nHyperthreaded ovvero pi√π thread simultanei, quindi pi√π spezzettamenti di una singola istruzione che lavorano in parallelo\nHa 3 livelli di cache e lo snooping\n\n\nUltraSPARC 3\n\nlinea di processori RISC usata per server e workstation\n130 nm 1,2 GHz\ndue CPU CISC e RISC non si possono confrontare tra loro\nLa CPU poteva eseguire 4 istruzioni per ciclo di clock e aveva:\n\n6 pipeline interne:\n\n2 a 14- stadi per operazioni su numeri interi\n2 per operazioni a virgola mobile\n1 per operazioni di LOAD e STORE\n1 salti e branch del programma\nha 2 cache, quando fa una ricerca di una parola e non la trova nella cache di primo livello(miss) cerca la parola nella cache esterna di secondo livello che √® pi√π lenta\n\n\n\n\n\nMicro controllore 8051\nimportante per gli esercizi sugli indirizzimenti e l‚ÄôI/O\na pagina 73\n√à uno dei microcontrollori pi√π diffusi, il microcontrollore √® un apparato per svolgere compiti specifici programmabili e pi√π economici di una normale CPU\n\n40 pin con 16-bit di address pu√≤ indirizzare fino a 64KB di meoria, 8-bit per il bus dati\nha 32 linee di I/O divise in 4 gruppi di 8 bit ciascuno\ni primi 7 a sinistra sono usati per interfacciarsi a memorie esterne\n\nla A viene usata per l‚Äô indirizzamento alla memoria esterna\nla D √® un pin dati a 8-bit per il trasporto dati\n\\overline{RD} si asserisce per indicare che deve fare una lettura\n\\overline{WR} si asserisce per indicare che deve fare una scrittura con la memoria esterna\nALE indica la presenza di un indirizzo valido sul bus\n\\overline{PSEN} (Program Store Enable):si attiva quando viene usata una memoria esterna\n\\overline{EA} (External Access)pu√≤ essere collegato:\nhigh usa sia la memoria interna che quella esterna\nlow: usare solo quella esterna\n\n\ndue cicli di clock esterni\ndue priorit√† di interrupt diverse\nlinee di I/O:\n\nTXD usato per l‚Äôuscita seriale(uscita sequenziale)\nRXD ricevere il segnale in modo sequenziale\nci sono anche 4 porte seriali sia di I/O bidirezionali ciascuna con 8- bit paralleli\n\n\nRST serve per resettare il chip\n\n\ni tipi di Bus\nci sono diversi tipi di bus uno √® quello AGP\nfu introdotto negli anni 90 e era dedicato alle schede grafiche\n\nBus PCI\n\n√® sincrono e ha un master che invia i dati ad uno slave e viceversa\nrispetto EISA aveva una larghezza di banda maggiore cos√¨ trasferiva pi√π dati\nInoltre le linee di indirizzi e dati sono multiplexate per ridurre i pin, in modo da rendere necessari solo 64 pin per i segnali di indirizzo e di dati.\ncosa fa il bus PCI?\n\nsvolge un‚Äôoperazione di lettura immettendo l‚Äôindirizzo sul bus(lo fa il master)\nrimuove l‚Äôindirizzo che ha depositato e il bus si inverte per far s√¨ che l‚Äôinformazione che cercava il master arrivi a lui\nlo slave(componente) invia i dati che ha richiesto il master con gli stessi pin\nNelle operazioni di scrittura il bus non deve essere invertito perch√© il master invia e basta e lo slave se lo salva\n\n\n\n\nBus PCIE(express)\n\nsi chiama PCI ma in realt√† non √® nemmeno un bus e nemmeno ci azzecca con il PCI\nil PCIE ha un commutatore(gestore) che ha il compito di fare da intermediario tra le componenti e il chip bridge, le componenti sono collegate con il commutatore attraverso un sistema punto-punto e il commutatore invia le informazioni al chip bridge che le scambia con la memoria e la CPU\nIl modello concettuale del bus PCI √® quello di un master che lancia allo slave un comando per leggere una parola oppure un blocco di parole. Il modello di PCI Express √® invece quello di un dispositivo che spedisce un pacchetto di dati a un altro dispositivo.\ncon il bus PCIE puoi inserire le componenti anche sul momento\n\n\nIL PACCHETTO DEL PCIE\nfunziona con una serie di protocolli a strati\n\nLa stratificazione dei protocolli consente una progettazione modulare e flessibile\n\nI LIVELLI dei protocolli del PCIE:\n\nfisico: lo spostamento(zozzo) dei bit da un mittente a un destinatario lungo la connessione punto a punto\ntrasmissione: si assicura che la connessione tra i due dispositivi avvenga con successo e che non ci sia perdita di pacchetti\ntransazione: gestisce le azioni sul bus, quindi il trasferimento la formattazzione del pacchetto e il traffico\nsoftware: interfaccia il sistema PCI Express al sistema operativo\n\nnella figura b c‚Äô√® come vengono suddivise le informazioni di un pacchetto\n\n\n\n                  \n                  cosa √® un protoccolo \n                  \n                \n\nuna serie di istruzioni e regole che servono per consentire la comunicazione tra due parti(tipo https con server e pc)\n\n\nUniversal Serial Bus\nnasce da un problema PCI E PCIE sono troppo costose per connettere periferiche a bassa velocit√†\n\n√® composto da un HUB principale o root hub dove ogni periferica √® collegata con esso, l‚ÄôHUB √® collegato direttamente sul bus\nil cavo √® composto da 4 fili 2 per i dati, 1 di alimentazione √® 1 per la massa\nquando un nuovo dispositivo viene collegato che succede?\nl‚Äôhub root rileva questo evento genera un interrupt per il sistema operativo che:\n\nriceve l‚Äôinterrupt e interroga il dispositivo per sapere di che tipo √® e la necessit√† di banda\nse la larghezza di banda √® sufficiente il sistema operativo gli assegna un numero unico e carica le informazioni del dispositivo\nora tutto funziona e non serve fare altro\nl‚Äôhub si collega ai dispositivi di I/O con un collegamento punto-punto, i dispositivi non possono connettersi tra loro ma solo con l‚Äôhub\nper mantenere sincronismo spedisce ogni tot ms un nuovo frame(pacchetti)\n\n\n\nTipi di Frame\nUSB supporta 4 tipi di frame, ovvero pi√π pacchetti dati che vengono scambiati ogni tot ms con l‚Äôhub\n\ndi controllo: servono per configurare i dispositivi, per assegnargli dei comandi e per fare dei check di stato\nisocroni: per dispositivi in tempo reale che devono inviare pacchetti ogni tot(mirofoni)\nbulk: utilizzati per trasferire file di grandi dimensioni\ninterrupt: la USB non accetta interrupt quindi per far funzionare una tastiera viene interrogata ogni 50 ms per raccogliere i dati relativi alla pressione dei tasti\n\nTipi di pacchetti\nUn frame contiene n pacchetti\nne esistono 4:\n\ntoken: servono per il controllo del sistema dall‚Äôhub al device\ndati: servono per sincronizzare e identificare i pacchetti dati\nhandshake: serve per stabilire la connessione e c‚Äô√® una attesa\nspecial: per usi specifici specialissimi\n\n\nInterfacce di I/O\nqueste interfacce sono delle schede che permettono di collegarsi ad elementi esterni\nesistono dei chip standard:\n\nUART: legge un byte dal bus dati e lo trasmette un bit alla volta in output oppure al contrario\nUSART: √® UART gestisce vari protocolli allo stesso tempo, in modo sincrono\nPIO: chip per il collegamento di un dispositivo I/O che lavora in parallelo\n\nCome √® fatto il PIO?(esercizi a pag.73)\nchip programmabile 8255A\nha due porte di I/O(quelle a destra)\ne possono inviare 8 bit per porta\n\n\\overline{CS} : collega pi√π PIO in parallelo\nA0-A1: comunica con il bus indirizzi per scegliere l‚Äôinformazione\n\\overline{WR} : si asserisce quando la CPU ha emesso i dati sul bus e sono validi per la scrittura\n\\overline{RD} : si asserisce quando la CPU effettua una lettura dal bus dati\nD: viene usato per scambiare i dati con il bus dati\n\n\nI dispositivi di I/O si dividono in due tipi di indirizzamento:\n\nport mapped I/O:\n\n√® un reale dispositivo di I/O\nquesto dispositivo viene contraddistinto dal control bus come un dispositivo separato dalle memorie che gi√† gestisce\nperci√≤ hanno un indirizzo di memoria a s√© e la CPU decide se rivolgersi ad esso oppure ad una delle sue memorie\n\n\nmemory-mapped I/O:\n\n√® trattato come se avesse un indirizzo di memoria uguale alla memoria che c‚Äô√® gi√† nel sistema(ordinaria)\nLa CPU scrive dentro questo dispositivo come se fosse una componente di memoria(es. ram, Hdd o un registro)\nle informazoni che verranno inviate a quel determinato indirizzo in realt√† andranno sul dispositivo di I/O\n\n\n\n\n\n                  \n                  Chat GPT esempio: \n                  \n                \n\nEcco alcuni esempi pratici dei due metodi di indirizzamento I/O:\n\nPort-mapped I/O:\n\n\n\nEsempio pratico: Supponiamo che un computer debba inviare un byte a una stampante.\n\n\nNella port-mapped I/O, la CPU utilizza una specifica istruzione OUT che trasmette il byte a un\n\n\nindirizzo I/O che √® dedicato alla stampante. Questo indirizzo √® diverso da qualsiasi indirizzo di\n\n\nmemoria e l‚Äôistruzione OUT √® specifica per le operazioni di I/O.\n\n\nApplicazioni tipiche: I sistemi che usano port-mapped I/O spesso riservano questo metodo\n\n\nper dispositivi che richiedono una comunicazione semplice e diretta con la CPU, come il\n\n\ncontrollo di piccole luci a LED o motori in un sistema embedded.\n\n\n\nMemory-mapped I/O:\n\n\nEsempio pratico: Consideriamo un sistema grafico in cui la GPU deve aggiornare\ncontinuamente i pixel sullo schermo. Nella memory-mapped I/O, ci sarebbe un blocco di\nmemoria dedicato che rappresenta l‚Äôintero schermo, detto framebuffer. La GPU legge e scrive\ndirettamente a questo blocco di memoria per cambiare l‚Äôimmagine visualizzata sullo\nschermo. La CPU tratta queste operazioni come se stesse leggendo e scrivendo su normale\nmemoria, anche se in realt√† sta interagendo con la GPU.\nApplicazioni tipiche: Questo metodo √® spesso usato per dispositivi che necessitano di\nun‚Äôintensa e rapida trasmissione dati, come schede video, schede di rete, o per implementare\ninterfacce utente complesse in sistemi operativi.\n\n\n\nArchitettura di esempio del memory-mapped I/O\n\nlo spazio di indirizzamento sono 16 bit ovvero 64 KB\nche verranno rispettivamente utilizzati dalla EPROM(programma) e la RAM(dati) con 2 KB per uno e la PIO con 4B\n\nLa EPROM riconosce che la CPU si sta rivolgendo a lei(si accende) quando viene inviato un segnale compreso tra 0000 e 07FF ovvero quando sono bassi A15 fino a A11\nla RAM si accende quando A15 √® alto e A14 fino ad A11 sono bassi(8000 e 87FF)\nLa PIO risponde quando A15 fino a A2 sono alti(accesi) quindi FFFC e FFFF\n\n"},"UNI/ANNO-1/ARCHITETTURA/LEZIONI/8.Architettura-ARM":{"slug":"UNI/ANNO-1/ARCHITETTURA/LEZIONI/8.Architettura-ARM","filePath":"UNI/ANNO 1/ARCHITETTURA/LEZIONI/8.Architettura ARM.md","title":"8.Architettura ARM","links":["tags/0xF0000000","UNI/ANNO-1/ARCHITETTURA/ESERCIZI/ESERCIZI-ARM"],"tags":["0xF0000000"],"content":"Cosa √®?\nL‚Äôacronimo sta per Advanced RISC Machine\ndal tipo di architettura ARM, prende il nome l‚Äôazienda che ne detiene le licenze\n\nVarie versioni della architettura ARM\nQuelle che vedremo di pi√π sono le v7\ne si dividono in 3 tipologie:\n\nCortex-A: dispositivi ad elaborazione avanzata tipo per i telefoni\nCortex-R: per applicazioni in tempo reale tipo roba per automobili\nCortex-M: per processori a basso consumo e che siano veloci\n\n\nInstruction set ARM\nL‚Äôinstruction set √® una serie di istruzioni che occupano determinati bit di lunghezza fissa e che esegue il processore di tipo ARM, l‚Äôarchitettura ARM ne prevede 3 :\n\n32 bit istruzioni ARM: uso di istruzioni di tipo LOAD/STORE dove ogni istruzione pu√≤ essere di tipo condizionale modificando lo stato di una flag\n16 bit Thumb: √® una versione compressa delle istruzioni ARM ma non ha tutte le sue funzionalit√†, ad esempio non √® condizionale tranne la funzione Branch(salto) dove in base a una condizione avviene il salto da un indirizzo di memoria all‚Äôaltro\n8 bit Jazelle: permette l‚Äôesecuzione di bytecode Java sulla CPU senza convertirlo in istruzioni ARM\n\n\n\n                  \n                  cosa √® il bytecode \n                  \n                \n\nIl bytecode √® un tipo di codice sorgente intermedio pi√π astratto rispetto al codice macchina\nnativo eseguito direttamente da un processore. Mentre il codice macchina √® specifico per\nun‚Äôarchitettura hardware particolare, il bytecode √® progettato per essere eseguito su una\nmacchina virtuale (VM) anzich√© direttamente su un hardware fisico.\n\n\n\n\n                  \n                  cosa √® il registro di stato? \n                  \n                \n\nil registro di stato √® quella memoria che salva tutti gli stati delle flag(tipo 0 o 1) che vengono usati per svolgere problemi di tipo condizionale\n\n\nLe sue caratteristiche\n\nOgni istruzione pu√≤ essere skippata o meno  in base a delle condizioni che si verificano dalle flag(es: se due valori sono uguali, oppure un risultato di una operazione ha stato negativo)\nArchitettura LOAD/STORE, ovvero una architettura che ha le operazioni di caricamento dalla memoria e di salvataggio sulla memoria separate.\nNon √® possibile fare operazioni di shift elementari ma solo operazioni aritmetiche logiche che possono portare allo stesso risultato anche con solo una istruzione\nNon esiste la divisione matematica, deve farla un coprocessore\nIncremento o Decremento degli indirizzi di memoria per andare alla successiva o alla precedente per fare lavori su array di memoria (tipo ++ sui puntatori in c)\nPi√π istruzioni di Load/Store in una sola istruzione, aumentando quindi l‚Äôefficienza di trasferimento\n\nLe eccezioni ARM\nLe eccezioni sono eventi asincroni(indipendenti da altri processi), avvengono improvvisamente quando c‚Äô√® una interruzione di tipo:\n\nhardware\nsoftware\nerrore\nreset\ni processori ARM sono progettati per ridurre al minimo la gestione delle eccezioni\n\nModalit√† di funzionamento\nCi sono diverse modalit√† in cui opera l‚Äôarchitettura ARM:\n\nUSER: di solito √® in questa modalit√† ovvero NON privilegiata\nFIQ: entra in questa modalit√† quando si verifica un interrupt ad alta priorit√†, gestisce le interruzioni in modo pi√π efficiente e veloce\nIRQ: entra in questa modalit√† quando si verifica un interrupt a bassa priorit√†\nSupervisor: √® il supervisore e fornisce accesso alle risorse di sistema, gestisce gestioni critiche tipo software interrupt\nUndef: usato per gestire le violazioni all‚Äôaccesso di memoria, un programma accede a una porzione di memoria a cui non pu√≤ accedere\nSystem: funziona come un user solo che ha accesso ai registri con modalit√† privilegiata\n\nPriorit√† delle eccezioni\n\nCome sono organizzati i registri dell‚Äôarchitettura ARM?\n\n16 registri utilizzabili vanno da R0 a R15\nun registro che serve per gli stati dei programmi CPSR(Current Program Status Register)\n20 registri non accessibili\n\nREGISTRI\nOgni registro dei 16 che possiamo usare hanno una funzione di base\n\nDa R_0 a R_{12}  sono per uso generale\nR_{13} (SP): √® un registro che viene spesso usato per tenere l‚Äôindirizzo dello stack presente in memoria\nR_{14} (LR): Link Register √® un registro dove viene salvato l‚Äôindirizzo precedente all‚Äôinizio di una determinata procedura cos√¨ da poterci tornare indietro una volta finita\nR_{15} (PC):Program Counter, √® quel registro che salva l‚Äôindirizzo di memoria dell‚Äôistruzione successiva a quella attuale\n\n\n\n                  \n                  cosa √® lo stack? \n                  \n                \n\nlo stack √® una struttura dati usata spesso per tenere in registro le chiamate a funzione e\nl‚Äôallocazione dinamica\n\n\n\nRegistro CPSR\nCurrent Program Status Register\nMemorizza lo stato del processore inclusi vari flag e bit di controllo\n√® composto da 32 bit divisi in 3 tipologie\n\nbit di modalit√†(quelle viste prima FIQ, IRQ‚Ä¶)\nbit di controllo\nbit di flag, contengono le varie operazioni tra flag ecc‚Ä¶\nFlag di stato(esprimono delle condizioni aritmetiche di un confronto):\nN: Negativo\nZ: Zero\nC: Riporto\nV: Overflow\n\n\nOgni modalit√† ha dei registri disponibili ecco la foto:\n\n\nPre-condizioni\nLe condizioni sono quelle robe che determinano se una istruzione va eseguita o meno\nLa pre-condizione serve per definire se bisogna eseguire una condizione si esprime con i valori delle flag del registro CPSR(quello di prima)\n\n\n                  \n                  chatgptoso esempio \n                  \n                \n\nUn‚Äôistruzione con una condizione ‚ÄúEQ‚Äù (equal) sar√† eseguita solo se il flag Zero (Z) nel CPSR √®\nimpostato, indicando che il risultato dell‚Äôultima operazione era zero. Questo permette di creare\ncodice molto efficiente che utilizza meno salti e branch.\n\n\n\nArchitettura interna del processore\nL‚Äôorganizzazione interna dell‚ÄôARM prevede l‚Äôutilizzo di 3 registri:\n\nRd: il registro destinazione dove viene salvato il risultato di una operazione\ndue registri sorgente:\n\nRn: registro sorgente che contiene il primo operando utilizzato nella ALU\nRm: registro sorgente che contiene il secondo operando eseguito dopo il passaggio nel barrel shifter\n\n\n\n\nCosa √® un barrel shifter?\n√à un circuito digitale che esegue uno shift di bit in un solo ciclo di clock, si realizza collegando in parallelo tanti multiplexer e pu√≤ fare lo shift in diversi modi, definendo il tipo e il numero di shift:\n\nshift a destra\nshift a sinistra\nrotate\n\nTipi di dati:\nle istruzioni ARM operano su diversi tipi di dati tra cui:\n\nByte, 1-Byte sono 8-bit\nHalf word 2-Byte, 16-bit\nFull word 4-Byte, 32 bit\nAttraverso questi tipi di dati il linguaggio assembly pu√≤ esprimere diversi formati:\nInteri in diversi basi\nNumeri in virgola mobile\nValori booleani\nSingoli caratteri\nStringhe di caratteri\n\nModalit√† di indirizzamento\nCi sono 3modalit√† di indirizzamento per fare in modo che il processore trovi e usi i dati(operandi) per fare calcoli o compiti:\n\nquando il dato √© dentro l‚Äôistruzione si dice indirizzamento immediato\nquando il dato √® dentro un registro si dice indirizzamento a registro\nquando il dato √® dentro un registro ma prima di essere usato va shiftato si dice indirizzamento a registro con shift\n\nOltre a quelle 3 modalit√† si divide in altri 5 modi\n\nL‚Äôindirizzamento si pu√≤ anche usare in una istruzione di elaborazione dati\npuoi fare l‚Äôindirizzamento su operazioni di LOAD e STORE su word o byte senza segno\npuoi fare un indirizzamento su LOAD e STORE trattando word double-word o byte\nPuoi fare l‚Äôindirizzamento su LOAD e STORE multiple\nPuoi fare un indirizzamento su LOAD e STORE con uso di coprocessori\n\nRegistro e offset\ntutte le istruzioni che usano Load e Store hanno bisogno di un registro base e il suo offset che √® come se fosse l‚Äôindice del registro\nci sono diverse operazioni che possiamo fare con l‚Äôoffset per muoversi nel registro ad esempio:\n\nl‚Äôoffset √® immediato ed √® un valore senza segno specificato nell‚Äôistruzione(tipo r0+#0)\nl‚Äôoffset a registro √® quando il valore dell‚Äôoffset √® dentro un registro e pu√≤ essere incrementato o decrementato\nun offset a registro scalato: quando l‚Äôoffset ha un valore che viene calcolato di ogni tot attraverso uno shift( tipo r0*4)\n\nModalit√† di indicizzazione\nl‚Äôindicizzazione ti permette di calcolare indirizzi di memoria per raggiungerli durante l‚Äôaccesso a dati, istruzioni ecc‚Ä¶\nfondamentalmente √® il modo in cui il registro viene messo in base al registro di base\nci sono due modalit√† di indicizzazione:\n\npre-indicizzata: sappiamo gi√† dove andare, quindi sappiamo gi√† la cella, quindi facciamo registro base+ cella che gi√† sappiamo, e che ci porta direttamente l√¨\npost-indicizzato: prima accediamo alla memoria poi il dato viene sommato con l‚Äôoffset cos√¨ ottenendo l‚Äôindirizzo finale, quindi scorrendo tutto il registro\n\nQuindi abbiamo la possilit√† di combinarli i metodi(modi+registro e offset+indicizzazione)\nnon tutte le funzioni sfruttano queste combinazioni\nEsempi di indirizzamento\n\nTipo di istruzioni\nCi sono diverse istruzioni ARM e si dividono nelle seguenti tipologie:\n\nElaborazione e trasferimento dati\nDiramazione del flusso o di branch: variazione nel flusso di un programma\nAccesso in memoria\nCambiamento di stato\nVerso i coprocessori\nPer generare eccezioni\nPer generare dati Pseudo istruzioni\n\nIstruzioni di Elaborazione e trasferimento dati\n\n\nAritmetiche e logiche\n\n\nAritmetiche con saturazione\n\n\nconfronto\n\n\nSIMD(Single Instruction Multiple Data)\n\n\nSelezione dei byte\n\n\nMoltiplicazione\n\n\nTrasferimento dati\n\n\nAritmetiche e logiche\noperano su due operandi e il primo √® sempre un registro il secondo o un valore o un\nregistro o un registro con barrell shifter\nsono istruzioni che possono aggiornare i flag del registro di stato\ne sono roba tipo or ecc‚Ä¶\nsintassi di queste cose:\n&lt;MNEM&gt;{&lt;PreCond&gt;}{&lt;S&gt;} &lt;Rd&gt;, &lt;Rn&gt;, OP2\n\nMNEM: il nome della specifica istruzione\nPreCond: √® opzionale, indica l‚Äôesecuzione dell‚Äôistruzione se verificata(condizione)\nS: opzionale, forza la scrittura nel registro di stato(CPSR), delle informazioni dell‚Äôoperazione compresi cambiamenti del flag di stato\nRd: destinazione quindi tipo quello prima dell‚Äôuguale\nRn: sorgente del primo operando\nOP2: secondo operando, pu√≤ essere valore, registro o registro shiftato\n\nOgni istruzione √® una parola a 32 bit e ha un suo OPCODE\n\n\n\nil bit 25 indica se c‚Äô√® o meno uno shift\n\nIndirizzamento immediato\nUn problema dell‚Äôindirizzamento immediato √® che tu hai solo 12 bit(quelli su OP2) per rappresentare la word ovvero l‚Äôistruzione completa(32 bit)\nper risolvere questa cosa i progettisti hanno diviso i 12 bit in 4 di posizione e 8 di valore\nvedendo la tabella si puo‚Äô notare un esempio\nla posizione rappresenta il numero di shift di 2 bit\ni valori rappresentano quei bit in binario che una volta sistemati rappresentano l‚Äôindirizzo immediato voluto\nes:\n\nvalori 10000001_2\nposizioni 1101_2\n\notterremo quindi un indirizzo a 32 bit ovvero 0x00002040\n\nA volte gli indirizzamenti portano a errori\nad esempio se noi proviamo a fare una\nMOV R0,#0xFFFFFFFF\nl‚Äôassembler non riuscir√† a fare l‚Äôoperazione MOV perch√© pu√≤ spostare al massimo 8 bit e con tutte quelle F ne abbiamo di pi√π\nquindi il programmatore deve inventarsi dei trucchi per aggirare il problema\nquali sono:\n\nfare NOT #0x0000000\nspostarsi piano piano l‚Äôindirizzo ad esempio:\n\ncon 0X55550000 te li sposti piano piano usando or e traslazioni\n\n\n\n\nIstruzioni aritmetiche con saturazione\nIl linguaggio ARM prevede che i numeri vadano fino a 2^{31}-1 per le cose positive\ne per i negativi -2^{31}\nSe si fanno operazioni di diverso tipo si potrebbe incorrere in overflow o underflow\nsforando il numero potrebbe rappresentare qualcosa di sbagliato\nSoluzione:\nI progettisti hanno definito un dominio che √® limitato, se il numero supera quel determinato limite rappresentabile viene asserito un flag Q nel registro di stato CPSR e quel numero non cicla, ovvero non torna dal punto di inizio, ma satura.\nle istruzioni aritmetiche di saturazione\n&lt;MNEM&gt;{&lt;PreCond&gt;} &lt;Rd&gt;, &lt;Rm&gt;, &lt;Rn&gt;\n\nIstruzioni di confronto\nLe istruzioni di confronto hanno in ingresso due operandi ma non un registrazione poich√© il loro effetto √® nel registro di stato in base al flag del risultato\n&lt;MNEM&gt;{&lt;PreCond&gt;}&lt;Rn&gt;,Op2\n\n\ncosa fanno CMP, TEQ, CMN e TST?\n\nCMP: fa la comparazione e si comporta come SUB quindi fa la sottrazione per fare un confronto(se esce il numero negativo o positivo)\n\nTEQ: test di uguaglianza bit a bit e si comporta come un EOR XOR\nCMN: comparazione negativa e funziona come l‚ÄôADD\nTST: test bit e funziona come l‚Äôand\n\nIstruzioni SIMD(Single Instruction Multiple Data)\nSono delle istruzioni che operano su dati multipli come se fossero una sorta di Array.\nUn esempio di una singola istruzione √® la somma tra due array.\n\nCome e fatta una istruzione SIMD\n&lt;MNEM&gt;{&lt;PreCond&gt;} &lt;Rd&gt;, &lt;Rn&gt;, &lt;Rm&gt;\n\nDifferenza tra array di byte e array di halfword\n\narray di byte sono quegli array dove ogni elemento √® composto da 8 bit ovvero 1 byte le istruzioni che ci si possono fare sono queste\n\narray di halfword sono quegli array dove ogni elemento compone met√† parola ovvero 16 bit\n\n\nI flag GE(Greater than or Equal) &gt;=\nQueste flag presenti nel registro CPSR\nTengono conto dell‚Äôesito del confronto dei singoli byte o delle singole half word di un registro di dati(array)\nl‚Äôesisto di un confronto puo‚Äô essere Top o Bottom\nIstruzione di Selezione di Byte\nSi chiama select e analizza i flag di confronto del GE e decide quale byte copiare nel registro di destinazione\nSEL{&lt;PreCond&gt;}&lt;Rd&gt;,&lt;Rn&gt;,&lt;Rm&gt;\n\nda 8 a 11 SBO(Should Be One) i bit della codifica\nIstruzioni di moltiplicazione\npermettono di fare moltiplicazioni o somme su halfword e word e devi avere minimo 2 registri e massimo 3 come operandi, con o senza segno e ritornano o una word o una double word\n&lt;MNEM&gt;{&lt;PreCond&gt;}{&lt;S&gt;}&lt;Rd&gt;,&lt;Rn&gt;,&lt;Rm&gt;\nla tabella sotto √® a 2 operandi\n\n\n\na 3 operandi\n\n\n\ndouble word\n\n\n\nIstruzioni di trasferimento dati\nSono istruzioni che svolgono il compito di trasferire dati(registri, numeri, ecc‚Ä¶)\n&lt;MNEM&gt;{&lt;PreCond&gt;}{&lt;S&gt;}&lt;Rd&gt;,&lt;OP2&gt;\n\nIstruzioni di accesso ai registri di stato\nsi dividono in\n\n\nMRS(Move to Register from Status register):\ncopia il valore del CPSR, o del SPSR, all‚Äôinterno dei registri di uso generale.\nMRS {&lt;PreCond&gt;} &lt;Rd&gt;, {CPSR|SPSR}\n\n\nMSR (Move to Status register from Register): copia il contenuto di un registro o una costante in una o pi√π ambiti del registro CPSR o SPSR\nVari tipi di ambiti:\nc = controllo\nx = estensione\ns = stato\nf = flag\nMRS {&lt;PreCond&gt;} {CPSR|SPSR}{_&lt;ambiti&gt;}, &lt;Rm&gt;\nMRS {&lt;PreCond&gt;} {CPSR|SPSR}{_&lt;ambiti&gt;}, #&lt;valore&gt;\n\n\n\n\n\n                  \n                  Esempio di istruzione ai registri di stato \n                  \n                \n\nMRS R0, CPSR          // R0 = CPSR (lettura stato)\nBIC R0, R0, #Ox1F     // Ripulisce mode bit\nORR R0, R0, #0X13     // Imposta modo Supervisor\nMSR CPSR_c, R0        // CPSR = R0 (scrittura stato)\n\nNel caso si debba modificare esclusivamente un certo ambito del registro di stato (es. flag), si pu√≤ restringere l‚Äôapplicazione dell‚Äôistruzione utilizzando la sintassi\n\n\n\nMSR CPSR_F, 0xF0000000\n\n\n\nIstruzioni di branch\nservono per saltare da una istruzione all‚Äôaltra sfruttando i tag(arrivano fino a 32 MB)\nvediESERCIZI ARM\n&lt;MNEM&gt;{&lt;PreCond&gt;}&lt;Operando\nsi pu√≤ scrivere come:\n\nB(Branch): carica nel PC(R15) l‚Äôistruzione da noi desiderata\nBL(Branch with Link): oltre a fare un normale branch carica l‚Äôindirizzo di ritorno dell‚Äôistruzione su LR(R14)(registro di chiamata a funzione)\n\n\n\nIstruzioni LOAD/STORE\nSono le uniche istruzioni che permettono di accede alla memoria\nsi dividono in 2 istruzioni\n\nLDR(Load Register):\nSTR(Store Register):\n&lt;MNEM&gt;{&lt;PreCond&gt;}{B}{T}&lt;Rd&gt;,&lt;Indirizzamento&gt;\nB:quando viene usato Garantisce che solo un byte venga letto o scritto, viene usato per operazioni su stringhe che sono estremamente precise\nT: viene usato per fare operazioni di LOAD e STORE in user mode, pu√≤ essere usato quando si devono gestire troppi ruoli e cos√¨ forzi le operazioni di LOAD e STORE in modalit√† user\nLe operazioni di load e store prevedono un loro suffisso che ne specifica il tipo di dato\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSUFFISSODESCRIZIONEBByte senza segnoSBByte con segnoHHalfword senza segnoSHHalfword con segnonon indicatoWordLoad e Store possono spostare anche pi√π registri insieme con diverse modalit√†\nSRS(Store Return State)\nSalva lo stato di ritorno da inviare al RFE che avr√† il compito di inviare questo stato al PC e al CPSR se si verifica una eccezione\nReturn from Exception\nLa RFE permette di caricare la coppia di registri PC  e CPSR ad un punto di ripristino se si verifica una eccezione(errore)"},"UNI/ANNO-1/ARCHITETTURA/LEZIONI/9.PROGRAMMARE-IN-ARM":{"slug":"UNI/ANNO-1/ARCHITETTURA/LEZIONI/9.PROGRAMMARE-IN-ARM","filePath":"UNI/ANNO 1/ARCHITETTURA/LEZIONI/9.PROGRAMMARE IN ARM.md","title":"9.PROGRAMMARE IN ARM","links":["UNI/ANNO-1/ARCHITETTURA/LEZIONI/8.Architettura-ARM"],"tags":[],"content":"Lezione del capitolo 4 che ci introduce la programmazione in ARM\nAlgoritmo\nInsieme di passi finiti e elementari che ci permettono di raggiungere un determinato risultato(obiettivo)\n\nIL CONTRATTO\ninput e output si affacciano con il mondo esterno e vengono processati da un algoritmo\n\nFLOW-CHART\nPrima di creare il programma il programmatore deve creare una struttura che indica il funzionamento del codice ad esempio usando il flow chart\n\nTeorema di B√∂hm-Jacopini\nNel 1966 fu enunciato da questi due informatici italiani un enunciato che dice:\nqualunque algoritmo pu√≤ essere implementato usando solo tre strutture:\n\nsequenza\nselezione\niterazione\nquesto metodo risolutivo non √® strutturato e quindi si chiama spaghetti code\n\nPROBLEMA\nUn algoritmo destrutturato(tipo flow-chart) ha un problema ovvero che non pu√≤ essere tradotto in un linguaggio di programmazione imperativo(tipo c)\nInvenzione del DNS (Diagrami Nassi-Shneiderman)\n√à una alternativa strutturata dello spaghetti-code, permette di rappresentare il codice con dei blocchi\n\npu√≤ essere usato con tantissimi linguaggi di programmazione(C, Java o Assembly)\ntraduzione semplice\n\nESEMPIO DI DNS\n\nAlgoritmo DNS complesso\n√à come si mostra il programma DNS completo\n\nBlocchi di selezione\nSelezionare significa dividere la sequenza in pi√π vie risolutive a seconda di condizioni che si verificano durante l‚Äôesecuzione\nsono di diverso tipo:\n\nSingola: Se si verifica una condizione (+ o true) Viene eseguito un determinato blocco altrimenti si passa direttamente a (- o false) si procede con il normale algoritmo\nBinaria: Si divide in 2 condizioni che portano a due blocchi diverse (+) e (-)\nMultipla: ho una variabile che rappresenta un intervallo di valori se la condizione √© verificata per quell‚Äôintervallo viene eseguito il blocco associato oppure quello di default(tipo lo switch)\n\n\ntutti questi blocchi del DNS poi ci riconducono a del vero codice sorgente\nBlocchi iterativi\nSono dei blocchi che rappresentano delle istruzioni che si ripetono fino al verificarsi di un determinato evento logico\n\n\nper approfondire i registri CPSR e altri leggere 8.Architettura ARM\nEsempio istruzione ARM\nSe si vuole eseguire una istruzione con precondizione si deve scrivere\nADD(PRECOND)\nad esempio ADDGT, l‚Äôistruzione verr√† eseguita se e solo se Greater Then √® verificata\nper verificarlo andr√† a leggere il CPSR basandosi sulle flag nella colonna 3 della tabella sopra\nesempi con add:\nADD R0, R1,R2\nSomma tra i contenuti dei due registri, indirizzamento a registro\nADD R0, R1,#16\nSomma tra un registro e un indirizzamento immediato (il numero decimale 16)\nADD R0, R1,#0xF\nSomma tra quello che c‚Äô√® tra il registro R1 e il numero exa F\nBranch LR\nBranch con utilizzo di link che ti riportano all‚Äôindirizzo dell‚Äôistruzione prima di eseguire il Branch\nIR e PC piano piano vanno avanti con l‚Äôesecuzione del codice andando riga per riga finch√© non incontrano BL che funge da salto in una determinata etichetta.\nessendoci una situazione di Link viene sfruttato il registro 14 ovvero il registro LR che terr√† al suo interno la situazione ‚Äúpre-Branch‚Äù ovvero quel momento prima di eseguire il salto cos√¨ che il program counter possa tornarci una volta finita l‚Äôetichetta\n\nIstruzione di load(LDR)\nLOAD serve per caricare in un registro una cosa a cui si punta tipo un‚Äôaltro registro\nLDR{type}{condition} dest, [pointer]\nLDR{type}{condition} dest, [pointer,offset]\n\n‚Ä¢ [pointer] Supponiamo di avere un registro R3 contenente un indirizzo di memoria e vogliamo caricare il contenuto di quella locazione di memoria in un altro registro, ad esempio R4.\nPossiamo fare ci√≤ utilizzando l‚Äôindirizzamento a registro come segue: LDR R4, [R3] In questo caso, [R3] indica che il contenuto della memoria all‚Äôindirizzo specificato nel registro R3 deve essere caricato nel registro R4.\nSe R3 contiene ad esempio l‚Äôindirizzo 0x1000, l‚Äôistruzione caricher√† il contenuto della locazione di memoria 0x1000 in R4.\nIstruzione di store(STR)\nfa la stessa cosa carica in memoria il contenuto di un registro sorgente nella memoria attraverso un puntatore\nTraduzione dei blocchi DNS in linguaggio assembly ARM\nPer tradurre uno schema con il DNS a un codice tipo assembly\nprima si prendono le variabili e si mettono  nel caso del linguaggio assembly all‚Äôinterno di registri\nogni blocco viene tradotto in istruzioni come CMP MOV Branch ecc‚Ä¶"},"UNI/ANNO-1/ARCHITETTURA/LISTA-ARGOMENTI":{"slug":"UNI/ANNO-1/ARCHITETTURA/LISTA-ARGOMENTI","filePath":"UNI/ANNO 1/ARCHITETTURA/LISTA ARGOMENTI.md","title":"LISTA ARGOMENTI","links":[],"tags":[],"content":"INTRODUZIONE SULLE ARCHITETTURE (Cap 1 ‚Äì Architettura dei calcolatori)\n\n Dominio digitale e analogico\n Linguaggi, livelli e macchine virtuali\n Evoluzione delle architetture di computer\n Approccio strutturale\n Pietre miliari nell‚Äôarchitettura dei computer\n Tipologie di computer\n Unit√† metriche\n\nPROCESSORI E MEMORIA PRINCIPALE (Cap 2 ‚Äì Architettura dei calcolatori)\no PROCESSORI\n\n Organizzazione della CPU\n Esecuzione dell‚Äôistruzione\n RISC contro CISC\n Principi di progettazione dei calcolatori\n Parallelismo a livello di istruzione\n Parallelismo a livello di processore\n\nMEMORIA PRINCIPALE\n\n Bit\n Sistemi di numerazione\n Indirizzi di memoria\n Ordinamento dei byte\n Codici di correzione di errore\n Memoria cache\n Memoria principale\n\nMEMORIA SECONDARIA\n\n Gerarchie di memorie\n Dischi magnetici\n Floppy disk\n Dischi IDE\n Dischi SCSI\n RAID\n Dischi a stato solido\n CD-ROM\n CD-Registrabili\n CD-Riscrivibili\n DVD\n\nINPUT/OUTPUT\n\n Il bus\n Direct Memory Access (DMA)\n Tastiere\n Monitor LCD\n RAM della scheda video (VRAM)\n Dispositivi di puntamento\n Stampanti\n Apparati di Telecomunicazioni\n Codifica dei caratteri\n\nLIVELLO LOGICO DIGITALE (Cap 3 ‚Äì Architettura dei calcolatori)\n\n Algebra di Boole\n Trasformazioni nel dominio di Boole\n Circuiti logici digitali elementari\n Circuiti Integrati o CIRCUITI COMBINATORI\n Multiplexer\n Decoder\n Comparatori\n Programmable Logic Arrays (PLA)\n Shifter\n Adder\n Arithmetic Logic Units (ALU)\n Clock o MEMORIA\n Flip-flop\n Registri\n Organizzazione della Memoria\n Buffer\n Chip di memoria\n Random Access Memory\n Memorie Non-volatili (ROM, PROM, EPROM, EEPROM)\n Chip di CPU\n BUS\n Ampiezza del bus\n clock del bus\n Bus sincroni/asincroni\n Arbitraggio del bus\n Interrupt handling\n ESEMPI DI CPU\n Intel Pentium 4\n Intel Core i7\n UltraSPARC III\n Intel 8051\n ESEMPI DI BUS\n Bus ISA\n Bus PCI\n PCI Express\n USB\n INTERFACCE\n Interfacce di I/O\n Interfacce PIO\n Decodifica dell‚Äôindirizzo\n\nIL LIVELLO DI MICROARCHITETTURA (Cap 4 ‚Äì Architettura dei calcolatori)\n\n Un esempio di microarchitettura\n Il modello di esecuzione\n Data path (o percorso dati)\n Formato delle microinstruzioni\n Microarchitettura Mic-1\n Esempio di ISA: IJVM\n Lo stack\n Il modello della memoria\n Insieme delle istruzioni\n\nIL LIVELLO DI MACROARCHITETTURA (Cap 5 ‚Äì Architettura dei calcolatori)\n\n Overview del livello ISA\n Tipi di dati\n Formati di istruzioni\n Modalit√† di indirizzamento\n Tipi di istruzioni\n Controllo del flusso\n Architetture Intel IA-32 e IA64\n\nIL LIVELLO DEL LINGUAGGIO ASSEMBLATIVO (Cap 7 ‚Äì Architettura dei calcolatori)\n\n Introduzione al linguaggio assemblativo\n Le macroistruzioni\n Il processo di assemblaggio\n Linker e loader\n\nINTRODUZIONE AI SISTEMI OPERATIVI (Cap 1 ‚Äì I moderni sistemi operativi)\n\n Che cos‚Äô√® un sistema operativo?\n Storia dei sistemi operativi\n Panoramica dei SO\n Concetti di base dei SO\n Le chiamate di sistema\n Struttura di un sistema operativo\n Introduzione al linguaggio C\n\nPROCESSI E THREAD (Cap 2 ‚Äì I moderni sistemi operativi)\n\n GESTIONE DELLA MEMORIA (Cap 3 ‚Äì I moderni sistemi operativi)\n FILE SYSTEM (Cap 4 ‚Äì I moderni sistemi operativi)\n INPUT/OUTPUT (Cap 5 ‚Äì I moderni sistemi operativi)\n\nARCHITETTURE PER IL CALCOLO PARALLELO (Cap 8 ‚Äì I moderni sistemi operativi e Cap 8 ‚Äì I moderni sistemi operativi)\n\n INTRODUZIONE\n PARALLELISMO NEL CHIP\n COPROCESSORI\n MULTIPROCESSORI\n MULTICOMPUTER\n VIRTUALIZZAZIONE\n"},"UNI/ANNO-1/DISCRETA/ARGOMENTI-CON-LIMITI-E-INTEGRALI":{"slug":"UNI/ANNO-1/DISCRETA/ARGOMENTI-CON-LIMITI-E-INTEGRALI","filePath":"UNI/ANNO 1/DISCRETA/ARGOMENTI CON LIMITI E INTEGRALI.md","title":"ARGOMENTI CON LIMITI E INTEGRALI","links":[],"tags":[],"content":"ESERCIZI SU NOTAZIONI ASINTOTICHE\nquello che bisogna sempre vedere\n\n\nTROVARE FORMULA CHIUSA\n"},"UNI/ANNO-1/DISCRETA/Discreta-INDICE":{"slug":"UNI/ANNO-1/DISCRETA/Discreta-INDICE","filePath":"UNI/ANNO 1/DISCRETA/Discreta INDICE.md","title":"Discreta INDICE","links":["UNI/ANNO-1/DISCRETA/ORGANIZZAZIONE-DISCRETA","UNI/ANNO-1/DISCRETA/GRAFI-e-RETI","UNI/ANNO-1/DISCRETA/INSIEMISTICA","UNI/ANNO-1/DISCRETA/OPA","ciao/content/UNI/ANNO-1/DISCRETA/PROBABILIT√Ä","UNI/ANNO-1/DISCRETA/RELAZIONI","UNI/ANNO-1/DISCRETA/RSA","UNI/ANNO-1/DISCRETA/ARGOMENTI-CON-LIMITI-E-INTEGRALI"],"tags":[],"content":"Indice\npiano personale:\nORGANIZZAZIONE DISCRETA\nGRAFI e RETI\nINSIEMISTICA\nOPA\nPROBABILIT√Ä\nRELAZIONI\nRSA\nARGOMENTI CON LIMITI E INTEGRALI"},"UNI/ANNO-1/DISCRETA/GRAFI-e-RETI":{"slug":"UNI/ANNO-1/DISCRETA/GRAFI-e-RETI","filePath":"UNI/ANNO 1/DISCRETA/GRAFI e RETI.md","title":"GRAFI e RETI","links":[],"tags":[],"content":"ACCOPPIAMENTO da A in B\nnormale: costrizione nei gradi deg(s)&gt;=deg(t) a in b\nsemplicemente ti calcoli i gradi facendo A sceglie B per S e viceversa per T.\nse uno non puoi farlo perch√® sotto √® pi√π grande di sopra allora devi prendere l‚Äôinsieme totale e sottrargli quello che dovevamo mettere sopra al coefficiente e basta.\n\ncon intersezione: uguale all‚Äôaltro solo che cambia il calcolo combinatorio da fare\n\noppure tecnica lavoratori lavori dove ogni lavoratore deve avere almeno un lavoro e lo occupa senn√≤ non c‚Äô√© accoppiamento\nNUMERO DI COLORAZIONI\ncerca di colorarlo con il meno numero di colori possibile\n\nSE SONO ISOMORFI\ndai dei numeri ai nodi se non hanno la stessa logica allora non lo sono, ad esempio se 7 √® collegato con 3 e 4 ma in nessun modo nell‚Äôaltro grafo riesci a farlo allora non sono isomorfi\nNON SONO ISOMORFI PERCH√à LA LORO STRUTTURA √à DIFFERENTE\n\nDIPENDENTI INDIPENDENTI\nCOLORABILE CON 100001312312 COLORI\nRETI DI COMUNICAZIONE\nORARI PARALLELI DI TEMPO MINIMO\n"},"UNI/ANNO-1/DISCRETA/INSIEMISTICA":{"slug":"UNI/ANNO-1/DISCRETA/INSIEMISTICA","filePath":"UNI/ANNO 1/DISCRETA/INSIEMISTICA.md","title":"INSIEMISTICA","links":[],"tags":[],"content":""},"UNI/ANNO-1/DISCRETA/OPA":{"slug":"UNI/ANNO-1/DISCRETA/OPA","filePath":"UNI/ANNO 1/DISCRETA/OPA.md","title":"OPA","links":[],"tags":[],"content":"OPA 1\nax+by=n\n\nfare mcd\nmcd|n? fai n/mcd e vedi se esce un numero che appartiene agli interi\nse esce un numero che non appartiene agli interi scrivilo dicendo che non appartiene agli interi\nfai bezout con r=a+b(-q)\nuna volta fatto bezout moltiplica gli argomenti x e y con il risultato della divisione tra n e mcd\nscrivere equazione diofantea\n\n\nOPA 2\nINVERSA MOLTIPLICATIVA\n[a]_b\nse hai [-a]_b fai [a-b]_b e continua esercizio\nfai MCD\n\nse esiste fai bezout\n\nOPA 3\nRICORSIONI LINEARI"},"UNI/ANNO-1/DISCRETA/ORGANIZZAZIONE-DISCRETA":{"slug":"UNI/ANNO-1/DISCRETA/ORGANIZZAZIONE-DISCRETA","filePath":"UNI/ANNO 1/DISCRETA/ORGANIZZAZIONE DISCRETA.md","title":"ORGANIZZAZIONE DISCRETA","links":[],"tags":[],"content":"Data esame 26 febbraio\n10 giorni\nguida:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPriorit√†ColoreImportanteRossoMedioGialloNormaleBianco\nargomenti da vedere\n\n  3 opa con priorit√† al terzo\n\ninversa moltiplicativa\nbezout\nricursiun linuar\n\n\n\n\n Calcolo combinatorio\n\ncoeff.bin\nmultinomiale\ncomposizione/debole\nmultinsiemi\nsequenze cin rep.\nprincipio i.e.\n\n\n somme\n\npolinimiali\nnon polinomiali\ndoppie\nproduttorie\nnotazioni asintotiche\n\n\n RSA\n\ncapire A e B!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n\n\n Insiemistica\n\nrelazione equivalenza\niniettiva, surry e biunivoca\ngruppo simmetrico\nidentit√†, inversa funzione\n\n\n Grafi\n\nisomorfi\nnumero cromatico\naccoppiamenti\nreti di comunicazione\norari paralleli\n\n\n"},"UNI/ANNO-1/DISCRETA/PROBABILIT√Ä":{"slug":"UNI/ANNO-1/DISCRETA/PROBABILIT√Ä","filePath":"UNI/ANNO 1/DISCRETA/PROBABILIT√Ä.md","title":"PROBABILIT√Ä","links":[],"tags":[],"content":""},"UNI/ANNO-1/DISCRETA/RELAZIONI":{"slug":"UNI/ANNO-1/DISCRETA/RELAZIONI","filePath":"UNI/ANNO 1/DISCRETA/RELAZIONI.md","title":"RELAZIONI","links":[],"tags":[],"content":"riflessiva\ntransitiva\nsimmetrica"},"UNI/ANNO-1/DISCRETA/RSA":{"slug":"UNI/ANNO-1/DISCRETA/RSA","filePath":"UNI/ANNO 1/DISCRETA/RSA.md","title":"RSA","links":[],"tags":[],"content":"HAI A E B CHE SONO DUE PERSONE\n\nA HA LE SUE CHIAVI PUBBLICHE E PRIVATE\nB IDEM\nSE VUOI INVIARE UN MESSAGIO CODIFICATO PRENDI LE CHIAVI PUBBLICHE DEL DESTINATARIO\nSE VUOI DECODIFICARE USI LE TUE CHIAVI PRIVATE PER DECODIFICARLO\nLE FORMULE SONO:\nDECODIFICA: m^d mod n\nCODIFICA: m^e mod n\n\npoi fai le riduzioni di modulo classiche\nCREARE RSA\na e b sono due numeri coprimi inventati da noi\n"},"UNI/ANNO-1/GEOMETRIA/Drawing-2025-02-10-17.58.47.excalidraw":{"slug":"UNI/ANNO-1/GEOMETRIA/Drawing-2025-02-10-17.58.47.excalidraw","filePath":"UNI/ANNO 1/GEOMETRIA/Drawing 2025-02-10 17.58.47.excalidraw.md","title":"Drawing 2025-02-10 17.58.47.excalidraw","links":[],"tags":["excalidraw"],"content":"‚ö†  Switch to EXCALIDRAW VIEW in the MORE OPTIONS menu of this document. ‚ö†"},"UNI/ANNO-1/GEOMETRIA/ESERCIZI-MECCANICI-1.0":{"slug":"UNI/ANNO-1/GEOMETRIA/ESERCIZI-MECCANICI-1.0","filePath":"UNI/ANNO 1/GEOMETRIA/ESERCIZI MECCANICI 1.0.md","title":"ESERCIZI MECCANICI 1.0","links":[],"tags":[],"content":"ESERCIZI SU MATRICI\nUna matrice √® composta da RxR con partenza colonna e arrivorighe\nRANGO\nnumero di pivot dopo semplificazione di michael jordan\nDETERMINANTE\ndistribuisci + - alternati facendo in modo che le colonne tra loro siano sempre diverse, prendi una serie di valori lineari in righe o colonne moltiplichi poi quei valori(con il laser) per il determinante della sotto matrice che ti si crea, quando arrivi a una matrice 2x2 applichi la place quindi fai det(A)=ad-bc\ncondizioni per barare: se avevi due righe o due colonne uguali allora il det=0\noppure se hai una riga o una colonna full di zeri allora il det=0\n\nbase KER o NUCLEO\nprendi la matrice e te la semplifichi con il michael jordan poi moltiplichi con un vettore con le variabili che rappresentano ognuna una colonna e poni tutto uguale a 0, ti svolgi il tutto come se fosse un sistema, se hai delle variabili che non trovi devi metterle uguali a una lettera, successivamente scrivi il risultato cos√¨ (0,0,1,1) se hai una lettera devi metterci il suo coefficiente\n\nbase IMMAGINE\nmichael jordan, vedi dove sono i pivot e ti scrivi le colonne che c‚Äôerano originariamente\n\ndimensione IMMAGINE\n√® il rango\ndimensione NUCLEO\nn di colonne-dimensione(IMM)\nuna trasformazione lineare da \\mathbb{R}^3  a  \\mathbb{R}^5 avr√† 3 colonne e 5 righe.\nPOLINOMIO CARATTERISTICO\nP(A)=det(A-\\lambda *I_n )\nfai il determinante mettendo A-\\lambda ad ogni pivot, senza fare michael jordan\nAUTOVALORE\nlo trovi facendo il polinomio caratteristico, alla fine dello svolgimento del determinante potresti incorrere in code simili  a formule come ad esempio (\\lambda-4)(-\\lambda^2-4\\lambda-4) prendendo le \\lambda trovi gli autovalori ovvero 4 e -2(doppio)\nAUTOSPAZIO\nper trovare l‚Äôautospazio devi applicare gli autovalori alle \\lambda della matrice creata, successivamente fai il michael jordan e poi ti calcoli l‚Äôautovettore(come la base del nucleo) senza per√≤ cambiare le t in numeri e lasci le lettere e scrivi il tuo autospazio\nAUTOVETTORE\nsostituisci le lambda e fai come il calcolo del sistema per trovare la base del nucleo\nMOLTEPLICIT√Ä o MEDIA GEOMETRICA E ALGEBRICA\nfai il polinomio caratteristico, quante volte appare \\lambda_n rappresenta la media algebrica\nse fai n-rango hai la media geometrica, dove n √® la partenza della matrice ovvero colonne\nogni lambda ha una media geometrica e algebrica a s√®\nDIAGONIZZABILE\ndevi fare il polinomio caratteristico, poi trovi le \\lambda e le loro molteplicit√†, applichi le lambda ai pivot della matrice e fai il michael jordan, e scopri cos√¨ il rango di quei singoli casi\nla media geometrica deve essere uguale da quella algebrica\nla media geometrica era n-rango dove n √® la partenza(colonne)\nla media algebrica √® il numero di autovalori che trovi(molteplicit√†)\ndopo aver fatto questi controlli devi fare la somma delle medie geometriche e deve essere uguale a n\nINVERTIBILE\ndet diverso da 0 oppure rango=max oppure biunivoca\nINVERSA\nmetti l‚Äôidentita a destra e fai il michael jordan della matrice a sinistra modificando per√≤ anche quella a destra, devi avere l‚Äôidentit√† a sx e a dx avrai l‚Äôinversa\noppure\nfai \\frac{1}{det}*catania\nper fare catania ti devi fare il determinante di ogni singolo elemento della matrice, poi ogni singolo elemento della riga lo metti come se fosse una colonna quindi metti la matrice al contrario, poi moltiplichi per 1/det\nVETTORE APPARTIENE A IMMAGINE(A)\nmetti la matrice= a quel vettore facendo un sistema e svolgendolo tipo un sistema omogeneo\nVEDERE SE ESISTE UN VETTOREx T.C. A*x=w\ndevi verificare se esiste l‚Äôinversa perch√® ti porti a destra la A come frazione, successivamente fai la moltiplicazione del vettore w con la A^{-1} per farlo moltiplichi ogni elemento del vettore w per il suo rispettivo elemento della riga per ogni riga, dopodich√® otterrai un vettore che sar√† il risultato della x\nVETTORI BASE DI R\nmetti i vettori nella matrix fai il michael jordan e vedi il rango se rango=max allora √® base di R\nBINET\ndeterminante di (A*B) √® uguale a det(A)*det(B)\nMOLTIPLICAZIONE TRA MATRICI\nogni riga della prima matrice va moltiplicata con ogni colonna della seconda\nDIAGONALE\ntrova i risultati degli autovalori e mettili in diagonale\nTEOREMA DEGLI ORLATI\nse hai una matrice puoi sfruttare il teorema degli orlati per definire il rango minimo, se prendi una matrice a caso dentro di una determinata dimensione n*n, se il suo determinante √® diverso da 0 significa che la matrice pi√π grande √® almeno di quella n\nESERCIZI SU APPLICAZIONI LINEARI\nLINEARIT√Ä\nper verificare linearit√† bisogna capire se c‚Äô√® omogeneit√† e additivit√†\nl‚Äôomogeneit√† si verifica moltiplicando per c tutte le variabili della matrice e del sistema lineare e poi si porta fuori\n\npoer verificare l‚Äôadditivit√† invece bisogna verificare se T(U+V) √® uguale a T(U)+T(V)\ndove u √® x1,y1 invece v √® x2,y2\nLINEARMENTE INDIPENDENTE\nquando fai il giordano e i pivot che non sono 0 sono indipendenti se sono tutti 0 sono tutti dipendenti\nMATRICE ASSOCIATA\nprendi i coefficienti dei vettori e te li spalmi in una matrice in colonna\nMATRICE A BASE CANONICA\nprendi i risultati dei vettori e li spalmi in una matrice\nMATRICE\nla scrivi con le lettere cos√¨ com‚Äô√®\nSURRY\nil rango della matrice deve essere uguale alla n di arrivo\nINNY\nse il rango della matrice √® uguale a quella di partenza\nBIUNY\nse √® biunivoca √® invertibile ed √® sia inny che surry\nCOMBINAZIONI LINEARI\nv_{1,2,3}=v_4 ?\nmettiti la matrice e fai rouche capelli\nGEOMETRIA SPAZIALE\nVETTORI FORMANO UNA BASE\nmichael jordan mettendo i vettori sulle colonne e poi vedi se rango=max\nCOME TROVARE UN PIANO\nbho\nRETTE INCIDENTI PARALLELE SGHEMBE COMPLANARI\nscrivi equazione parametrica applicando la formula A+t(B-A)\nparallele\nper vedere se sono parallele devi controllare se c‚Äô√® un valore che molitplicato per il vettore di una delle due rette esce uguale alla sua amica retta\nincidenti\ni risultati delle equazioni parametriche delle due rette devono esserci soluzioni e non devono esserci cose strane tipo h=1 e h=3 o √® 1 o 3\nsghembe\nn√® parallele n√® incidenti\ncomplanari\nvedi se sono parallele\nEQUAZIONE PARAMETRICA E CARTESIANA\nprendi i vettori e applica la seguente formula r=A+t(B-A)\nfai il sistema con le corrispondenze delle varie x y e z\nVEDERE SE UN SISTEMA √à COMPATIBILE\nti fai la matrice e il rg(A) deve essere uguale al rg(A|B)   (teorema rouche capelli)\nVEDERE QUANTE SOLUZIONI HA UN SISTEMA\n\nrg max ha una sola soluzione\nrg non max infinite soluzioni/oppure non ne ha proprio\n\nVEDERE QUANDO UN SISTEMA SI COMPORTA COME UNA RETTA\nun sistema ha infinite soluzioni(ha almeno un parametro t s o roba cos√¨)"},"UNI/ANNO-1/GEOMETRIA/ESERCIZI-MECCANICI-2.0":{"slug":"UNI/ANNO-1/GEOMETRIA/ESERCIZI-MECCANICI-2.0","filePath":"UNI/ANNO 1/GEOMETRIA/ESERCIZI MECCANICI 2.0.md","title":"ESERCIZI MECCANICI 2.0","links":[],"tags":[],"content":"DETERMINATE\n\nAssegna ad ogni elemento un + o un - partendo da + (segni della matrice degli sviluppi di Laplace)\nscegli la colonna o riga che pi√π ti aggrada e escludi le rispettive righe e colonne associate a quella determinata posizione, per ognuna si calcola il segno*numero*det(matrice formata)\n\nil det si calcola facendo ad-bc\n\n\nsommi tutti i risultati assieme\n\nVERIFICA SE INVERTIBILE\nDue modi\n\nfai il determinante e vedi se esce != 0\noppure\ncontrolli se rango=max √® invertibile\n\nRango\n\nGauss\nControlli il numero di pivot != 0\n\nMatrice inversa\n\ncalcola il determinante della matrice\nprendi i successivi cofattori della matrice (ogni singolo valore) e calcola il determinante SENZA CONTARE IL NUMERO STESSO\nscrivi la matrice risultante con tutti i det e moltiplicala per \\frac 1 9\nscrivi la matrice finale\n\nGauss con sistemi lineari\n\ncomponi la matrice aumentata dei coefficienti\n\nsi scrive mettendo A|B dove\n\nA sono i coefficienti delle varie incognite (prima dell‚Äôuguale)\nB sono i risultati\n\n\n\n\napplica Gauss\ndopo Gauss puoi avere diversi casi\n\ntutte le righe sono != 0 ‚Üí  sistema determinato dove puoi ricavarti i valori delle incognite (svolgi il sistema)\nuna o pi√π righe sono interamente = 0 ‚Üí sistema indeterminato\nuna o pi√π righe hanno A = 0 MA B != 0 ‚Üí sistema impossibile\n\n\n\nRango nei sistemi lineari\n\nprendi la matrice applicata ai coefficienti e prendi anche quella aumentata con A|B\napplica Gauss e vedi le righe per definire il rango\nDiversi casi (Rouch√©-Capelli)\nRango matrice = Rango matrice aumentata ‚áí sistema compatibile e hai almeno 1 soluzione\n\nrango matrice = numero di incognite ‚Üí un‚Äôunica soluzione\nrango matrice &lt; numero di incognite ‚Üí  \\infty soluzioni\n\nper incognite si intende le varie x, y, z\n\n\n\n\nRango matrice != Rango matrice aumentata ‚Üí non ci sono soluzioni ed √® incompatibile, impossibile\n\nVettori linearmente indipendenti\nCi portano a capire la dimensione del sottospazio e la base del sottospazio vettoriale\n\nprendi gli elementi dei vettori e li scrivi sulla matrice come righe\napplichi Gauss\nil numero di pivot esprime la sua dimensione\n\nse ad un pivot hai una funzione allora devi verificare quando essa √® diversa da 0\n\nsolo in quel caso vale come pivot altrimenti √® 0 e non conta\n\n\n\n\nla base si scrive come un insieme di vettori delle singole righe post Gauss\n\nLIVELLO 2\nPolinomio caratteristico\naggiungi ai pivot -\\lambda\n\ncalcola il determinante\notterrai una formula con le varie lambda quello √® il polinomio caratteristico\n\nAutovalori e Autovettori\n\nPolinomio Caratteristico ‚Üí risolvi l‚Äôequazione del polinomio risultante\n\ni risultati sono gli autovalori\n\n\nsostituisci ogni autovalore alla matrice con i -\\lambda, la moltiplichi con un vettore (x1,x2,x3) e scrivi un sistema ponendo tutto a 0\nrisolvi il sistema con Gauss e poi lo rimetti su un sistema\nRISULTATO ‚Üí v=(x1,x2,x3) con i valori sostituiti\n\nDiagonizzabile\n\nTrova gli autovalori e calcoli quante volte appaiono (molteplicit√† algebrica)\ncalcoli rango per ogni autovalore trovando la molteplicit√† geometrica data da numero \\ colonne-rango\nse \\forall autovalore ma=mg √® diagonizzabile\n\nBase nucleo(ker)\nNON CONFONDERE CON LA DIMENSIONE\n\nprendi la matrice e fai GAUSS\nmetti a sistema le varie righe e eventualmente definisci dei parametri liberi per risolvere il sistema\nper ogni parametro definiamo i vettori (compreso il parametro dei termini noti)\nRISULTATO ‚áí ker(MATRICE) = span{METTI I VETTORI SENZA PARAMETRI}\n\nBase immagine\nDA NON CONFONDERE CON LA DIMENSIONE\n\nfai GAUSS e prendi tutte le colonne linearmente indipendenti (con pivot diversi da zero)\nscrivi i vettori prendendo le colonne della matrice ORIGINALE associate alle colonne linearmente indipendenti\n\nDimensione nucleo (Null)\n\ndopo aver calcolato la base, calcoli la cardinalit√† dell‚Äôinsieme dello span\n\nDimensione immagine\n\nletteralmente il rango\n\nMatrice associata\nINGREDIENTI:\n\nMatrice\nBase, con i vari vettori\nFormula\n\nRISOLUZIONE\n\ndefiniamo una N come a1b1+a2b2+a3b3‚Ä¶\ncalcoliamo la formula con A e ogni base (poi dipende dalla formula ovviamente)\nprendiamo i risultati e li mettiamo come coefficienti di N per ogni base\nRISULTATO ‚áí la matrice risultante avr√† come COLONNE i vari vettori trovati\n\nLIVELLO 3\nTrovare equazione parametrica\nDue casi da cui partire\nCASO 1: equazione cartesiana\n\nprendi il sistema\neffettui delle sostituzioni definendo un parametro libero\nRISULTATO ‚áí finito il sistema avrai la tua equazione parametrica (ossia con il parametro libero)\n\nCASO 2: partendo da punti\nPossiamo o inventarli o li d√† il prof\n\nuna volta ottenuti facciamo P1-P0 per ottenere il vettore direttore\nuna volta ottenuto scriviamo la formula generale della equazione mettendo la prima colonna con i valori di P0 la seconda con t moltiplicato per il vettore direttore\n\nSISTEMA:\n\\begin{cases} x = x_0+t v_0 \\\\ y = y_0+t v_1 \\\\ z = z_0+t v_2 \\end{cases}\n\n\n\nPer il piano\n\nSe i punti non li da lui dobbiamo trovarli noi sostituendo x,y \\ o \\ z (ne sostituisci al massimo due) all‚Äôequazione cartesiana per trovare le varie P\ntroviamo 2 vettori direttori facendo P1-P0 e P2-P0\nLi sostituiamo alla formula generale dell‚Äôequazione parametrica che √® IDENTICA alla retta ma con un vettore e un parametro in pi√π.\n\nN.B.: se un piano √® parallelo a delle rette user√† gli stessi vettori direttori delle rete\nEquazione cartesiana\nSe hai la parametrica\n\ntrovati le equazioni per i parametri\nsostituiscili in una riga e ponila = 0\nRISULTATO ‚áí la riga senza parametri sar√† l‚Äôequazione cartesiana\n\nIntersezione tra retta e piano\nINGREDIENTI:\n\nequazione CARTESIANA del PIANO\nequazione PARAMETRICA della RETTA\n\nSVOLGIMENTO:\n\nal posto di x, y, z dell‚Äôequazione CARTESIANA del PIANO sostituiamo i valori dell‚Äôequazione PARAMETRICA della retta\nsvolgiamo l‚Äôequazione per trovare t\nsostituiamo t all‚Äôequazione PARAMETRICA della RETTA per trovare i valori effettivi di x, y, z\nRIAULTATO ‚áí metti queste coordinate in un vettore\n\nRette parallele coincidenti incidenti sghembe\nparallele\n\nprendi i vettori direttori delle rette e controlli se hanno dei multipli in comune\n\ncoincidenti\nPUOI CALCOLARLO SE E SOLO SE SONO PARALLELE\n\nprendi una delle due equazioni parametriche\nscegli una riga (es. quella di x) e mettila uguale al termine noto della stessa riga nell‚Äôaltra equazione parametrica per trovare il t\nuna volta trovato, sostituisco il t alle altre righe dell‚Äôequazione parametrica\nRISULTATO ‚áí se i risultati delle altre due coordinate (in questo caso y, z) sono UGUALI al punto di partenza delle altre (prima colonna nell‚Äôaltra eq. parametrica) ‚Üí SONO COINCIDENTI\n\nincidenti\nPUOI CALCOLARLO SE NON SONO PARALLELE\n\nprendi le due equazioni parametriche le metti uguali in un unico sistema\nRISULTATO ‚áí se il sistema ha soluzioni ‚Üí SONO INCIDENTI\n\nsghembe\nSE NON SONO NULLA ‚Üí SONO SGHEMBE\nFunzioni Suriettive, Iniettive, Biunivoche\nSURIETTIVA\nR(A) = R(A|b)\nINIETTIVA\nR(A) = numero \\ colonne\nBIUNIVOCA\n\\text{SURIETTIVA + BIUNIVOCA}"},"UNI/ANNO-1/GEOMETRIA/GEOMETRIA-INDICE":{"slug":"UNI/ANNO-1/GEOMETRIA/GEOMETRIA-INDICE","filePath":"UNI/ANNO 1/GEOMETRIA/GEOMETRIA INDICE.md","title":"GEOMETRIA INDICE","links":["UNI/ANNO-1/GEOMETRIA/ESERCIZI-MECCANICI-1.0","UNI/ANNO-1/GEOMETRIA/ESERCIZI-MECCANICI-2.0"],"tags":[],"content":"ESERCIZI MECCANICI 1.0\nESERCIZI MECCANICI 2.0"},"UNI/ANNO-1/GEOMETRIA/LISTA-ESERCIZI-PER-ESAME":{"slug":"UNI/ANNO-1/GEOMETRIA/LISTA-ESERCIZI-PER-ESAME","filePath":"UNI/ANNO 1/GEOMETRIA/LISTA ESERCIZI PER ESAME.md","title":"LISTA ESERCIZI PER ESAME","links":[],"tags":[],"content":"üìå Lista di Esercizi per Superare l‚ÄôEsame di Geometria\nüöÄ Obiettivo: Risolvere questi esercizi in ordine crescente di difficolt√† per coprire tutti i temi ricorrenti.\n\nüü¢ Livello 1 - Fondamentali (Facili)\nüëâ Questi esercizi servono per acquisire le basi e risolvere i problemi pi√π semplici dell‚Äôesame.\nüìñ Matrici e operazioni\n\n\nCalcolo del determinante\n\nüìå Esame 16/09/2008 - Esercizio 1a\nüìå Esame 11/06/2008 - Esercizio 2b\nüìå Esame 12/07/2024 - Esercizio 2a\n\n\n\nVerifica se una matrice √® invertibile\n\nüìå Esame 21/06/2019 - Esercizio 1b\nüìå Esame 18/02/2020 - Esercizio 2a\n\n\n\nCalcolo della matrice inversa\n\nüìå Esame 21/01/2020 - Esercizio 2b\nüìå Esame 24/06/2024 - Esercizio 2b\n\n\n\n\nüìñ Sistemi Lineari\n\n\nRisolvere un sistema lineare con il metodo di Gauss\n\nüìå Esame 03/02/2025 - Esercizio 1\nüìå Esame 21/01/2020 - Esercizio 1\n\n\n\nDeterminare il rango di una matrice\n\nüìå Esame 06/09/2019 - Esercizio 3a\nüìå Esame 24/06/2024 - Esercizio 3a\n\n\n\n\nüìñ Spazi vettoriali\n\n\nVerificare se un insieme di vettori √® linearmente indipendente\n\nüìå Esame 26/06/2007 - Esercizio 1a\nüìå Esame 12/07/2024 - Esercizio 4a\n\n\n\nDeterminare una base di uno spazio vettoriale\n\nüìå Esame 06/09/2019 - Esercizio 3b\nüìå Esame 24/06/2024 - Esercizio 3c\n\n\n\n\nüü° Livello 2 - Intermedio\nüëâ Questi esercizi coprono gli aspetti pi√π tecnici che compaiono spesso negli esami.\nüìñ Autovalori e autovettori\n\n\nCalcolare il polinomio caratteristico di una matrice\n\nüìå Esame 16/09/2008 - Esercizio 1a\nüìå Esame 21/06/2019 - Esercizio 4b\n\n\n\nDeterminare gli autovalori e autovettori\n\nüìå Esame 17/07/2007 - Esercizio 1a\nüìå Esame 12/07/2024 - Esercizio 2a\n\n\n\nVerificare se una matrice √® diagonalizzabile\n\n\n\nüìå Esame 02/02/2009 - Esercizio 2c\nüìå Esame 24/06/2024 - Esercizio 4d\n\n\nüìñ Applicazioni lineari\n\nTrovare il nucleo e l‚Äôimmagine di un‚Äôapplicazione lineare\n\n\nüìå Esame 13/09/2007 - Esercizio 1a\nüìå Esame 03/02/2025 - Esercizio 3\n\n\nDeterminare la matrice associata a un‚Äôapplicazione lineare\n\n\nüìå Esame 21/01/2020 - Esercizio 2d\nüìå Esame 06/09/2019 - Esercizio 3c\n\n\nüî¥ Livello 3 - Avanzato (Difficili)\nüëâ Questi sono i problemi pi√π complessi, spesso richiesti nelle prove finali.\nüìñ Geometria Affine\n\nDeterminare equazioni parametriche di una retta\n\n\nüìå Esame 06/09/2019 - Esercizio 2a\nüìå Esame 12/07/2024 - Esercizio 3c\n\n\nTrovare l‚Äôintersezione tra una retta e un piano\n\n\nüìå Esame 19/09/2024 - Esercizio 1c\nüìå Esame 21/01/2020 - Esercizio 4d\n\n\nDimostrare che due rette sono parallele, coincidenti o sghembe\n\n\nüìå Esame 18/02/2020 - Esercizio 1a-b\nüìå Esame 19/09/2024 - Esercizio 3c\n\n\nüìñ Problemi avanzati con matrici\n\nCalcolare l‚Äôinversa di una matrice complessa\n\n\nüìå Esame 24/06/2024 - Esercizio 2b\nüìå Esame 06/09/2019 - Esercizio 3c\n\n\nDimostrare una propriet√† su matrici nilpotenti o speciali\n\n\nüìå Esame 06/09/2019 - Esercizio 5a\nüìå Esame 18/02/2020 - Esercizio 3a\n\n\nüéØ Piano di Studio per gli Esercizi\nSe vuoi ottimizzare il tempo, segui questa sequenza:\n\nGiorni 1-2 ‚Üí Completa il livello 1\nGiorni 3-5 ‚Üí Fai il livello 2 (focalizzandoti su quelli pi√π difficili)\nGiorni 6-7 ‚Üí Affronta il livello 3\nGiorno 8 ‚Üí Ripeti gli esercizi difficili e fai una simulazione d‚Äôesame\n\n\nüìå Cosa fare se un esercizio non viene\n\nRivedi gli appunti e la teoria di base\nProva a confrontarlo con un esercizio simile\nScrivi i passaggi che conosci, anche senza arrivare alla soluzione completa (prendi punti comunque!)\n"},"UNI/ANNO-1/LOGICA/Logica-INDICE":{"slug":"UNI/ANNO-1/LOGICA/Logica-INDICE","filePath":"UNI/ANNO 1/LOGICA/Logica INDICE.md","title":"Logica INDICE","links":["UNI/ANNO-1/LOGICA/PARTE1LOGICA/Cap1-logica","UNI/ANNO-1/LOGICA/PARTE1LOGICA/Cap2-logica","UNI/ANNO-1/LOGICA/PARTE1LOGICA/Cap3-logica","UNI/ANNO-1/LOGICA/PARTE1LOGICA/Cap4-logica","UNI/ANNO-1/LOGICA/PARTE1LOGICA/Cap5-logica","UNI/ANNO-1/LOGICA/PARTE2LOGICA/Cap6-logica","UNI/ANNO-1/LOGICA/PARTE2LOGICA/Cap7-logica","UNI/ANNO-1/LOGICA/PARTE2LOGICA/Cap8-logica","UNI/ANNO-1/LOGICA/PARTE2LOGICA/Cap9-logica","UNI/ANNO-1/LOGICA/PARTE2LOGICA/Cap10-logica","UNI/ANNO-1/LOGICA/PARTE2LOGICA/Cap11-logica"],"tags":[],"content":"\n\n                  \n                  purtroppo li avevo scritti sul onenote quindi dovete fare tasto destro ‚Üístampa per visualizzarli adeguatamente\n                  \n                \n\nParte 1ü§î:¬†\n\n\nCantor, induzione, tabelle della verit√†¬†\n\n\nTautologie, tableaux¬†\n\n\nAssiomi¬†\n\n\nLogica del primo ordine, tableaux¬†\n\n\nSoddisfacibilit√†\n\n\nParte 2üîå:¬†\n\n\nBinario, complemento a due, conversioni¬†\n\n\nHalf adder, full adder¬†¬†\n\n\nCodice gray, karnaugh¬†\n\n\nEncoder,decoder,multiplex¬†\n\n\nLatch,flip-flop¬†\n\n\nMacchine a stati finiti, alla moore,alla mealy¬†\n\n\nVirgola mobile\n\n"},"UNI/ANNO-1/LOGICA/PARTE1LOGICA/Cap1-logica":{"slug":"UNI/ANNO-1/LOGICA/PARTE1LOGICA/Cap1-logica","filePath":"UNI/ANNO 1/LOGICA/PARTE1LOGICA/Cap1-logica.md","title":"Cap1-logica","links":[],"tags":[],"content":""},"UNI/ANNO-1/LOGICA/PARTE1LOGICA/Cap2-logica":{"slug":"UNI/ANNO-1/LOGICA/PARTE1LOGICA/Cap2-logica","filePath":"UNI/ANNO 1/LOGICA/PARTE1LOGICA/Cap2-logica.md","title":"Cap2-logica","links":[],"tags":[],"content":""},"UNI/ANNO-1/LOGICA/PARTE1LOGICA/Cap3-logica":{"slug":"UNI/ANNO-1/LOGICA/PARTE1LOGICA/Cap3-logica","filePath":"UNI/ANNO 1/LOGICA/PARTE1LOGICA/Cap3-logica.md","title":"Cap3-logica","links":[],"tags":[],"content":""},"UNI/ANNO-1/LOGICA/PARTE1LOGICA/Cap4-logica":{"slug":"UNI/ANNO-1/LOGICA/PARTE1LOGICA/Cap4-logica","filePath":"UNI/ANNO 1/LOGICA/PARTE1LOGICA/Cap4-logica.md","title":"Cap4-logica","links":[],"tags":[],"content":""},"UNI/ANNO-1/LOGICA/PARTE1LOGICA/Cap5-logica":{"slug":"UNI/ANNO-1/LOGICA/PARTE1LOGICA/Cap5-logica","filePath":"UNI/ANNO 1/LOGICA/PARTE1LOGICA/Cap5-logica.md","title":"Cap5-logica","links":[],"tags":[],"content":""},"UNI/ANNO-1/LOGICA/PARTE2LOGICA/Cap10-logica":{"slug":"UNI/ANNO-1/LOGICA/PARTE2LOGICA/Cap10-logica","filePath":"UNI/ANNO 1/LOGICA/PARTE2LOGICA/Cap10-logica.md","title":"Cap10-logica","links":[],"tags":[],"content":""},"UNI/ANNO-1/LOGICA/PARTE2LOGICA/Cap11-logica":{"slug":"UNI/ANNO-1/LOGICA/PARTE2LOGICA/Cap11-logica","filePath":"UNI/ANNO 1/LOGICA/PARTE2LOGICA/Cap11-logica.md","title":"Cap11-logica","links":[],"tags":[],"content":""},"UNI/ANNO-1/LOGICA/PARTE2LOGICA/Cap6-logica":{"slug":"UNI/ANNO-1/LOGICA/PARTE2LOGICA/Cap6-logica","filePath":"UNI/ANNO 1/LOGICA/PARTE2LOGICA/Cap6-logica.md","title":"Cap6-logica","links":[],"tags":[],"content":""},"UNI/ANNO-1/LOGICA/PARTE2LOGICA/Cap7-logica":{"slug":"UNI/ANNO-1/LOGICA/PARTE2LOGICA/Cap7-logica","filePath":"UNI/ANNO 1/LOGICA/PARTE2LOGICA/Cap7-logica.md","title":"Cap7-logica","links":[],"tags":[],"content":""},"UNI/ANNO-1/LOGICA/PARTE2LOGICA/Cap8-logica":{"slug":"UNI/ANNO-1/LOGICA/PARTE2LOGICA/Cap8-logica","filePath":"UNI/ANNO 1/LOGICA/PARTE2LOGICA/Cap8-logica.md","title":"Cap8-logica","links":[],"tags":[],"content":""},"UNI/ANNO-1/LOGICA/PARTE2LOGICA/Cap9-logica":{"slug":"UNI/ANNO-1/LOGICA/PARTE2LOGICA/Cap9-logica","filePath":"UNI/ANNO 1/LOGICA/PARTE2LOGICA/Cap9-logica.md","title":"Cap9-logica","links":[],"tags":[],"content":""},"UNI/ANNO-1/PROGRAMMAZIONE/C/10.Capitolo10":{"slug":"UNI/ANNO-1/PROGRAMMAZIONE/C/10.Capitolo10","filePath":"UNI/ANNO 1/PROGRAMMAZIONE/C/10.Capitolo10.md","title":"10.Capitolo10","links":[],"tags":[],"content":"Array, Puntatori, malloc e sizeof in C\nArray in C\nUn array √® una sequenza di elementi dello stesso tipo, con indice e dimensione statica ben definita.\nEsempio di Array\nint franco[5] = {1, 2, 3, 4, 5};\nfor(int i = 0; i &lt; 5; i++) {\n    printf(&quot;%d &quot;, franco[i]);\n}\nPuntatori\nI puntatori in C sono variabili che memorizzano l‚Äôindirizzo di memoria di altre variabili.\nEsempio di Puntatore\nint x = 3;\nint *p;\np = &amp;x;\nprintf(&quot;%p&quot;, p);  // Stampa l&#039;indirizzo di x\nprintf(&quot;%d&quot;, *p); // Stampa il valore di x\nmalloc e sizeof\nmalloc √® una funzione utilizzata per allocare dinamicamente la memoria, mentre sizeof viene usato per determinare la dimensione in byte di un tipo di dato.\nEsempio di malloc e sizeof\nint *a = malloc(sizeof(int) * 4);\na[3] = 3;\na = malloc(sizeof(int) * 5);\na[4] = 4;\nprintf(&quot;%d&quot;, a[4]);\n \n// Accesso out of range, non sempre segnalato come errore dal compilatore\na[8] = 9;\nprintf(&quot;%d %d&quot;, a[4], a[8]);\nQuesti esempi mostrano come gestire le strutture di dati e la memoria in C, con attenzione particolare agli array e ai puntatori."},"UNI/ANNO-1/PROGRAMMAZIONE/C/11.Capitolo-11":{"slug":"UNI/ANNO-1/PROGRAMMAZIONE/C/11.Capitolo-11","filePath":"UNI/ANNO 1/PROGRAMMAZIONE/C/11.Capitolo 11.md","title":"11.Capitolo 11","links":[],"tags":[],"content":"Funzioni, Struct e typedef in C\nFunzioni in C\nIn C, le funzioni devono specificare il tipo di dato che ritornano e il tipo di ogni parametro. Ecco come si definisce e si chiama una funzione che somma due numeri:\nEsempio di Funzione con Parametri Valore\nint somma(int x, int y) {\n    int q = x + y;\n    return q;\n}\n \nint main() {\n    int x = 3;\n    int y = 4;\n    printf(&quot;%d&quot;, somma(x, y));  // Output: 7\n}\nEsempio di Funzione con Parametri Indirizzo\n#include &lt;stdio.h&gt;\n \nint somma(int *x, int *y) {\n    int q = *x + *y;\n    *x = 50;\n    *y = 70;\n    return q;\n}\n \nint main() {\n    int x = 3;\n    int y = 4;\n    printf(&quot;%d\n&quot;, somma(&amp;x, &amp;y));  // Output: 7\n    printf(&quot;%d %d&quot;, x, y);  // Output: 50 70\n}\nStruct in C\nLe struct permettono di definire nuovi tipi di dati composti da pi√π valori, potenzialmente di tipi differenti.\nEsempio di Struct\nstruct punto {\n    int x;\n    int y;\n};\n \ntypedef struct punto punto;\n \nint main() {\n    punto p1;\n    p1.x = 5;\n    p1.y = 6;\n    punto p2 = {1, 3};\n    printf(&quot;%d&quot;, p1.x);  // Output: 5\n}\nTypedef in C\ntypedef √® utilizzato per dare un nuovo nome a un tipo esistente, semplificando la sintassi e migliorando la leggibilit√† del codice.\nEsempio di Typedef\ntypedef int pollo;\npollo numero = 5;  // &#039;pollo&#039; ora rappresenta &#039;int&#039;\nQuesti esempi illustrano alcune delle funzionalit√† fondamentali di C che facilitano la creazione di codice modulare, il controllo di tipi complessi e la gestione della memoria."},"UNI/ANNO-1/PROGRAMMAZIONE/C/12.Capitolo-12":{"slug":"UNI/ANNO-1/PROGRAMMAZIONE/C/12.Capitolo-12","filePath":"UNI/ANNO 1/PROGRAMMAZIONE/C/12.Capitolo 12.md","title":"12.Capitolo 12","links":[],"tags":[],"content":"Lezione 12: Sequenze, Free, e Funzioni Avanzate in C\nSequenze in C\nLe sequenze in C possono essere gestite attraverso strutture che simula il comportamento dinamico delle liste di Python.\nDefinizione di Sequenza\nstruct sequenza {\n    int *a; // Array di elementi\n    int n;  // Numero di elementi effettivi\n    int c;  // Capacit√† totale dell&#039;array\n};\n \ntypedef struct sequenza Sequenza;\n \nSequenza nuova_sequenza() {\n    Sequenza v = {NULL, 0, 0};\n    return v;\n}\n \nvoid set_sequenza(Sequenza v, int p, float x) {\n    v.a[p] = x;\n}\n \nfloat get_sequenza(Sequenza v, int p) {\n    return v.a[p];\n}\n \nint dim_sequenza(Sequenza v) {\n    return v.n;\n}\n \nint cap_sequenza(Sequenza v) {\n    return v.c;\n}\n \nSequenza append_sequenza(Sequenza v, float x);\nSequenza pop_sequenza(Sequenza v);\nint isempty_sequenza(Sequenza v);\nSequenza insert_sequenza(Sequenza v, int p, float x);\nSequenza delete_sequenza(Sequenza v, int p);\nFunzioni per la Gestione di Sequenze\nFunzioni come append, pop, insert e delete permettono di gestire le sequenze in modo simile alle liste in Python ma con una gestione manuale della memoria.\nEsempio di Append e Pop\nSequenza append_sequenza(Sequenza v, float x) {\n    if (v.n == v.c) {\n        v.c = 2 * v.c + 1;\n        v.a = realloc(v.a, sizeof(int) * v.c);\n    }\n    v.a[v.n++] = x;\n    return v;\n}\n \nSequenza pop_sequenza(Sequenza v) {\n    if (4 * v.n &lt; v.c) {\n        v.c = v.n * 2 + 1;\n        v.a = realloc(v.a, sizeof(float) * v.c);\n    }\n    v.n--;\n    return v;\n}\nFree e Gestione della Memoria\nLa funzione free() √® essenziale per prevenire perdite di memoria quando si lavora con l‚Äôallocazione dinamica.\nUso di Free\nint *a = malloc(sizeof(int) * 4);\na[3] = 3;\nfree(a);  // Libera la memoria allocata\nGestione delle Stringhe in C\nLa gestione delle stringhe in C richiede una cura particolare, includendo funzioni come la concatenazione e il calcolo della lunghezza.\nEsempio di Funzioni Stringa\nint len(char *s) {\n    int length = 0;\n    while (s[length] != &#039;\\0&#039;) length++;\n    return length;\n}\n \nchar *cat(char *x, char *y) {\n    int n = len(x);\n    int m = len(y);\n    char *w = malloc((n + m + 1) * sizeof(char));\n    if (w) {\n        memcpy(w, x, n);\n        memcpy(w + n, y, m);\n        w[n + m] = &#039;\\0&#039;;\n    }\n    return w;\n}\nQuesto capitolo dimostra come le sequenze e la gestione della memoria sono cruciali per la programmazione in C, offrendo un controllo fine sulla memoria ma richiedendo una gestione attenta degli errori e delle risorse."},"UNI/ANNO-1/PROGRAMMAZIONE/C/13.Capitolo-13":{"slug":"UNI/ANNO-1/PROGRAMMAZIONE/C/13.Capitolo-13","filePath":"UNI/ANNO 1/PROGRAMMAZIONE/C/13.Capitolo 13.md","title":"13.Capitolo 13","links":[],"tags":[],"content":"Lezione 13: Realloc e Gestione delle Stringhe in C\nRealloc\nrealloc √® utilizzata per ridimensionare un‚Äôallocazione di memoria esistente senza perdere i dati originali. √à particolarmente utile quando si deve espandere o ridurre la memoria allocata dinamicamente durante l‚Äôesecuzione del programma.\nEsempio di Uso di Realloc\nint *m = malloc(sizeof(int) * 4);\nm = realloc(m, sizeof(int) * 5);  // Rialloca la memoria per contenere 5 interi\nApplicazione in una Sequenza Dinamica\nSequenza append_sequenza(Sequenza v, int x) {\n    int n = dim_sequenza(v);\n    if (v.n == v.c) {\n        v.c = 2 * v.c + 1;\n        v.a = realloc(v.a, sizeof(int) * v.c);\n    }\n    v.a[n] = x;\n    v.n++;\n    return v;\n}\nGestione delle Stringhe in C\nLe stringhe in C sono gestite come array di caratteri, terminati da un carattere nullo (‚Äò\\0‚Äô).\nDichiarazione e Stampa di Stringhe\nchar s[] = &quot;python&quot;;\nprintf(&quot;%s\\t%s&quot;, s, s);  // Stampa la stringa due volte separata da un tab\nLunghezza della Stringa\nint len(char *s) {\n    int count = 0;\n    while (s[count] != &#039;\\0&#039;) count++;\n    return count;\n}\nModifica del Case dei Caratteri\nchar change_case(char c) {\n    if (c &gt;= &#039;a&#039; &amp;&amp; c &lt;= &#039;z&#039;) {\n        return &#039;A&#039; + c - &#039;a&#039;;\n    } else if (c &gt;= &#039;A&#039; &amp;&amp; c &lt;= &#039;Z&#039;) {\n        return &#039;a&#039; + c - &#039;A&#039;;\n    }\n    return c;\n}\nConcatenazione di Stringhe\nchar *cat(char *x, char *y) {\n    int len_x = len(x);\n    int len_y = len(y);\n    char *result = malloc((len_x + len_y + 1) * sizeof(char));\n    if (result) {\n        memcpy(result, x, len_x);\n        memcpy(result + len_x, y, len_y);\n        result[len_x + len_y] = &#039;\\0&#039;;\n    }\n    return result;\n}\nFunzioni della Libreria string.h\nLa libreria string.h fornisce funzioni standard per la manipolazione di stringhe, come strlen per la lunghezza e strcat per la concatenazione.\nEsempio di Uso di string.h\n#include &lt;string.h&gt;\nchar *a = &quot;Hello, &quot;;\nchar *b = &quot;world!&quot;;\nchar *c = strcat(a, b);  // Concatena &#039;b&#039; a &#039;a&#039;\nprintf(&quot;%s&quot;, c);  // Stampa &quot;Hello, world!&quot;\nQuesto capitolo illustra come gestire efficacemente le stringhe e la memoria in C, mostrando l‚Äôimportanza di funzioni come realloc per la gestione dinamica della memoria."},"UNI/ANNO-1/PROGRAMMAZIONE/C/14.Capitolo14":{"slug":"UNI/ANNO-1/PROGRAMMAZIONE/C/14.Capitolo14","filePath":"UNI/ANNO 1/PROGRAMMAZIONE/C/14.Capitolo14.md","title":"14.Capitolo14","links":[],"tags":[],"content":"Lezione 14: Gestione dei Nodi in Liste Doppiamente Collegate in C\nDefinizione di Nodo\nUn nodo √® un elemento fondamentale nelle strutture dati come le liste collegate. Consiste di uno o pi√π valori e riferimenti ai nodi adiacenti.\nStruttura di un Nodo\n#include&lt;stdio.h&gt;\n#include&lt;stdlib.h&gt;\n \nstruct nodo {\n    int valore;\n    struct nodo *succ;  // Puntatore al nodo successivo\n    struct nodo *prec;  // Puntatore al nodo precedente\n};\n \ntypedef struct nodo Nodo;\nFunzioni per la Gestione dei Nodi\nLe operazioni comuni su liste collegate includono inserimento, eliminazione, e ricerca.\nCreazione di una Nuova Lista\nNodo *lista_nuova() {\n    return NULL;  // Inizia con una lista vuota\n}\nInserimento di un Nodo all‚ÄôInizio\nNodo *insert0(Nodo *a, int b) {\n    Nodo *p = malloc(sizeof(Nodo));\n    p-&gt;valore = b;\n    p-&gt;succ = a;\n    if(a != NULL) a-&gt;prec = p;\n    return p;  // Ritorna il nuovo inizio della lista\n}\nInserimento dopo un Nodo Specifico\nNodo *insert1(Nodo *a, int b) {\n    if(a == NULL) return insert0(a, b);  // Se la lista √® vuota, inserisci all&#039;inizio\n    Nodo *p = malloc(sizeof(Nodo));\n    p-&gt;valore = b;\n    p-&gt;succ = a-&gt;succ;\n    p-&gt;prec = a;\n    if(a-&gt;succ != NULL) a-&gt;succ-&gt;prec = p;\n    a-&gt;succ = p;\n    return a;  // Ritorna il nodo dopo il quale l&#039;inserimento √® avvenuto\n}\nEliminazione di un Nodo\nNodo *elimina0(Nodo *a) {\n    if(a == NULL || a-&gt;succ == NULL) return NULL;  // Gestisci lista vuota o un solo elemento\n    Nodo *temp = a-&gt;succ;\n    free(a);\n    if(temp != NULL) temp-&gt;prec = NULL;\n    return temp;  // Ritorna il nuovo inizio della lista\n}\nRicerca di un Nodo\nNodo *lista_cerca(Nodo *x, int pos) {\n    Nodo *p = x;\n    for(int i = 0; i &lt; pos &amp;&amp; p != NULL; i++) {\n        p = p-&gt;succ;\n    }\n    if(p == NULL) return NULL;\n    printf(&quot;Nodo trovato: %d\\n&quot;, p-&gt;valore);\n    return p;\n}\nVisualizzazione della Lista\nvoid mostrastruct(Nodo *a) {\n    for(Nodo *p = a; p != NULL; p = p-&gt;succ) {\n        printf(&quot;%d &quot;, p-&gt;valore);\n    }\n    printf(&quot;\\n&quot;);\n}\nEsempio di Utilizzo\nint main() {\n    Nodo *inizio = lista_nuova();\n    inizio = insert0(inizio, 4);\n    inizio = insert0(inizio, 8);\n    mostrastruct(inizio);\n    inizio = insert1(inizio, 5);\n    mostrastruct(inizio);\n    inizio = elimina0(inizio);\n    mostrastruct(inizio);\n}\nQuesto capitolo illustra come gestire nodi e liste doppiamente collegate in C, fornendo una base per strutture dati pi√π complesse."},"UNI/ANNO-1/PROGRAMMAZIONE/C/15.Capitolo15":{"slug":"UNI/ANNO-1/PROGRAMMAZIONE/C/15.Capitolo15","filePath":"UNI/ANNO 1/PROGRAMMAZIONE/C/15.Capitolo15.md","title":"15.Capitolo15","links":[],"tags":[],"content":"Lezione 15: Implementazione di Dizionari in C\nStrutture e Tipi\nUn dizionario in C pu√≤ essere implementato utilizzando una combinazione di array di puntatori a nodi e strutture per memorizzare coppie chiave-valore.\nStrutture Utilizzate\n#include&lt;stdio.h&gt;\n#include&lt;stdlib.h&gt;\n#include&lt;string.h&gt;\n \nstruct d_item {\n  char *k;\n  float v;\n};\ntypedef struct d_item d_item;\n \nstruct nodo {\n  d_item info;\n  struct nodo *succ;\n};\ntypedef struct nodo nodo;\n \nstruct dict {\n  nodo **a;\n  int m; // Numero di liste (dimensione di a)\n  int n; // Numero di elementi nel dizionario\n};\ntypedef struct dict dict;\nFunzioni di Gestione del Dizionario\nLe funzioni includono inizializzazione, aggiornamento di valori, ricerca per chiave, e visualizzazione del contenuto del dizionario.\nInizializzazione\ndict dict_init(int m) {\n  dict d;\n  d.a = malloc(m * sizeof(nodo*));\n  d.m = m;\n  d.n = 0;\n  for(int i = 0; i &lt; m; i++) {\n    d.a[i] = NULL;\n  }\n  return d;\n}\nAggiornamento del Dizionario\ndict dict_update(dict d, d_item e) {\n  int index = h(e.k, d);\n  nodo *p = lista_cerca_k(d.a[index], e.k);\n  if (p == NULL) {\n    d.a[index] = lista_in0(d.a[index], e);\n    d.n++;\n  } else {\n    p-&gt;info.v = e.v;\n  }\n  return d;\n}\nRicerca per Chiave\nnodo *lista_cerca_k(nodo *x, char *k) {\n  nodo *p = x;\n  while (p != NULL) {\n    if (strcmp(p-&gt;info.k, k) == 0) {\n      return p;\n    }\n    p = p-&gt;succ;\n  }\n  return NULL;\n}\nVisualizzazione del Dizionario\nvoid dict_mostra(dict d) {\n  for (int i = 0; i &lt; d.m; i++) {\n    printf(&quot;%d - &quot;, i);\n    lista_mostra(d.a[i]);\n  }\n}\n \nvoid lista_mostra(nodo *x) {\n  nodo *p = x;\n  while(p != NULL) {\n    printf(&quot;(%s, %.2f) &quot;, p-&gt;info.k, p-&gt;info.v);\n    p = p-&gt;succ;\n  }\n  printf(&quot;\\n&quot;);\n}\nEsempio di Utilizzo\nint main(int argc, char *argv[]) {\n  dict d = dict_init(3);\n  d_item e;\n  for (int i = 1; i &lt; argc; i++) {\n    e.k = argv[i];\n    e.v = i;\n    d = dict_update(d, e);\n  }\n  dict_mostra(d);\n}\nQuesto capitolo dimostra come implementare un dizionario in C utilizzando hash table e liste collegate per gestire collisioni, offrendo un modo efficiente per mappare chiavi a valori."},"UNI/ANNO-1/PROGRAMMAZIONE/C/9.Capitolo9":{"slug":"UNI/ANNO-1/PROGRAMMAZIONE/C/9.Capitolo9","filePath":"UNI/ANNO 1/PROGRAMMAZIONE/C/9.Capitolo9.md","title":"9.Capitolo9","links":[],"tags":[],"content":"Differenze tra C e Python, Librerie e Cicli\nIntroduzione a C e Python\nC e Python sono due linguaggi di programmazione con diverse filosofie e livelli di astrazione.\nDifferenze Chiave\n\nLibrerie: In C, si usano le direttive #include per includere librerie standard come &lt;stdio.h&gt;, che fornisce funzionalit√† di input/output.\nCompilazione vs Interpretazione: C compila il codice in un file eseguibile direttamente dal computer, mentre Python utilizza un interprete.\nLivello di Astrazione: C √® un linguaggio di basso livello vicino al linguaggio macchina, che lo rende pi√π veloce e reattivo. Python √® di alto livello, pi√π facile da scrivere ma generalmente pi√π lento.\n\nSintassi di Base in C\nDichiarazione di Variabili\nint x = 5;  // Tipo di dato specificato esplicitamente\nfloat y = 3.3;  // Variabili di tipo float\nStampa di Variabili\nprintf(&quot;///%d///%d&quot;, y, x);  // %d per gli interi\nprintf(&quot;///%.2f///%f&quot;, y, x);  // %f per i float, .2 per due cifre decimali\nStrutture di Controllo\nIF e ELSE\nif(x &gt; y) {\n    printf(&quot;suca&quot;);\n} else {\n    printf(&quot;palle&quot;);\n}\n// Versione inline per singole istruzioni\nif(x &gt; y) printf(&quot;suca&quot;);\nelse printf(&quot;palle&quot;);\nCicli in C\nC offre diversi tipi di cicli che permettono di eseguire ripetizioni di blocchi di codice.\nFOR\nfor(int i = 0; i &lt; 5; i++) {\n    printf(&quot;%d&quot;, i);\n}\nWHILE\nint x = 5;\nint y = 3;\nint q = 0;\nwhile(q &lt; 20) {\n    x++;\n    y++;\n    q = y + x;\n    printf(&quot;%d   &quot;, q);\n}\nOperatori Logici\n\nAND: &amp;&amp;\nOR: ||\n\nQuesto capitolo offre una panoramica delle differenze fondamentali tra C e Python e mostra alcuni esempi di sintassi di base in C, mettendo in luce come le operazioni comuni sono gestite in modo diverso nei due linguaggi."},"UNI/ANNO-1/PROGRAMMAZIONE/Programmazione-INDICE":{"slug":"UNI/ANNO-1/PROGRAMMAZIONE/Programmazione-INDICE","filePath":"UNI/ANNO 1/PROGRAMMAZIONE/Programmazione INDICE.md","title":"Programmazione INDICE","links":["UNI/ANNO-1/PROGRAMMAZIONE/Python/1.Capitolo1","UNI/ANNO-1/PROGRAMMAZIONE/Python/2.Capitolo2","UNI/ANNO-1/PROGRAMMAZIONE/Python/3.Capitolo-3","UNI/ANNO-1/PROGRAMMAZIONE/Python/4.Capitolo-4","UNI/ANNO-1/PROGRAMMAZIONE/Python/5.Capitolo-5","UNI/ANNO-1/PROGRAMMAZIONE/Python/6.Capitolo-6","UNI/ANNO-1/PROGRAMMAZIONE/Python/7.Capitolo-7","UNI/ANNO-1/PROGRAMMAZIONE/Python/8.Capitolo-8","UNI/ANNO-1/PROGRAMMAZIONE/C/9.Capitolo9","UNI/ANNO-1/PROGRAMMAZIONE/C/10.Capitolo10","UNI/ANNO-1/PROGRAMMAZIONE/C/11.Capitolo-11","UNI/ANNO-1/PROGRAMMAZIONE/C/12.Capitolo-12","UNI/ANNO-1/PROGRAMMAZIONE/C/13.Capitolo-13","UNI/ANNO-1/PROGRAMMAZIONE/C/14.Capitolo14","UNI/ANNO-1/PROGRAMMAZIONE/C/15.Capitolo15","UNI/ANNO-1/PROGRAMMAZIONE/pre-test"],"tags":[],"content":"Python\nCapitolo 1:\nCicli, dati, condizioni, input, output, costi computazionali\nCapitolo 2:\nApprofondimenti sulle Stringhe e Funzioni in Python\nCapitolo 3:\nFunzioni Avanzate e Aliasing in Python\nCapitolo 4:\nUso di Break, Bubble Sort e Zip in Python\nCapitolo 5:\nSorted, Sort, Lambda, e Ricorsione in Python\nCapitolo 6:\nMerge Sort e Binary Search in Python\nCapitolo 7:\nDizionari, Metodi, Ord, Chr, e File Handling in Python\nCapitolo 8:\nGestione delle Eccezioni e Identificazione degli Oggetti in Python\nC\nCapitolo 9:\nDifferenze tra C e Python, Librerie e Cicli\nCapitolo 10:\nArray, Puntatori, malloc e sizeof in C\nCapitolo 11:\nFunzioni, Struct e typedef in C\nCapitolo 12:\nSequenze, Free, e Funzioni Avanzate in C\nCapitolo 13:\nRealloc e Gestione delle Stringhe in C\nCapitolo 14:\nGestione dei Nodi in Liste Doppiamente Collegate in C\nCapitolo 15:\nImplementazione di Dizionari in C\npre-test"},"UNI/ANNO-1/PROGRAMMAZIONE/Python/1.Capitolo1":{"slug":"UNI/ANNO-1/PROGRAMMAZIONE/Python/1.Capitolo1","filePath":"UNI/ANNO 1/PROGRAMMAZIONE/Python/1.Capitolo1.md","title":"1.Capitolo1","links":[],"tags":[],"content":"In questo capitolo vedremo i seguenti argomenti:\nCicli, dati, condizioni, input, output, costi computazionali\nI dati\nint\np=5\nfloat\nx=3.5\nlista-modificabile\na=[3,4,5]\ntuple\nb=(3,4,5)\ntuple non modificabili\ndictionary\nc={&quot;chiave&quot;:&quot;valore&quot;,&quot;chiave1&quot;:&quot;valore2&quot;}\nLe condizioni\nif, else ed elif\n \nif p&gt;0:\n  print(&#039;ciao&#039;)\nelse: \n  print(&quot;suca&quot;)\n \n#elif\nif p&gt;0:             \n                \n  print(&#039;ciao&#039;)\nelif p&gt;1:\n  print(3)\ncosto computazionale:\nanche se bruno lo ha spiegato meglio\nI programmi hanno un costo computazionale ‚Äúsprecano‚Äù risorse temporali e spaziali.\nTemporali: tempo per es eguire il programma\nSpaziale: la memoria che utilizzano in pi√π\nLe unit√† di misura sono:\nO: quando non siamo sicuri del costo effettivo (limitazione massima)\nTheta: quando ne siamo sicuri (esattamente)\ni cicli:\n \nk=&#039;giuseppe&#039;\nn=len(k) #n=lunghezza di k, esempio dell&#039;etichetta\n \nfor i in k:      #i √® una variabile temporale muore out ciclo\n                  #costi computazionali: temp:Theta(n) perch√®\n                  #siamo esattamente sicuri di quanto il for \n                #ci mette, tira dritto fino all&#039;ultimo elemento\n                    #spaz:O(1)\n  if i==&quot;c&quot;:    #costa temp: O(1), siccome nel for Theta(n)\n    print(&quot;c&#039;√® la c&quot;)\n#se qua si mettesse &quot;break&quot;interrompe il ciclo quando si \n#verifica la condizione rende il costo del ciclo O(n)\n  print(i)\n#utilizzo di &quot;in&quot;\nq=&#039;giuseppe&#039;\nif k in q:\n  print(&quot;ciao&quot;)\n \n#while\ny=3\nwhile y==3:         #costo temp:O(n) e spaz:O(1)\n  print(&quot;cacchina&quot;)\n  y+=1\n#input by luca gugliottong\nm=input(&quot;inserisci qui la parola&quot;)\nprint(m)"},"UNI/ANNO-1/PROGRAMMAZIONE/Python/2.Capitolo2":{"slug":"UNI/ANNO-1/PROGRAMMAZIONE/Python/2.Capitolo2","filePath":"UNI/ANNO 1/PROGRAMMAZIONE/Python/2.Capitolo2.md","title":"2.Capitolo2","links":[],"tags":[],"content":"Approfondimenti sulle Stringhe e Funzioni in Python\nStringhe\nLe stringhe sono contenitori che contengono caratteri. Vediamo alcuni esempi e operazioni che possiamo fare con le stringhe.\nCreazione di Stringhe\na = &quot;hey&quot;\nprint(a)\nprint(a[0])\nConfronto tra Stringhe\nb = &quot;ciao&quot;\nif a &gt; b:\n    print(a &gt; b)  # Output: True\nCosti computazionali:\n\nSpaziali: O(1)\nTemporali: O(n), dove n √® la lunghezza della stringa pi√π piccola\n\nConfronto tra due stringhe semi uguali\np = &quot;ciaox&quot;\no = &quot;ciao&quot;\nprint(p &gt; o)  # Printer√† True\nFunzioni Stringa in Python\nFunzione 1: join\na = &quot;-.&quot;\nb = &quot;ciao&quot;\nl = a.join(b)\nprint(l)  # Output: c--..i--..a--..o\nCosti computazionali:\n\nTemporali: O(n*m)\nSpaziali: O(n*m)\n\nFunzione 2: strip\ntxt = &quot;.....banana....&quot;\nx = txt.strip(&quot;.&quot;)\nprint(&quot;k&quot;, x, &quot;frakka&quot;)\nFunzione 3: slicing\na = &quot;ciaop&quot;\nprint(a[::-1])  # Stampa la stringa al contrario\nfor i in a[:]:\n    print(i)\nFunzione 4: lower/upper\na = &quot;ciAo&quot;\nprint(a.upper())  # CIAO\nprint(a.lower())  # ciao\nFunzione 5: replace\nm = &quot;odio i negri&quot;\nprint(m)  # Output: odio i negri\nprint(m.replace(&quot;odio&quot;, &quot;amo&quot;))  # Output: amo i negri\nFunzione 6: split\ntxt = &quot;luca fai schifo&quot;\nx = txt.split()\nprint(x)  # Output: [&#039;luca&#039;, &#039;fai&#039;, &#039;schifo&#039;]\nFunzione 7: trasformazione di una stringa in una serie di interi\na = &quot;123&quot;\nprint(a[0] + a[1])\nprint(int(a[0]) + int(a[1]))  # Output: 3\nEsercizio di confronto tra stringhe\na = &quot;sucaa&quot;\nb = &quot;suca&quot;\nk = False\ni = 0\nm = len(a)\nn = len(b)\nwhile k is False:\n    if i in (m, n):\n        if len(a) &gt; len(b):\n            print(&quot;a √® &gt; b&quot;)\n            break\n        elif len(a) &lt; len(b):\n            print(&quot;a √® &lt; b&quot;)\n            break\n    if a[i] &gt; b[i]:\n        print(&quot;a √® &gt; b&quot;)\n        k = True\n    elif a[i] &lt; b[i]:\n        print(&quot;a √® &lt; b&quot;)\n        k = True\n    else:\n        i += 1\nList, Tuple e Funzioni\nList\nLe liste sono collezioni indicizzate di dati che sono mutabili. Esempi di operazioni su liste:\na = []\na = [2, 3, 4, &quot;ciao&quot;, &quot;b&quot;]\na.append(3)  # Aggiunge un elemento\nprint(a)  # Output: [2, 3, 4, &#039;ciao&#039;, &#039;b&#039;, 3]\nprint(len(a))  # Lunghezza\na.extend([3, 4, 5, 6])  # Aggiunge una lista alla fine\ndel a[0]  # Elimina il primo elemento\na.remove(3)  # Rimuove il primo 3 trovato\nprint(a.pop())  # Rimuove e ritorna l&#039;ultimo elemento\nTuple\nLe tuple sono come le liste ma non sono modificabili:\na = (1, 1, 2, 3, 4)\nprint(a.count(1))  # Output: 2\nCreazione di Funzioni\ndef somma(a, b):\n    return a + b\n \nx, y = int(input()), int(input())\nprint(somma(x, y))"},"UNI/ANNO-1/PROGRAMMAZIONE/Python/3.Capitolo-3":{"slug":"UNI/ANNO-1/PROGRAMMAZIONE/Python/3.Capitolo-3","filePath":"UNI/ANNO 1/PROGRAMMAZIONE/Python/3.Capitolo 3.md","title":"3.Capitolo 3","links":[],"tags":[],"content":"Funzioni Avanzate e Aliasing in Python\nJoin, Min, Max, Range, Extend, Aliasing\nJoin\nIl metodo join √® un metodo delle stringhe che permette di unire i caratteri di una stringa separandoli con un specifico separatore.\na = &quot;ciao&quot;\nb = &quot;-&quot;\nprint(b.join(a))  # Output: c-i-a-o\nMin e Max\nmin e max sono funzioni che permettono di trovare il valore minimo e massimo in un iterabile.\nMin\na = [1, 2, 3, 1, 6, 90000, 1, 2]\nprint(min(a))  # Output: 1\nMax\na = [&quot;1&quot;, &quot;2&quot;, &quot;80000&quot;, &quot;9&quot;, &quot;2&quot;]\nprint(max(a, key=int))  # Output: 80000\nIl parametro key consente di specificare una funzione di un solo argomento utilizzata per estrarre una chiave di confronto da ciascun elemento in a.\nRange\nLa funzione range genera una sequenza di numeri.\nprint(list(range(90)))  # Stampa i numeri da 0 a 89\nExtend\nIl metodo extend aggiunge gli elementi di una lista a un‚Äôaltra lista.\na = [1, 2, 3, 3]\nb = [2, 32, 3, 32, 23]\na.extend(b)\nprint(a)  # Output: [1, 2, 3, 3, 2, 32, 3, 32, 23]\nAliasing\nL‚Äôaliasing si verifica quando una variabile si riferisce allo stesso oggetto a cui si riferisce un‚Äôaltra variabile.\nEsempio con Tuple (Immutabili)\na = (1, 2, 3, 4)\nb = a\nb += (1, 2, 3)\nprint(b)  # Output: (1, 2, 3, 4, 1, 2, 3)\nprint(a)  # Output: (1, 2, 3, 4)\nEsempio con Liste (Mutabili)\nx = [1, 2, 3, 4]\ny = x\ny[0] = 3\nprint(y)  # Output: [3, 2, 3, 4]\nprint(x)  # Output: [3, 2, 3, 4]\nFunzione che Modifica la Lista\ndef double(L):\n    for i in range(len(L)):\n        L[i] = L[i] * 2\n    print(L)\n \na_list = [5, 6]\ndouble(a_list)\nprint(a_list)  # Output: [10, 12]"},"UNI/ANNO-1/PROGRAMMAZIONE/Python/4.Capitolo-4":{"slug":"UNI/ANNO-1/PROGRAMMAZIONE/Python/4.Capitolo-4","filePath":"UNI/ANNO 1/PROGRAMMAZIONE/Python/4.Capitolo 4.md","title":"4.Capitolo 4","links":[],"tags":[],"content":"Uso di Break, Bubble Sort e Zip in Python\nBreak\nIl comando break serve per interrompere l‚Äôesecuzione di un ciclo.\nfor i in k:       # temp: O(n), spazio: O(1)\n  if i == qualcosa:\n      break\nZip\nPacking e Unpacking\nPacking √® il processo di impacchettamento di pi√π valori in una singola variabile, mentre unpacking √® il processo di spacchettamento.\nPacking\na = 1, 2, 3, 4, 5, 6\nb = 5\np = &quot;ciao&quot;\na = 1, 2, 3, 4, 5, 6, b, p\nprint(a)  # Output: (1, 2, 3, 4, 5, 6, 5, &#039;ciao&#039;)\nUnpacking\nx = 1, 2, 3, 4\ny, z, t, k = x\nprint(y, z, t, k)  # Output: 1 2 3 4\nZip per Comprimere Sequenze\na = (1, 2, 3, 4)\nb = (5, 6, 7, 8)\np = zip(a, b)\nprint(*p)  # Output: (1, 5) (2, 6) (3, 7) (4, 8)\nBubble Sort\nBubble Sort √® un algoritmo di ordinamento che confronta ripetutamente gli elementi adiacenti e li scambia se sono nell‚Äôordine sbagliato.\na = [3, 5, 8, 2, 43]\ncontinua = True\nwhile continua:\n    continua = False\n    for c in range(len(a) - 1):\n        if a[c] &gt; a[c + 1]:\n            continua = True\n            a[c], a[c + 1] = a[c + 1], a[c]\nprint(a)  # Output: [2, 3, 5, 8, 43]"},"UNI/ANNO-1/PROGRAMMAZIONE/Python/5.Capitolo-5":{"slug":"UNI/ANNO-1/PROGRAMMAZIONE/Python/5.Capitolo-5","filePath":"UNI/ANNO 1/PROGRAMMAZIONE/Python/5.Capitolo 5.md","title":"5.Capitolo 5","links":[],"tags":[],"content":"Sorted, Sort, Lambda, e Ricorsione in Python\nSorted vs Sort\nsorted √® una funzione che ritorna una nuova lista ordinata senza modificare l‚Äôoriginale, mentre sort √® un metodo delle liste che modifica direttamente la lista su cui √® chiamato.\nLambda\nLe funzioni lambda sono piccole funzioni anonime definito con la parola chiave lambda. Sono particolarmente utili per operazioni concise che possono essere definite in una singola espressione. Sono spesso usate in combinazione con funzioni come sorted e max.\nEsempi di Lambda\nEsempio 1: Semplice Addizione\na = lambda a: a + 4\nprint(a(4))  # Output: 8\nEsempio 2: Condizionale\na = lambda a: a if a &gt; 9 else &quot;pizza&quot;\nprint(a(8))  # Output: pizza\nEsempio 3: Uso con max e List\na = [1, 2, 3, 4, 5, 6, 7, 8, 9]\nprint(max(a, key=lambda e: e if e % 2 == 0 else 0))  # Output: 8\nEsempio 4: Altro Uso con max\na = [33, 44, 5, 1, 2, 4, 3]\nprint(max(a, key=lambda x: x if x &lt; 5 else 0))  # Output: 4\nRicorsione\nLa ricorsione √® una tecnica di programmazione in cui una funzione si chiama se stessa direttamente o indirettamente. √à molto utile per risolvere problemi che possono essere suddivisi in sotto-problemi simili di dimensioni minori.\nEsempio di Ricorsione\na = [1, 2, 3, 4, [3, 3, 3, [2, 2, 3, 4], 4]]\n \ndef copynz(a):\n    b = []\n    for i in a:\n        if type(i) == int:\n            b.append(i)\n        elif type(i) == list:\n            b.append(copynz(i))\n    return b\n \nprint(copynz(a))  # Output: [1, 2, 3, 4, [3, 3, 3, [2, 2, 3, 4], 4]]"},"UNI/ANNO-1/PROGRAMMAZIONE/Python/6.Capitolo-6":{"slug":"UNI/ANNO-1/PROGRAMMAZIONE/Python/6.Capitolo-6","filePath":"UNI/ANNO 1/PROGRAMMAZIONE/Python/6.Capitolo 6.md","title":"6.Capitolo 6","links":[],"tags":[],"content":"Merge Sort e Binary Search in Python\nMerge Sort\nMerge Sort √® un algoritmo di ordinamento che divide ricorsivamente l‚Äôarray in met√†, ordina ciascuna met√† e poi le fonde insieme.\nDefinizione del Merge\ndef merge(a, b):\n    n, m = len(a), len(b)\n    c = []\n    i, j = 0, 0\n    while i &lt; n and j &lt; m:\n        if a[i] &lt; b[j]:\n            c.append(a[i])\n            i += 1\n        else:\n            c.append(b[j])\n            j += 1\n    if i == n:\n        c.extend(b[j:])\n    else:\n        c.extend(a[i:])\n    return c\nMerge Sort Completo\ndef merge_sort(a, sx=0, dx=None):\n    if dx is None:\n        dx = len(a)\n    n = dx - sx\n    if n &gt;= 2:\n        cx = (sx + dx) // 2\n        merge_sort(a, sx, cx)\n        merge_sort(a, cx, dx)\n        merge(a, sx, cx, dx)\n    # La complessit√† temporale √® Theta(n log n)\n    # La complessit√† spaziale √® Theta(n)\n \na = [3, 7, 3, 9, 8, 1, 4, 2, 1, 0, 9, 3, 1, 4, 5]\nmerge_sort(a)\nprint(a)  # Output: [0, 1, 1, 1, 2, 3, 3, 3, 4, 4, 5, 7, 8, 9, 9]\nBinary Search\nBinary Search √® un algoritmo di ricerca che divide ripetutamente a met√† la porzione di lista che potrebbe contenere l‚Äôelemento, fino a quando non viene trovato o fino a quando l‚Äôintervallo di ricerca non √® vuoto.\nEsempio di Binary Search\ndef binary_search(a, num):\n    sx, dx = 0, len(a)\n    while dx &gt; sx:\n        cx = (sx + dx) // 2\n        if num == a[cx]:\n            return cx\n        if num &gt; a[cx]:\n            sx = cx\n        else:\n            dx = cx\n    return -1\n \na = [2, 4, 6, 7, 7, 10, 11, 12, 13, 14, 16, 17, 20, 23, 23]\nprint(binary_search(a, 7))  # Output: indice di uno dei &#039;7&#039; nella lista"},"UNI/ANNO-1/PROGRAMMAZIONE/Python/7.Capitolo-7":{"slug":"UNI/ANNO-1/PROGRAMMAZIONE/Python/7.Capitolo-7","filePath":"UNI/ANNO 1/PROGRAMMAZIONE/Python/7.Capitolo 7.md","title":"7.Capitolo 7","links":[],"tags":[],"content":"Dizionari, Metodi, Ord, Chr, e File Handling in Python\nDizionari e Metodi\nI dizionari in Python sono collezioni di coppie chiave-valore. Sono mutabili e possono essere modificati in vari modi.\nDefinizione e Accesso\nd1 = {34: &quot;paolo&quot;, 131231: &quot;frakka&quot;}\nprint(d1)  # Output: tutto il dizionario\nprint(d1[34])  # Output: &#039;paolo&#039;\nModifica di Elementi\nd1[34] = &quot;franco&quot;\nprint(d1)  # Output: {34: &#039;franco&#039;, 131231: &#039;frakka&#039;}\nMetodi dei Dizionari\nprint(d1.values())  # Restituisce i valori\nprint(d1.items())   # Restituisce le coppie chiave-valore\nprint(d1.keys())    # Restituisce le chiavi\nprint(d1.get(34, &quot;non trovato&quot;))  # &#039;franco&#039;, &#039;non trovato&#039; se 34 non esiste\nIterazione su Chiavi\nfor i in d1:\n    print(i)  # Stampa le chiavi una a una\nCopia e Rimozione\nd2 = d1.copy()  # Crea una copia del dizionario\nx = d1.pop(34)  # Rimuove la chiave 34 e ritorna il valore\nprint(x)        # Output: &#039;franco&#039;\nprint(d1)       # Output: {131231: &#039;frakka&#039;}\nd1.update({55: &quot;pisellino&quot;})\nprint(d1)       # Aggiunge o aggiorna chiave-valore\ndel d1[55]      # Elimina la chiave 55\nCasting e Ordinamento di Dizionari\nx = dict([(1, 3)])\ny = dict([(1, 3), (2, 3)])\np = []\nfor x in d1:\n    p.append((x, d1[x]))\nprint(dict(sorted(p, key=lambda e: e[1])))  # Ordina il dizionario per valori\nOrd e Chr\nFunzioni per convertire caratteri in codici ASCII e viceversa.\nEsempi Ord e Chr\nprint(ord(&quot;a&quot;))  # Output: 97\nprint(chr(97))  # Output: &#039;a&#039;\nGestione dei File con Open\nAprire, leggere, scrivere e chiudere file.\nLeggere un File\ntxt = open(&quot;puppa.txt&quot;)\nprint(txt.read())\ntxt.close()\nScrivere su un File\ntxt = open(&quot;puppa.txt&quot;, &quot;w&quot;)\ntxt.write(&quot;suca&quot;)\ntxt.close()\nAggiungere a un File\ntxt = open(&quot;puppa.txt&quot;, &quot;a&quot;)\ntxt.write(&quot;suca&quot;)\ntxt.close()"},"UNI/ANNO-1/PROGRAMMAZIONE/Python/8.Capitolo-8":{"slug":"UNI/ANNO-1/PROGRAMMAZIONE/Python/8.Capitolo-8","filePath":"UNI/ANNO 1/PROGRAMMAZIONE/Python/8.Capitolo 8.md","title":"8.Capitolo 8","links":[],"tags":[],"content":"Gestione delle Eccezioni e Identificazione degli Oggetti in Python\nTry-Except\nLa gestione delle eccezioni in Python viene eseguita utilizzando i blocchi try e except. Questi blocchi permettono di catturare e gestire gli errori che si verificano durante l‚Äôesecuzione del codice, prevenendo interruzioni indesiderate del programma.\nEsempio di Try-Except\na = (1, 2)\ntry:\n    x = int(input(&quot;Inserisci un numero: &quot;))\n    print(x + a)  # Questo genera TypeError poich√© non si possono sommare int e tuple\nexcept TypeError as p:\n    print(&quot;L&#039;errore uscito √® il TypeError e stampa il seguente log:&quot;)\n    print(p)\nexcept ValueError:\n    print(&quot;Value error: non √® stato inserito un numero valido.&quot;)\nexcept:\n    print(&quot;Errore di altro tipo.&quot;)\nID\nLa funzione id ritorna l‚Äôidentificatore unico per l‚Äôoggetto specificato, che corrisponde al suo indirizzo in memoria. √à utile per determinare se due variabili si riferiscono allo stesso oggetto (aliasing) o a oggetti distinti.\nEsempio di ID\nx = [1, 2, 3, 4]  # Lista base\np = x              # Alias\nk = x[:]           # Copia\nprint(id(x), id(p), id(k))  # Output: id(x) e id(p) saranno uguali, id(k) sar√† diverso\nQuesti esempi mostrano come gestire gli errori in modo pi√π robusto e come identificare e comprendere la gestione della memoria degli oggetti in Python."},"UNI/ANNO-1/PROGRAMMAZIONE/pre-test":{"slug":"UNI/ANNO-1/PROGRAMMAZIONE/pre-test","filePath":"UNI/ANNO 1/PROGRAMMAZIONE/pre-test.md","title":"pre-test","links":[],"tags":[],"content":"1\n\nLa risposta O(1) si riferisce generalmente alla complessit√† temporale di un‚Äôoperazione in un algoritmo o una struttura dati che si compie in un tempo costante, indipendentemente dalla dimensione dell‚Äôinput. Nella domanda che hai mostrato, si sta probabilmente chiedendo quale sia la complessit√† temporale dell‚Äôoperazione di accesso (ricerca, inserimento, eliminazione) in un dizionario (o hash table) implementato come descritto dal codice.\nNel caso di una hash table ben dimensionata con una buona funzione hash, le operazioni di inserimento, ricerca ed eliminazione hanno tutte una complessit√† temporale media di O(1). Questo perch√© l‚Äôindice dell‚Äôarray al quale accedere viene calcolato tramite la funzione hash, che √® un‚Äôoperazione che richiede un tempo costante, e idealmente, se le collisioni sono gestite efficientemente (per esempio, con il chaining), l‚Äôaccesso agli elementi della lista a quel particolare indice √® anche veloce e non dipende dalla dimensione del dizionario.\nNel codice specifico fornito, la struttura dict √® composta da un array di puntatori a liste (rappresentate dalla struttura nodo). La complessit√† O(1) si assume quando la funzione hash distribuisce uniformemente gli elementi tra le liste, e la dimensione dell‚Äôarray m √® proporzionale al numero di elementi n, mantenendo le liste brevi e quindi le operazioni veloci.\nTuttavia, nel caso peggiore (quando tutti gli elementi vengono inseriti nella stessa lista a causa di collisioni), la complessit√† temporale pu√≤ degradare a O(n), dove n √® il numero di elementi nella lista, poich√© bisognerebbe attraversare tutta la lista per trovare un elemento. Ma la risposta O(1) suggerisce che ci si aspetta di operare nella media e non nel caso peggiore, con una buona funzione hash e un numero adeguato di liste per minimizzare le collisioni.\n2\n\nIl codice mostrato esegue una copia dei caratteri dalla stringa b[] alla stringa a[] fino a quando non incontra il carattere &#039;o&#039; in b[]. La stringa b √® &quot;algoritmo;&quot;, e la copia si ferma quando si arriva al carattere &#039;o&#039;, che √® il settimo carattere di b[]. Quindi, i primi sei caratteri di b[] (&quot;algorit&quot;) vengono copiati in a[].\nLa stringa a[] era inizialmente &quot;programmazione&quot;, che ha una lunghezza di 14 caratteri (incluso il terminatore nullo \\0 alla fine, che √® il modo standard in C di indicare la fine di una stringa). Poich√© la copia non include il terminatore nullo, la lunghezza finale della stringa a[] rimane inalterata, perch√© in C la lunghezza di una stringa √® determinata dalla posizione del terminatore nullo, e non dalla quantit√† di memoria allocata o dal numero di caratteri copiati.\nPertanto, dopo l‚Äôesecuzione del ciclo, la stringa a[] contiene i caratteri &quot;algoritmazione\\0&quot;, che √® ancora lunga 14 caratteri, inclusa la terminazione nullo. Per questo motivo, la risposta corretta √® 14.\n3\n\nLa domanda si riferisce all‚Äôordinamento di k sequenze ognuna di dimensione n/k. Per ordinare ciascuna sequenza, se utilizziamo un algoritmo di ordinamento efficiente come Merge Sort o Quick Sort, avremo una complessit√† di O((n/k) * log(n/k)) per ogni sequenza.\nPoich√© ci sono k sequenze da ordinare, moltiplichiamo la complessit√† di ordinamento di una sequenza per il numero di sequenze, ottenendo k * O((n/k) * log(n/k)).\nSe espandiamo questa espressione, otteniamo O(n/k * log(n/k) * k), che semplifica a O(n * log(n/k)).\nTuttavia, la risposta che hai evidenziato √® O(n*log k), che non √® la semplificazione corretta della complessit√† computazionale data dalla domanda, a meno che non ci siano informazioni aggiuntive non visibili nell‚Äôimmagine, come un passaggio successivo in cui si fondono tutte le sequenze ordinate insieme, che potrebbe giustificare una tale complessit√†.\nNell‚Äôordinamento di sequenze multiple, un passaggio comune dopo l‚Äôordinamento individuale √® quello di fondere le sequenze ordinate in una singola sequenza ordinata, che ha una complessit√† di O(n log k) se fatto in modo efficiente. Questa potrebbe essere la giustificazione per la risposta indicata, ma senza ulteriori dettagli del problema non posso fornire una spiegazione pi√π precisa.\n4\n\nNel frammento di codice presentato, abbiamo un array di interi a e due puntatori, p di tipo int * e c di tipo char *. Il puntatore p viene inizializzato per puntare al primo elemento di a, mentre c viene inizialmente impostato per puntare alla stessa locazione, ma viene trattato come puntatore a char.\nDopo l‚Äôinizializzazione, il puntatore p viene incrementato (p++), il che fa s√¨ che punti al secondo elemento dell‚Äôarray a, perch√© p √® un puntatore a int, e l‚Äôincremento di un puntatore a int fa muovere il puntatore di sizeof(int) bytes avanti. Nella maggior parte delle piattaforme moderne, sizeof(int) √® 4 bytes. D‚Äôaltra parte, c √® un puntatore a char, e quando viene incrementato (c++), si muove avanti di sizeof(char) bytes, che √® sempre 1 byte.\nQuindi, dopo l‚Äôincremento, p punta al secondo elemento di a, mentre c punta al secondo byte del primo elemento di a. In un‚Äôarchitettura con interi a 32 bit (4 bytes), p sar√† avanti di 4 bytes rispetto a c, dato che il primo elemento di a occupa i primi 4 bytes. Di conseguenza, l‚Äôindirizzo di memoria contenuto in c sar√† minore di quello contenuto in p, rendendo l‚Äôaffermazione c &lt; p vera.\nIn termini pi√π semplici, c √® indietro rispetto a p nella memoria a causa del modo in cui i diversi tipi di puntatori incrementano i loro valori quando viene applicato l‚Äôoperatore ++.\n5\n\nIl frammento di codice mostrato nell‚Äôimmagine √® un algoritmo di ordinamento. Analizzando il codice:\n\nSi inizia con un ciclo for che itera su ciascun elemento dell‚Äôarray a.\nPer ogni elemento, si esegue un ciclo while che confronta elementi adiacenti dell‚Äôarray.\nSe un elemento √® minore del suo predecessore (a[i] &lt; a[i-1]), questi vengono scambiati.\nQuesto processo √® noto come ‚Äúbubble sort‚Äù se viene eseguito fino a quando non sono necessari pi√π scambi.\n\nIl comportamento √® definito in quanto il codice esegue in modo deterministico. Tuttavia, la ragione per cui la complessit√† temporale √® quadratica √® che in caso peggiore, dove l‚Äôarray √® ordinato in modo inverso, ogni elemento deve essere scambiato attraverso l‚Äôintero array per raggiungere la sua posizione corretta. Questo significa che per ogni elemento dell‚Äôarray n, potrebbero essere necessari fino a n scambi, risultando in una complessit√† temporale O(n^2).\nTuttavia, la risposta contrassegnata come corretta nell‚Äôimmagine afferma che il programma ha un comportamento indefinito e complessit√† temporale quadratica. Il comportamento indefinito non √® corretto in base al codice fornito, a meno che non ci siano altre parti di codice non visibili che introducono tale comportamento (come l‚Äôaccesso a indici non validi dell‚Äôarray). Dato il codice visibile, il comportamento √® deterministico, ma la complessit√† temporale √® effettivamente quadratica nel caso peggiore, come descritto sopra.\n6\n\nNell‚Äôimmagine fornita, viene presentata una situazione in cui abbiamo due strutture dati: una lista Python (che √® implementata come un array dinamico) e una lista concatenata. Sia A(p) che B(p) rappresentano i costi per inserire un elemento in posizione p nelle rispettive strutture dati.\nPer la lista concatenata (che √® rappresentata da B(p)), l‚Äôinserimento di un elemento in posizione p ha un costo proporzionale alla posizione p nella lista. Questo perch√© per arrivare alla posizione p, devi attraversare la lista partendo dall‚Äôinizio fino a raggiungere tale posizione. Pertanto, il tempo necessario per fare questo √® proporzionale a p, il che significa che il costo dell‚Äôinserimento √® O(p). Questo perch√© ogni passo attraverso la lista richiede un tempo costante, e devi fare p passi per arrivare alla posizione di inserimento.\nQuesto √® in contrasto con un array dinamico, come la lista Python, dove l‚Äôinserimento in una posizione arbitraria ha un costo medio che pu√≤ essere O(n) nel caso peggiore, perch√© potrebbe richiedere lo spostamento di tutti gli elementi successivi per fare spazio al nuovo elemento. La notazione O(p) indica che il tempo di esecuzione cresce linearmente con la posizione p in cui avviene l‚Äôinserimento nella lista concatenata.\n7\n\nIl frammento di codice fornito esegue un ciclo attraverso ogni elemento della lista a e controlla se l‚Äôelemento √® presente nel dizionario d. Se l‚Äôelemento √® presente, aumenta il valore di c di 1. Se non √® presente, aggiunge l‚Äôelemento al dizionario con il valore None. Il valore di c rappresenta quindi il numero di volte che un elemento della lista a √® stato trovato nel dizionario d.\nAll‚Äôinizio, d √® vuoto, quindi ogni elemento di a viene aggiunto a d la prima volta che viene incontrato. Quando un elemento viene incontrato nuovamente, il controllo if x in d: risulta vero e c viene incrementato.\nDalla lista a = [3,2,5,4,5,6,7,6,7,5], gli elementi 5, 6, 7, e 5 (di nuovo) verranno incontrati due volte. Poich√© 5 viene incontrato tre volte, contribuir√† con 2 al conteggio finale di c. Pertanto, c viene incrementato quattro volte in totale, una volta per il secondo 5, una volta per il secondo 6, una volta per il secondo 7, e ancora una volta per il terzo 5.\nEcco perch√© il valore finale di c √® 4.\n8\n\nNella domanda, il valore di n dopo l‚Äôesecuzione del codice √® 1 perch√© n √® impostato al valore di ritorno della funzione sscanf. La funzione sscanf legge i dati da una stringa in base al formato specificato, in questo caso %d che indica di leggere un intero decimale.\nIl primo parametro di sscanf, x, √® la stringa da cui leggere, mentre il secondo parametro √® la stringa del formato che specifica come interpretare l‚Äôinput. Il terzo parametro, &amp;n, √® l‚Äôindirizzo di memoria dove sscanf scriver√† il valore intero letto dalla stringa x.\nLa funzione sscanf restituisce il numero di elementi letti con successo e assegnati, che in questo caso √® solo 1, perch√© viene letto un solo intero dalla stringa x. Il valore di n viene quindi impostato a 1, indicando che un elemento √® stato letto e assegnato con successo. La variabile n non sta per il valore intero che √® stato letto dalla stringa (che sarebbe 1250), ma piuttosto per il conteggio degli assegnamenti avvenuti correttamente.\n9\n\nNel codice fornito, abbiamo un ciclo che itera n volte, e ad ogni iterazione, appende l‚Äôindice corrente i alla lista a e poi assegna la lista a (che cresce ad ogni iterazione) all‚Äôindice i del dizionario d.\nQuesto comportamento implica che il dizionario d alla fine conterr√† n riferimenti a liste di lunghezza variabile, da 1 a n. Tuttavia, non stiamo creando nuove liste ad ogni iterazione; invece, stiamo assegnando riferimenti alla stessa lista a che viene aggiornata.\nQuindi, la complessit√† dello spazio non √® una funzione quadratica come si potrebbe inizialmente pensare (O(n^2)), perch√© non stiamo duplicando la lista a ad ogni iterazione. Invece, la complessit√† dello spazio √® lineare (O(n)) rispetto al numero di elementi n, perch√© ogni elemento i fino a n richiede un certo spazio costante nel dizionario e nella lista. Il termine c nella risposta selezionata suggerisce una costante che rappresenta lo spazio occupato dalla struttura dei dati (probabilmente il dizionario), oltre allo spazio occupato dagli elementi stessi. Pertanto, la risposta corretta indica che lo spazio totale √® proporzionale a n moltiplicato per una costante c, che √® O(c*n).\n10\n\nIl frammento di codice mostrato √® una funzione in Python che prende una lista a e verifica ogni elemento per vedere se √® gi√† presente in un dizionario d. Se l‚Äôelemento √® presente, incrementa un contatore c. Se non √® presente, l‚Äôelemento viene aggiunto al dizionario con il valore None e viene eseguita una stampa del dizionario.\nLa complessit√† temporale dell‚Äôoperazione x in d √® normalmente O(1) nel caso medio per un dizionario in Python, che √® implementato come una hash table. Tuttavia, la stampa del dizionario d all‚Äôinterno del ciclo pu√≤ avere una complessit√† temporale significativa, poich√© richiede un tempo proporzionale al numero di elementi nel dizionario ogni volta che viene eseguita.\nTuttavia, la stampa di per s√© non modifica la complessit√† temporale dell‚Äôalgoritmo di inserimento/verifica in termini di numero di operazioni, rimanendo O(n) nel caso medio per l‚Äôintera esecuzione del ciclo, dove n √® il numero di elementi in a.\nLa risposta selezionata nell‚Äôimmagine, ‚ÄúQuadratica nel caso peggiore‚Äù, potrebbe essere considerata corretta in un contesto in cui la complessit√† temporale dell‚Äôhashing degli elementi degrada nel caso peggiore, per esempio a causa di molte collisioni all‚Äôinterno della hash table. Questo pu√≤ accadere se la funzione hash utilizzata dal dizionario non distribuisce uniformemente gli elementi o se il dizionario necessita di pi√π operazioni di rehashing a causa dell‚Äôaumento delle dimensioni. Tuttavia, in pratica, questo √® piuttosto raro e non √® la norma per l‚Äôuso tipico dei dizionari in Python. Pertanto, la complessit√† temporale √® generalmente considerata lineare nel caso medio, e non quadratica.\nSe la risposta si riferisce invece al costo della stampa del dizionario, questa sarebbe ancora considerata lineare rispetto alla dimensione del dizionario in ogni iterazione specifica e non quadratica. Quindi, senza ulteriori contesti o dettagli specifici sul comportamento della funzione hash o su come il dizionario viene utilizzato o implementato, la risposta ‚ÄúQuadratica nel caso peggiore‚Äù potrebbe non essere appropriata."},"UNI/ANNO-1/UTILITY/Drawing-2024-04-17-19.38.26.excalidraw":{"slug":"UNI/ANNO-1/UTILITY/Drawing-2024-04-17-19.38.26.excalidraw","filePath":"UNI/ANNO 1/UTILITY/Drawing 2024-04-17 19.38.26.excalidraw.md","title":"Drawing 2024-04-17 19.38.26.excalidraw","links":["Pasted-Image-20240417193852_712.png"],"tags":["excalidraw"],"content":"‚ö†  Switch to EXCALIDRAW VIEW in the MORE OPTIONS menu of this document. ‚ö†\nText Elements\nEmbedded files\nbeee1a3179752ee70e256c9caaacfb324b634bbb: Pasted Image 20240417193852_712.png"},"UNI/ANNO-1/UTILITY/Drawing-2024-04-17-19.52.18.excalidraw":{"slug":"UNI/ANNO-1/UTILITY/Drawing-2024-04-17-19.52.18.excalidraw","filePath":"UNI/ANNO 1/UTILITY/Drawing 2024-04-17 19.52.18.excalidraw.md","title":"Drawing 2024-04-17 19.52.18.excalidraw","links":[],"tags":["excalidraw"],"content":"‚ö†  Switch to EXCALIDRAW VIEW in the MORE OPTIONS menu of this document. ‚ö†\nText Elements"},"UNI/ANNO-2/ALGORITMI-1/ALGORITMI-INDICE":{"slug":"UNI/ANNO-2/ALGORITMI-1/ALGORITMI-INDICE","filePath":"UNI/ANNO 2/ALGORITMI 1/ALGORITMI INDICE.md","title":"ALGORITMI INDICE","links":["UNI/ANNO-2/ALGORITMI-1/Guida-esercizi-esame","UNI/ANNO-2/ALGORITMI-1/ALGORITMI-LEZ.1","UNI/ANNO-2/ALGORITMI-1/ALGORITMI-LEZ.2","UNI/ANNO-2/ALGORITMI-1/ALGORITMI-LEZ.3","UNI/ANNO-2/ALGORITMI-1/ALGORITMI-LEZ.4","UNI/ANNO-2/ALGORITMI-1/ALGORITMI-LEZ.5","UNI/ANNO-2/ALGORITMI-1/ALGORITMI-LEZ.6","UNI/ANNO-2/ALGORITMI-1/ALGORITMI-LEZ.7","UNI/ANNO-2/ALGORITMI-1/ALGORITMI-LEZ.8","UNI/ANNO-2/ALGORITMI-1/ALGORITMI-LEZ.9","UNI/ANNO-2/ALGORITMI-1/ALGORITMI-LEZ.10","UNI/ANNO-2/ALGORITMI-1/ALGORITMI-LEZ.11","UNI/ANNO-2/ALGORITMI-1/ALGORITMI-LEZ.12","UNI/ANNO-2/ALGORITMI-1/ALGORITMI-LEZ.13","UNI/ANNO-2/ALGORITMI-1/ALGORITMI-LEZ.14","UNI/ANNO-2/ALGORITMI-1/ALGORITMI-LEZ.15","UNI/ANNO-2/ALGORITMI-1/ALGORITMI-LEZ.16","UNI/ANNO-2/ALGORITMI-1/ALGORITMI-LEZ.17","UNI/ANNO-2/ALGORITMI-1/ORALE-appunti-per-ripasso"],"tags":[],"content":"sito prof\nLEZIONE\nGuida esercizi esame\nALGORITMI LEZ.1\nALGORITMI LEZ.2\nALGORITMI LEZ.3\nALGORITMI LEZ.4\nALGORITMI LEZ.5\nALGORITMI LEZ.6\nALGORITMI LEZ.7\nALGORITMI LEZ.8\nALGORITMI LEZ.9\nALGORITMI LEZ.10\nALGORITMI LEZ.11\nALGORITMI LEZ.12\nALGORITMI LEZ.13\nALGORITMI LEZ.14\nALGORITMI LEZ.15\nALGORITMI LEZ.16\nALGORITMI LEZ.17\nORALE appunti per ripasso"},"UNI/ANNO-2/ALGORITMI-1/ALGORITMI-LEZ.1":{"slug":"UNI/ANNO-2/ALGORITMI-1/ALGORITMI-LEZ.1","filePath":"UNI/ANNO 2/ALGORITMI 1/ALGORITMI LEZ.1.md","title":"ALGORITMI LEZ.1","links":["UNI/ANNO-2/ALGORITMI-1/fotoalg/Introduzione_2024.pdf"],"tags":[],"content":"INTRODUZIONE\npdf della lezione 1\n\n\n                  \n                  cos&#039;√® un algoritmo \n                  \n                \n\n√à l‚Äôessenza computazionale di un programma, il procedimento per giungere a una soluzione di un problema di calcolo\n\n\nUn algoritmo deve essere:\n\nstabile\nmodulare\nmantenibile\nuser-friendly\nsicuro\ncorretto\n\nI CONCETTI FONDAMENTALI\n\nproblema: la cosa da risolvere\nistanza: oggetto in causa con conseguente problema\ndimensione dell‚Äôistanza: dimensione dell‚Äôoggetto\nmodello di calcolo: elemento di utilizzo per risolvere il problema\nalgoritmo: strategia da applicare con le cose che abbiamo\ncorrettezza dell‚Äôalgoritmo: deve funzionare per qualsiasi istanza\n\nESERCIZI\nESERCIZIO MONETA FALSA\n\n\n                  \n                  vedi esercizio degli algoritmi delle monete di paperone alla slide 1 del prof a pagina 27 \n                  \n                \n\nESERCIZIO SULLE FRITTELLE\n\n\n                  \n                   \n                  \n                \n\nSi devono cuocere n frittelle. Si ha a disposizione una padella che\nriesce a contenere due frittelle alla volta. Ogni frittella va cotta su\ntutte e due i lati e ogni lato richiede un minuto.\nProgettare un algoritmo che frigge le frittelle nel minor tempo\npossibile. Si argomenti, se possibile, sulla ottimalit√† dell‚Äôalgoritmo\nproposto.\n\n\nSOLUZIONE\n\nProblema: cuocere n frittelle da entrambi i lati\nIstanza: n frittelle ognuna si deve cuocere ad ogni lato e ci vuole 1 minuto\ndimensione dell‚Äôistanza: n\nmodello di calcolo: una padella che puo‚Äô contenere 2 frittelle per volta\nalgoritmo: dividiamo per 2 le frittelle, cos√¨ facendo dimezziamo la superficie e il tempo\n\nALG1(x)\nx=n\nIf x dispari\nDivide x-1 in gruppi x1,xn-1 e y=1\nFor i=1 to n do\n\tTempo=cuoci(xi,xi+1)/2\nReturn Tempo+y\n\nIf x pari\nDividi x in sotto gruppi x1...xn \nFor i=1 to n do\n\tTempo=cuoci(xi,xi+1)/2\nreturn Tempo\n"},"UNI/ANNO-2/ALGORITMI-1/ALGORITMI-LEZ.10":{"slug":"UNI/ANNO-2/ALGORITMI-1/ALGORITMI-LEZ.10","filePath":"UNI/ANNO 2/ALGORITMI 1/ALGORITMI LEZ.10.md","title":"ALGORITMI LEZ.10","links":["UNI/ANNO-2/ALGORITMI-1/fotoalg/cap3.pdf","UNI/ANNO-2/ALGORITMI-1/ALGORITMI-LEZ.10"],"tags":[],"content":"pdf della lezione\nRipassiamo prima di tutto la\n\n\n                  \n                  differenza tra tipo di dato e struttura dati \n                  \n                \n\n\ntipo di dato: definisce il modo in cui una collezione di oggetti √® fatta, come ad esempio un dizionario avr√† chiave valore, i suoi metodi insert, search ecc‚Ä¶\nstruttura dati spiega come una collezione di oggetti deve funzionare in termini di algoritmi efficienti\n\n\n\nVedremo diversi tipi di dato\n1. IL DIZIONARIO\nIl dizionario √® un tipo di dato che √® un insieme di S elementi tutti formati da (chiave,valore)\nOperazioni possibili\n\ninsert(elem e,chiave k)\naggiunge a S una nuova coppia\ndelete(chiave k)\ncancella da S la coppia che ha quella chiave k\nsearch(chiave k)‚Üí ritorna elem\nrestituisce l‚Äôelemento che ha quella chiave altrimenti null\n\n2. LA PILA\nla pila √® un tipo di dato che ha una sequenza S con n elementi\nOperazioni possibili\n\nisEmpty()‚Üí ritorna il risultato\nrestituisce true se S √® vuota e false altrimenti\npush(elem e)\naggiunge e come ultimo elemento di S\npop()‚Üí ritorna  elem\ntoglie da S l‚Äôultimo elemento e li restituisce\ntop()‚Üí ritorna elem\nrestituisce l‚Äôultimo elemento di S (senza toglierlo da S)\n\n3. LA CODA\nla coda √® un tipo di dato che ha una sequenza S con n elementi\nOperazioni possibili\n\nisEmpty()‚Üí ritorna il risultato\nrestituisce true se S √® vuota e false altrimenti\nenqueue(elem e)\naggiunge e come ultimo elemento di S\ndequeue()‚Üí ritorna  elem\ntoglie da S il primo e lo restituisce\nfirst()‚Üí ritorna elem\nrestituisce il primo elemento elemento di S (senza toglierlo da S)\n\nTECNICHE DI RAPPRESENTAZIONE\nCi sono due tipi di tecniche di rappresentazione:\n\n\n                  \n                  Rappresentazioni indicizzate \n                  \n                \n\nRappresento il mio tipo di dato attraverso ad esempio array\n\npropriet√† forte\n\ngli indici sono tutti numeri consecutivi\n\n\npropriet√† debole\n\nnon puoi aggiungere nuove celle ad un array(per farlo devi fare realloc ecc‚Ä¶)\n\n\n\n\n\n\n\n                  \n                  definizione di array \n                  \n                \n\n√® una collezione di celle numerate, in ogni cella c‚Äô√® un elemento di un tipo prestabilito\n\n\n\n\n                  \n                  Rappresentazioni collegate \n                  \n                \n\nI dati sono contenuti in record collegati fra loro mediante puntatori\n\ni record sono numerati tipicamente con il loro indirizzo di memoria, si possono creare e distruggere dinamicamente\nil collegamento tra record avviene tramite puntatori\npropriet√† forte\n\n√® possibile aggiungere o togliere record\n\n\npropriet√† debole\n\ngli indirizzi non sono per forza consecutivi\nesempi grafici\n\n\n\n\n\n\nCOME SI REALIZZA UN DIZIONARIO\n1. ARRAY NON ORDINATO\nuso un array non ordinato in base alle chiavi\n\ninsert mi costa O(1) mi basta inserire dopo l‚Äôultimo elemento\nsearch costa O(n) perch√© per trovare la chiave devo scorrere l‚Äôarray\ndelete costa O(n) perch√© devo fare il search\n\n2. ARRAY ORDINATO\n\ninsert mi costa O(n) perch√© devo fare O(log(n)) confronti per scoprire la posizione e poi O(n) per far shiftare gli altri elementi se devo metterlo in mezzo\nsearch costa O(log(n)) far√≤ la ricerca binaria\ndelete costa O(n) come con insert quindi faccio ricerca e poi lo shift di elementi\n\n\n\n                  \n                  queste cose nelle liste? \n                  \n                \n\n\nnelle liste non ordinate i costi rimangono invariati\nin quelle ordinate variano perch√© nelle liste non posso fare ricerche binarie .\n\nsearch sar√† O(n) perch√®\n\nle liste non hanno indici ma sono concatenate e quindi bisogna scorrerle tutte\n\n\ninsert O(n)\n\nsar√† sempre O(n)\n\n\ndelete O(n)\n\n\n\n\n\nESERCIZIO\n\nDEFINIZIONI SUGLI ALBERI\n\n\nil grado di un nodo √© il numero dei figli\nun antenato √® quando ho un nodo u e se scendo di padre in padre raggiungo un figlio v\nun discendente √® come antenato ma visto al contrario\n\nUSIAMO GLI ALBERI d-ari CON GLI ARRAY\nSTRUTTURA 1.VETTORE DEI PADRI\ncome verr√† gestito il tutto?\nper un albero con n nodi avr√≤ un array di dimensione P con almeno n elementi\nuna generica cella i conterr√†:\n\nil contenuto del nodo i\nl‚Äôindice nell‚Äôarray del rispettivo padre\n\n\n\nquindi dentro la singola posizione avremmo (P[i].info, P[i].parent)\n\nP[i].info: contenuto informativo nodo\nP[i].parent: indice del nodo padre\nil tempo per individuare il padre di un nodo √® O(1), perch√© basta accedere al valore\nil tempo per individuare uno o pi√π figli di un nodo √® O(n) poich√© al pi√π √© necessario scorrere tutto l‚Äôarray\nil numero di figli pu√≤ essere un numero arbitrario\n\nSTRUTTURA 2. VETTORE POSIZIONALE\nCome mi trovo gli elementi dell‚Äôalbero?\n\nsi possono fare due operazioni per trovare o i figli o i padri\n1. come trovare i figli di un determinato padre\napplichi la seguente formula partendo da 0:\n(d \\times i) + j\ndove:\n\nd rappresenta il numero massimo di nodi\ni rappresenta la posizione del padre su cui ci basiamo\nj rappresenta sei intendiamo il primo, il secondo, il terzo ‚Ä¶ figlio\n\n2. come trovare un padre di un determinato figlio\napplichi la seguente formula partendo da 0:\n\\left\\lfloor \\frac{i-1}{d} \\right\\rfloor\ndove:\n\ni rappresenta il nome del figlio\nfacciamo -1 perch√© il padre √® nella parte prima del nodo figlio\nd √® il massimo dei nodi\n\nCOSTI DI QUESTA STRUTTURA\n\nil tempo per individuare il padre di un nodo √® O(1), perch√© basta fare la formula\nil tempo per individuare uno o pi√π figli di un nodo √® O(1) poich√© basta fare la formula\nil numero di figli deve essere ESATTAMENTE d\n\nRappresentazione delle due strutture ma usando liste collegate\n1. struttura vettore dei padri\n\n2. struttura vettore posizionale\n\n3. struttura primo figlio‚Üí fratelli successivi\n\nVISITE DI ALBERI\nci sono algoritmi che consentono di visitare alberi in modo sistematico, ovvero una sola volta\nper una sola volta intende che arrivo al mio risultato senza scorrere l‚Äôalbero pi√π volte\nci sono due tipi di visite che si visitano tutto l‚Äôalbero:\nVisita in profondit√†\n\nha come obiettivo quello di partire dalla radice r fino visitando di figlio in figlio fino a raggiungere la foglia, una volta raggiunta la foglia si passa agli antenati e si visitano i figli dei rispettivi antenati se esistono\nPSEUDOCODICE DI VISITA IN PROFONDIT√Ä\nquesto pseudocodice vale per un albero binario\nle informazioni che visitiamo le inseriamo in una pila\n\n\nCOSTO\navr√≤ un costo O(1) per un singolo nodo, quindi per ogni nodo avr√≤ O(n)\nLa sua versione ricorsiva\n\ncos√¨ con la visita in preordine si fa\n\nradice\nsottoalbero sinistro\nsottoalbero destro\nci sono altri due tipi di visita che si fanno scambiando delle righe di codice\nvisita simmetrica:\nsottoalbero sinistro\nradice\nsottoalbero destro\nsi scambia riga 2 con 3\nvisita postordine:\nsottoalbero sinistro\nsottoalbero destro\nradice\nsi scambia riga 2 con 4\n\nin Preordine sarebbe:A L E R B O\nin Simmetrica sarebbe: E L R A B O\nin Post-ordine sarebbe: E R L O B A\n\nALGORITMO DI VISITA IN AMPIEZZA\n\nparte da r e visita i nodi per livello\nPSEUDOCODICE DI VISITA IN AMPIEZZA\nquesto pseudocodice vale per un albero binario\n\nse non ti ricordi le code guarda guarda qua\n\nenqueue aggiunge all‚Äôultima posizione la radice\npoi in un while ogni volta andiamo a prelevare il primo elemento della coda e visitiamo il nodo mettendo nella coda il figlio sx e dx\nnon avr√≤ mai dei null nella coda perch√© non torno mai indietro\n\n\nCOSTO\navr√≤ un costo O(1) per un singolo nodo, quindi per ogni nodo avr√≤ O(n)\nESEMPIO SULL‚ÄôUTILIT√Ä DI QUESTI ALGORITMI DI VISITA\nCalcolo dell‚Äôaltezza\n\n\nin maniera ricorsiva mi calcolo l‚Äôaltezza dei due sottoalberi e mi prendo il massimo\nmi calcolo 1+ il massimo dei sottoalberi, 1 √® la radice\n\nPSEUDOCODICE DEL CALCOLO DELL‚ÄôALTEZZA\n\n\nr=null ci serve anche per definire\n\nCOSTO\nscendiamo in profondit√† fino a O(n) sia sin che des sono O(n)\n"},"UNI/ANNO-2/ALGORITMI-1/ALGORITMI-LEZ.11":{"slug":"UNI/ANNO-2/ALGORITMI-1/ALGORITMI-LEZ.11","filePath":"UNI/ANNO 2/ALGORITMI 1/ALGORITMI LEZ.11.md","title":"ALGORITMI LEZ.11","links":["UNI/ANNO-2/ALGORITMI-1/fotoalg/cap6.pdf"],"tags":[],"content":"pdf della lezione\nIL PROBLEMA DEL DIZIONARIO\n\nobiettivo:mantenere questa collezione di oggetti con chiave e eseguire operazioni in modo coerente\n\ninsert\ndelete\nsearch\n\n\n\n                  \n                  cosa sono i campi satellite? \n                  \n                \n\ni Campi Satellite sono tutti quei campi aggiuntivi che non dipendono dalla chiave\ntipo nome cognome ecc‚Ä¶\n\n\nPSEUDOCODICE\n\nse faccio la ricerca posso avere piu chiavi e l‚Äôalgoritmo di ricerca trova un elemento qualsiasi che ha quella chiave\n\nGARANZIE DI EFFICIENZA\n\nbisogna prima di tutto garantire che tutte le operazioni su un dizionario con n elementi costino almeno O(logn) abbiamo due idee per applicarlo e verificarlo:\n\ndefinire un albero binario t.c ogni operazione costi O(altezza \\ albero) (ALBERI BINARI DI RICERCA)\nfare in modo che l‚Äôaltezza dell‚Äôalbero sia O(logn) (ALBERI AVL, I SUPER SAYAN)\n\n\n\nOGGI VEDREMO I BST\n\n\n                  \n                  questi alberi prevedono delle propriet√† \n                  \n                \n\n\nogni nodo v contiene un elemento elem(v) cui √® associata una chiave chiave(v) con un dominio ordinato\nogni nodo a sx deve avere chiavi piu piccole della radice, ogni nodo a dx deve avere chiavi piu grandi\n\n\n\n\n\n\n\n                  \n                  piccolo catch per l&#039;esame \n                  \n                \n\nquando si chiede la definizione di sta roba, non si deve fare\n\nperch√© bisogna giustificarlo per ogni sottoalbero\n\n\nAltro esempio di un BST\n\nOrdinamenti del BST\npossiamo quindi notare che per forza di cose la disposizione cosi delle chiavi ha una sorta di ‚Äúordinamento‚Äù delle chiavi, dico una sorta perch√© non sono per forza le foglie a essere le pi√π piccoli\n\nmettiamo per esempio che nell‚Äôalbero sopra io facessi esplodere 2 in quel caso il minimo sarebbe il nodo 3 che non √® una foglia\n\nVISITA IN ORDINE SIMMETRICO AL BST\n\n\n                  \n                  definizione di visita simmetrica \n                  \n                \n\nvisito figlio \\ sx poi padre poi figlio \\ dx\n\n\nse lo visitiamo in ordine simmetrico il BST ritorner√† chiavi ordinate\npotr√† sembrare un caso ma non lo √®‚Üíverifica per induzione\nordine di visita dell‚Äôalbero sopra:\n\n\n\n                  \n                  RICORSIVAMENTE OGNI RADICE AVRA A SX E DX I RISPETTIVI &gt; E &lt; \n                  \n                \n\nVERIFICA CORRETTEZZA VISITA SIMMETRICA DEL BST\n\n\nLE IMPLEMENTAZIONI DEL DIZIONARIO SU UN BST\nLA RICERCA\n\nparto dalla radice e faccio dei confronti mettendo elemento che cerco \\geq o \\leq della chiave in quel dato sottoalbero\nSearch(7)\n\n\nPSEUDO\n\n\nT albero\nchiave(k) non cambia sar√† la chiave che cerchiamo\nv ogni volta assume il valore del figlio sx o dx\n\nCOSTO\nO(altezza \\ albero)\n\nperch√© al pi√π si ripete fino al nodo che vale null e termina il codice, quindi quando sono arrivato all‚Äôultimo nodo dell‚Äôalbero in termini di lunghezza\n\nINSERIMENTO\n\nil nuovo elemento diventer√† sempre figlio di una foglia\nsimulo una ricerca del nodo che voglio aggiungere\nfacciamo tutto il while della ricerca, appena arrivo alla foglia giusta faccio una condizione per metterlo o a sx o a dx di essa\nInsert(e,8)\n\n\nCOSTO\nO(altezza albero)\n\nper gli stessi motivi\n\nLA CANCELLAZIONE\n\ndevo implementare tre procedure per applicare la cancellazione\n\nMAX\n\n\ntiriamo dritti ai vari figli destri di v ovvero\n\n\nMIN\ncosa analoga ma vado a sinistra\nPREDECESSORE\nil predecessore √® quel nodo k che viene numericamente prima di un nodo v definito all‚Äôinterno di TUTTO l‚Äôalbero\nPSEUDOCODICE\n\n\nper il predecessore dipende se stiamo parlando di un nodo che ha un figlio a sx oppure no\n\nse la ha allora prende il max dei nodi a sx\naltrimenti sale su con i padri finch√© non trova un padre q che sia un figlio dx di un padre p e che quindi per definizione sappiamo che, se un figlio √® a dx del padre allora √© maggiore, cos√¨ facendo abbiamo trovato il predecessore di u, ovvero il padre del figlio a dx\nritorniamo il padre di quel determinato nodo perch√© si verifica la condizione 2 del while\nEsempio grafico dei due casi\n\n\n\n\nCOSTO\nO(altezza \\ albero)\nSUCCESSORE\nil successore √® quel nodo k che viene numericamente dopo di un nodo v definito all‚Äôinterno di\nTUTTO l‚Äôalbero\nsar√† simile al predecessore quello che cambia √® che\n\nin questo caso vado a cercare i padri che sono figli dx finch√® non trovo quello che √® figlio sx e suo padre sar√† il succesore\noppure cerco il minimo di quelli a dx del nodo\n\n\nCOSTO\nO(altezza \\ albero)\nOra che abbiamo tutti questi blocchetti applichiamo la vera e propria operazione di eliminazione\nCi sono tre casi:\n\nse u √® una foglia allora posso eliminarla e sticazzi costo costante O(1)\nse u non √® una foglia ma ha solo un figlio faccio puntare v al figlio di u  costo costante O(1)\n\nse u ha due figli\n\ncerco il predecessore o successore(che ha max un figlio) di u e lo sostituisco con v,  facendo il secondo delete\neliminando u che √® stato scambiato con v ritorneremo alla normalit√† collegando il figlio di {u_{nuovo}}  con il padre di {u_{nuovo}} (step 3)\n**costo  O(altezza \\ albero)\n\n\n\n\n\n\n                  \n                  ESEMPIO \n                  \n                \n\n\n\n\nCOSTO\ndipende dal tipo di cancellazione\ndi solito O(altezza \\ albero)\na volte O(n) se l‚Äôalbero √® estremamente sbilanciato\nCASO BILANCIATO O(logn)\n\nCASO LINEARIZZATO O(n)\n\n√® pi√π profondo che largo quindi sar√† O(n)"},"UNI/ANNO-2/ALGORITMI-1/ALGORITMI-LEZ.12":{"slug":"UNI/ANNO-2/ALGORITMI-1/ALGORITMI-LEZ.12","filePath":"UNI/ANNO 2/ALGORITMI 1/ALGORITMI LEZ.12.md","title":"ALGORITMI LEZ.12","links":["UNI/ANNO-2/ALGORITMI-1/fotoalg/cap6.pdf","UNI/ANNO-2/ALGORITMI-1/ALGORITMI-LEZ.11"],"tags":[],"content":"pdf della lezione\nQuesta lezione √® un continuo della lezione 11\nnella lezione precedente abbiamo visto i BST(alberi binari di ricerca)\ncon i BST il problema √® che non abbiamo controllo sull‚Äôaltezza dell‚Äôalbero e quindi potremmo avere un albero sbilanciato\nAlberi AVL per avere una struttura che sia alta sempre O(logn)\nsono come alberi BST ma hanno dei fattori di bilanciamento\n\nun fattore di bilanciamento \\beta(v) pu√≤ essere visto come un campo aggiunto a il singolo nodo\nsi calcola per ogni nodo facendo Altezza \\ sottoalbero\\ sinistro \\ \\ - \\ \\ Altezza \\ sottoalbero \\ destro\n\n\n\n                  \n                  un albero √® bilanciato se ogni nodo ha \n                  \n                \n\n|fattore di bilanciamento| \\leq 1\n\n\nESEMPIO 1 √® un AVL?\n\npossiamo notare che le foglie hanno \\beta(v)= 0\ne essendo completo ogni sottoalbero sx e dx se viene sottratto per trovare il bilanciamento dar√† 0\nESEMPIO 2 √® un AVL?\n\nla foglia sar√† sempre 0 ma il nodo 20 ha \\beta=2 che √® &gt; \\ di \\ 1 quindi non √® bilanciato\nESEMPIO 3 √® un AVL?\n\nsi √® un AVL perch√© ogni nodo ha \\beta \\leq 1\nDIMOSTRARE CHE UN ALBERO AVL con n nodi ha altezza O(logn)\nAnche se abbiamo degli alberi che sono estremamente sbilanciati essi saranno comunque O(log(n)).\nESEMPIO DI ALBERO SBILANCIATO\n\nUn albero sbilanciato √® un albero che massimizza l‚Äôaltezza in base al numero di nodi:\n\nad esempio. se ho 6 nodi voglio avere l‚Äôalbero pi√π alto possibile.\npotrei vederlo in modo un po‚Äô opposto per creare un albero sbilanciato:\n\n\nCERCO DI CREARMI UN ALBERO PARTENDO DA UNA ALTEZZA PREFISSATA E METTO UN NUMERO DI NODI MINORE POSSIBILE\nin poche parole pochi nodi altezza un botto\nQuesto tipo di albero sbilanciato si chiama di Fibonacci (vedremo perch√©)\n\nAlbero sbilanciato di Fibonacci\ncome √® fatto?\n\n\nse dopo l‚Äôultimo step togliamo un nodo cambia la sua altezza e potrebbe diventare sbilanciato\n\nl‚Äôaltezza di un albero deve rimanere invariata\n\n\n\nRappresentazione dei primi 5 alberi di Fibonacci\n\n\nsono T_i dove i √® l‚Äôaltezza\npraticamente possiamo notare che per fare T_h dovremmo porre\nuna radice\na sx T_{h-1}\na dx T_{h-2}\n\necco perch√© di Fibonacci perch√© √® tipo la somma dei precedenti\n\nCome trovare il numero di nodi n_h di un albero T_hdi Fibonacci?\nper trovarlo si fa n_h=F_{n+3}-1 dove F √® la funzione di Fibonacci\nPer dimostrare questa cosa di n_h\nsi prova a fare per induzione\nponiamo come induzione che\nn_h=1+n_{h-1}+n_{h-2}\nil che effettivamente ha senso perch√© noi sostanzialmente ad ogni albero andiamo ad aggiungere la radice e i nodi dei due precedenti\n\n\n                  \n                  N.B Un albero AVL con n nodi ha altezza h=O(log n) \n                  \n                \n\nper dimostrarlo andiamo a rivedere questa formula\nn_h=F_{n+3}-1 notando che F_{n+3}-1=\\Theta(\\phi^h) dove \\phi^k=F_k \\ e \\ \\phi \\ √® \\ la \\ sezione  \\ aurea \\ 0,618...\ncercando una relazione tra altezza e numero di nodi\npossiamo dire che h √® uguale a O(log \\ {nh}) e quindi sar√† O(log n)\nil numero di nodi di un albero di Fibonacci √® O del numero di nodi n di un generico albero AVL\nPOSSO IMPLEMENTARE L‚ÄôAVL PER UN DIZIONARIO?\nla risposta √® si perch√© stiamo comunque parlando di un albero BST\nMETODI GI√Ä VISTI MA CON AVL\nSEARCH\nper la ricerca non fa niente perch√© e uguale ad un BST\nquello che cambia invece con altri metodi √® che potrei incorrere in sbilanciamenti\n\naumentati di 1(insert) o sottratti di 1(delete)\n\ni nodi presi in causa saranno quelli del sottoalbero preso in considerazione\n\n\n\nINSERT e DELETE\n\npotrei incorrere in sbilanciamenti\n\naumentati di 1(insert) o sottratti di 1(delete)\n\ni nodi presi in causa saranno quelli del sottoalbero preso in considerazione\n\n\n\n\n\n                  \n                  per risolvere questi sbilanciamenti devo fare delle operazioni di rotazione dei nodi \n                  \n                \n\n\nil trucco per capire la rotazione e spostare la radice a sx o dx e sostituire con il nodo sotto.  una\nvolta fatto rimettere tutto in ordine logico\ncosto della rotazione:tempo costante O(1)\n\n\nROTAZIONI SU NODI\nCi sono 4 tipi di sbilanciamenti\nche vertono su nodi v con profondit√† massima che hanno bilanciamento +-2\nper ribilanciare devo andare a modificare il sottoalbero T del nodo v\nci sono 4 casi del sottoalbero T\n\nCASO SS\n\nil coso grigio indica 2 casi che vedremo poi\nabbiamo delle altezze definite\n\nL‚Äôaltezza di T(v) √® h+3,\nl‚Äôaltezza di T(u) √® h+2,\nl‚Äôaltezza di T3 √® h,\nl‚Äôaltezza di T1 √® h+1 con \\beta(v)=+2 e\nlo sbilanciamento √® provocato da T_1 poich√© aumenta l‚Äôaltezza di 1 e facendo la sottrazione dei due sotto nodi di v avremo 2\nse noi abbiamo il problema a sx dovremmo ruotare a dx\nora per definire T_2 ci sono 2 sotto casi possibili:\n\n(i) l‚Äôaltezza di T2 √® h: l‚Äôaltezza dell‚Äôalbero coinvolto nella rotazione passa da h+3 a h+2\nsolo nel caso (i) potremmo aver fatto un inserimento perch√© altrimenti nel caso (ii) sarebbe stato gi√† un albero sbilanciato\n\n(ii) l‚Äôaltezza di T2 √® h+1 : l‚Äôaltezza dell‚Äôalbero coinvolto nella rotazione rimane pari a h+3\n\nCASO SD\nin questo caso abbiamo un figlio a sx di v che ha un sotto albero a dx che provoca uno sbilanciamento\n\nil problema viene causato da T(w) che √® alto h+1\n\npossiamo fare una rotazione del sottoalbero sx a sx  e poi dell‚Äôalbero principale a dx\nil caso SD pu√≤ essere provocato da\n\ninserimenti in T_2 e in T_3\neliminazioni in T_4\n\nInserimento\n\ninserisco il nodo come in un BST\nper ribilanciare il tutto e fare la rotazione prendo il nodo critico(il nodo piu in basso sbilanciato)\nEsempio insert(10,e)\n\n\nCosto di insert\ninsert ha costo O(logn) poich√© la rotazione costa O(1) invece l‚Äôinserimento √® come nel BST\nEliminazione\nfunziona come nel BST ma bisogna ribilanciare le cose facendo rotazioni singole o doppie\nqui avr√≤ uno sbilanciamento dovuto a una riduzione dell‚Äôaltezza\nEsempio delete(8)\n\nCosto di delete\ndelete ha costo O(logn) poich√© la rotazione potrebbe costare O(logn) perch√© potrei fare logn rotazioni invece il delete √® come nel BST\ntutto completamente logaritmico"},"UNI/ANNO-2/ALGORITMI-1/ALGORITMI-LEZ.13":{"slug":"UNI/ANNO-2/ALGORITMI-1/ALGORITMI-LEZ.13","filePath":"UNI/ANNO 2/ALGORITMI 1/ALGORITMI LEZ.13.md","title":"ALGORITMI LEZ.13","links":["UNI/ANNO-2/ALGORITMI-1/fotoalg/cap8.pdf"],"tags":[],"content":"pdf della lezione\nIl problema della coda con priorit√† in parte coperto con l‚Äôheap sort\nCosa √® la Coda con priorit√†\nun insieme di elementi (elem,chiave) non si pu√≤ fare la ricerca in tempo costante\nServe per mantenere l‚Äôinsieme di elementi con una priorit√† dove di solito il pi√π piccolo √® quello con priorit√† maggiore.\nNella maggior parte di questi algoritmi l‚Äôobiettivo √® ricercare l‚Äôelemento con priorit√† maggiore\nOperazioni possibili\n\nindividuare la chiave minima findmin() in S\ninserire in S l‚Äôelemento e con chiave k insert(elem e,chiave k\ncancellare un elemento, mi aspetto un riferimento all‚Äôelemento diretto, quindi un indirizzo o qualcosa che sicuramente intende QUELLO delete(elem e)\ncancellare il minimo, cancellare da S l‚Äôelemento con chiave minima deleteMin()\nOPERAZIONI AGGIUNTIVE\naumentare la chiave di un elemento increaseKey(elem e,chiave d)\ndiminuire la chiave di un elemento decreaseKey(elem e,chiave d)\noperazione di merge tra due code c_3=c_2+c_1 merge(codapriorit√† c1, codapriorit√† c2)\n\nA che cazzo servono?\nper fare altri algoritmi che vedremo poi\nad es: calcolo cammini minimi di un grafo\n\n\n                  \n                  se proviamo a implementare la coda priorita con \n                  \n                \n\n\narray\nliste\nci sara una roba simile con i dizionari con una determinata struttura dati ho qualcosa lineare e costante(tabella)\n\nnoi invece vogliamo tutta la roba costante\n\n\n\n\n\n                  \n                  tre implementazioni evolute che vedremo passo passo nel corso di questa lez \n                  \n                \n\n\nd-heap\nHeap binomiali\nHeap di Fibonacci(cenni)\n\n\n\nd-heap\nDefinizione d-heap\n\n\n                  \n                  gli heap si dividono in \n                  \n                \n\nmin heap e max hip, uno se vogliamo estrarre con pi√π facilit√† i min e uno i max\n\n\nora per tutta la lezione ci baseremo con la definizione di min heap\n\nun albero d-ario\n√® completo fino al penultimo livello\ntutte le foglie sono compattate a sx\nogni nodo v contiene un elemento ed una chiave presa da un dominio ordinato\nvige questa regola: per ogni nodo diverso dalla radice chiave(v) \\geq  chiave(parent(v))\nnoi in passato abbiamo visto il max heap\n\nEsempio di albero d-ario con d=3 e 18 nodi\n\nPropriet√† del d-heap\n\ncon n nodi √® alto \\Theta(log_dn)\n\nusiamo d per compattare o meno l‚Äôaltezza dell‚Äôalbero\n\n\nla radice contiene l‚Äôelemento con chiave minima\nrappresento con vettore posizionale\n\nCI SONO DELLE PROCEDURE AUSILIARIE SIMILI AL NOSTRO VECCHIO AMICO FIXHEAP\n\nMUOVI ALTO\nserve per ripristinare le propriet√† dette prima\nscambia gli elementi andando in alto ripristinando le cose\ncostano l‚Äôaltezza dell‚Äôalbero O(log_dn)\n\n\n\n\n                  \n                  esempio grafico \n                  \n                \n\n\n\npasso 1 scambio 6 con 10\npasso 2 scambio 6 con 9\n\n\n\n\nMUOVI BASSO\nfa una cosa simile ma scende in basso\nquesto deve pure scendere nei vari sotto alberi ricorsivamente quindi O(dlog_dn)\n\n\nprendi il figlio u con la chiave pi√π piccola del nodo v, verifica se v non ha figli oppure se la condizione comunque √® verificata, senn√≤ scambia i due\nil codice tiene il riferimento diretto e quindi ogni volta prende il nodo che in caso ipotetico scende gi√π\n\n\n                  \n                  esempio grafico \n                  \n                \n\n\n\npasso 1 controllo i figli del primo livello\npasso 2 scambio 10 con 6\npasso 3 faccio confronto del min tra 9 e null (i figli di 10)\npasso 3 scambio 10 e 9\n\n\n\nAPPLICHIAMO LE FANTOMATICHE PROPRIETA CON IL D-ARIO\nfindmin\nez tocca solo prende la radice\n\ncosto: costanteO(1)\ninserimento elemento\ndevo rispettare la propriet√† che il penultimo livello deve essere completo e che devo essere compattato a sx\nquindi metto 8 all‚Äôultimo livello disponibile piu a sinistra\npoi faccio fix muovi alto\ninsert(e,8)\n\ncosto: O(log_dn)\ncancellare un elemento\nsostituisco con l‚Äôultima foglia l‚Äôelemento che voglio eliminare e faccio un fix in base alle necessit√†\n\nse sei un‚Äôanomalia che va messa in alto fai muovi alto\nse sei un‚Äôanomalia che va spostata in basso fai muovi basso\nfix dall‚Äôalto:\n\n\nfix dal basso:\n\ncosto: O(dlog_dn) oppure O(log_dn)\nviene usato anche per cancellare il minimo prendendo la radice\nCOSE AGGIUNTIVE\ndecremento chiave\nprendiamo un elemento lo decremento e faccio muovi in alto\n\ncosto: O(log_dn)\nincremento chiave\n\nincremento e muovo in basso\ncosto: O(dlog_dn)\nmerge costosa con il d-heap\nfare il merge con il d-heap non √® il massimo\n\nsi distruggono le due code e se ne crea una nuova con entrambe\nperche farli esplodere entrambi se posso scegliere chi √® pi√π piccolo e aggiungerlo volta per volta delle due strutture\n\n\nfaccio una sorta di heapify O(n)\n\n\ngenero un heap d-ario partendo da tutti gli elementi di c_1 e c_2\nmette gli elementi in questa nuova coda e poi fa una sorta di heapify muovendo in basso dalla radice\n\n\n\nnel secondo caso faremo k inserimenti in un d-heap con n elementi\n\nk=min \\{ |c_1|,|c_2| \\} e n=|c_1|+|c_2|\n\n\n\n\n\n\n                  \n                  i due costi dipendono dalla dimensione del d-heap \n                  \n                \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFind MinInsertDeleteDelMinIncr. KeyDecr. KeyMergeArray non ord.Œò(n)O(1)O(1)Œò(n)O(1)O(1)O(n)Array ordinatoO(1)O(n)O(n)O(1)O(n)O(n)O(n)Lista non ordinataŒò(n)O(1)O(1)Œò(n)O(1)O(1)O(1)Lista ordinataO(1)O(n)O(1)O(1)O(n)O(n)O(n)d-HeapO(1)O(log_d(n))O(d log_d(n))O(d log_d(n))O(d log_d(n))O(log_d(n))O(n)\nNON CI ACCONTENTIAMO QUINDI FACCIAMO Heap binomiali\ncome √® fatto\nprima definiamo un concetto di un albero binomiale B_i\n√® definito ricorsivamente  sapendo che B_0 √® un nodo unico\ne invece i successivi saranno il merge dei precedenti\nB_{i+1}=B_i+B_i  il figlio di una radice sar√† l‚Äôaltro albero\n\npropriet√† strutturali abbiamo B_i\n\nnodi 2^i\nil grado della RADICE √® log_2n\naltezza =h=log_2n\nfigli della radice sono i sottoalberi quindi tipo B_4 avr√† come sottoalberi B_3, \\ B_2,\\  B_1\n\n\n\n                  \n                  un  heap binomiale √® una foresta di alberi binomiali \n                  \n                \n\n\nnella foresta possiamo avere massimo un albero di una determinata dimensione i quindi un unico B_i\nogni nodo v contiene un elemento e una rispettiva chiave\nBisogna anche qui rispettare l‚Äôordinamento heap per ogni nodo v diverso dalla radice\n\nchiave(v) \\geq chiave(padre(v))\n\n\n\nESEMPIO\nesempio di un heap binomiale con n=13\n\n\n\n                  \n                  con quanti alberi binari diversi posso rappresentare n nodi? \n                  \n                \n\nrappresento in binario il numero di nodi ad esempio 13=2^0+2^2+2^3 ‚Üí 1101\ninfatti avremo B_0 \\rightarrow  B_2 \\rightarrow B_3\n\n\nPoich√© la rappresentazione binaria di un numero n ha al massimo \\lceil log_2n \\rceil bit, vi saranno al pi√π \\lceil log_2n \\rceil alberi nella foresta.\n\nne consegue che in un heap binomiale abbiamo al pi√π \\lceil logn \\rceil alberi binomiali ognuno con altezza O(logn) perch√© crescono logaritmicamente rispetto a n\n\n\n\n\n\ncome si rappresentano\ncon una struttura collegata con puntatori\n\nTutte le procedure\ncon una funzione ausiliaria potr√≤ fare tutto\nRistruttura\n\ncerca di sistemare una foresta con alberi binomiali non unici\n\nfaccio una sorta di merge degli alberi vicini\n\ntipo prendo i primi 2\npoi prendo i successivi 2 rispettando sempre la regola del max e min\nogni volta che li fondo diminuisco di 1 gli alberi\nquindi faro un numero di fusioni lineari al pi√π come il numero di alberi\nT(n)‚Üí il numero di alberi √® O(log(n))\n\n\n\n\ndata una foresta H con n nodi ciascuno contiene elemento e chiave\nfindmin\nscorre tutte le radici che tanto sono quelle il min\ninserimento\naggiunge ad H un nuovo B_0 (elem \\ e, chiave \\ k)e poi fa ricostruisci\nCancellazione minimo\nelimino la radice di un albero, che a sua volta si spezzer√† in sotto alberi, aggiungo tutti questi alberi in H e faccio ricostruisci\n\nDecremento chiave\ndecrementi e fai muovi in alto del singolo alberello O(log_n) altezza albero\n\nCancellazione\nrichiamo decreaseKey finche non diventa il minimo e faccio la cancellazione del minimo perch√© diventa il minimo O(logn)\nincremento chiave\nfaccio delete e poi inserisco l‚Äôelemento con la chiave aggiornata\nmerge\naggiungo la foresta e faccio ristruttura\n\nHeap di Fibonacci\n\n\n                  \n                  bisogna sapere solo cosa √® e quanto costa \n                  \n                \n\ninventato da Tarjan esperto di strutture dati\n\nil concetto principale √®: perch√© fare subito le ristrutturazioni quando potrei farle alla fine?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFindMinInsertDeleteDelMinIncKeyDecKeyMerged-Heap (d cost.)O(1)O(log n)O(log n)O(log n)O(log n)O(log n)O(n)Heap Binom.O(log n)O(log n)O(log n)O(log n)O(log n)O(log n)O(log n)Heap Fibon.O(1)O(1)O(log n)*O(log n)*O(log n)*O(1)*O(1)\nquelle con asterisco indicano che quella non √® la complessit√† nel caso peggiore ma la complessit√† in senso ammortizzato(solo intuizione)\nCosto ammortizzato\nIl costo ammortizzato di un‚Äôoperazione √® il costo ‚Äúmedio‚Äù rispetto a una sequenza qualsiasi di operazioni\nQuando facciamo una serie di operazioni e calcoliamo il costo alla fine\nin casi in cui facessimo k operazioni, se ha costo ammortizzato costante avr√≤ O(k)\nMolto utile quando si vogliono buone prestazioni sull‚Äôintera sequenza e non garanzie sulla singola operazione ‚Äì esempio: progettare algoritmi veloci attraverso strutture dati efficienti"},"UNI/ANNO-2/ALGORITMI-1/ALGORITMI-LEZ.14":{"slug":"UNI/ANNO-2/ALGORITMI-1/ALGORITMI-LEZ.14","filePath":"UNI/ANNO 2/ALGORITMI 1/ALGORITMI LEZ.14.md","title":"ALGORITMI LEZ.14","links":["UNI/ANNO-2/ALGORITMI-1/fotoalg/grafi_2024.pdf"],"tags":[],"content":"pdf della lezione\nI GRAFI\nPOCA STORIA\nIl concetto dei grafi nasce nel 700 da Eulero, matematico che per risolvere un problema us√≤ i grafi,\nil problema: la citta di Konigsberg aveva 7 ponti, voleva farli visitare a un amico senza passare piu di una volta su un singolo ponte\n\nDefinizione di grafo(non orientato)\nUn grafo G=(V,E)\n\nV= vertici o nodi\nE= insieme di coppie non ordinate di vertici detti archi\n\nGrafo di Eulero\n\nquesto si dice multigrafo quando ha archi paralleli (collegamenti)\nil grafo di Eulero possiamo vedere che ha 4 vertici e 7 coppie ovvero i collegamenti\nV={A,B,C,D}\nE={(A,B), (A,B), (A,D), (B,C), (B,C), (B,D), (C,D)}\n3 ESEMPI DI GRAFI PARTICOLARI\n\ngrafo completo \n\nc‚Äô√® un arco per ogni coppia di vertici, tutti i nodi sono collegati tra loro\n\na stella\ncentro e le punte formando una stella\n\n\ngrafo a caso\nbho un classico grafo non direzionato\nGrafo che modella scenario sulla scacchiera dei possibili cammini di un rook\n‚ôú‚ôú‚ôú‚ôüÔ∏è‚ôüÔ∏è\n\nqui si potrebbe usare un grafo orientato se ipoteticamente la torre dovesse fare solo una direzione senza tornare indietro\nGRAFO ORIENTATO\nesempio di grafo orientato con frecce\nUn grafo diretto D=(V,A)\n\nV=vertici\nA=coppie \\ ordinate \\ di \\ archi \\ diretti\n\n\nesempio di grafo sociale dove uno conosce il nome e cognome di un altro\nc‚Äô√® un arco (u,v) se u conosce il nome e cognome di v\n\nTERMINOLOGIA DEI GRAFI\n\ngrafo non diretto:\n\nn viene usato per indicare la cardinalit√† dei vertici |V|\nm viene usato per il numero di archi |E|\nu e v sono adiacenti o vicini\nl‚Äôarco (u,v) √® incidente a u e a v\nil grado(\\delta) di u √® il numero di archi che riguardano u\ngrado di G=max tra tutti i vertici di tutti i gradi di V\n\ndeg G= max_{ \\{v \\in V \\} } \\ \\{ \\delta(v)\\}\n\n\n\ngrafo diretto:\n\nnell‚Äôarco (u,v) sar√† uscente da u e entrante in v\nil grado uscente (\\delta_{out}) di u √® il numero di archi uscenti da u\nil grado entrante (\\delta_{in}) di u √® il numero di archi entranti da u\n\ngrado entrante o uscente  di G=max tra tutti i \\delta_{out}  oppure \\delta_{in}di V\n\ndeg G= max_{ \\{v \\in V \\} } \\ \\{  \\delta_{out} (v)\\}\ndeg G= max_{ \\{v \\in V \\} } \\ \\{  \\delta_{in} (v)\\}\n\n\n\nRelazione fra grado dei nodi e numero di archi\nin un grafo non orientato:\n\nnon √® orientato, facciamo la somma di tutti i gradi di tutti i vertici\notterremmo 2 volte il numero di archi facendo una sommatoria \\forall v\n\\sum_{v \\in V} \\delta(v) = 2m\nil numero di nodi di un grado dispari √® sempre pari\nin un grafo orientato:\n\n\\sum_{v \\in V} \\delta_{in}(v) = \\sum_{v \\in V} \\delta_{out}(v)= m\nAltre terminologie\n\n\nil cammino indica una sequenza di nodi connessi tra loro con archi\nlunghezza di un cammino: il numero di archi del cammino\ndistanza tra due vertici indica il cammino piu corto per arrivare da un vertice a un altro\n\ndistanza tra L e A e 4 (L,H,E,B,A)\n\n\nG √® connesso se esiste un cammino per ogni coppia di vertici\nciclo: cammino chiuso che parte da un vertice e finisce nel vertice stesso\nil diametro indica la lunghezza massima dell‚Äôinsieme di tutti i cammini minimi di tutti i nodi\n\nmax_{u,v\\in V} dist(u,v)\nse non √® connesso la distanza e infinito\n\n\n\nESEMPI\n\nGrafo di Petersen\n\n\npercorribile ogni nodo in 2, quindi diametro=2\nha un ciclo interno e un ciclo esterno, la stella e il pentagono\ntutti vertici hanno grado 3\n\ngrafo estremale di Hoffman\n\ndi diametro 2 e grado 7\n\n\nGrafo pesato\nmettere dei pesi o costi sui grafi\nG=(V,E,w)\nil cammino pi√π corto si calcola sommando i pesi\n\n\nQuanti archi pu√≤ avere un grafo con n nodi\n\nuno totalmente sconnesso ha 0 archi\n\nuno completo ha m=|E|=n*(n-1)/2\n\nindicato con K_n\nun grafo semplice pu√≤ avere da 0 a n*(n-1)/2= \\ \\theta(n^2) \\ archi\n\ngrafo connesso ma con numero minimo di archi\n\nnon esistono nodi lasciati da soli\nn-1 archi\naciclico non ha ciclo perch√© non ritorno su quel nodo\nlibero\nradicato\n\n\nCome dimostriamo che √® n-1 ? induzione\ncaso base: il grafo ha un solo vertice 0 archi n=1 ‚Üí (1-1)\ncaso induttivo:\nnel caso in cui abbiamo un grafo con n nodi aciclico e connesso\n\ndeve avere almeno una foglia\nrimuovendo questa foglia avremmo n-1 nodi e n-2 archi per l‚Äôipotesi induttiva\n\n\n\n                  \n                  quindi T ha ancora n-1 archi \n                  \n                \n\n\nESERCIZIO PER VEDERE DEFINIZIONI ALTERNATIVE\n\nimportante, se abbiamo un grafo G connesso deve avere almeno n-1 archi e al pi√π n^2 archi\nm=\\Omega(n) oppure m=O(n^2)\n\n\n                  \n                  non √® detto che se un grafo ha n-1 archi sia connesso \n                  \n                \n\nCome si risolve la cosa dei 7 pontos?\nciclo si dice euleriano se puoi attraversare tutti gli archi di G solo una volta\n\nquando un grafo ammette un ciclo euleriano? ‚áê&gt; tutti i nodi hanno grado pari\nammette invece un cammino euleriano se tutti i nodi hanno grado pari tranne 2 nodi\nquesto pontos non si pu√≤ fare\n\n\nPk i grafi?\nutilizzato per reti stradali nodi=incroci archi=strade\nper voli aerei nodi= aereoporti archi= rotte aeree\nper la metro nodi=fermate archi=tratte metro\n\n\n                  \n                  ecco esempi grafici \n                  \n                \n\n\n\n\n\n\nPERCORSO PROFESSOR PASQUALE\nIl professor pasquale voleva da centocelle arrivare alla pallalottomatica in breve tempo\nil navigatore suggerisce il percorso migliore prendendo pesi degli archi come\n\nla lunghezza(strada pi√π breve)\ntempo di percorrenza(strada pi√π veloce)\n\n\nReti sociali\n\nKevin Bacon ha mille collegamenti impossibile incredibile\n\nReti delle dipendenze\n\nci sono nodi che hanno compiti da svolgere\nl‚Äôarco (u,v) indica che u deve essere eseguito prima di v, in termini di compiti\n\nesami a propedeuticita\nmoduli software di un progetto a dipendenze\n\nOrdinamento topologico del grafo, mettendo le dipendenze da sx a dx\n\nnodi: compiti da svolgere\narchi u,v rappresentano conflitti\ndate esami e vincoli\ncerti esami non possono essere svolti lo stesso giorno\nvedere poi il problema alle ultime slide\nNumero cromatico\nPer colorazione si intende ‚Äúcolorare‚Äù i nodi del grafo usando il minimo numero X di colori evitando di mettere colori simili adiacenti.\n\n\\chi(G)=3\n\n\n                  \n                  ESERCIZIO \n                  \n                \n\n\n\n"},"UNI/ANNO-2/ALGORITMI-1/ALGORITMI-LEZ.15":{"slug":"UNI/ANNO-2/ALGORITMI-1/ALGORITMI-LEZ.15","filePath":"UNI/ANNO 2/ALGORITMI 1/ALGORITMI LEZ.15.md","title":"ALGORITMI LEZ.15","links":["UNI/ANNO-2/ALGORITMI-1/fotoalg/visite_2024.pdf","UNI/ANNO-2/ALGORITMI-1/ALGORITMI-LEZ.14"],"tags":[],"content":"pdf della lezione\n20 febbraio\n\nscritto\norale\npunti ipotetici problem set\n\nVISITE DI GRAFI\nVedremo la parte algoritmica dei grafi\n\nquali sono i modi piu standard per rappresentare un grafo in memoria?\nalgoritmi di visita dei grafi\n\nI GRAFI IN MEMORIA\nCi sono principalmente 2 modi\nprima li vedremo sui grafi non diretti poi sui diretti\nPrendiamo di avere un grafo non diretto\n\npotremmo usare una matrice di adiacenza, una matrice n*n\n\ncome funziona?\n\nse non ci sono pesi usiamo variabili booleane\n\ndicendo che 1 se c‚Äô√® accoppiamento oppure 0 se non c‚Äô√®\n\n\nusiamo lettere ma conviene numerarli con tipo 1,2,3,‚Ä¶n\nOCCUPA SPAZIO O(n^2)\n\nUsiamo liste di adiacenza\n\nper ogni nodo abbiamo una lista collegata che indica chi √® collegato con quel nodo\nOCCUPA SPAZIO O(n+m)\ndove m indica il numero di archi\nPer capire il numero di record(archi) facciamo \\sum_{v \\in V} \\delta(v) = 2m\nripreso dalla lezione ALGORITMI LEZ.14\nGrafi diretti\n\nmatrice di adiacenza\nUsiamo la stessa rappresentazione della matrice ma non √® simmetrica come prima,\n\nin questo caso indico con 1 quando gli elementi verdi entrano dentro quelli in rosso\nliste di adiacenza: mettiamo solo i gradi uscenti\n\nOperazioni che dipendono dal tipo di struttura usato\ngrafo non diretto\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOperazionematricelisteElenco di archi che si incrociano in vO(n)O\\delta(v)vedere se c‚Äô√® arco in (u,v)O(1)O(min \\{\\delta(u), \\delta(v)\\})\ngrafo diretto\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOperazionematricelisteElenco di archi che si incrociano in vO(n)O\\delta(v)vedere se c‚Äô√® arco in (u,v)O(1)O(delta(u))\nAlgoritmi di visita\nservono per calcolare alcune informazioni importanti del grafo, e lo visitano\n\nAbbiamo un grafo G, in modo sistematico lo visitiamo esaminando i vari nodi e archi in esso\nFare la visita ci genera un albero di visita(lo vedremo tra poco)\nEsistono due tipi di visite e fanno cose diverse\n\nBFS, ampiezza\nDFS, profondit√†\n\n\n\nBFS Visita in ampiezza\nCOSA FA? √® importante saperlo\nPrende un grafo, prende un nodo sorgente S, si calcola tutte le distanze o cammini minimi(sono la stessa cosa) da S verso ogni altro nodo v\nHa diverse applicazioni\n\nUsato per fare web crawling\n\nogni pagina e un nodo di un grafo, e le pagine sono collegate\nil search engine di google scopre cosi nuove pagine\nTORRENTIO funziona cosi!\n\n\nsocial networking\n\ntrovare gli amici che potresti conoscere\nnodo per ogni utente\nvisito tutti i nodi vicini a quelli a distanza 1(gli amici degli amici)\n\n\nnetwork broadcast\n\nse voglio mandare un pacchetto in broadcast(da un nodo sorgente a tutti i nodi)\n\n\ngarbage collection\n\nCome scoprire memoria non piu raggiungibile da buttare\n\n\nrisolvere puzzle(lo vedremo meglio tra poco)\n\ntipo il cubo di Rubik\n\n\n\nChi sa risolvere il cubo di Rubik? io no\ncome risolvere in poche mosse il cubo di Rubik 2x2x2\n\n\nrappresentiamo il cubo di Rubik attraverso\n\nil grafo delle configurazioni\nun vertice e un possibile stato del cubo\n\n\ngrafo non orientato\nnumero di vertici‚áê 8! * 3^8\nPartiamo dalla configurazione gi√† risolta e poi andiamo a tutti i vicini casi con 1 mossa\n\nci sono poi a sua volta altre sequenze di mosse che portano a nuove configurazioni\n\nsaranno tutte le possibili mosse con 2 mosse\n\n\npoi ci sono 3 mosse 4 mosse ecc‚Ä¶ finche il grafo non finisce\n\n\nla distanza tra il nodo S e il punto pi√π lontano si dice eccentricit√†(distanza massima da S a un nodo)\n\nsi dice anche god‚Äôs number, il numero minimo di mosse sufficiente per risolvere\n\n\nandiamo a ritroso dal nodo in cui siamo fino al nodo per risolverlo\n\n\nAlgoritmo di visita in ampiezza\nCodice\n\n\nuso una coda per salvare momentaneamente tutti i vertici visitati e mi segno la distanza dal vertice S\nfacciamo un ciclo che scorre finche la coda √® vuota, ovvero quando abbiamo visitato tutti gli elementi\n\nEsempio di visita BFS\n\n\ni tratteggi indicano che comunque gi√† lo conosco nella cosa quel nodo e quindi non serve visitarlo\nse gi√† conosci vai avanti\n\n\nalbero dei cammini di G radicato in S\nNei grafi orientati\n\nper i grafi orientati basta solo andare a vedere i nodi in uscita\nQuanto costa fare una visita BFS\ndipende da come rappresentiamo il grafo:\ncon le matrici di adiacenza abbiamo: O(n^2)\ncon le liste di adiacenza:O(m+n)\nma abbiamo delle osservazioni perch√©\n\nse il grafo √® connesso abbiamo m\\geq n-1  quindi non conta O(m+n) ma basta O(m)\n\npoich√© prevale asintoticamente\n\n\nsi ricorda che il numero di archi m ha un upper-bound al numero totale di archi possibili con quel numero di nodi m\\leq n(n-1)/2\n\nsi ha quindi che se O(m+n)=O(n^2) ‚Üí m+n sar√† sempre con un upper bound a n^2\nsempre se m=o(n^2) ‚Üí deve rimanere strettamente sotto posso dire che le liste so mejo\n\n\n\nTeorema\nil livello di un qualsiasi nodo v dell‚Äôalbero BFS corrisponde al cammino minimo dal nodo v alla sorgente s\n\nVisita in profondit√†\nOGGI VEDREMO SOLO COME FUNZIONA, Domani lo usiamo per calcolare tante cose\nPer spiegarlo usa un labirinto e fa un esempio con la corda e il gesso\n\nad ogni strada che prendo la segno con il gesso\nuso una corda per tornare indietro\n\n\nPSEUDOCODICE\n\nFunzione ricorsiva per ogni nodo, ogni nodo si fa un for che vede i suoi archi\n\nad ogni nodo non visitato richiama la funzione ricorsiva\n\nrossi piccoli: ancora in attivo\nrossi grandi: si usano in quel momento\n\n\nbho nel grafo diretto √® cos√¨\n\n\n\n                  \n                  cammino minimo \n                  \n                \n\nper contare i cammini minimi si deve usare la visita in ampiezza\nquella in profondit√† non worka\n\n\nCosto visita in profondit√†\n\ncon liste O(m+n)\ncon matriceO(n^2)\n\n\nriprendendo l‚Äôalbero possiamo fare delle considerazioni\n\nse prendo un arco (u,v)\n\nl‚Äôho contato e quindi formano un arco\noppure sono uno discendente/antenato dell‚Äôaltro\n\nse √® orientato:\nle stesse cose di prima ma si aggiunge una cosa\n\n\n(u,v) possono formare un arco trasversale a sinistra\n"},"UNI/ANNO-2/ALGORITMI-1/ALGORITMI-LEZ.16":{"slug":"UNI/ANNO-2/ALGORITMI-1/ALGORITMI-LEZ.16","filePath":"UNI/ANNO 2/ALGORITMI 1/ALGORITMI LEZ.16.md","title":"ALGORITMI LEZ.16","links":["UNI/ANNO-2/ALGORITMI-1/fotoalg/usi_dfs_2024.pdf","UNI/ANNO-2/ALGORITMI-1/ALGORITMI-LEZ.15","UNI/ANNO-2/ALGORITMI-1/ALGORITMI-LEZ.14"],"tags":[],"content":"pdf della lezione\nIl BFS serve per calcolare i cammini minimi da una sorgente\nIl DFS no quindi a che serve?\nOggi risponderemo a questa domanda\nRivediamo l‚Äôalgoritmo DFS ALGORITMI LEZ.15\n\nalgoritmo ricorsivo\nrestituisce l‚Äôalbero DFS, inizialmente vuoto\nalbero che verra riempito con tutti gli archi visitati\n\nAlgoritmo DFS con aggiunta di clock\n\nquesta aggiunta ci consente di tenere conto\n\n\nil tempo di visita iniziale\n\n\nil tempo che intercorre tra la visita iniziale e finale\n\ndove in mezzo ci saranno state ipotetiche visite\n\n\n\npossiamo vedere come nell‚Äôalgoritmo visitaDFS inizializziamo clock a 1 globalmente\n\n\nche succede se alcuni vertici non sono raggiungibili da S?\n\nnon li conta\nci sono delle situazioni in cui invece conta visitarli quindi ora vedremo un codice modificato che visita tutti i vertici\n\n\n\nCodice\n\n\nlui si scorre prima tutti i nodi anche quelli non collegati\npoi fa la chiamata ricorsiva per ogni nodo v che non √® stato gi√† marcato dalle precedenti chiamate\n\n\n\n                  \n                  esempio grafico un p√≤ storto \n                  \n                \n\n\n\n\nESEMPIO GRAFICO\n\nI contatori pre e post hanno delle propriet√† particolari:\nprendiamo due nodi u e v e giochiamoci un po‚Äô\n\nse prendiamo gli intervalli [pre(u),post(u)] e  [pre(v),post(v)]\n\nsuccede che se i valori si incrociano uno √® contenuto nell‚Äôaltro(non sono disgiunti)\n\n\nu √® antenato di v se pre(u)&lt;pre(v)&lt;post(v)&lt;post(u)\n\nil pre(v) e il post(v) sono compresi tra u\n\n\nsfruttando queste cose possiamo capire di un arco(u,v) il suo tipo\n\nin avanti. quando un nodo v √® compreso in uno v\nindietro, quando un grafo\ntrasversali, quando non si incrociano\n\n\n\n\n\nRICONOSCERE UN CICLO IN UN GRAFO G\n\nfacciamo una visita DFS e capiamo se c‚Äô√® un arco all‚Äôindietro\n\n\n\n                  \n                  PROPRIET√Ä \n                  \n                \n\nun grafo diretto G si dice che ha un ciclo se e solo se la visita DFS rivela un arco all‚Äôindietro\n\n\n\n\n                  \n                  DIMOSTRAZIONE \n                  \n                \n\n‚áê se c‚Äô√® un arco all‚Äôindietro allora c‚Äô√® ciclo\n‚áí supponiamo che esista un ciclo &lt;v_0,v_1,...v_k=v_0&gt;  in G\nvisto che v_k √® uguale a v_0 significa proprio che abbiamo un ciclo\n\nsupponiamo che v_i sia il primo nodo che visitiamo, visto che v_{i-1} √® raggiungibile da v_i allora prima del termine delle visite di v_i\nv_{i-1} andr√† da v_i facendo verificare un arco all‚Äôindietro (v_{i-1},v_i)\n\n\n\n\nORDINAMENTO TOPOLOGICO UN‚ÄôALTRO UTILIZZO DEI DFS\nDefinizione di DAG\nUn Grafo G diretto si dice DAG quando √® un grafo diretto senza cicli\nDefinizione di ORDINAMENTO TOPOLOGICO\n\n√® un ordinamento di vertici in un certo ordine o sx o dx in modo che tutti gli archi vanno solo o a sx o a dx\nformalmente:\n√à una funzione biettiva che mappa i vertici fra 1...n tale che per ogni arco(u,v) il\n\\sigma(u)&lt;\\sigma(v)\n\nLa funzione œÉ  serve per assegnare un numero a ogni nodo in modo che rispetti la direzione degli archi nel grafo. Se un nodo punta a un altro, deve venire prima nell‚Äôordine.\nin poche parole mette gli archi in ordine dei vertici con le posizioni in ordine\n\nil nodo deve essere in una posizione precedente di quelli con cui ha un arco\n\n\n\n\n                  \n                  Ricorda molto la roba delle dipendenze \n                  \n                \n\n\n\n                  \n                  infatti l&#039;ordine topologico ci consente di vedere le dipendenze sfruttabili \n                  \n                \n\n(creare un software che ordini le cose da progettare con le varie dipendenze)\n\n\nse non ti ricordi:\nlezione sulle reti delle dipendenze\nQuali grafi non ammettono ordinamento topologico?\n\nun ciclo sicuramente no perch√© ci sono dipendenze infinite\nUN DAG ammette sempre un ordinamento topologico? si\nDimostriamolo per assurdo ‚Üí\n\nDimostriamo che per ogni DAG abbiamo un ordinamento topologico\n‚áí\nper assurdo poniamo \\sigma come ordinamento topologico di G\ne sia  &lt;v_0,v_1,...v_k=v_0&gt; un ciclo\nallora \\sigma(v_0)&lt;\\sigma(v_1)&lt;‚Ä¶&lt;\\sigma(v_{k-1})&lt;\\sigma(v_k)=\\sigma(v_0)\ncos√¨ stiamo dimostrando che per ognuno di questi abbiamo un ordinamento topologico ovviamente senza contare quel nodo che forma il ciclo che poi verr√† uguale\n\n\n                  \n                  ordinamento topologico di un G non √® per forza 1 \n                  \n                \n\nCome aggiunta alla dimostrazione ora vedremo degli algoritmi che ordinano in modo topologico\nALGORITMO 1\n\nfai una visita DFS e ordina in modo decrescente rispetto ai tempi di fine visita post\nCODICE\n\nogni volta che finisce il primo vertice sar√† quello pi√π piccolo, quindi gli altri li aggiungiamo alla lista nello stesso tempo in cui finiscono\n\nCOSTA UGUALE ALLA VISITA IN PROFONDITA \\Theta(n+m)\nESEMPIO GRAFICO\n\n√à CORRETTO?\n\nSi ma non dobbiamo prendere i passi all‚Äôindietro ovviamente\n\nUn algoritmo alternativo\n\n\ntroviamo un vertice senza archi entranti‚Üí rimuoviamo tutti i suoi vertici incidenti\ntroviamo il prossimo vertice senza archi entranti\nfinch√® non abbiamo pi√π vertici senza archi entranti\nha il vantaggio di far capire meglio la sua correttezza\nda implementare √® piu difficile in tempo lineare\n\nTempo O(n+m)\n\nCOMPONENTI FORTEMENTE CONNESSE\nUn grafo √® fortemente connesso se per ogni nodo v abbiamo una coppia (u,v) ordinata possiamo avere che u raggiunge v e che v raggiunge u\n\nLe componenti fortemente connesse sono quelle tratteggiate\nUna componente fortemente connessa √® una propriet√† associabile a un grafo G con un insieme C di vertici che √® massimale.\nIl numero massimo di vertici che formo con quei determinati nodi forma un insieme da mettere in C(i tratteggi)\n\n\n\n                  \n                  def del prof \n                  \n                \n\n\n\n\n\nCFC sorgente: una componente che non ha archi entranti da altre CFC.\nCFC pozzo: una componente che non ha archi uscenti verso altre CFC.\n\nmassimale: se tu all‚Äôistanza C aggiungi un nodo non risulta pi√π vera la propriet√†  della componente fortemente connessa\n\nN.B E pu√≤ raggiungere F ma F non E\nIl grafo delle CFC rappresenta un DAG\n\nQuesto problema per trovare tutte le CFC si pu√≤ risolvere in O(n)\nDiverse propriet√†\nPropriet√† 1:\nSe facessi partire la visita in uno dei vertici CFC raggiungerei solo i vertici di quella determinata componente pozzo\nIl codice termina quanto hai visitato tutti i nodi raggiungibili da u\nPropriet√† 2:\nSe C e C&#039; hanno un vertice che collega C in C&#039; allora inevitabilmente C avr√† una variabile\npost \\ &gt; \\ di \\ C&#039;\n\ndeve prima scorrersi tutto C&#039; e poi C finir√†\nse partiamo da C&#039; non ci arriva mai in C\n\n\nPropriet√† 3:\nCi basta vedere chi ha il post pi√π grande della singola visita DFS su un insieme CFC per trovare una  componente di tipo sorgente\n\n\n                  \n                  Noi ora abbiamo capito come trovare una sorgente abbiamo bisogno di una componente pozzo? \n                  \n                \n\nInvertiamo gli archi\ninvertiamo le direzioni per ottimizzare le cose del componente puzzo\nRimane tutto invariato in termini di propriet√†\n\nabbiamo il Grafo G‚Üí\n\n‚Üícreiamo il suo inverso G^r\n\n\n\nCalcoliamo i valori di post visita e prendiamo il piu grande e ora troviamo la componente pozzo\n\nALGORITMO che mette insieme tute le idee\nCODICE lo fa vedere dopo la spiegazione grafica alle slide dopo\n\n\ninverto il grafo(nelle foto sopra  √® gi√† invertito)costa lineare\nFa una visita DFS completa del grafo G^r\nAndiamo a fare una visita partendo da H, andiamo a prendere quindi tutti i componenti del suo CFC\npoi vediamo il valore piu piccolo del suo post 24 subito dopo e che non sia marcato e quindi di un‚Äôaltra CFC\n\nquindi tutto lineare\nCODICE\n\nIl resto \\Theta(n+m)"},"UNI/ANNO-2/ALGORITMI-1/ALGORITMI-LEZ.17":{"slug":"UNI/ANNO-2/ALGORITMI-1/ALGORITMI-LEZ.17","filePath":"UNI/ANNO 2/ALGORITMI 1/ALGORITMI LEZ.17.md","title":"ALGORITMI LEZ.17","links":["UNI/ANNO-2/ALGORITMI-1/fotoalg/Dijkstra_2024.pdf"],"tags":[],"content":"pdf della lezione\nALGORITMO DI DIJKSTRA\nConsente di trovare il cammino minimo in un grafo pesato\nCammino minimo su un grafo pesato\nSia G=(V,E,w) dove w indica il peso in inglese\nil grafo deve essere orientato o non\nquando il grafo √® pesato il cammino viene dato dalla\nquindi in base alla somma dei pesi\nprendiamo un cammino \\pi = &lt;v_{0}, v_{1}, v_{2},...,v_{k}&gt;\navremo un costo:\nw(\\pi) = \\sum_{i=1}^{k} w(v_{i-1}, v_i)\nOra che abbiamo visto la definizione di cammino con i pesi vediamo la vera e propria definizione di cammino minimo\ntra una coppia di vertici x e y √® un cammino che ha costo \\leq a quello di ogni altro cammino tra gli stessi vertici x e y\n\n\n                  \n                  non deve averne per forza 1 \n                  \n                \n\nesempio su excalidraw\n\nesempio slide prof\n\n\n\nESEMPIO con pesi negativi\nsi pu√≤ notare come ci sia -1 o -10\nquesto non si pu√≤ fare con Dijkstra\n\nUn cammino minimo viene detto distanza\nPROBLEMA reale:\ndati u e v, trovare un cammino minimo(distanza) tra due nodi\n\n\nse il peso w √® dato dalla lunghezza in km abbiamo la strada pi√π breve\nse il peso w e il tempo di percorrenza avremo la strada pi√π veloce\n\nEsiste sempre un cammino minimo da u a v?\n\nse non esiste un cammino tra u e v no\n\ndiciamo che la distanza d(u,v)=\\infty\n\n\nse abbiamo un cammino con un ciclo che ha un costo negativo allora non va bene\n\ndiciamo che e -\\infty\n\n\n\nse non esistono cicli negativi in G esistono dei cammini minimi detti semplici\n\nche non contengono nodi ripetuti\n\n\n\nSotto-struttura ottima\nOgni sotto-cammino di un cammino minimo √® a sua volta un cammino minimo\nDimostrazione\nusiamo la tecnica del cut &amp; paste per dire che se quello non era un cammino minimo allora assumiamo per assurdo che ne esista uno pi√π corto, dopo aver tagliato ci accorgiamo che ne esce uno ancora pi√π piccolo quindi significa che quello di prima era il pi√π corto\n\nDisuguaglianza triangolare\n\\forall \\ u,v,x \\in V  \\ \\ \\ vale \\ \\ \\ d(u,v) \\le d(u,x) + d(x,v)\nd indica la distanza\n\nCammini minimi a singola sorgente\nnel grafo prendiamo una sorgente S, dalla sorgente S vogliamo calcolare tutti i cammini minimi che partono da esse\n\nSPIEGAZIONE DEL PROBLEMA:\ndue varianti:\n\nDato G = (V,E,w) con s \\in V, calcola le distanze di tutti i nodi da s, ovvero d_G(s,v) per ogni v \\in V\nDato G = (V,E,w) con s \\in V, calcola l‚Äôalbero dei cammini minimi di G radicato in s\nche significa la seconda?\nche abbiamo un albero T con radice s, formato dai suoi cammini minimi con corrispondenza 1:1\nc‚Äôe tipo d_T(s,v)=d_G(s,v)\ncon questo albero rappresentiamo n-1 cammini minimi da s a v\nCOSA CI RICORDA? il BFS(funziona senza pesi)\n\nAlbero dei cammini minimi (o Shortest Path Tree - SPT)\ndijkstra in output mi da lo shortest path tree\ninvece questo SPT con\n\n\nESERCIZIO PER CASA\n\nOra parliamo del vero e proprio DIJKSTRA\nAssumiamo che tutti i pesi siano \\geq0\n\nogni arco (u,w) ha w(u,w)\\geq0\n\nIdea dell‚Äôalgoritmo\n\nandiamo a scoprire i cammini minimi\nprendiamo tipo che gli archi siano dei tubi e S √® la sorgente dove sputiamo acqua costante\nslide di acqua che scorre e che una volta raggiunto il nodo a una determinata celletta di acqua la prende\n(ogni tubo viene diviso per il suo peso)\napproccio greedy\n\nper ogni nodo v noi creiamo una stima della distanza, per eccesso.\n\novviamente la prima stima deve essere per forza D_{ss} 0 con se stesso\ntutti gli altri devono essere \\infty\n\n\nmantiene un insieme X di nodi per cui le stime sono esatte\n\n(nella gif sotto sono le stime dopo i collegamenti blu)\ninizialmente X = \\{s\\}\n\n\nl‚Äôalgoritmo mi ritorna alla fine un albero T con i cammini minimi\n\nT si aggiorna fino alla fine\nT non ha archi\n\n\nAd ogni passo inserisce in X il nodo u in V-X con stima esatta\nse una stima non √® esatta allora avr√≤ un arco arancione se confermata blu\nAggiorno le varie stime\n\n\n\nX si allarga piano piano\nnodi bianchi sono nodi a cui ancora non abbiamo scoperto il suo cammino che li raggiunge e sono a infinito\narancioni sono quelli con cui almeno abbiamo un cammino per√≤ non sappiamo se √® il minimo\n\nli metto in una coda e ci metto la loro stima\n\n\n\n\nABBIAMO PARLATO DI STIMA ma come si aggiornano e\nLa stima non aggiornata √® data da\nD_{sy} = min\\{D_{sx} + w(x,y)\\} : (x,y) \\in E, \\ x \\in X\ndove\n\nD_{sx} indica la distanza tra la radice e il nodo da cui parte l‚Äôarco entrante in y, che ho gi√† calcolato come minima\nw(x, y) √® il peso\n(x, y) deve appartenere all‚Äôinsieme E di archi (deve esistere un arco tra x e y)\nx deve appartenere all‚Äôinsieme di nodi con le stime confermate X (questa cosa mi conferma ancora di pi√π il primo punto)\n\nOgni volta che trovo una stima migliore la aggiorno\nAd esempio\nse un nodo y √® in coda con un arco (x,y) associato\nse aggiungiamo un nodo u a T troviamo un arco (u,y) tale che\nD_{su} + w(u,y) &lt; D_{sx}+ w(x,y)\nsignifica che abbiamo trovato un arco migliore di (x,y) per raggiungere y partendo da s ovvero (u,y)\nPSEUDOCODICE\n\n\nassegna ad ogni vertice u nel grafo una distanza di \\infty\ncrea un albero che ha come X zero perch√© ha una area molto ristretta\ninserisce nella coda la prima scoperta s quindi 0\nfa un ciclo finch√© la coda non √® vuota\nse non ho ancora mai visitato quel nodo avr√≤ come media attesa infinito quindi procedo a inserirlo nella coda\n\nmetto u padre di v perch√© sta prima e ci accontentiamo di tutto\n\n\nse la media attesa gi√† esiste\n\nfaccio un controllo se l‚Äôarco √® meglio e in caso modifico il tutto\ncompreso il padre\n\nparto dal nodo S e mi leggo tutti i suoi archi, sommo i vari cammini e li metto come stima\nfaccio la stessa cosa e aggiorno la stima con decreasekey\nQuelli arancioni sono i cammini scoperti\n\n\n\nDIMOSTRAZIONE DELLA CORRETTEZZA, per assurdo\n\nabbiamo un caso in cui la distanza diretta tra s e v √® pi√π piccola di quella passante per u\nmettiamo che l‚Äôalgoritmo sbagli e pensi che passando da u si faccia prima\nallora l‚Äôalbero T avr√† (s,u) con una freccia blu e (u,v) con freccia blu\nriprendiamo la cosa dei sotto-cammini e mettiamo due nodi x e y con x \\in T e y \\not\\in T\n\n(s,x) avr√† freccia blu\nPer√≤ per la propriet√† sappiamo che \\pi_{sy} ha costo minore di D_{sv} e quindi l‚Äôalgoritmo ha sbagliato poich√© avrebbe dovuto togliere dalla coda con priorit√† prima y rispetto a v.\n\nCOMPLESSIT√Ä\nComplessit√†\nEscludendo le operazioni sulla coda con priorit√† la complessit√† √® O(m+n)dove\n\nm = numero di archi (visito al pi√π tutti gli archi una sola volta)\nn = numero di nodi (entro in ogni nodo solo una volta)\n\nAndiamo a vedere ora quanto costerebbe una coda con priorit√† in base a come √® implementata.\nInnanzitutto noi nell‚Äôalgoritmo avremo\n\nn insert, inserisco tutti i nodi nella coda\nn deleteMin, tolto tutti i nodi dalla coda\nAL PI√ô m decreaseKey, al massimo dovr√≤ cambiare le chiavi m volte\n\nIl costo delle operazioni nella coda con priorit√† cambiano in base alla struttura utilizzata\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSTRUTTURAInsertDelMinDecKeyHeap binarioO(1)O(n)O(1)Array ordinatoO(n)O(1)O(n)Lista non ordinataO(1)O(n)O(1)Lista ordinataO(n)O(1)O(n)Heap binarioO(log(n))O(log(n))O(log(n))Heap binomialeO(log(n))O(log(n))O(log(n))Heap di FibonacciO(1)O(log(n))*(ammortizzata)O(1)*(ammortizzata)Quindi\n\n\nn¬∑O(1) + n¬∑O(n) + O(m)¬∑O(1) = O(n^2) con array non ordinati\n\n\nn¬∑O(n) + n¬∑O(1) + O(m)¬∑O(n) = O(m¬∑n) con array ordinati\n(ricorda che al 99% [[13. Grafi#^4975e1|il numero di archi m &gt; numero di nodi n ]])\n\n\nn¬∑O(1) + n¬∑O(n) + O(m)¬∑O(1) = O(n^2) con liste non ordinate\n\n\nn¬∑O(n) + n¬∑O(1) + O(m)¬∑O(n) = O(m¬∑n) con liste ordinate\n\n\nn¬∑O(log n) + n¬∑O(log n) + O(m)¬∑O(log n) = O(m¬∑log n) utilizzando heap binari o binomiali\n\n\nn¬∑O(1) + n¬∑O(log n)* + O(m)¬∑O(1)* = O(m + n¬∑log n) utilizzando heap di Fibonacci\n\n\nLA SOLUZIONE MIGLIORE LA AVR√í CON L‚ÄôHEAP DI FIBONACCI.\n\n\n                  \n                  Osservazione sulla decreaseKey\n                  \n                \n\nPer rendere le complessit√† temporali sulla decreaseKey valida devo mantenere un puntatore diretto tra in nodo v nell‚Äôarray dei nodi della lista di adiacenza del grafo e l‚Äôelemento nella coda di priorit√† associato al nodo v; tale puntatore viene inizializzato nella fase di inserimento di quest‚Äôultimo all‚Äôinterno della coda.\n\n"},"UNI/ANNO-2/ALGORITMI-1/ALGORITMI-LEZ.2":{"slug":"UNI/ANNO-2/ALGORITMI-1/ALGORITMI-LEZ.2","filePath":"UNI/ANNO 2/ALGORITMI 1/ALGORITMI LEZ.2.md","title":"ALGORITMI LEZ.2","links":["UNI/ANNO-2/ALGORITMI-1/fotoalg/Cap1.pdf"],"tags":[],"content":"PDF rispettivo della lezione\nF_n = \\begin{cases}\n    F_{n-1}+F_{n-2} &amp; \\text{se } n \\geq 3 \\\\\n    1 &amp; \\text{se } n = 1,2\n\\end{cases}\nALGORITMI DI FIBONACCI CON PSEUDO-CODICE\nALGORITMO 1\nAlgoritmo di Fibonacci1 con le \\phi viene usato ma ha un problema di approssimazione ed √® il seguente:\nF_n=\\frac{1}{\\sqrt{5}}*(\\phi^n-\\phi_2^n)\n\nPSEUDO CODICE\n\nAlgoritmo2\nlo troviamo con pseudo codice\n\nsfruttando uno divide and conquer\nPer calcolare il costo computazionale del Fibonacci2\ncalcoliamo il numero di linee di codice mandate in esecuzione al variare di n\nUsiamo T(n) ovvero \\# di linee di codice eseguite nel caso peggiore su un input n\nE avremo che T(n)=2+T(n-1)+T(n-2) \\ \\ T(1)=T(2)=1\nPer creare una formula generica usiamo l‚Äôalbero della ricorsione\n\nOgni nodo superiore fa i passi delle foglie (basi)sotto l‚Äôalbero\nF(4) ha 3 foglie e 2 nodi interni\nOgni foglia 1 linea di codice ogni nodo interno 2 linee di codice\nCreo due supposizioni\n\nLemma1 il numero di foglie dell‚Äôalbero √® F_n\nLemma2 il numero di nodi interni √® \\# Foglie-1\n\nF_n+2(F_n-1)=3F_n-2\nDimostrazione sui lemmi(ipotesi)(slide 18)\nL‚Äôalgoritmo di Fibonacci2 fa cagare perch√© piu‚Äô volte ricalcola le stesse cose tipo F(6), rifaccio le stesse computazioni\nAlgoritmo3\nUsando un Array ausiliario in posizione i metto il risultato di quel Fibonacci\n\nContare le linee di codice\nT(n)\\leq n+n+3=2n+3\nFib3 es mejor than Fib2\nOccupazione della memoria\nFibonacci3 usa abbastanza memoria perci√≤ useremo Fibonacci4 che dovr√† usare meno memoria\nAlgoritmo4\nPseudo codice Fibonacci4\n\nPossiamo dimenticare tutti i precedenti senza usare l‚Äôarray risparmiando cosi‚Äô memoria ausiliaria usando memoria costante\nTempo di Fibonacci4 4n+2 ma solo perch√® contiamo le linee di codice e quindi √® un po‚Äô approssimato\nNotazione asintotica\nEsprimo il costo T(n) in modo qualitativo\n\nignoro costanti moltiplicative\nignoro termini di ordine inferiore\nQuindi sia Fibonacci4 che 3 sono O(n)\n\nMatrici=Fibonacci\n\n\nAlgoritmo5\nCon matrici e induzione slide\nPseudo codice\n\nSar√† sempre O(n)\nAlgoritmo6\nVedi propriet√† delle somme degli esponenti che permette di scomporre in sotto problemi ad esempio 3^8=3*3*3*3*3*3*3*3=((3^2)^2)^2\nsostanzialmente dimezzo la potenza perch√© tanto da stessi risultati\na^n=(a^{n/2})^2\nPosso sfruttare questa cosa per diminuire la potenza senza fare tutte le moltiplicazioni\n\nPer capire il costo computazionale di questo algoritmo bisogna fare degli accorgimenti arrivando al caso log_2n\nT(n)\\leq c*parte \\ intera \\ log_2n+T(1)=O(log_2n)\n\n\n                  \n                  spiegazione raffazzonata sulla ricorsione \n                  \n                \n\n\n\n\nQuanta memoria usa un algoritmo ricorsivo?\n\nAlgoritmo non ricorsivo: dipende dalla memoria (ausiliaria) allocata; es. variabili, array‚Ä¶\nAlgoritmo ricorsivo: dipende dalla memoria (ausiliaria) allocata da ogni chiamata e dal numero di chiamate che sono contemporaneamente attive.quindi In base all‚Äôespansione dei nodi\n"},"UNI/ANNO-2/ALGORITMI-1/ALGORITMI-LEZ.3":{"slug":"UNI/ANNO-2/ALGORITMI-1/ALGORITMI-LEZ.3","filePath":"UNI/ANNO 2/ALGORITMI 1/ALGORITMI LEZ.3.md","title":"ALGORITMI LEZ.3","links":["UNI/ANNO-2/ALGORITMI-1/fotoalg/Cap1.5.pdf"],"tags":[],"content":"PDF rispettivo della lezione\nIntroduzione\nCi sono vari tipi di modelli di calcolo come la macchina di Turing ma √® troppo vecchia per usarla nel corso\nVedremo invece una RAM, macchina a registri come modello di calcolo che √® una astrazione della macchina di Von Neumann\n\n\nOgnuna di queste risorse della RAM viene usata per svolgere le istruzioni del programma finito\n\nANALISI DI UN ALGORITMO\nSi basa su un concetto di passo elementare ad esempio(nella RAM):\n\naccesso ai nastri I/O\noperazione aritmetico/logica\naccesso/modifica in memoria\n\nQuanto costa un passo elementare\n\n\n                  \n                  Criterio di costo Uniforme \n                  \n                \n\n\nIn questo caso tutte le operazioni hanno lo stesso costo definito\nLa complessit√† temporale viene calcolata in base al numero di passi\n\n\n\n\n\n                  \n                  Criterio di costo Logaritmico \n                  \n                \n\n\nIl costo di una singola operazione √® in base alla dimensione degli operandi dell‚Äôistruzione\nUn‚Äôoperazione su un operando di valore x avr√† costo logx\nSi usa principalmente in algoritmi numerici per calcolare meglio la loro complessit√†\n\n\n\nNel corso di algoritmi per quasi tutti i problemi il modo 1 dovrebbe essere pi√π usato del modo 2 giusto con Fibonacci viene usato 2\nQuindi useremo principalmente modello RAM con costo uniforme\nCaso peggiore e Caso medio\nIl tempo di esecuzione di un algoritmo viene calcolato in base alla dimensione delle istanze dell‚Äôalgoritmo Che per√≤ possono avere dimensione variabile e potrebbero richiedere tempo diverso quindi differenziato due modi per calcolare il tempo di esecuzione\nNel caso peggiore\nPrendiamo Tempo(I) come tempo di esecuzione su una Istanza I allora il caso peggiore sar√†:\nIl massimo dell‚Äôinsieme di tutti i tempi delle istanze I, ovviamente parlando di istanze con dimensione n non potremmo avere un numero definito.\nT_{worst}(n)=max_{istanze \\ I \\ di \\ dimensione \\  n} \\ \\{Tempo(I)\\}\nT_{worst} sar√† una garanzia sul tempo di esecuzione e indicher√† il massimo sforzo che dovr√† fare la macchina per eseguire l‚Äôalgoritmo\nNel caso medio\nNel caso medio si calcola la probabilit√† del tempo di esecuzione delle istanze\nT_{avg}n=\\sum_{istanze \\ I \\ di \\ dimensione \\ n} \\{P(I)tempo(I)\\}\nOvviamente parlando di caso medio si pu√≤ dedurre come si tratti dei casi tipici degli input n\nCome capiamo la distribuzione di probabilit√† sulle istanze?\n\nDi solito non la conosciamo quindi facciamo delle assunzioni\n\nEsercizio per casa\nLa somma di n frazioni 1/n+1/n‚Ä¶n\nNotazione asintotica\nComplessit√† computazionale di un algoritmo espressa con T(n) in modo qualitativo quindi\nIgnoro\n\ncostanti\nordini inferiori\n\n\n\n                  \n                  Info\n                  \n                \n\nIl prof intende log come log_2\n\n\nT(n) √® il numero di passi elementari eseguiti su una RAM nel caso peggiore su una Istanza di dimensioni n\nESEMPIO DI NOTAZIONE ASINTOTICA\n\nVisto che siamo nel caso peggiore prenderemo la n pi√π grande\nQuindi T(n) √® asintoticamente proporzionale e a n^2\n\n\n                  \n                  Carrellata di esempi sulle slide a pagina 17-18 \n                  \n                \n\nDEFINIZIONI NOTAZIONI ASINTOTICHE(5)\n\nO\n\n\n\n                  \n                  Notazione asintotica  Serve per dare degli upper-bound \n                  \n                \n\n\n\n\n\n\\Omega\n\n\n\n                  \n                  lower-bound \n                  \n                \n\n\n\n\n\n\\Theta\n\n\n\n                  \n                  doppio confronto quindi uguali \n                  \n                \n\n\n\n\n\no\n\n\n\n                  \n                  rapp tra infiniti con 0 notare che \n                  \n                \n\no \\subset O\n\n\n\n5)\\omega\n\n\n                  \n                  infiniti con inf con \n                  \n                \n\n\\omega \\subset \\Omega\n\n\n\nPROPRIET√Ä NOTAZIONE ASINTOTICA (non devi saperle tutte )\n\n\nUsare la Notazione asintotica nelle analisi\n\n\nNotazione asintotica perch√® √® da fighi\n\nTi da una misura indipendente da quelle della macchina utilizzata\nI dettagli sono poco rilevanti si semplifica tutto\nanalizza il numero dei passi in modo abbastanza dettagliato\ndescrive abbastanza bene gli algoritmi\n"},"UNI/ANNO-2/ALGORITMI-1/ALGORITMI-LEZ.4":{"slug":"UNI/ANNO-2/ALGORITMI-1/ALGORITMI-LEZ.4","filePath":"UNI/ANNO 2/ALGORITMI 1/ALGORITMI LEZ.4.md","title":"ALGORITMI LEZ.4","links":["UNI/ANNO-2/ALGORITMI-1/fotoalg/cap2.pdf","UNI/ANNO-2/ALGORITMI-1/ALGORITMI-LEZ.2","UNI/ANNO-2/ALGORITMI-1/ALGORITMI-LEZ.5"],"tags":[],"content":"pdf della lezione 4\nEsercizio per casa\nN-1n/2\nALGORITMI DI RICERCA\nALGORITMO DI RICERCA DI UN ELEMENTO IN UN ARRAY NON ORDINATO\n\nalg1. Scorriamo tutto il vettore finch√©  non troviamo il numero\n\n\nT_{worst}=n ovvero n passaggi del for nel caso peggiore\nT_{avg}=n+1/2\n\n\n                  \n                  pk n+1/2? \n                  \n                \n\n\n\n\nQuindi\nT_{worst}=\\Theta n\nT_{avg}=\\Theta n\nALGORITMO DI RICERCA DI UN ELEMENTO IN UN ARRAY ORDINATO BINARIA\nTecnica divide and conquer\nParto con una una posizione nel mezzo dell‚Äôarray e confronto ricorsivamente se ci troviamo dopo o prima della nostra posizione attuale, cos√¨ da ridurre le possibili ‚Äúcelle‚Äù dell‚Äôarray da cercare\n\ni e j sono degli indici\nla funzione √® di tipo ricorsivo\n\n\n\n\n                  \n                  Example\n                  \n                \n\n\n\n\nT(n)=T(n/2)+O(1)\nT(n)=log_n\n\n\n                  \n                  perch√® log? ALGORITMI LEZ.2\nL&#039;obiettivo √® quello di usare lo srotolamento srotolando n/2 portando le cose al passo i\nSe mi aprissi la T avrei ogni volta degli O(1)\n\n                  \n                \nPer spiegarlo mi riprendo alle slide del prof della \n\nLE EQUAZIONI DI RICORRENZA\nLe equazioni di ricorrenza servono per calcolare i relativi costi computazionali di algoritmi ricorsivi.\nLe abbiamo usate fino ad ora e si possono svolgere in diversi modi\nMetodi per svolgere equazioni di ricorrenza\nMetodo dell‚Äôiterazione\nObiettivo: srotolare la ricorsione finch√© non arrivi ad avere T(1)\n\n\n                  \n                  ESEMPIO 1: \n                  \n                \n\n\n\n\n\n\n                  \n                  ESEMPIO 2: \n                  \n                \n\n\n\n\n\n\n                  \n                  ESEMPIO 3: \n                  \n                \n\n\nquindi alla fine scappa fuori \\Theta (1)\n\n\n\n\n                  \n                  Esercizi per casa su questo metodo \n                  \n                \n\n\n\n\n\n\nMetodo dell‚Äôalbero della ricorsione\nObiettivo: disegnare un albero con tutte le varie chiamate ricorsive indicando la dimensione di ogni nodo e stimare il costo di ogni nodo e sommarlo con tutti i nodi\n\nT(n) √® proporzionale al numero di nodi\n\n\n\n                  \n                  ESEMPIO 1: \n                  \n                \n\n\nl‚Äôalbero ha n nodi \\Theta (n) per il discorso della proporzionalit√†\n\n\n\n\n                  \n                  ESEMPIO 2 \n                  \n                \n\nSimile all‚Äôesempio 1 ma avremmo un costo per nodo al pi√π n quindi con un upper-bound con O(n^2)\nora si chiede se √® un \\Theta per dimostrarlo user√† il doppio confronto con \\Omega\n\nper dimostrare l‚Äôomega si prende la met√† superiore dei nodi e definisce che ognuno di quei nodi costa almeno n/2, poi moltiplica il num di nodi per il costo di ogni nodo e visto che esce \\ge\nuseremmo \\Omega\n\n\n\n\n                  \n                  ESEMPIO 3 \n                  \n                \n\nh √® uguale al cammino(num collegamenti) pi√π lungo quindi n-1\n\nper fare T(n) moltiplica la somma dei nodi con il costo di ogni nodo sostituendo ad h l‚Äôaltezza\n\n\n\n\n\n                  \n                  ESEMPIO 4 \n                  \n                \n\nuguale all‚Äôesempio 3 ma con costi di un nodo con n\nvisto che abbiamo n il costo √® al pi√π n quindi useremo O\n\n\n\n\n\n                  \n                  ESEMPIO 5 \n                  \n                \n\nPer definire il costo di un algoritmo uso un‚Äôaltro algoritmo come confronto\n\n\n\n\n\n\n                  \n                  esercizi per casa su questo metodo \n                  \n                \n\n\nper Esempio 1 fare\n\n\n\n\n                  \n                  il professore ogni volta che ha dei log in qualche base visto che la base √® una non la scrive \n                  \n                \n\n\n\n                  \n                  ESEMPIO 6 \n                  \n                \n\n\nci rendiamo conto che a sx scende di meno di quello a dx e che a sx cresce con i fratti di 3 invece a dx con i fratti di 2/3 per dei calcoli matematici sx log3 e dx log 3/2\nmoltiplicheremo il costo di ogni livello per i livelli dell‚Äôalbero con upper-bound quindi con il ramo che si estende di pi√π a dx\n\nper fare il lower-bound bisogna invece prendere i rami pi√π corti e moltiplicarli sempre con i costi di ogni livello quindi al pi√π n\nuna volta verificati entrambi potremmo dire che si parla di \\Theta\n\n\naltri metodi sulla lezione 5"},"UNI/ANNO-2/ALGORITMI-1/ALGORITMI-LEZ.5":{"slug":"UNI/ANNO-2/ALGORITMI-1/ALGORITMI-LEZ.5","filePath":"UNI/ANNO 2/ALGORITMI 1/ALGORITMI LEZ.5.md","title":"ALGORITMI LEZ.5","links":["UNI/ANNO-2/ALGORITMI-1/fotoalg/cap2.pdf"],"tags":[],"content":"pdf della lezione5 (31)\nI due metodi visti in precedenza sono intuitivi e semplici ma a volte rischiosi perch√© poco preciso.\nCi sono altri metodi pi√π precisi\nMetodo della sostituzione\nAbbiamo una equazione di ricorrenza, prima dobbiamo intuire la forma della soluzione al livello asintotico(guess)\n\nabbiamo una equazione di ricorrenza\ntroviamo una forma della soluzione al livello asintotico(guess) ad es.O(n^3)\nutilizziamo l‚Äôinduzione per verificare l‚Äôipotesi\nrisolviamo per le costanti\n\n\n\n                  \n                  come posso capire la mia ipotesi? \n                  \n                \n\n\nutilizzo in modo raffazzonato le conoscenze che ho dagli esercizi precedenti con equazioni di ricorrenza simili e faccio una stima dell‚Äôandamento della funzione\nvado a tentativi partendo da una O meno efficiente\n\n\n\n\n\n                  \n                  esempio 1 \n                  \n                \n\nPoniamo un upper-bound molto generico e prendiamo la sua c per evitare di fare notazioni asintotiche nelle induzioni che sono estremamente difficili\n\nfaccio il passo base e pongo T(n) in base alla mia ipotesi(cerchio in blu)\nper il passo induttivo pongo una k esprimerlo\nsostituisco c alla mia T nella parte destra e raccolgo per escludermi la n\n\n\n\n\n                  \n                  esempio 2 \n                  \n                \n\nIl goal √® vero se e solo se il residuo √® \\geq 0 perch√© significherebbe che ho una cosa pi√π\ngrande del mio upper-bound(goal) che mi sono posto\nAl posto di T(n/2) sostituire c k al cubo\n\n\n\n\n\n                  \n                  esempio 3 \n                  \n                \n\n= a esempio 2 ma con O(n^2)\nLa dimostrazione non si riesce a chiudere quindi non posso concludere n√© che sia vera n√©\nche sia falsa non funziona perch√© l‚Äôipotesi induttiva non √® abbastanza grande,\n\nconviene usare qualcosa di pi√π forte quindi proviamo a dimostrare per qualcosa che ci fa uscire una cosa maggiore per mangiare il termine che ci dava fastidio\n\n\n\nMettiamo che si scopre che l‚Äôalgoritmo costi O(n^3) ma poi si scopre che valga anche O(n^2) per farlo non c‚Äô√® un modo per capirlo subito ma bisogna andare a tentativi con tecniche di analisi per un algoritmo\nTecnica del divide et impera\nla tecnica del divide et impera si utilizza il 99% delle volte per una forma di questo tipo\n\ndividi il problema (di dimensione n) in a sotto-problemi di dimensione n/b\nrisolvi i sotto-problemi ricorsivamente - ricombina le soluzioni\n\n\n\n\n                  \n                  problema di Fibonacci6 con divide et impera \n                  \n                \n\n\n\nuna vola trovata l‚Äôequazione di ricorrenza possiamo procedere ad individuare a,b\\ e\\ f(n)\n\n\n\n\n                  \n                  la tecnica del divide et impera riguarda la suddivisione in a,b\\ e\\ f(n)\n                  \n                \n\nteorema master enunciato(easy)\n\nNoi facciamo un confronto asintotico su chi va pi√π velocemente a infinito tra una funzione che ci creiamo basandoci sulla suddivisione del divide et impera e una f(n)\n\nSe hanno stesso ordine asintotico ‚Üí T(n) = \\Theta (f(n) \\ log \\ n)\nSe una delle due √® ‚Äúpolinomialmente‚Äù pi√π veloce ‚Üí T(n) ha l‚Äôordine asintotico della pi√π veloce\n\n\n\n\nEntrando un po‚Äô pi√π nello specifico avremo i seguenti casi\n\nEnunciato hard teorema master sul libro ‚Üí non chieder√† la dimostrazione\n\n\n                  \n                  ESEMPIO 1 \n                  \n                \n\nDefinisco  a,b\\ e\\ f(n)\nfaccio un confronto asintotico e sono identici\nOvviamente esce theta di nlogn\n\n\n\n\n\n                  \n                  ESEMPIO 2 \n                  \n                \n\nfacciamo i passaggi uguali all‚Äôesercizio precedente solo che ora ha vinto n^{1/2} e quindi rientriamo nel caso 1\n\n\n\n\n\n                  \n                  ESEMPIO 3 \n                  \n                \n\nrivedere meglio la parte finale\n\n\n\n\n\n                  \n                  Esempio 4 \n                  \n                \n\nnon si pu√≤ fare il teorema master perch√® al variare di \\epsilon cambia il confronto asintotico\n\n\n\n\n\n                  \n                  ESEMPIO 5 \n                  \n                \n\nNlogn +2tn/2\nUso il caso 3 ma non scappa bene quindi non ci dice la soluzione\n\n\nCambio di variabile\nPresto lo dimenticheremo ci dobbiamo solo ricordare questo esempio e basta (GODO)\n\neffettuo una sostituzione di variabile per ricondurmi a una forma nota\nuna volta rappresentata la sostituzione ne effettuo un‚Äôaltra con R(x) per rappresentarla consiglio di vedere gli argomenti della funzione R rispetto a T\nora sono in una forma notevole che gi√† conosco e costa O(log \\ x)\nsostituisco la x con la vera x\nfine\n\n\n\n\n                  \n                  due problemi per casa \n                  \n                \n\n\n\n1 algoritmo ricorsivo e analisi con equazioni di ricorrenza\n\n\n2 trovare un algoritmo ricorsivo e vedere quanti spostamenti fa con equazioni ricorrenza ecc\n\n\n\n"},"UNI/ANNO-2/ALGORITMI-1/ALGORITMI-LEZ.6":{"slug":"UNI/ANNO-2/ALGORITMI-1/ALGORITMI-LEZ.6","filePath":"UNI/ANNO 2/ALGORITMI 1/ALGORITMI LEZ.6.md","title":"ALGORITMI LEZ.6","links":["UNI/ANNO-2/ALGORITMI-1/fotoalg/cap4.pdf"],"tags":[],"content":"pdf della lezione 6\nAlgoritmi di ordinamento\ngli algoritmi di ordinamento hanno un insieme di n numeri in input e in output devono stamparli in ordine crescente quindi dove ogni numero precedente deve essere pi√π piccolo del successivo\n\nAlgoritmo 1 Selection Sort\n\nAlgoritmo semplice da applicare ma poco efficiente\n\nCome funziona?\nCi scorriamo il nostro array e ad ogni elemento facciamo un controllo su qual √® l‚Äôelemento pi√π piccolo in quella determinata posizione\n\n\nPSEUDOCODICE\n\n\nIl primo ciclo for scorrer√† tutto l‚Äôarray partendo da una posizione definita\nAd ogni posizione del primo ciclo for faremo un confronto tra tutti i successivi dettati da j e li confrontiamo con la posizione m, se troviamo un numero pi√π piccolo di quello in posizione m la nuova m diventer√† la posizione che abbiamo trovato essere la pi√π piccola\nla m sostanzialmente indica lo smallest e la k del for iniziale i round(vedi gif sopra)\nsostituir√† la posizione del pi√π piccolo di quel momento con la posizione del successivo, quindi\npiccola precisazione, per il prof la posizione 0 non si scambia.\nn-2 alla condizione del primo for perch√© controllare l‚Äôultima posizione √® inutile\n\nParentesi sulle invarianti\nle invarianti sono delle propriet√† che devono rimanere immutate nella fase di esecuzione dell‚Äôalgoritmo e che ci servono per capire se un algoritmo √® corretto perch√© permette di isolare propriet√† dell‚Äôalgoritmo, spiegarne il funzionamento, capire a fondo l‚Äôidea su cui si basa.\nin questo caso abbiamo due  invarianti definite su un generico passo k:\n\ni precedenti di k+1 sono gi√† ordinati\ni precedenti di k+1 sono gli elementi pi√π piccoli dell‚Äôarray\n\nComplessit√† temporale del seguente algoritmo\nVedremo solo upper-bound e lower-bound\nNel caso di upper-bound\n\nil for sopra lo facciamo al pi√π n volte\ne quello dentro anche al pi√π n volte in modo molto approssimato\nper il nostro modello RAM ogni riga di codice ci costa tempo costante\nnoi avremo quindi 5 righe di codice che saranno eseguite al pi√π n^2 volte\n\n\ncaso lower-bound\nprendiamo per fare il lower-bound la parte che ci esegue pi√π operazioni\n\novviamente √® il for interno\nper calcolare il numero di passaggi dentro a quel for faremo una sommatoria che va da k=0 a n-2 ovvero il numero dei passaggi del for superiore,\nsuccessivamente so che il primo elemento dell‚Äôarray non viene confrontato quindi ho n-1 confronti quindi so che il ciclo for dentro √® n-(k+2) ma visto che il nostro array lo prendiamo come se partisse da 1 sommiamo 1 e quindi avremmo n-k-1\n\n\nquindi abbiamo in tutto \\Theta (n^2)\nAlgoritmo 2 Insertion Sort\n\nAlgoritmo simile al precedente funziona tipo con le carte\n\nCome funziona?\nSi scorre l‚Äôarray fino a n-1 confrontando l‚Äôelemento nella posizione corrente con i precedenti finch√© non trova un punto in cui risulta maggiore del precedente controllato\n\n\nPSEUDOCODICE\nComplessit√† temporale del seguente algoritmo\n\\Theta(n^2)\nAlgoritmo 3 Bubble Sort\n\ngli elementi pi√π grandi vengono spinti verso destra confrontando gli elementi adiacenti tra loro\n\nCome funziona?\nSi scorre l‚Äôarray n-1 volte per un numero di i volte, dovuto al fatto che dobbiamo ogni volta scorrere il nostro array diverse volte, ad ogni posizione nell‚Äôarray confrontiamo il numero di quella posizione con il numero nella posizione precedente, e andiamo avanti cos√¨ finch√© l‚Äôarray non √® ordinato\n\n\nPSEUDOCODICE\nComplessit√† temporale del seguente algoritmo\n\\Theta(n^2)\nAlgoritmi sotto il quadrato\nAlgoritmo 4 Merge Sort\n\nIl merge sort √® un algoritmo che applica il divide et impera e ha un costo pi√π basso degli altri\n\nCome funziona?\n\nPSEUDO-CODICE\nMergeSort(A, i, f)\n1.  if(i &lt; f)  then\n2.     m = PARTE_INFERIORE[(i + f) / 2]\n3.     MergeSort(A, i, m)\n4.     MergeSort(A, m+1, f)\n5.     Merge(A, i, m, f)\n \n6.  if(i = f) then return A[i] \n\n\nse gli indici inizio &lt; fine entro nell‚ÄôIF\n\n\ntrovo la met√†\n\n\ncalcolo ricorsivamente il MergeSort della prima met√†\n\nfintanto che i &lt; f (quindi fino a quando non ho UN SINGOLO ELEMENTO DA PASSARE AL MERGESORT) calcolo ricorsivamente;\nquando ho un singolo elemento vuol dire i = f, quindi ritorno quel valore\na questo punto ho i risultati della riga 3 e 4 del penultimo MergeSort chiamato\nripercorro tutto tornando sopra e avr√≤ il risultato finale della riga 3 chiamata la prima volta (in pratica ho la prima met√† ordinata)\n\n\n\ncalcolo ricorsivamente il MergeSort della seconda met√†\n\nrifaccio la stessa cosa che ho scritto nel punto 3\n\n\n\nQUANDO HO IL RISULTATO DEL PUNTO 3 E 4 posso eseguire il merge.\n\n\nAlgoritmo 4.5 Merge\n\nIl merge √® quell‚Äôalgoritmo che ci consente di fondere due array A e B e che sono entrambi ordinati singolarmente\n\nCome funziona?\n\nestrai ripetutamente il minimo di A e B e copialo nell‚Äôarray di output, finch√© A oppure B non diventa vuoto\ncopia gli elementi dell‚Äôarray non vuoto alla fine dell‚Äôarray di output\n\n\n\nPSEUDOCODICE\n\n\nLa funzione Merge prende come argomento\n\nl‚Äôarray(A)\nla posizione iniziale(i_1)\nla posizione al centro(f_1)\nla posizione finale(f_2)\n\n\ncrea un array lungo quanto la posizione finale-inizio+1\ni √® uguale a 1 perch√© alcune volte lo pseudo codice si fa con array che partono da 1\nk_1 prende il valore iniziale k_2 prende il valore dell‚Äôinizio della seconda parte dell‚Äôarray\ninseriamo gli elementi dei vari array scambiando in base alla necessit√† quale prendere in considerazione dei due per l‚Äôinserimento\n\nad ogni assegnazione nell‚Äôarray incremento i e k_1 se uso l‚Äôarray1 oppure k_2 se uso array2\n\n\nse alla fine del for k_1 deve ancora finire di inserirsi del tutto metter√≤ per completezza gli ultimi elementi alla fine dell‚Äôarray, oppure copio gli ultimi elementi di k_2\nmettiamo x nelle posizioni dell‚Äôarray che avevamo\nfine.\n\nComplessit√† temporale del Merge\nOgni passaggio costa un elemento delle due sequenze che abbiamo che saranno rispettivamente lunghe n_1 e l‚Äôaltra n_2, visto che ogni passaggio costa un elemento delle due avremmo sicuramente il while che costa tutto n_1 e un po‚Äô di n_2 oppure viceversa, poi i restanti elementi del vettore che manca da mettere dentro X saranno aggiunti con una funzione di copia che avr√† tempo lineare\nquindi alla fine avremmo \\Theta (n_1+n_2)\nComplessit√† temporale del Merge Sort\nAbbiamo due chiamate ricorsive che ogni volta diminuiscono proporzionalmente di n/2 e ad ogni chiamata di funzione faremo un merge che costa O(n) O perch√© alle ultime chiamate non facciamo esattamente n\npoi applichiamo il teorema master per svolgere questa equazione di ricorrenza\n\nQuanta memoria (ausiliaria) usiamo?\n\\Theta(n) perch√© l‚Äôunica cosa che occupa memoria √® la creazione dell‚Äôarray ausiliario ad ogni chiamata del merge, ogni chiamata del merge avviene singolarmente e non se ne eseguono pi√π di una nello stesso tempo perci√≤ il costo rimarr√† sempre \\Theta (n), anche se vedessimo il costo di tutte le chiamate contemporanee di merge sort avremmo logn dato dal T(n/2), comunque logn √® asintoticamente pi√π lento di n e quindi non lo consideriamo in memoria\nAlgoritmo 5 Quick Sort\n\nIl quick sort √® un algoritmo che ha un costo sotto n^2 e che usa la tecnica del divide et impera\n\nCome funziona?\nricorsivamente chiamo Partition dove si pone un perno e si fanno scorrere due controlli\n\nda sinistra verso destra dell‚Äôarray controllo se il numero preso in quel momento √® maggiore del perno\nda destra verso sinistra dell‚Äôarray se il numero preso in quel momento √® minore del perno\nse si verificano quelle condizioni avviene uno scambio tra i due\n\n\nFunzionamento algoritmo Partition\n\nPSEUDOCODICE Partition\n\n\nogni volta viene creato un perno x dato dalla posizione A[i]\n\nla parte inferiore √® data da i\nla parte superiore dalla fine +1\n\n\nfacciamo un ciclo while che continua finch√© non si attiva il break\nabbiamo quei due cicli che dicevamo prima che scorrono da dx a sx e viceversa che si fermano se trovano una contraddizione della richiesta di una tipica lista ordinata\n\nha senso il fatto che da sx verso dx cerchi il maggiore perch√© cos√¨ se abbiamo sempre numeri minori significa che siamo su un punto gi√† ordinato e che non dobbiamo togliere\nstessa cosa vale da dx a sx\n\n\nuna volta terminato i due cicli procediamo a fare uno scambio se inf continua a essere pi√π piccolo del sup(significa che i due non si stanno incrociando)\nse si incrociano usciamo e mettiamo il perno ‚Äúal centro‚Äù ovvero il punto dove doveva stare perch√© sup sar√† arrivato dove doveva arrivare\nrestituiamo la posizione del perno\n\nPSEUDOCODICE Quick Sort\n\nIl quicksort principalmente serve per andare a fare il partition e le varie chiamate ricorsive una a sx dell‚Äôarray e una a dx, partition ogni volta inserisce nella posizione corretta il perno mettendo nell‚Äôemisfero sinistro dell‚Äôarray i numeri pi√π piccini del perno e a dx i pi√π grandicelli\nFunzionamento algoritmo Quick Sort\n\n\napplica il partition e ordina in base al perno facendo quella cosa sx e dx\nchiama ricorsivamente due chiamate quick una con gli elementi a sx e una con gli elementi a dx del perno\nfa la cosa ricorsivamente modificando l‚Äôarray\n\nComplessit√†\n\nAd ogni invocazione il perno scelto in quel momento viene posizionato correttamente\ndopo n invocazioni di costo O(n) ho il vettore ordinato, se lo vedessi su un albero farei n*O(n) e quindi O(n^2)\ni due casi peggiori sono che ho il perno scelto come numero pi√π piccolo o pi√π grande in assoluto e quindi ho difficolt√† a fare un confronto con il &lt; o &gt;\nquindi avrei complessit√†\nT(n) = T(n-1) + T(0) + O(n) = T(n-1) + O(1)+O(n) = T(n-1) + O(n)\n= T(n) = O(n^2)\n\nCaso Migliore\n√à facile intuire che il miglioramento di costo avviene quando le partizioni sono bilanciate ovvero il perno viene posto al centro dell‚Äôarray, mentre all‚Äôaumentare dello sbilanciamento il tutto si complica.\nCaso Medio\n\nNel caso medio si osserva che anche se il 90% degli elementi sta a sinistra del perno e il restante 10% a destra il QuickSort ha comunque un costo di nlog(n)\nTutti i vari casi medi dello stesso problema avranno la medesima altezza dell‚Äôalbero.\nquicksort randomizzato\n\nScegli un perno a caso\nil costi non cambiano\nma il caso medio non esiste\n\n"},"UNI/ANNO-2/ALGORITMI-1/ALGORITMI-LEZ.7":{"slug":"UNI/ANNO-2/ALGORITMI-1/ALGORITMI-LEZ.7","filePath":"UNI/ANNO 2/ALGORITMI 1/ALGORITMI LEZ.7.md","title":"ALGORITMI LEZ.7","links":["UNI/ANNO-2/ALGORITMI-1/fotoalg/cap4.5.pdf","UNI/ANNO-2/ALGORITMI-1/ALGORITMI-LEZ.5"],"tags":[],"content":"pdf della lezione 7\nHeap sort\nCome funziona?\n\nHa un approccio simile al [[ALGORITMI LEZ.6#algoritmo-1-selection-sort|selection sort]]\nmetodo di progettazione mediante struttura dati efficiente O(log_n)\nseleziona i numeri dal pi√π grande al pi√π piccolo(cercando il massimo e portandolo in fondo)\n\n\n\n                  \n                  differenza rispetto al selection sort? \n                  \n                \n\nusa una struttura dati che ci permette di estrapolare il massimo in tempo logaritmico\n\n\n\n\n                  \n                  differenza tra tipo di dato e struttura dati \n                  \n                \n\n\ntipo di dato: definisce il modo in cui una collezione di oggetti √® fatta, come ad esempio un dizionario avr√† chiave valore, i suoi metodi insert, search ecc‚Ä¶\nstruttura dati spiega come una collezione di oggetti deve funzionare in termini di algoritmi efficienti\n\n\n\nOBIETTIVO\nPer fare l‚Äôheap sort bisogna progettare una struttura dati che abbia le seguenti caratteristiche:\n\nDato un Array A generare H velocemente\nTrovare il valore pi√π grande in H\nCancellare l‚Äôoggetto pi√π grande in H\n\nAlbero d-ario\nUn albero che ha tutti i nodi interni con al pi√π d figli\n\n\n                  \n                  precisazioni su alberi \n                  \n                \n\n\nRADICE, origine\nPADRE, nodo che genera un altro nodo\nFIGLIO, nodo generato da un padre\nFRATELLI, figli dello stesso padre\nNODO INTERNO, che √® sia figlio che padre\nFOGLIA, nodo senza figli\nLIVELLI, nodi paralleli\nALTEZZA, cammino pi√π lungo partendo dalla foglia fino alla radice contando le freccette\n\n\n\n\nAlbero Completo=Albero che ha nodi interni con d figli e non al pi√π\n\nSpecifichiamo meglio la struttura dati che useremo per l‚Äôheap\n\nAbbiamo una struttura dati associata a un insieme di elementi S (i numeri disordinati)\nDeve essere COMPLETO fino al penultimo livello\n\ndeve essere rafforzato quindi a sinistra deve essere compattato\n\n\nGli elementi di S sono memorizzati singolarmente in ogni nodo v\ndeve esserci questa propriet√† chiave(padre(v))\\geq chiave(v) \\forall \\ nodo \\ eccetto \\ v\n\n\n\n                  \n                  esempio \n                  \n                \n\n\n\n\nse questo albero ha n nodi la sua altezza non puo essere tantissima\n3 proprieta salienti\n\nil valore massimo dell‚Äôinsieme S √® nella radice\nalbero con n nodi √® alto O(log_n) (lo vediamo subito dopo)\nun heap con struttura rafforzata pu√≤ essere rappresentato con un array di dimensione n\n\nDimostrazione punto 2\n\nprendiamo l‚Äôalbero come completo fino al penultimo livello e avr√≤ una sommatoria\nmetto 1+ perch√® rappresenta il nodo che deve essere almeno 1 della parte rafforzata\nil numero di nodi deve essere maggiore dell‚Äôaltezza\nla sua altezza deve essere pi√π piccola della sua larghezza\n\n\n\nDimostrazione punto 3\ndimostriamo che sia sufficiente un array lungo n applicando queste regolette mentre inseriamo gli elementi dell‚Äôalbero dall‚Äôalto verso il basso\n\nla posizione 0 non la usiamo\nil nodo a sinistra verr√† posizionato nella posizione doppia a i dove siamo quindi 2i\nil nodo a destra verr√† posizionato nella posizione doppia a i+1 quindi 2i+1\nogni padre si posiziona in \\lfloor i/2 \\rfloor\nnello pseudocodice verr√† indicato con heapsize([A])\n\n\n\n\n                  \n                  se si ha bisogno di vedere un&#039;altro esempio \n                  \n                \n\n\n\n\nFunzione FixHeap\nQuando abbiamo un albero che ha una radice pi√π piccola non abbiamo un heap\n\nper albero si intende anche eventuali sotto alberi\nper risolverlo usiamo FixHeap\n\n\nPSEUDOCODICE FixHeap\nfixHeap(nodo v, heap H)\n    if (v non √® una foglia) then\n    // sia u il figlio di v con chiave massima\n    if ( chiave(v) &lt; chiave(u) ) then\n        scambia chiave(v) e chiave(u)\n        fixHeap(u,H)\n\n\n                  \n                  codice di Guala complesso \n                  \n                \n\nfixHeap(i, A)    // i √® una posizione, A √® l&#039;array\n1.   s = sin(i)  // ricorda che sin(i) = 2i, s √® una posizione\n2.   d = des(i)  // ricorda che des(i) = 2i+1, d √® una posizione\n3.   n = heapsize[A]  // numero di elementi totale di A\n \n4.   if (s ‚â§ n e A[s] &gt; A[i])  \n5.       then massimo = s   // se s √® pi√π grande di suo padre devo scambiarlo\n6.   else massimo = i       // se s non √® pi√π grande di suo padre lo lascio\n \n7.   if (d ‚â§ n e A[d] &gt; A[massimo])\n8.       then massimo = d  // se d √® pi√π grande di suo padre devo scambiarlo\n \n9.   if (massimo ‚â† i)   // questo vuol dire che i deve essere scambiato\n10.       then scambia A[i] e A[massimo]\n11.      fixHeap(massimo, A)\n\ns e d rappresentano le posizioni degli elementi a sinistra e a destra della radice che prendiamo come inizio albero ricorsivo\nfaccio due controlli uno per il ramo di sinistra e uno per il ramo di destra\n\ncontrollo se s o d sta sforando la dimensione dell‚Äôarray e controllo se l‚Äôarray nella posizione sinistra o destra √® pi√π grande del padre preso in quella determinata ricorsione(all‚Äôinizio potrebbe essere la radice)\nse si verificano uno dei due uso una variabile massimo per salvare la posizione altrimenti massimo rimane i\n\n\nse massimo √® stato cambiato scambio le due posizioni e richiamo la funzione ricorsiva prendendo il ramo pi√π grande\n\n\n\n\n\n                  \n                  animazione FixHeap\n                  \n                \n\n\n\n\nComplessit√† FixHeap\nO(log_n)\nAlgoritmo per trovare il massimo\n\nl‚Äôalbero deve essere un Heap\nscambiamo la radice dell‚Äôalbero con l‚Äôultima posizione a destra dell‚Äôalbero\ntogliamo la foglia(la radice) e la mettiamo da parte\nApplichiamo FixHeap per riordinare il tutto\n\n\nComplessit√† Trovare il massimo\nO(log_n)\nHeapify\n\nper avere gli elementi disposti bene far√≤ delle chiamate ricorsive fino alla fine dell‚Äôalbero dividendo parte sx dalla parte dx, una volta arrivato alla fine dell‚Äôalbero inizio a organizzare correttamente gli elementi prendendo padre per padre con FixHeap\n\nPrendo il sottoalbero sinistro e lo faccio diventare un heap\nfaccio la stessa cosa con il destro\nMI RITROVO NELLA SITUAZIONE IDEALE DEL FixHeap, lo eseguo cos√¨ avr√≤ la struttura HEAP da cui posso estrarre il massimo.\n\n\n\nPSEUDOCODICE Heapify\nheapify(heap H)\n    Se (H non √® vuoto) then\n        heapify(sottoalbero sinistro di H)\n        heapify(sottoalbero destro di H)\n        fixHeap(radice di H, H)\nComplessit√† Heapify\nPer calcolare la complessit√† in modo semplice noi cerchiamo di calcolarlo su un albero completo binario e non come dovrebbe essere un heap\nquindi se l‚Äôalbero ha n elementi noi avremo n&#039;\\geq n e sia un ipotetico heap con n&#039;\n\ndi altezza h\ncompleto fino alla fine\nci sar√† la seguente considerazione\n\nT(n)\\leq T(n&#039;)\nvisto che n rappresenta l‚Äôheap rafforzato e n&#039; rappresenta solo n ma con i nodi in pi√π per renderlo completo, inevitabilmente avr√≤ che n&#039;\\leq 2n\n\n\n\n\nApplico Teorema Master\n\nT(n) \\le T(n&#039;) = O(n&#039;) = O(2n) = O(n)\nvisto che prima abbiamo detto che n&#039;\\leq 2n allora inevitabilmente 2n lo posso scrivere come n  e fine.\nMax Heap e Min Heap\ngi√† abbiamo visto l‚Äôalgoritmo per trovare il massimo, se vogliamo farlo con il min useremo algoritmi simili ma con \\leq\nusare Max √® meglio di min per fare il sort e lo vederemo subito\nL‚ÄôHeap Sort\n\nCrea un Heap con Heapify\nEstrae il massimo n-1 volte mette il massimo nella posizione libera dell‚Äôarray\n\nheapSort(A)\n1. Heapify(A)    //O(n)\n2. Heapsize[A] = n   // calcolo la grandezza dell&#039;array\n \n// da 3-6, n-1 estrazioni di costo O(log(n))\n3. for i = n down to 2 do  // fino a 2 perch√© parto dalla posizione 1\n \n4.     scambia A[1] e A[i]  // scambio l&#039;elemento in posizione 1 (il max) con    \n                            // quello in posizione i (il min)\n \n5.     Heapsize[A] = Heapsize[A] - 1  // diminuisco la dimensione dell&#039;array perch√© \n                                    // so che l&#039;ultimo elemento √® ordinato\n \n6.     fixHeap(1, A)  // devo riordinare l&#039;array perch√© ora ho il min in cima \n                      // all&#039;albero e non va bene\n\n\n\n                  \n                  TEOREMA \n                  \n                \n\nL‚Äôalgoritmo HeapSort ordina in loco un array di lunghezza n in tempo O(n log n) nel caso peggiore.\n\n\n\n\n                  \n                  Perch√© abbiamo utilizzato il Max-Heap e non il Min-Heap? \n                  \n                \n\nnel senso perch√© estraiamo il pi√π grande e non il pi√π piccolo?\nPerch√© cos√¨ utilizziamo memoria costante, con il Min-Heap utilizzeremo memoria lineare.\n\n"},"UNI/ANNO-2/ALGORITMI-1/ALGORITMI-LEZ.8":{"slug":"UNI/ANNO-2/ALGORITMI-1/ALGORITMI-LEZ.8","filePath":"UNI/ANNO 2/ALGORITMI 1/ALGORITMI LEZ.8.md","title":"ALGORITMI LEZ.8","links":["UNI/ANNO-2/ALGORITMI-1/fotoalg/cap4.7.pdf"],"tags":[],"content":"pdf della lezione 8\nComplessit√† di un algoritmo\nFino ad ora abbiamo sempre definito la complessit√† di un algoritmo basandoci su delle risorse\nche staranno in un upper-bound o lower-bound\n\nlower-bound: definisco un \\Omega (f(n)) tale che tutte le risorse che genero r(n) del mio algoritmo rispettino la seguente condizione r(n)=\\Omega(f(n)) nel caso peggiore\n\nf(n) √® il ‚Äúpunto minimo‚Äù da cui partire, e posso solo andare a salire.\n\n\nupper-bound: definisco un O (f(n)) tale che tutte le risorse che genero r(n) del mio algoritmo rispettino la seguente condizione r(n)=Of(n)) nel caso peggiore\n\nf(n) √® il ‚Äúpunto massimo‚Äù che posso raggiungere, e posso solo andare sotto a lui\n\n\n\n\n\n                  \n                  che intende per risorsa di calcolo? \n                  \n                \n\nmemoria o spazio utilizzati\n\n\n\nlower-bound di un problema: minimo si sta a quel determinato costo computazionale\nper dimostrare un lower bound in termini di costi si puo usare una tecnica che usa gli alberi di decisione(non funziona con tutti gli algoritmi ma solo su algoritmi basati su confronti)\n\nAnalizzare invece un problema e non un algoritmo\n\n\n                  \n                  come vedo io la differenza tra problema e algoritmo \n                  \n                \n\n\nil problema rappresenta una cosa risolvibile con pi√π algoritmi e quindi i costi devono definire ogni algoritmo\nl‚Äôalgoritmo invece √® una singola istanza del problema che lo risolve\n\n\n\nUn problema ha una complessit√† rispetto ad una risorsa di calcolo definibile in due casi\n\nlower bound:  se ogni algoritmo del problema P ha costo di esecuzione nel caso peggiore di \\Omega(f(n)) in quella determinata risorsa\nupper bound:  se esiste almeno un algoritmo del problema P che ha costo di esecuzione nel caso peggiore O(f(n)) rispetto a una determinata risorsa\n\nQuando un algoritmo √® ottimale?\nUn algoritmo si dice ottimale quando abbiamo un problema con lower-bound tipo \\Omega(f(n)) e l‚Äôalgoritmo riesce a risolvere il problema rispetto a quella risorsa di calcolo in O(f(n))  quindi in maniera Ottima, ovvero che pi√π di cos√¨ non si pu√≤ fare\nEsempio con ordinamento\nse ho n numeri e voglio ordinarli ad esempio il lower-bound potrebbe essere \\Omega(n)\nma non sappiamo algoritmi che fanno la cosa in n ma solo con upper-bound tipo nlogn\nquindi abbiamo un gap\npossiamo fare meglio?\nComplessit√† temporale del problema dell‚Äôordinamento\n\n\nLower bound: \\Omega(n)\n\nun algoritmo che deve ordinare n per forza di cose deve vederli tutti.\nnon esiste al momento nessun algoritmo che costi n\n\n\n\nupper-bound: O(n^2)\n\nInsertion Sort\nSelection Sort\nQuick Sort\nBubble Sort\n\n\n\nupper-Bound migliore: O(n \\space log(n))\n\nMerge Sort\nHeap Sort\nQuesti due algoritmi, sulla base della definizione di prima, sono definiti ottimi all‚Äôinterno della classe degli algoritmi basati su confronti.\n\n\n\nAbbiamo quindi un gap di log (n) tra il lower-bound e il miglior upper-bound.\nCome accennato prima, **tutti questi algoritmi sono basati su CONFRONTI.\nAlgoritmi basati su confronti\nSono tutti quegli algoritmi che confrontano gli elementi per dare un risultato.\n\n\n                  \n                  Tutti gli algoritmi che abbiamo visto sono per confronto e quindi questo lower bound vale \n                  \n                \n\n\n\n                  \n                  DEFINIZIONE: ORDINAMENTO PER CONFRONTI \n                  \n                \n\nDati due elementi a_i e a_j, per determinare l‚Äôordinamento relativo effettuiamo una delle seguenti operazioni di confronto:\n\na_{i} &lt; a_j\na_{i} \\le a_j\na_{i} = a_j\na_{i} \\ge a_j\na_{i} &gt; a_j\n\nNon si possono esaminare i valori degli elementi oppure ottenere informazioni sul loro ordine senza eseguire ALMENO UNA di queste operazioni.\n\n\nTeorema Lower-Bound\nEnunciato\nprendete un algoritmo che gira su modello RAM di tipo confronto\n\nordina n elementi\ndeve fare nel caso peggiore \\Omega (nlogn) confronti\nMI RACCOMANDO DI USARE LA PAROLA CONFRONTI\nMerge e Heap sono ottimi\n\nPer dimostrare il Teorema usiamo albero di decisione\nIDEA: descrivere in modo astratto il comportamento di un generico algoritmo di ordinamento per confronto attraverso una struttura ad albero, basandosi sull‚Äôipotetico input dato in pasto all‚Äôalgoritmo.\nIn pratica, partendo dall‚Äôinput, descrive i confronti che l‚Äôalgoritmo esegue.\nLa sequenza di confronti che osserviamo sul display dipende dall‚Äôinput stesso\n\ndescriviamo in modo astratto tutte le possibili sequenze su un input di dimensione n\n\nattraverso un albero\nla prossima decisione di ogni algoritmo la facciamo in base al confronto che facciamo prima, ovvero l‚Äôesito che porta\n\n\n\nUn generico algoritmo di ordinamento per confronto lavora nel modo seguente:\n\nconfronta due elementi a_i e a_j (ad esempio effettua il test a_i\\le a_j );\na seconda del risultato, riordina e/o decide il confronto successivo da eseguire.\n\nSTRUTTURA: l‚Äôalbero √® radicato e\n- i nodi interni (cerchi grigi) sono i potenziali confronti\n- le foglie (rettangoli bianchi) sono le risposte dell‚Äôalgoritmo\n\n\n\n                  \n                  spiegazione dettagliata degli step \n                  \n                \n\nGuardando dalla radice e spostandoci al figlio di sinistra:\n\nconfronta il primo elemento con il secondo (1:2)\n\nse il primo √® \\le del secondo, scende a crea il figlio a sinistra (2:3)\n\n\nconfronta il secondo con il terzo (2:3)\n\nse il secondo √® \\le del terzo dar√† come input PRIMO, SECONDO, TERZO\nse il secondo √® &gt; del terzo crea un altro figlio (1:3)\n\n\nconfronta il primo con il terzo (1:3)\n\nse il primo √® \\le del terzo dar√† come input PRIMO, TERZO, SECONDO\nse il primo √® &gt; del terzo dar√† come input TERZO, PRIMO, SECONDO\n\n\n\n\n\nci da una descrizione compatta di tutte le decisioni possibili da fare\n\n\n                  \n                  al posto dei : dobiamo mettere il simbolo sulla freccia(&gt;, &lt;, ecc...)\n                  \n                \n\navremo quindi le varie permutazioni della sequenza\nVarie osservazioni utili\nOSSERVAZIONI\n\n\n                  \n                  L&#039;albero di decisione non √® associato a un problema\n                  \n                \n\nquesto perch√© non rappresenta il problema da risolvere ma i passi decisionali che un algoritmo potrebbe eseguire per risolvere il problema.\n\n\n\n\n                  \n                  L‚Äôalbero di decisione non √® associato solo ad un algoritmo\n                  \n                \n\nnon √® associato AL SINGOLO algoritmo ma mostra i passaggi che ALGORITMI DIVERSI potrebbero fare\n\n\n\n\n                  \n                  L‚Äôalbero di decisione √® associato ad un algoritmo e a una dimensione dell‚Äôistanza\n                  \n                \n\nnel punto 2 abbiamo detto che di per s√© l‚Äôalbero di decisione non √® associato ad un solo algoritmo; ma se noi costruiamo un albero di decisione per un algoritmo specifico e per una determinata istanza, allora l‚Äôalbero sar√† ottimizzato per quel singolo algoritmo.\n\n\n\n\n                  \n                  L‚Äôalbero di decisione descrive le diverse sequenze di confronti che un certo algoritmo pu√≤ eseguire su istanze di una data dimensione\n                  \n                \n\nl‚Äôalbero mostra tutte le possibili sequenze di scelte o confronti che l‚Äôalgoritmo potrebbe fare per risolvere il problema per un input di una certa dimensione.\n\n\n\n\n                  \n                  L&#039;albero di decisione √® una descrizione alternativa dell&#039;algoritmo (customizzato per istanze di una certa dimensione) \n                  \n                \n\n\n\n                  \n                  Esercizio sull&#039;albero \n                  \n                \n\n\n\n\n                  \n                  ecco la soluzione \n                  \n                \n\n\n\nPropriet√†\n\n\nPer una particolare istanza, i confronti eseguiti dall‚Äôalgoritmo su quella istanza rappresentano un cammino radice ‚Äì&gt; foglia\n\n\nL‚Äôalgoritmo segue un cammino diverso a seconda delle caratteristiche dell‚Äôistanza (input)\n\nCaso peggiore: cammino pi√π lungo\n\n\n\nIl numero di confronti nel caso peggiore √® pari all‚Äôaltezza dell‚Äôalbero di decisione\n\n\nUn albero di decisione di un algoritmo (corretto) che risolve il problema dell‚Äôordinamento di n elementi deve avere necessariamente almeno n! foglie\n\nse ce ne fossero meno vorrebbe dire che c‚Äô√® una permutazione che non compare mai.\n\n\n\n\n\n                  \n                  l&#039;istanza peggiore √® quella che innesca il cammino pi√π lungo \n                  \n                \n\nLemma che ci serve per dimostrare il lower-bound\n\n\n                  \n                  Info\n                  \n                \n\nUn albero binario T con k  foglie, ha un altezza di almeno log_2(k)\n\n\n\nk lo poniamo all‚Äôinizio\n\nCaso base\nAbbiamo una radice che ovviamente ci porta un albero lungo 0\nCaso induttivo con almeno 2 foglie\nCi poniamo un nodo v che rappresenta il primo padre pi√π vicino alla radice\ninevitabilmente v deve avere due figli e uno dei due figli potrebbe essere un sotto albero u che avr√† almeno k/2 foglie minori del numero di k\napplico l‚Äôipotesi induttiva e avr√≤ log_2(k/2)\n\n1 approssimazione di tutti i nodi prima che arrivi a v\nfaccio formule matematiche\n\n\n\n\n                  \n                  TUTTO QUESTO RIGUARDA GLI ALBERI PER CONFRONTO \n                  \n                \n\nDimostrazione lower bound \\Omega (nlog(n)) con lemma\nconsiderando un albero di decisione di un generico algoritmo di ordinamento avremo che\n\n√® almeno alto log_2(n!) per il punto 4 delle propriet√†\nApplico formula di Stirling : n! \\approx 2(\\pi \\space n)^{\\frac 1 2} \\times (\\frac n e)^n\nfaccio delle semplificazioni varie e ottengo che\n h \\geq n \\ log(n)\n\n\n\n                  \n                  semplificazioni varie \n                  \n                \n\n\n\n\n\n\n                  \n                  Esercizio sul lower bound \n                  \n                \n\n\n\n\n53 questo all&#039;orale ci sventra\nAlgoritmi non basati su confronti\nIntegerSort\nCome funziona?\nper ordinare n elementi con valori posizionati in un array fatto da [1,k]\n\nusiamo un array y con k contatori che conteranno quante volte appare il numero in quella data posizione\nin poche parole\nY[x]= numero \\ di \\ volte \\ in \\ cui \\ appare \\ il \\ numero \\ x \\ nell&#039;array \\ X\nquanti confronti? zero\n\nInserimento in y\n\nRicostruzione in x\n\nPSEUDOCODICE\nAlgoritmo IntegerSort (X, k)\n1. Sia Y un array di dimensione k   // O(1)\n \n2. for i = 1 to k do        // O(k)  \n3.     Y[i] = 0       \n \n4. for i = 1 to n do        // O(n)\n5.     Y[X[i]] += 1   \n \n6. j = 1                    // O(1)\n7. for i = 1 to k do        // O(k)\n8.     while (Y[i] &gt; 0) do  // per i fissato,                                \n                            // #volte eseguite √® al pi√π 1 + Y[i] -&gt; O(k + n)\n9.         X[j] = i\n10.        j += 1\n11.        Y[i] -= 1\n\nil primo for mette ad ogni posizione di Y zero\nil secondo for incrementa in base alle volte in cui appare l‚Äôelemento nella posizione\nfaccio un for per ricostruirmi l‚Äôarray X\ndecremento Y con un while finch√® non diventa 0\n\nCOSTI COMPUTAZIONALI\n\nda riga 7 \\ a \\ 11 ho costo 1+Y[i] k volte perch√© ogni volta il while lo faccio almeno una volta Ogni iterazione del while ha costo O(1), quindi il totale √® proporzionale a 1+Y[i]\n\n\nIntegerSort: analisi\n\nTempo O(1) + O(k) = O(k), per inizializzare Y a 0 (righe 2-3 del codice)\nTempo O(1) + O(n) = O(n), per calcolare i valori dei contatori (righe 4-5 del codice).\nTempo O(n+k), per ricostruire X (righe 6-11)\nCOSTO TOTALE:O(n+k)Quindi abbiamo un tempo lineare se k = O(n)\nQuesto non contraddice il lower-bound di \\Omega(n \\space log(n)) perch√© L‚ÄôINTEGER SORT NON √à UN ALGORITMO BASATO SU CONFRONTI!\n\nse fa cagare dipende da k se k supera n avremo una cosa non lineare"},"UNI/ANNO-2/ALGORITMI-1/ALGORITMI-LEZ.9":{"slug":"UNI/ANNO-2/ALGORITMI-1/ALGORITMI-LEZ.9","filePath":"UNI/ANNO 2/ALGORITMI 1/ALGORITMI LEZ.9.md","title":"ALGORITMI LEZ.9","links":["UNI/ANNO-2/ALGORITMI-1/fotoalg/cap4.7.pdf"],"tags":[],"content":"pdf della lezione 9\nAltri algoritmi che non usano i confronti\nSpiegazione del bucket sort\n\n√® una variante dell‚Äôinteger sort\nverr√† poi usato per il Radix Sort che vedremo in questa lezione\n\nObiettivo\nordinare n record basandosi su una chiave interna [1,k]\n\n\n                  \n                  Esempio \n                  \n                \n\nSupponiamo di voler ordinare una lista di studenti (ogni studente √® un record) con i seguenti campi:\n\nnome\ncognome\nanno di nascita\nmatricola\n\n\n\nVogliamo ordinarli in base alla loro matricola, e sappiamo che tutte le matricole sono numeri interi tra 1 e 1000. Quindi:\n\n\nn rappresenta il numero totale di studenti.\nogni studente ha una campo chiave (la matricola) rispetto al quale ordinare.\nle chiavi (matricole) vanno da 1 a k, con k = 1000\nogni studente ha poi altri campi associati alla chiave (informazioni satellite)\n\n\nSembra facile ma ci sono delle complicanze\n\n\n                  \n                  complicanze \n                  \n                \n\nvisto che con l‚Äôinteger contavamo quante volte appariva quell‚Äôelemento non possiamo definire a\nquale record appartiene quella determinata chiave\nper risolvere collego ad ogni chiave il record usando degli array di lunghezza 2\n[chiave,lista]\n\n\nCome Funziona\n\n\ncreo una array Y, dove in Y[i] inserir√≤ tutti gli elementi con chiave uguale a i\n\nnel senso, se io voglio ordinare una array di prodotti in base al loro prezzo, nella posizione Y[4] (che √® di per s√© una lista) metter√≤ tutti i record (i prodotti) che costano 4.\n\n\n\nconcateno le liste Y[i] in ordine, cos√¨ da ottenere una array ordinato correttamente\n\n\n\nPSEUDOCODICE\nBucketSort (X, k)\n1. Sia `Y` un array di dimensione `k`\n2. for i = 1 to k do          // creazione dell&#039;array con liste vuote\n3.\t   Y[i] = lista vuota\n \n4. for i = 1 to n do\n5.\t   appendi il record X[i] alla lista Y[chiave(X[i])]  \n       // appendo (inserisco alla fine) l&#039;elemento nella lista corretta\n \n6. for i = 1 to k do\n7.\t   copia ordinatamente in `X` gli elementi della lista Y[i]\n      // inserisco gli elementi nell&#039;array originale nell&#039;ordine corretto\n\ncreo un array e ad ogni posizione creo una lista vuota\nfaccio un for che si gira tutta la lista X mettendo il record X[i] nella lista Y in posizione chiave\nfaccio un‚Äôaltro for che sta volta metter√† gli elementi di Y[i] in X nell‚Äôordine corretto\n\nCOMPLESSIT√Ä\ncomplessit√† uguale a integer sort O(n+k) buona quando k √® piccolo\n\n\n                  \n                  stabilit√† di un algoritmo \n                  \n                \n\ntutte le volte che nell‚Äôinput abbiamo due elementi con stessa chiave in output li troviamo messi\ncomunque nello stesso ordine in cui stavano\n\n\n                  \n                  Esempio [Pane, 4\nPasta, 6\nYogurt, 4\nZucchine, 6\nCarote, 4]\n                  \n                \nImmagina di avere una lista del genere, sempre con prodotti e costi\n\n\nSe l‚Äôalgoritmo √® stabile, ordinando in base ai costi avremo\n[Pane, 4\nYogurt, 4\nCarote, 4\nPasta, 6\nZucchine, 6]\n\n\n\n\n\n\n                  \n                  Algoritmo di bucket √® stabile? \n                  \n                \n\nDipende dall‚Äôimplementazione su come gestiamo le liste, ad esempio guala fa append in\nordine di lettura e le mette in ordine (nello pseudocodice questo avviene nelle righe 4-5).\n\n\nRadix Sort\nIl radix prende in input un vettore con k elementi e da in output quegli elementi\n\ndefinisco una base(importante per capire la complessit√†)\nprendo i numeri e li ordino dalla cifra meno significativa a quella pi√π significativa\n\nandiamo avanti finch√© la cifra pi√π significativa √® 0 quindi non c‚Äô√® e siamo alla fine\nOgni volta che facciamo una passata di ogni cifra usiamo il bucket per ordinare dei record in cui la chiave sono i numeri di quella cifra e nella lista avremo gli altri numeri\nse abbiamo una base possiamo capire le chiavi in che range appartengono con [0,b-1]\n\nDimostrazione di correttezza\ndopo t passate di bucket sort i numeri sono tutti ordinati rispetto alle ultime t cifre meno significative\n\nprendiamo due numeri x e y\nse siamo alla t-esima passata avremo due casi\n\nse sono uguali il bucket √® stabile quindi saranno ordinati in base alle cifre meno significative controllate prima per induzione\nse sono diverse il pi√π grande verr√† messo adeguatamente\n\n\nordiniamo in ordine da dx‚Üísx perch√© dobbiamo applicare un algoritmo stabile che non ci distrugge l‚Äôordinamento precedente\n\nChe succede se ho una base piccola?\nfaccio confronti meno costosi con basi pi√π piccole ma magari ho numeri generalmente pi√π lunghi quindi devo avere uno sweet-spot tra le due\nComplessit√† Radix Sort\n\n\nse abbiamo una serie di numeri interi in [1,k] il numero pi√π grande √® k\n\n\nse questi numeri saranno rappresentati con base b per trovare il numero di cifre massimo di cui ho bisogno, devo fare la formula inversa di b^{x} ovvero x=log_bk\n\nIn base 10, il numero 999 richiede 3 cifre (perch√© il massimo numero a 3 cifre in base 10 √® 999), infatti log_{10}(999) \\approx 3\n\nIn base 2 (binario), il numero 7 richiede 3 cifre binarie (111 in binario √® 7), infatti log_{2}(7) \\approx 3\n\n\n\n\n\nquindi questo vuol dire che per ordinare completamente i numeri devo eseguire log_{b}(k) passate di BucketSort\n\nad esempio se devo ordinare dei numeri in base decimale e il massimo √® 999, devo eseguire 3 volte il BucketSort\n\n\n\nciascuna passata di BucketSort ha n record quindi coster√† ogni passata O(n)\n\n\n\nO(n) per distribuire n elementi nei bucket (ovvero scorro l‚Äôarray originale e li inserisco in quello d‚Äôappoggio)\n\n\n\n\n\nOgni bucket che abbiamo fatto √® in un array d‚Äôappoggio e ora dobbiamo rimetterlo al suo posto b volte, ovvero quante cifre abbiamo\n\navremo quindi un costo O(b)\n\n\n\nquindi sicuramente avremo O(n+b)\n\n\nnumero di passate=O(log_bk)\ncosto di ogni passata=O(n+b)\nnumero \\ di \\ passate*il \\ costo \\ di \\ ogni \\ passata\nO((n + b) \\times log_{b}(k))\ncome scelgo b?\nb lo scelgo grande pi√π o meno quanti numeri sono\n\nESERCIZIO IN AULA\n\nStrutture dati= oracolo perch√© risponde a domande(query)\nFacciamo un IntegerSort che si ricorda quanti valori abbiamo nelle posizioni precedenti\n\n\nad ogni passaggio sommo l‚Äôelemento precedente della struttura dati IntegerSort\n\n\n\n                  \n                  ogni elemento a sua volta avr√† la somma del precedente della somma del precedente ecc... \n                  \n                \n\n\nmetto a-1 perch√© devo contare anche in quel momento quanti numeri ho aggiunto\n\nALTRO ESERCIZIO PER CASA\n"},"UNI/ANNO-2/ALGORITMI-1/ESERCIZIO-1-totale":{"slug":"UNI/ANNO-2/ALGORITMI-1/ESERCIZIO-1-totale","filePath":"UNI/ANNO 2/ALGORITMI 1/ESERCIZIO 1 totale.md","title":"ESERCIZIO 1 totale","links":[],"tags":[],"content":"1.\n\n2.\nTeorema master\n\n\nFibonacci\n\nAlbero della ricorsione\n1-ario\n\nb-ario\n\nCambio di variabile\n\neffettuo una sostituzione di variabile per ricondurmi a una forma nota\nuna volta rappresentata la sostituzione ne effettuo un‚Äôaltra con R(x) per rappresentarla consiglio di vedere gli argomenti della funzione R rispetto a T\nora sono in una forma notevole che gi√† conosco e costa O(log \\ x)\nsostituisco la x con la vera x\nfine\n\n\n3.\nOrdinare n interi compresi tra un val min e un val max\n\nsi usa il radix sort con costo\nO(n+b)log_b(val_{max})\nse b=n la base √® ottimale con costo O(2n)log_n(val_{max})\n\nAggiungere \\sqrt n elementi a un heap binario di n elementi\n\nMerge con inserimenti ripetuti\nO(\\sqrt n \\ log(n)\ncon \\sqrt n elem e log(n)  altezza\n\nFondere 2 heap binari uno con n nodi e l‚Äôaltro con n^2  nodi\n\nMerge con inserimenti ripetuti, prendendo l‚Äôheap pi√π piccolo e si fonde con quello pi√π grande\n\nO(n \\ log(n^2)) = O(n*2 log(n))=O(nlogn)\n\n\nse invece voglio fare un merge da zero e quindi creare un heap che contiene i due dentro devo metterli in un array qualsiasi e poi faccio Heapify che ha un costo di O(m^2 + n)=O(m^2)\n\nFondere 2 heap binomiali con n e n^2 nodi\n\nMerge con costo O(log(n+n^2))= O(log(n^2))=O(log(n))\n\nCostruire un heap binario con n chiavi\n\nprocedura heapify con costo O(n)\n\nCostruire un heap binomiale con n chiavi\n\nInserimento ripetuto in modo incrementale da 1 a n, poi unioni log(n) quindi poi √® O(nlogn)\n\nPartendo da un nodo calcola nodi raggiungibili di un grafo diretto con matrice adiacenza\n\nuso DFS, O(n^2) per la profondit√†\n\nCercare in albero AVL l‚Äôelemento pi√π grande fra quelli pi√π piccoli di un elemento dato x\nRicerca predecessore\n\nO(log n)\n\nIn un grafo non orientato e pesato, calcolare distanza tra tutte le coppie di nodi\nDijkstra da ogni nodo O(n(m+nlogn)\nAggiungere 2 elementi ad un heap binomiale di n elementi\ninsert con\n\nO(logn+logn) ‚Üí O(log n)\n\nCalcolare in un grafo diretto e pesato il nodo pi√π lontano da un certo nodo T\n\nDijkstra e si seleziona v tale che d(t‚Üív) sia massima\nO(m+nlogn)\n\nDato un vettore di n numeri, trovare i k elementi pi√π grandi\n\nOrdina con merge sort e poi prende ultimi k elementi\nO(n logn)\n\nOrdinare un vettore V [1 : n] di n bit (V [i] ‚àà {0, 1}):\n\nInteger sort con n bit quindi k=O(n)\nalgoritmo costa O(n)\n\nCercare elemento in una lista ordinata implementata con record e puntatori\n\nnon √® possibile fare un accesso casuale\nquindi si ha una ricerca lineare ordinata O(n)\n\nRestituire gli elementi di un BST in ordine decrescente di chiavi\n\nvisita nodo DX, Radice, SX ricorsivamente VISITA SIMMETRICA\n\nCercare in un grafo diretto e pesato quanto √® lungo il cammino pi√π corto da S a T che non usa archi e1 ed e2\n\nimposto archi e1 ed e2 un peso di 100\napplico Dijkstra e seleziono il percorso che va da S a T\nO(m+nlogn)\n\nOrdinare n interi compresi tra 1 e nlog(logn)\n\nRadix sort\nO(nlog(log n))\n\nIn un grafo orientato capire se tutti i nodi possono raggiungere 2 nodi T1 e T2\n\ninvertiamo la direzione degli archi\nfacciamo il DFS in T1 e T2 e controlliamo il risultato dell‚Äôalgoritmo applicato\nO(n+m)\n\nIn un grafo pesato e non orientato, capire se esiste un cammino minimo da S a T che oltre a essere minimo passa per uno specifico nodo u\n\nDijkstra in S\ntrovo cammino minimo d(S‚Üí u) e d(S‚Üí T)\npoi chiamo Dijkstra da u e vedo d(u‚ÜíT)\nse d(S‚Üíu)+d(u‚Üí t) √® uguale a d(s‚Üít) allora ok\ncosto O(m+nlogn)\n\nCostruire albero AVL contenente n chiavi prese in input\n\nn inserimenti ‚Üí O(nlogn)\n\nOrdinare n interi compresi tra 1 e n^4\n\nRadix sort\ncosto O((n+n)log_n n^4) ‚Üí O(n)\n\nDato un BST di n nodi, restituire tutte le chiavi associate in ordine crescente\n\nvisita in profondit√†\nin ordine simmetrico (SX,RAD,DX)\ncosto O(n)\n\nIn un grafo orientato capire se c‚Äô√® un cammino da S a T di al pi√π K archi che passa per uno specifico nodo w\n\nBFS in S per trovare d(S, w)\npoi BFS in w per trovare d(w, T)\nse d(S, w)+d(w, T) \\leq K  allora ok\nO(n+m)\n\nCostruire un heap binario con n chiavi\n\nprocedura Heapify\nO(n)\n\nIn un grafo orientato, capire se c‚Äô√® un cammino da S a T di al pi√π K archi che evita nodo specifico w\n\nelimino archi collegati al nodo w\npoi faccio BFS in S e controllo se d(s‚Üít)\\leq K\nO(n+m)\n\nTrovare k-esimo minimo in una lista ordinata di n elementi (implementata con record e puntatori)\n\nRicerca lineare sequenziale\ncon record e puntatori non si pu√≤ fare la ricerca casuale\nO(n)\n\nDato un grafo diretto G, stabilire se tutti i nodi possono raggiungere un nodo T\n\ninverto direzione archi\nDFS su t\ncosto O(n+m)\n\nIn un arco non orientato completo e pesato, calcola albero dei cammini minimi con sorgente S\n\nDijkstra in S\npoich√© completo m=n^2\nO(n^2+nlogn) ‚Üí O(n^2)\n\nOrdinare un vettore di n interi compresi tra n e n^2\n\nRadix Sort\nO((2n)log_n n^2) ‚Üí O(n)\n\nFondere due alberi AVL uno contenente n nodi e l‚Äôaltro contenente logn nodi\n\neffettuo logn inserimenti nell‚Äôalbero da n nodi\nO(logn*logn) ‚Üí O(log^2n)\n\nCostruire un heap binomiale con n chiavi\n\ninserimenti ripetuti\nO(nlogn)\n\nIn un grafo diretto dire se un nodo T non pu√≤ essere raggiunto da almeno un nodo S\n\nGrafo componenti fortemente connessi\napplico DFS\ncosto O(n+m)\n\nIn un grafo non orientato e pesato individua il cammino pi√π corto da S a T che non passa per specifico nodo w\n\nMetto tutti gli archi di w a \\infty\napplico Dijkstra in S e restituisco d(S‚ÜíT)\n\nCostruire un albero AVL con n chiavi in input\n\nn inserimenti\nO(nlogn)\n"},"UNI/ANNO-2/ALGORITMI-1/GUIDA-ESAME-VELOCE":{"slug":"UNI/ANNO-2/ALGORITMI-1/GUIDA-ESAME-VELOCE","filePath":"UNI/ANNO 2/ALGORITMI 1/GUIDA ESAME VELOCE.md","title":"GUIDA ESAME VELOCE","links":[],"tags":[],"content":"\\infty= omega\n0= o-piccolo\ncompreso=Theta\n1 ‚â™ log log n ‚â™ log n‚â™ n ‚â™ n log n ‚â™ n^2 ‚â™ n^k ‚â™ a^n ‚â™ n! ‚â™ n^n\n\n\nCambio di variabile\n\neffettuo una sostituzione di variabile per ricondurmi a una forma nota\nuna volta rappresentata la sostituzione ne effettuo un‚Äôaltra con R(x) per rappresentarla consiglio di vedere gli argomenti della funzione R rispetto a T\nora sono in una forma notevole che gi√† conosco e costa O(log \\ x)\nsostituisco la x con la vera x\n\n"},"UNI/ANNO-2/ALGORITMI-1/Guida-esercizi-esame":{"slug":"UNI/ANNO-2/ALGORITMI-1/Guida-esercizi-esame","filePath":"UNI/ANNO 2/ALGORITMI 1/Guida esercizi esame.md","title":"Guida esercizi esame","links":[],"tags":[],"content":"ESERCIZIO 1.A\nL‚Äôesercizio 1.A chiede di determinare se alcune relazioni asintotiche tra funzioni sono vere o meno. Per risolvere correttamente questo tipo di esercizio, √® necessario conoscere i principali strumenti della notazione asintotica: O (Big-O), Œò (Theta), o (small-o), ‚Ñ¶ (Omega) e œâ (small-omega).\n\n1. Concetti Fondamentali\nPrima di procedere con gli esercizi, √® importante ricordare cosa significano queste notazioni:\n\n\nBig-O O(f(n)): Stima superiore asintotica. Indica che una funzione non cresce pi√π velocemente di un‚Äôaltra, al pi√π con una costante moltiplicativa.\n\n\nTheta \\Theta(f(n)): Stima stretta. Indica che due funzioni crescono con lo stesso ordine di grandezza.\n\n\nSmall-o o(f(n)): Stima superiore stretta. Indica che una funzione cresce in modo strettamente pi√π lento rispetto a un‚Äôaltra.\n\n\nBig-Omega \\Omega(f(n)): Stima inferiore asintotica. Indica che una funzione cresce almeno velocemente quanto un‚Äôaltra.\n\n\nSmall-omega \\omega(f(n)): Stima inferiore stretta. Indica che una funzione cresce strettamente pi√π velocemente rispetto a un‚Äôaltra.\n\n\n\n2. Strategia di Risoluzione\nPer determinare la correttezza delle relazioni date, seguiamo questi passi:\n\nIdentificare il termine dominante nelle funzioni, ossia quello che cresce pi√π velocemente asintoticamente.\nUtilizzare le propriet√† della notazione asintotica per confrontare le funzioni.\nApplicare approssimazioni matematiche (per es., trascurare i termini meno significativi quando n \\to \\infty).\nConfrontare i risultati con la definizione di O, \\Theta, o, \\Omega, \\omega.\n\n\n3. Esempio di Applicazione\nVediamo come affrontare una delle relazioni tipiche degli esami.\nEsempio 1\nVerificare se:\nn^{1/5} \\log n + \\sqrt{\\log n} = o(n^{1/4})\n‚úÖ Passaggio 1: Individuare i termini dominanti\n\nn^{1/5} \\log n cresce meno di n^{1/4} perch√© 1/5 &lt; 1/4.\n\\sqrt{\\log n} cresce molto pi√π lentamente di n^{1/4}.\n\n‚úÖ Passaggio 2: Stimare il rapporto tra le due funzioni\n\\frac{n^{1/5} \\log n + \\sqrt{\\log n}}{n^{1/4}}\nDividiamo tutto per n^{1/4}:\nn^{-1/20} \\log n + n^{-1/4} \\sqrt{\\log n}\nQuando n \\to \\infty, entrambi i termini tendono a 0, quindi possiamo concludere che:\nn^{1/5} \\log n + \\sqrt{\\log n} = o(n^{1/4})\n‚úÖ Risultato: La relazione √® vera.\n\nEsempio 2\nVerificare se:\n2^n = \\Theta(2^{n+ \\log n})\n‚úÖ Passaggio 1: Semplificare il termine a destra\n2^{n+ \\log n} = 2^n \\cdot 2^{\\log n}\nSappiamo che 2^{\\log n} = n, quindi possiamo riscrivere:\n2^{n+ \\log n} = 2^n \\cdot n\n‚úÖ Passaggio 2: Confrontare le funzioni\n\\frac{2^n}{2^n \\cdot n} = \\frac{1}{n}\nQuando n \\to \\infty, il rapporto tende a 0, il che significa che:\n2^n = o(2^{n+ \\log n})\n‚úÖ Risultato: La relazione non √® vera, perch√© non esiste una costante c tale che\n2^n \\cdot c = 2^{n+ \\log n}\nper ogni n sufficientemente grande.\n\n4. Tecniche di Calcolo Utili\nEcco alcuni strumenti che possono semplificarti i calcoli:\n\nRegola del quoziente: Per verificare se f(n) = O(g(n)), calcola il limite:\n\n\\lim_{n \\to \\infty} \\frac{f(n)}{g(n)}\n- Se il limite √® **0**, allora $f(n) = o(g(n))$.\n- Se il limite √® una **costante positiva**, allora $f(n) = \\Theta(g(n))$.\n- Se il limite √® **infinito**, allora $f(n) = \\omega(g(n))$.\n\n\n\nConfronto tra funzioni comuni:\n\n\nLogaritmi crescono pi√π lentamente di potenze.\n\\log^k n = o(n^\\epsilon) \\quad \\text{per ogni } k, \\epsilon &gt; 0.\n\n\nLe potenze crescono pi√π lentamente delle esponenziali.\nn^k = o(2^n) \\quad \\text{per ogni } k &gt; 0.\n\n\nLe esponenziali crescono pi√π lentamente dei fattoriali.\n2^n = o(n!).\n\n\n\n\n\n5. Consigli per l‚ÄôEsame\n\nFai pratica: Risolvi pi√π esercizi possibili per familiarizzare con le propriet√† della notazione asintotica.\nSii metodico: Segui sempre i passi di analisi indicati sopra per evitare errori.\nConcentrati sui termini dominanti: Spesso √® sufficiente identificare il termine che cresce pi√π velocemente per rispondere alla domanda.\n\n\nConclusione\nSeguendo questa guida, sarai in grado di risolvere con sicurezza l‚Äôesercizio 1.A di ogni esame di Algoritmi e Strutture Dati. Buono studio! üöÄ\nESERCIZIO 1.B\nüìñ Guida alla Risoluzione dell‚ÄôEsercizio 1.B (Equazioni di Ricorrenza)\n1Ô∏è‚É£ Cosa sono le Equazioni di Ricorrenza?\nLe equazioni di ricorrenza descrivono il costo di un algoritmo ricorsivo in termini del costo del problema ridotto a dimensioni minori. L‚Äôobiettivo √® trovare una stima asintotica della soluzione, espressa in notazione O, \\Theta, \\Omega.\nAd esempio:\nT(n) = 2T(n/2) + n\nsignifica che il problema di dimensione n viene diviso in 2 sottoproblemi di dimensione n/2 e che l‚Äôoperazione aggiuntiva costa O(n).\n\n2Ô∏è‚É£ Approcci per Risolvere le Equazioni di Ricorrenza\nEsistono 3 principali metodi per risolvere queste equazioni:\n\nMetodo del Teorema di Master (il pi√π veloce per molti casi)\nMetodo dell‚ÄôIterazione (Espansione Ricorsiva)\nMetodo del Cambio di Variabile (Caso Speciale)\n\nVediamo come usarli. üëá\n\n3Ô∏è‚É£ Metodo del Teorema di Master\nIl Teorema di Master √® il metodo pi√π rapido per molte equazioni della forma:\nT(n) = aT(n/b) + f(n)\ndove:\n\na √® il numero di sottoproblemi,\nb √® il fattore di riduzione della dimensione del problema,\nf(n) √® il costo del lavoro extra.\n\nRegole del Teorema di Master\nA seconda della crescita di f(n), confrontiamo con n^{\\log_b a}:\n\n\nCaso 1: Dominano le chiamate ricorsive\nSe f(n) = O(n^c) con c &lt; \\log_b a, allora:\nT(n) = \\Theta(n^{\\log_b a})\n\n\nCaso 2: Equilibrio tra ricorsione e lavoro extra\nSe f(n) = \\Theta(n^{\\log_b a}), allora:\nT(n) = \\Theta(n^{\\log_b a} \\log n)\n\n\nCaso 3: Dominano le operazioni extra\nSe f(n) = \\Omega(n^c) con c &gt; \\log_b a e la condizione di regolarit√† √® soddisfatta (a f(n/b) \\leq c f(n) per una costante c &lt; 1), allora:\nT(n) = \\Theta(f(n))\n\n\n\nüìå Esempi di Applicazione del Teorema di Master\nEsempio 1:\nT(n) = 4T(n/2) + n^2\n\nQui a = 4, b = 2 e f(n) = n^2.\nCalcoliamo \\log_2 4 = 2.\nConfrontiamo con f(n) = n^2.\nn^2 = n^{\\log_2 4}, quindi √® il Caso 2.\n\n‚úÖ Soluzione: T(n) = \\Theta(n^2 \\log n).\n\nEsempio 2:\nT(n) = 2T(n/4) + \\sqrt{n}\n\na = 2, b = 4, f(n) = \\sqrt{n}.\n\\log_4 2 = 1/2.\nConfrontiamo con f(n) = n^{1/2}.\nPoich√© f(n) domina (n^{1/2} &gt; n^{1/2 - \\epsilon}), √® il Caso 3.\n\n‚úÖ Soluzione: T(n) = \\Theta(\\sqrt{n}).\n\n4Ô∏è‚É£ Metodo dell‚ÄôIterazione (Espansione Ricorsiva)\nSe il Teorema di Master non √® applicabile, possiamo espandere la ricorrenza fino a trovare un pattern.\nüìå Esempio\nT(n) = T(n-1) + n\nEspandiamo:\nT(n) = T(n-2) + (n-1) + n\nContinuando:\nT(n) = T(n-k) + (n-k+1) + \\dots + n\nFermiamoci a T(1):\nT(n) = 1 + \\sum_{i=1}^{n} i = 1 + \\frac{n(n+1)}{2}\n‚úÖ Soluzione: T(n) = \\Theta(n^2).\n\n5Ô∏è‚É£ Metodo del Cambio di Variabile\nUsato quando la ricorrenza √® espressa in termini di T(\\sqrt{n}).\nüìå Esempio\nT(n) = T(\\sqrt{n}) + 1\nDefiniamo m = \\log n, quindi n = 2^m e la ricorrenza diventa:\nT(2^m) = T(2^{m/2}) + 1\nQuesta √® una ricorrenza lineare sulla variabile m, che si risolve in O(\\log \\log n).\n‚úÖ Soluzione: T(n) = \\Theta(\\log \\log n).\n\n6Ô∏è‚É£ Strategie Veloci per l‚ÄôEsame\n‚úÖ Passo 1: Identifica la forma della ricorrenza:\n\nSe √® del tipo T(n) = aT(n/b) + f(n), usa il Teorema di Master.\nSe √® tipo T(n) = T(n-1) + g(n), usa l‚Äôiterazione.\nSe √® T(n) = T(\\sqrt{n}) + f(n), prova il cambio di variabile.\n\n‚úÖ Passo 2: Applica il metodo scelto e semplifica la soluzione.\n‚úÖ Passo 3: Controlla la crescita asintotica per evitare errori.\n\nüìå Conclusione\nSeguendo questa guida, sarai in grado di risolvere qualsiasi esercizio di ricorrenza presente negli esami caricati.\nüí° Suggerimento finale:\n\nFai pratica con le ricorrenze pi√π comuni.\nMemorizza i casi del Teorema di Master per riconoscere velocemente il risultato.\nUsa l‚Äôiterazione o il cambio di variabile quando necessario.\n\nBuono studio! üöÄüî•"},"UNI/ANNO-2/ALGORITMI-1/LISTA-ALGORITMI":{"slug":"UNI/ANNO-2/ALGORITMI-1/LISTA-ALGORITMI","filePath":"UNI/ANNO 2/ALGORITMI 1/LISTA ALGORITMI.md","title":"LISTA ALGORITMI","links":[],"tags":[],"content":"üìå 1. Algoritmi numerici e ricorsivi\n\n\nfibonacci1 ‚Äì formula chiusa (approssimazione)\n\n\nfibonacci2 ‚Äì ricorsivo semplice\n\n\nfibonacci3 ‚Äì iterativo con array\n\n\nfibonacci4 ‚Äì iterativo con due variabili\n\n\nfibonacci5 ‚Äì potenze di matrici\n\n\nfibonacci6 ‚Äì esponenziazione binaria di matrici\n\n\nTorre di Hanoi\n\n\nProblema della celebrit√†\n\n\nAlgoritmo Alg1 ‚Äì pesatura lineare\n\n\nAlgoritmo Alg4 ‚Äì pesatura logaritmica (divide et impera)\n\n\n\nüìå 2. Ricerca\n\n\nRicerca sequenziale\n\n\nRicerca binaria ricorsiva\n\n\n\nüìå 3. Ordinamento ‚Äì Quadratici\n\n\nSelection Sort\n\n\nInsertion Sort\n\n\nBubble Sort\n\n\n\nüìå 4. Ordinamento ‚Äì Divide et Impera\n\n\nMerge Sort (con Merge)\n\n\nQuick Sort (con Partition)\n\n\nQuick Sort randomizzato\n\n\n\nüìå 5. Ordinamento ‚Äì Heap e strutture\n\nHeap Sort\n\nsi divide in minheap o maxheap\n\nil padre era o pi√π grande o pi√π piccolo dei figli\n\n\nHeapify, FixHeap, EstraiMax\n\n\n\n\nüìå 6. Ordinamento ‚Äì Lineari (non per confronto)\n\n\nInteger Sort / Counting Sort\n\narray ausiliario che mettevi quante volte appare quel numero da quell‚Äôindice\n\n\n\nBucket Sort\n\nuguale al integer sort ma usa una struttura con puntatori per salvare eventuali informazioni satellite\n\n\n\nRadix Sort\n\nera quello delle colonne dei numeri, fa prima le unit√† poi le decine ecc‚Ä¶\nogni posizione ordinata dal bucket\n\n\n\n\nüìå 7. Visite su grafi\n\n\nDFS (Depth First Search)\n\nPROFONDIT√Ä\n\n\n\nBFS (Breadth First Search)\n\nAMPIEZZA\n\n\n\nVisite multiple su componenti non connesse\n\n\n\nüìå 8. Usi avanzati della DFS\n\n\nIndividuazione cicli in grafi orientati\n\n\nOrdinamento topologico\n\n\nClassificazione degli archi (in avanti, indietro, trasversali)\n\n\nCalcolo delle Componenti Fortemente Connesse (CFC)\n\n\nDFS su grafo trasposto\n\n\nDFS ordinata su post(v)\n\n\n\n\n\nüìå 9. Cammini minimi\n\n\nAlgoritmo di Dijkstra\n\nCon heap binario, binomiale, Fibonacci heap\n\n\n\nAlbero dei cammini minimi (SPT)\n\n\n\nüìå 10. Strutture dati fondamentali\n\n\nPila (array e liste)\n\n\nCoda (array e liste)\n\n\nListe (collegate, doppiamente collegate)\n\n\nArray\n\n\nForesta di visita (da DFS)\n\n\n\nüìå 11. Alberi e dizionari\n\n\nAlbero Binario di Ricerca (BST)\n\n\nsearch(k), insert(e,k), delete(e)\n\n\nmin, max, predecessore, successore\n\n\n\n\nAlbero AVL\n\n\ninsert, delete con bilanciamento\n\n\nRotazioni: SS, SD, DS, DD\n\n\n\n\n\nüìå 12. Code con priorit√†\n\n\nImplementazioni:\n\n\nArray ordinato / non ordinato\n\n\nLista ordinata / non ordinata\n\n\n\n\nHeap binario\n\n\nd-Heap\n\n\nHeap binomiale\n\n\nHeap di Fibonacci\n\n\n\nüìå 13. Algoritmi su oracoli e range query\n\n\nCostruisciOracolo\n\n\nInterrogaOracolo\n\n\nVersione logaritmica con intervalli\n\n\n\nüìå 14. Teoria e tecniche di analisi\n\n\nRisoluzione di ricorrenze:\n\n\nIterazione\n\n\nAlbero di ricorsione\n\n\nMetodo di sostituzione\n\n\nTeorema Master\n\n\nCambio di variabile\n\n\n\n\nAnalisi della complessit√† asintotica:\n\nNotazioni: OOO, Œò\\ThetaŒò, Œ©\\OmegaŒ©, ooo, œâ\\omegaœâ\n\n\n"},"UNI/ANNO-2/ALGORITMI-1/LISTA-X-ORALE":{"slug":"UNI/ANNO-2/ALGORITMI-1/LISTA-X-ORALE","filePath":"UNI/ANNO 2/ALGORITMI 1/LISTA X ORALE.md","title":"LISTA X ORALE","links":[],"tags":[],"content":"Fibonacci\n\npseudocodice\ncon dimostrazioni\n\nLemma 1\nLemma 2\nLemma delle matrici\n\n\ndettagli su 2,3,5,6\n\nNotazione asintotica\ndefinizione di notazione asintotica\n\ncap4 lowerbound\n\nlowerbound e upperbound per algoritmi e problemi\n\n\ndefinizione di ottimalit√† di un algoritmo\nLemma altezza albero\n\nBinary Search\n\npseudocodice\n\nEquazioni di ricorrenza\n\ncambio di variabile\nil resto\n\nOrdinamento con confronti\n\nSelection Sort\n\nPseudocodice\nCorrettezza\n\n\nInsertion e Bubble\n\ndagli una letta\n\n\nMerge Sort\n\ndue pseudocodici\ndimostrazione e lemma\n\n\nQuick Sort\n\nPseudocodice\ndimostrazione con anche caso medio\nversione randomizzata\n\n\nHeap Sort\n\npseudocodici\n\nFixheap\nHeapify\n\ncomplessit√† come dimostrazione\n\n\nHeap Sort\n\nTeorema associato\n\n\nEstrazione Max\n\n\nHeap binomiale\n\nristruttura\n\ncon pseudocodice\n\n\nPropriet√† topologiche\nmerge\n\n\nHeap fibonacci\nHeap binario\nd-Heap\n\nmuovi alto\nmuovi basso\n\n\n\n\n\nsenza confronti\n\nInteger Sort\n\nPseudocodice\ncosto\n\n\nBucket Sort\n\nPseudocodice\nStabilit√†\n\n\nRadix Sort\n\nCorrettezza\n\n\n\nStrutture dati\n\nPila\nCoda\nDizionari\n\nBST\n\ncorrettezza\nsearch\n\ncon pseudocodice\n\n\ninsert\nricercamassimo\n\ncon pseudocodice\n\n\npredecessore\n\ncon pseudocodice\n\n\ndelete\n\n\nAVL\n\ninsert\n\ncon osservazioni\n\n\ndelete\n\ncon osservazioni\n\n\nle rotazioni\nanalisi complessit√†\n\n\n\n\nAlberi\n\nBFS\n\npseudocodice\ncomplessit√†\n\n\nDFS\n\npseudocodice\ncomplessit√†\n\n\n\n\nCode con priorit√†\n\ninsert\nfindmin\ndelete\ndeletemin\nincreasekey\ndecreasekey\nmerge\ncosti in base alle strutture dati\n\n\nGrafi\n\nterminologie varie\npropriet√†\nteorema |E|=|V|-1\nListe di adiacenza e matrici\nBFS\n\npseudocodice\ncosto\nteorema livello di un nodo nella BFS\n\n\nDFS\n\npseudocodice\ncosto\npropriet√†\npre-post v con clock\n\npseudocodice\npropriet√† su antenati\ntipologie di arco\n\n\nDAG\n\ndimostrazione sui cicli\n\n\nreti delle dipendenze\nordinamento topologico\n\nteorema quando un grafo lo ammette\npseudocodice\npseudocodice alternativo\n\n\ncomponenti fortemente connesse\n\ndefinizione\n3 propriet√†\npseudocodici\n\n\n\n\nCammini minimi\n\ncon piccola dimostrazione\nnon esiste sempre\n\ndimostrazione\n\n\n\n\ncammini minimi a singola sorgente\n\ndefinizione\nSPT\n\n\n\n\nDijkstra\n\npseudocodice\napproccio greedy\ncorrettezza\ndimostrazione\ncomplessit√†\n\n\n"},"UNI/ANNO-2/ALGORITMI-1/Lista-argomenti-orale":{"slug":"UNI/ANNO-2/ALGORITMI-1/Lista-argomenti-orale","filePath":"UNI/ANNO 2/ALGORITMI 1/Lista argomenti orale.md","title":"Lista argomenti orale","links":[],"tags":[],"content":"‚úÖ 2. Notazione asintotica\n\n\nDefinizioni di O, Œ©, Œò, o, œâ\n\n\nInclusioni: o‚äÜO,œâ‚äÜŒ©\n\n\n\n‚úÖ 3. Ottimalit√† degli algoritmi\n\n\nQuando un algoritmo √® ottimo\n\n\nUpper e lower bound\n\n\n\n‚úÖ 4. Teorema del lower bound per algoritmi basati su confronti\n\nAlbero delle decisioni e Œ©(nlog‚Å°n)\nUso della formula di Stirling\n\n\n‚úÖ **5. Albero binario con altezza log‚Å°2k\n\n‚úÖ 6. Ricerca binaria\n\nCosto O(log‚Å°n)\n\n\n‚úÖ 7. Equazioni di ricorrenza\n\n‚úÖ 8. Algoritmi di ordinamento\n\n\nSelection Sort: confronto minimo a ogni iterazione)O(n^2)\n\n\nInsertion Sort: spostamento verso sinistraO(n^2)\n\n\nBubble Sort: scambi ripetuti finch√© ordinato O(n^2)\n\n\nMerge Sort: merge + chiamate ricorsive O(n \\log n)\n\n\nQuick Sort: partizionamento, costo atteso O(nlog‚Å°n)), pessimo O(n^2)\n\n\n\n‚úÖ 9. Heap e Heap Sort\n\n\nPropriet√† di heap (max e min)\n\n\naltezza logn\n\n\nFixHeap\n\n\nHeapify\n\n\nHeap Sort O(n \\log n)\n\n\n\n‚úÖ 10. Code con priorit√†\n\n\nd-Heap: operazioni (insert, delete, decrease/increase key),muovi alto, muovi basso\n\n\nMerge tra heap\n\n\nHeap binomiali: struttura e operazioni (merge, decrease, delete)\n\n\n\n‚úÖ 11. Alberi e profondit√†\n\nDimostrazione altezza di un albero con k foglie √® alto ‚â• log‚Å°n\n\n\n‚úÖ 12. Integer Sort\n\nArray di conteggio, O(n+k)\n\n\n‚úÖ 13. Bucket Sort\n\nArray di liste, ordinamento stabile, O(n+k)\n\n\n‚úÖ 14. Radix Sort\n\nOrdinamento per cifre, costo O((n + b)\\log_b(valmax))\n\n\n‚úÖ 15. Strutture dati semplici\n\n\nPila: push, pop\n\n\nCoda: enqueue, dequeue\n\n\n\n‚úÖ 16. Visite sugli alberi\n\n\nDFS (profondit√†)\n\n\nBFS (ampiezza)\n\n\n\n‚úÖ 17. BST e AVL\n\n\nBST: ricerca, inserimento, max, predecessore/successore, cancellazione\n\n\nAVL: albero bilanciato, fattore di bilanciamento, rotazioni (SS, DD, SD, DS), altezza logaritmica\n\n\n\n‚úÖ 18. Grafi\n\n\nDefinizioni: grado, cammino, ciclo, archi, nodi, grafo completo, connesso, albero, numero archi = nodi ‚àí 1\n\n\nRappresentazione: lista di adiacenza, matrice di adiacenza\n\n\n\n‚úÖ 19. Visite su grafi\n\n\nBFS: coda, scoperta nodi e livelli, minimo cammino\n\n\nDFS: ricorsiva, clock, antenati/discendenti, archi (in avanti, indietro, etc.), foresta DFS\n\n\n\n‚úÖ 20. DAG (grafi aciclici diretti)\n\n\nDefinizione\n\n\nRiconoscimento tramite archi all‚Äôindietro\n\n\nOrdinamento topologico\n\n\n\n‚úÖ 21. CFC (Componenti Fortemente Connesse)\n\n\nComponente pozzo e sorgente\n\n\nDFS e grafo inverso\n\n\nOrdine di visita con post numeri\n\n\n\n‚úÖ 22. Dijkstra\n\n\nCorrettezza (cut and paste)\n\n\nAlbero dei cammini minimi (SPT)\n\n\nHeap di Fibonacci per ottimizzare il costo\n\n"},"UNI/ANNO-2/ALGORITMI-1/ORALE-appunti-per-ripasso":{"slug":"UNI/ANNO-2/ALGORITMI-1/ORALE-appunti-per-ripasso","filePath":"UNI/ANNO 2/ALGORITMI 1/ORALE appunti per ripasso.md","title":"ORALE appunti per ripasso","links":[],"tags":[],"content":"Fibonacci\n\nalgoritmo 1\n\nusa la formula con la radice e il \\phi\n\\phi^2\n\n\nalgoritmo 2\n\narray costoso\nn ma anche spazio n\n\n\nalgoritmo 3\n\nvariabili che dimenticano\nn\n\n\nalgoritmo 5\n\nmatrici vedi il lemma della matrice con F n+1 Fn Fn e Fn-1\nn\n\n\nalgoritmo 6\n\nsenza fare la potenza delle matrici ogni volta calcola la potenza della matrice k/2 e poi la moltiplica cos√¨ √® come se fa (n^{k/2})^2  con k che √® n-1 della F_n\nlog_2n\n\n\nLemma 1\n\nnumero di foglie di Fibonacci2= F_n\n\ninduzione radice foglie=1 p.b\nprende un albero n&gt;2 e vede che il numero di foglie dei sottoalberi n-1 e n-2 √® Fn-1 e Fn-2 che insieme infatti fanno Fn\n\n\n\n\nLemma 2\n\nil numero di nodi interni √® uguale al numero di foglie-1\n\np.b radice 1 foglia 0 nodi interni\np.i creo un albero con tot nodi interni e tot foglie, per ipotesi induttiva ho detto che nfoglie-1 nodi interni\ncreo T‚Äô con 1 nodo interno in meno quindi con 2 foglie in meno e vedo che i-1=f-1-1 quindi i=f-1\n\n\n\n\n\nNotazione asintotica\n\nesiste una costante maggiore di 0 per cui‚Ä¶\nlower bound\nupper bound\ntheta\no piccolo sottoinsieme O\nomega piccolo sottoinsieme omega grande\n\nOttimalit√† di un algoritmo\n\nun problema P si risolve in tempo O(f(n)) se esiste un algoritmo che lo fa\nun problema P si risolve in tempo \\Omega(f(n)) se ogni algoritmo lo risolve con un lower bound di f(n)\nun problema P con lower bound \\Omega f(n) viene risolto da un algoritmo ottimo in tempo O(f(n))\n\nTeorema del lower bound degli algoritmi basati su confronti\n\nun algoritmo basato su confronti impiega \\Omega(n*logn)\n\nprendiamo l‚Äôalbero delle decisioni esso avr√† n! foglie perch√© sono tutte le istanze possibili\n\nquest‚Äôultimo √® alto \\Omega (log (n!))\nla formula di stirling ci dice che (n!) \\ circa \\ (n/e)^n\nsostituisco e ho due logaritmi, semplifico e avr√≤ la soluzione voluta\n\n\n\n\n\nAlbero binario altezza log_2k\n\nsi fa per induzione si prende il nodo con almeno k/2 foglie e si vede che ha altezza log_2k/2  quindi l‚Äôaltezza totale √® log_2k\n\nBinary Search\n\nalgoritmo ordinato costo O(logn)\n\nEquazioni di ricorrenza\n\nSelection Sort\nCi scorriamo il nostro array e ad ogni elemento facciamo un controllo su qual √® l‚Äôelemento pi√π piccolo in quella determinata posizione\n\nO(n^2)\n\nInsertion Sort\n\nprende ogni elemento e lo sposta indietro se necessario se minore\nO(n^2)\n\nBubble soft\n\nscambia eventuali &lt; a coppie di 2 e fa n cicli finch√© non va bene\nO(n^2)\n\nMerge Sort\n\ndue algoritmi\n\nMerge\n\nprende inizio meta fine\nmette gli elementi in ordine e li copia nell‚Äôarray\n\n\nMerge Sort\n\nfa due chiamate di merge sort ogni volta dividendo la met√†\npoi fa merge\n\n\ncosto 2T(n/2)+O(n)\nAlbero chiamate\n\n\n\nQuick Sort\n\neffettua un tot di partition prendendo come perno l‚Äôinizio della partition\nogni volta scambia i valori sup e inf del perno\neffettua pi√π quick sort\ncosto peggiore O(n^2)\nprobabilit√† alta 1-1/n O(nlogn)\n\nHeap e Heap Sort\n\npadre(v)\\geq chiave(v) \\forall  nodo eccetto v\nrafforzato quindi fino al penultimo livello completo\n\npoi tutto a sx\n\n\nalto cmq logn perch√® fino all‚Äôultimo stiamo la\n\nFixHeap\n\nconfronta il nodo v con il figlio di v con chiave massima u se vince scambia, non lo fa per ogni nodo infatti se ho un min heap e voglio un max heap non basta solo un fixheap\ncosto logn\n\n\nHeapify\n\nfa un fixheap dalla radice e poi per ogni altro sottoalbero sx e dx\nessendo un heap rafforzato costa n‚Äô nodi ma sono praticamente n\n\n\nHeap sort\n\nfaccio heapify prendo il massimo dalla radice quindi pos1 e poi faccio fixheap\nO(nlogn)\n\n\n\n\n\nCode con priorit√†\nd-heap\n\nsi applica ai min heap principalmente\nmuovi alto\nmuovi basso\ninsert\n\ninserisci alla fine e fai muovi alto\n\n\ncancellazione\n\nscambio con foglia e elimino poi prendo la foglia e faccio muovi basso\n\n\ndecremento e incremento\n\ngiocano entrambi con muovi alto muovi basso\n\n\nper fare il merge o metti tutto su una nuova coda con costo n\n\noppure fai n inserimenti nel +grande dei due\n\n\n\nHeap binomiali\n\nd-heap min con propriet√† per cui Bi avr√† come sottoalberi Bi-1 e Bi-2\nristruttura\n\nserve per formare heap binomiali\n\nse ho due Bi uguali allora li fondo formando Bi+1 e mettendo come radice la chiave pi√π piccola\n\n\n\n\npoi ho i vari inserimenti, decrease key eliminazioni\nmerge\n\nprende la foresta la mette insieme alle altre e poi fa ristruttura\n\n\n\nAlberi alti almeno logn\n\npasso base ho un solo nodo alla radice quindi prof=0 infatti log_21=0\nper il caso induttivo dimostro che un albero con k/2 foglie abbia profontit√† almeno log_2(k/2) per induzione quindi un albero con k foglie deve avere log_2k come profondit√†\nper dimostrarlo prendo un nodo interno alla radice con 1 figlio che √® un sottoalbero con almeno k/2 foglie\n\nsommando poi la radice avrei 1+log_2k/2 che con calcoli semplici alla fine fa log2k\n\n\n\nInteger Sort\n\ncrea un array Y lungo quanto il valore max fornito\ninizializza a 0 ogni posizione\nincrementa a ogni elemento trovato la posizione\nricostruisce finche la posizione √® &gt;0 scorre i k elementi\nO(n+k) quindi dipende dal max se max=n daje\n\nBucket Sort\n\ncome integer sort solo che mette in un array di liste\nfa append quindi elementi con stessa chiave sono ordinati\ncampi satellite\nbilanciato per append\nO(n+k)\n\nRadix Sort\n\nutilizza i bucket per fare n passate per ogni cifra meno significativa\ndalle unit√† alle centinaia es‚Ä¶\nad ogni passata mette in un bucket le stesse cifre in ordine\nper induzione ad ogni passata avremo il bucket 0 con le cifre pi√π piccole gi√† ordinate per append\nO((n+b)log_b(valmax)\nse k √® un O di n^c allora basta fare il cambio di base da n a 2 per vedere quanto viene e viene cmq O(n)\n\nPila\n\npush e pop\n\nCoda\n\nenqueue e dequeue\n\nAlberi\n\nVisita DFS\n\nProfondit√†\nUsa la pila e per ogni nodo visita il figlio sx e dx e li mette nella pila finche pila non vuota\nAnche versione ricorsiva\n\n\nVisita BFS\n\nAmpiezza\nUsa la coda\nusando la coda visita prima figlio sx poi subito dopo figlio dx e non fa figlio sx, visita tutto e poi figlio dx\n\n\n\nBST e AVL\nBST\n\nPer ogni sottoalbero sx e dx di altezza h-1 dalla radice abbiamo elementi con chiave minore a sx e maggiore a dx\nalgoritmo di ricerca\n\nche si sposta a sx e a dx dell‚Äôalbero in base alle necessit√†\ncosto in base all‚Äôaltezza\n\n\ninserimento\n\ncerco la foglia giusta per posizionare l‚Äôelemento, lo inserisco a sx o a dx di essa\nsempre altezza\n\n\nmax\n\nvisita in profondita tutta a dx\n\n\npredecessore viene definito come il numero che viene numericamente prima\n\nse ha figli a sinistra allora basta che prende il massimo tra i figli a sinistra\nse non li ha deve scorrere i padri del nodo fino a che non trova un padre che ha come figlio dx quel nodo u, questo significa che quello √® il nodo piu piccolo quindi predecessore\n\n\nsuccessore\n\nper il successore stessa cosa solo che cerco un padre che ha il nodo u come figlio sx e non dx\n\n\neliminazione\n\n3 casi\n\n\n\nse u √® una foglia la cancello\n\n\n\n\nse u non √® una foglia ma ha solo un figlio, faccio puntare al nodo di u il figlio di u\n\n\n\n\nse ha 2 figli cerco il predecessore o il successore, li scambio e faccio l‚Äôeliminazione, se e solo se il nodo scambiato ha max 1 figlio, altrimenti continuo a fare scambi\n\n\n\n\n\n\nBST linearizzato O(n) di altezza se completo logn\n\nAVL\n\n\nalberi binari bilanciati\n\n\nogni nodo ha fattore di bilanciamento 1 0 o -1\n\npossiamo vederli come campi\n\n\n\nci serve per definire che sono sempre alti logn\n\n\nPer dimostrarlo prendo il caso limite di sbilanciamento, gli alberi di fibonacci\n\nse tolgo un nodo rischio sbilanciamento e modifica di altezza\nquindi abbiamo che il numero di nodi nh di un albero Th √® uguale a \n\n\n\n\nsearch sono sicuro che costi logn\n\n\ninsert\n\nse lo faccio devo correggere perch√® potrei avere sbilanciamento +1 in altezza\n\n\n\ndelete\n\nsbilanciamento -1\n\n\n\neffettuo rotazioni\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNome caso\\beta(v)SituazioneCosa faiSS+2sottoalbero sx figlio sxRotazione semplice a destraDD-2sottoalbero dx figlio dxRotazione semplice a sinistraSD+2sottoalbero dx figlio sx di vRotazione doppia: sinistra ‚Üí destraDS-2sottoalbero sx figlio dx di vRotazione doppia: destra ‚Üí sinistra\nGrafi\n\ngrado\ncammino\nciclo\narchi\nnodi\ndiametro\ngrafo completo\nfortemente connesso\nun albero pu√≤ rappresentare un grafo aciclico e connesso\n\nvogliamo dimostrare che il suo numero di archi √® = al numero di nodi -1\npartiamo dal caso base, ho solo un nodo, 0 archi quindi √® verificata\n\nper il passo induttivo prendo un albero con n nodi\n\nessendo aciclico e connesso ogni arco deve avere almeno 1 foglia quindi un nodo con grado 1\nse rimuovo una foglia ho un nodo in meno ma anche un arco in meno, quindi n-1 nodi e per ipotesi induttiva ho n-2 archi\ncos√¨ ho dimostrato che Tn ha n-1 archi\n\n\n\n\n\n\nin memoria rappresento i grafi in 2 modi\n\nliste di adiacenza\n\nper ogni nodo collego una lista dei nodi con cui ha un collegamento\n\n\nmatrice di adiacenza\n\nmetto i nodi su righe e colonne e 0 o 1 per archi\n\n\n\n\n\nVisita BFS di un grafo\n\nutilizza una coda\n\nscorre i vari archi con i vari nodi marcandoli e poi li mette dentro l‚Äôalbero T marcando il vertice\nusata per trovare distanza minima\ncosto\n\ngrado del nodo sorgente per ogni nodo\n\n\nla distanza da s a v √® uguale al livello dell‚Äôalbero BFS fornito\n\n\n\nVisita DFS ricorsiva\n\nla DFS non da il cammino minimo ma serve per altre cose\nfunzione call dalla radice che crea albero T vuoto\npoi DFS che marca il nodo chiamato poi fa un for per ogni arco e fa la chiamata DFS ricorsiva controllando se nodo dell‚Äôarco √® non marcato\n\naggiunge archi ad albero T\n\n\nserve soprattutto per antenati e discendenti\nconcetto di clock\n\nviene aggiunto un clock che incrementa a ogni passaggio fatto nel grafo\n\nviene aggiunto un pre e un post di v a inizio scansione e poi a fine scansione\n\n\nse un grafo non √® connesso devo fare un ciclo che scorre tutti i nodi e poi fare le rispettive chiamate DFS per ogni nodo non marcato\nad ogni nodo non marcato assegna un albero a se poi fai un merge in una foresta\n\n\nci permette di capire delle propriet√† su un arco (u,v)\n\nu √® antenato di v se nella visita DFS ho che\n\npre(u)&lt;pre(v)&lt;post(v)&lt;post(u)\n\n\nse v √® compreso in u allora u ha un arco in avanti a v\nse u √® compreso in v allora si ha un arco indietro\nse v e u hanno pre e post diversi\n\n\n\nDAG\n\nsono quei grafi diretti che non hanno cicli\n\nho un ciclo in un grafo se e solo se ho un arco all‚Äôindietro durante la visita\n\nse ho arco all‚Äôindietro sicuramente ho un ciclo\nse ho un ciclo partendo da vi se visito di nuovo vi prima di arrivare a vi-1 allora significa che ho un ciclo\n\n\n\n\nordinamento topologico di un grafo basandosi sui gradi dove si ha una funzione biettiva con grado di u &lt; grado di v per ogni arco (u,v)\n\nCFC\n\ncomponenti fortemente connesse\n√® un massimale di nodi C per cui ogni nodo pu√≤ raggiungere l‚Äôaltro\npropriet√†\n\nse faccio una visita in uno dei vertici otterrei solo i nodi di quella componente pozzo\n\ncomponente pozzo\n\nnodo che ha solo archi uscenti verso altri nodi ma non entranti da altri CFC\n\n\nsorgente\n\nnodo che non ha archi entranti da altre CFC\n\n\n\n\nse due insiemi fortemente connessi C e C‚Äô hanno un vertice che si collega a un‚Äôaltro vertice di C‚Äô allora\n\nC avr√† variabile di post &gt; di C‚Äô\n\n\nchi ha post &gt; di tutti allora √® una componente sorgente perch√® significa che non ha archi entranti verso di lui\nper quella puzzo basta fare DFS su grafo invertito\n\nprendi il valore di post massimo\n\n\n\n\nper calcolare dalla CFC le varie componenti\n\nmi trovo la componente pozzo e avr√≤ valori di post aggiornati sul grafo inverso\nparti in ordine di post\nquindi visito le varie componenti pozzo\n\nloro non hanno archi uscenti su altre CFC quindi sono ‚Äúsafe‚Äù\n\n\n\n\n\nDijkstra\nse ho un cammino minimo, ogni sottostruttura di questo cammino √® a sua volta minimo, altrimenti significa che senn√≤ esisterebbe un cammino ancora pi√π piccolo\n\ntecnica cut and paste\naggiungo un cammino ma per definizione deve per forza essere maggiore o uguale in termini di distanza\nSPT\n\nalbero che rappresenta i cammini minimi da una sorgente di un grafo\n\n\nAlgoritmo di Dijkstra, funziona solo con pesi positivi\n\nha un approccio greedy\n\nprende tutte le stime e le aggiorna per stime minime di Dsv\nmette in un insieme X le stime esatte, ovvero quelle dei nodi che sono gi√† stati visitati ma che ora devono essere usati come intermezzi per archi\n\n\n\n\ncorrettezza Dijkstra\n\nserve per definire che se io estraggo un nodo v dalla coda con priorit√† allora ho trovato il suo cammino minimo da s\nprendiamo un cammino Dsv e mettiamo che Dsv=Dsu+Duv\nmettiamo caso che in realt√† esiste un cammino migliore Dsv che passa per Dsv=Dsx+Dxy+Dyv\nper definizione se il percorso aggiunto √® migliore allora ha struttura interna minore del percorso definito con u\nma se cos√¨ fosse allora la coda con priorit√† avrebbe estratto prima y di v contando che x e u per√≤ sono inclusi in T quindi sono verificati con un cammino minimo corretto\nse non estrae prima y allora significa che il sottocammino dxy ha distanza uguale o maggiore del cammino uv\n\n\ncosto\n\nheap fibonacci\n\nm+n per vedere tutto\nlogn per usare la coda con priorit√†\n\n\n\n\n"},"UNI/ANNO-2/ALGORITMI-1/PROBLEM-SET/PS_1_bdg":{"slug":"UNI/ANNO-2/ALGORITMI-1/PROBLEM-SET/PS_1_bdg","filePath":"UNI/ANNO 2/ALGORITMI 1/PROBLEM SET/PS_1_bdg.md","title":"PS_1_bdg","links":["mailto:valerio.bernardi@students.uniroma2.eu","mailto:samuele.desantis@students.uniroma2.eu","mailto:luca.gugliotta@students.uniroma2.eu"],"tags":[],"content":"MEMBRI DEL GRUPPO\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNomeCognomeMatricolaEmail universitariaValerioBernardi0349538valerio.bernardi@students.uniroma2.euSamueleDe Santis0348324samuele.desantis@students.uniroma2.euLucaGugliotta0342634luca.gugliotta@students.uniroma2.eu\nProblema 1\nPSEUDOCODICE\nBILANCIATO(Sequenza S)\n    countAperto=0;\n    countChiuso=0;\n    n = lunghezza di S;\n    \n    if(n √® dispari) then return +inf;\n    \n    \n    for(i=1 to n) do\n        if(S[i] == &quot;)&quot;) then\n            if(countAperto &gt; 0) then countAperto--;\n                \n            else countChiuso++;\n            \n        else countAperto++;\n    \n    if(countAperto != countChiuso) then return +inf\n        \n    else return (countAperto + countChiuso)//2; \n       \nLEGENDA VARIABILI\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nnomeVariabiledescrizionecountApertoContatore per le parentesi apertecountChiusoContatore per le parentesi chiusenLunghezza Sequenza SSSequenza di parentesi\nCOSTO\nO(n) scorrendo tutta la sequenza 1 volta con il ciclo for\nCORRETTEZZA\n\nL‚Äôalgoritmo rispetta i Costi di esecuzione richiesti\nPrima di iniziare la spiegazione dell‚Äôalgoritmo, introduciamo una ipotesi per la risoluzione del seguente problema: possiamo dire che se il numero di parentesi chiuse e aperte √® diverso non √® possibile effettuare un bilanciamento, dato che le parentesi vanno inserite a coppie.\n\nVerificher√† se la lunghezza della sequenza S √® dispari, poich√© se cos√¨ fosse, il numero di parentesi aperte sar√† sempre diverso dal numero di parentesi chiuse e rientrebbe nell‚Äôipotesi.\nScorre la sequenza con un ciclo for, per tenere conto delle parentesi rimanenti da bilanciare e ‚Äúscartare‚Äù quelle gi√† bilanciate.\n\nIl numero di parentesi aperte viene decrementato ogni volta che si incontra una parentesi che la chiude\nQualora questo caso non si verificasse, entrambi i contatori verrebbero incrementati ad ogni occorrenza di una o dell‚Äôaltra\nTerminato il ciclo, andr√† a verificare una eventuale disparit√† tra parentesi aperte e chiuse, che non consentirebbe il corretto bilanciamento.\nIn caso contrario andr√† a effettuare un return con il numero di bilanciamenti necessari, dato dal numero di parentesi aperte o chiuse rimanenti.\n\n\nProblema 2: Il posto fisso\nPSEUDOCODICE\nTOPLAVORO(Lista S, n, M):\n    DeltaP = M - S[n];\n    k=0;\n    count=1;\n    \n    if (M==n) then return -1;\n    \n    for(i=n-1 to 1):\n        count++;\n        if (DeltaP == 1) then\n            return 1;\n\t\t\t\n        k=DeltaP*count;\n        if ((M-k-S[i])&lt;0) then\n            DeltaP--;\n\t\t\t\n    return DeltaP;\n \nLEGENDA VARIABILI\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nnomeVariabiledescrizioneDeltaPRappresenta la variabile \\Delta&#039;kVariabile che ci consente di verificare se quel determinato \\Delta&#039; √® sostenibilecountNumero di lavori soddisfattiMOrario di fine giornatanNumero di lavoriSLista dei lavori nei rispettivi istanti di tempo t_i\nCOSTO\nO(n) scorrendo tutta la sequenza n-1 volte con il ciclo for.\nO(n)=o(nM) poich√© T_n &lt; M\nCORRETTEZZA\n\nL‚Äôalgoritmo rispetta i Costi di esecuzione richiesti\nSappiamo a priori l‚Äôordine di arrivo dei clienti, il quale viene espresso con istanti di tempo interi T_i\nL‚Äôalgoritmo inizialmente deve assumere come \\Delta&#039; massimo la distanza tra il tempo di arrivo dell‚Äôultimo cliente T_n e il tempo di chiusura M\nSuccessivamente controlliamo a ritroso il tempo di arrivo dei clienti precedenti, correggendo ogni volta il \\Delta&#039; (Se necessario), andando a verificare se il \\Delta&#039; precedente, applicato per tutti i clienti controllati fino ad ora (k), eccede l‚Äôorario lavorativo M: per capirlo effettuiamo una differenza tra M-k-S[i]\nSe si incorre in tale condizione, decrementiamo il valore di \\Delta&#039;\nSappiamo che il tempo \\Delta rappresenta 1 e \\Delta&#039;\\geq \\Delta\n√à corretto perch√© tiene conto di tutti i clienti serviti prima dell‚Äô i-esimo cliente ed effettua un ricalcolo del tempo lavorativo impiegato fino a quel momento rispetto ai limiti imposti dalla giornata lavorativa\n\n\nProblema 3 (Algo Run)\nPer il seguente problema, non siamo riusciti a giungere ad una conclusione che rispetti i costi temporali richiesti.\nCi terremo comunque a presentare una nostra idea :\n\nLa nostra soluzione doveva sfruttare un AVL\nIl problema c‚Äô√® stato nella costruzione dello stesso\n\nTentativo AVL per valori\nl‚Äôidea era di prendere l‚ÄôAVL ordinato per valori\n\nPrendere ogni volta il valore massimo effettuando un max con il costo di log(n)\nTenere conto delle monete raccolte per ogni valore massimo preso, fino al raggiungimento della fine corsa\n\nPer contare le monete raccolte volevamo sfruttare il valore della singola tupla moltiplicato per il suo intervallo dato da (fine-inizio+1)*valore \\ moneta\n\n\nUna volta preso l‚Äôintervallo max si andavano a decrementare il secondo campo satellite (di fine sequenza) di tutti i nodi che rientravano nel suo stesso intervallo\nUna volta raggiunta la somma finale di tutti gli intervalli, quindi giunti a fine corsa, si sarebbe effettuato un return della somma totale delle monete\n\n"},"UNI/ANNO-2/ALGORITMI-1/RIPASSO-ESAME":{"slug":"UNI/ANNO-2/ALGORITMI-1/RIPASSO-ESAME","filePath":"UNI/ANNO 2/ALGORITMI 1/RIPASSO ESAME.md","title":"RIPASSO ESAME","links":[],"tags":[],"content":"FIBONACCI\nRICERCA\nRICERCA BINARIA (costo O(log(n))\nRicercaBinaria(array A, elem x, int i, int j)\n\tif (i &gt; j) then return -1\n\t\n\tm = [(i + j) / 2]  // PARTE INFERIORE\n\t\n\tif (A[m] == x) then return m\n\telse if (A[m] &gt; x) then\n\t\treturn RicercaBinaria(A, x, i, m-1)\n\telse \n\t\treturn RicercaBinaria(A, x, m+1, j)\n\nORDINAMENTO BASATO SU CONFRONTI\nSELECTION SORT (costo O(n^{2}))\nSelectionSort(A)\n\tfor k = 1 to n-1 do\n\t\tm = k\n\t\t\n\t\tfor j = k+1 to n do\n\t\t\tif (A[j] &lt; A[m]) then\n\t\t\t\tm = j\n\t\n\tScambia A[m] con A[k+1]\nMERGE SORT (cost O(nlog(n)))\nMergeSort(A, i, f)\n\tif (i &lt; f) then\n\t\tm = [(i + f) / 2]  // PARTE INFERIORE\n\t\tMergeSort(A,i,m)\n\t\tMergeSort(A, m+1, f)\n\t\tMerge(A, i, m, f)\n\t\n\tif (i = f) then return A[i]\nMERGE (O(n))\nMerge(A, i, m, f)\n\tX = array ausiliario di dimensione f-i+1\n\t\n\tj = 1, k_1 = i\n\tk_2 = m+1\n\t\n\twhile(k_1 &lt; = m AND k_2 &lt; = f) then\n\t\tif(A[k_1] &lt; A[k_2]) then\n\t\t\tX[j] = A[k_1]\n\t\t\tincrementa k_1 e j\n\t\telse\n\t\t\tX[j] = A[k_2]\n\t\t\tincrementa k_2 e j\n\t\n\tif (k_2 &lt; = f) then\n\t\tInserisci alla fine di X -&gt; A[k_2, f]\n\telse\n\t\tInserisci alla fine di X -&gt; A[k_1, m]\n\t\n\tCopia X in A[i, f]\nQUICK SORT (O(nlog(n)) oppure O(n^{2}))\nQuickSort(A, i, f)\n\tif (i &lt; f) then\n\t\tm = partition(A, i, f)\n\t\tQuickSort(A, i, m-1)\n\t\tQuickSort(A, m+1, f)\nPARTITION\nPartition(A, i, f)\n\tx = A[i]\n\tinf = i\n\tsup = f + 1\n\t\n\twhile (true)\n\t\tdo (inf += 1) while (inf &lt; f AND A[inf] &lt;= x)\n\t\tdo (sup -= 1) while (A[sup] &gt; x) \n\t\tif (inf &lt; sup) then\n\t\t\tscambia A[inf] e A[sup]\n\t\telse\n\t\t\tbreak\n\t\t\n\t\tScambia A[i] e A[sup]\n\treturn sup\n\nTipo di dato\nSpecifica una collezione di oggetti e una serie di operazioni di interesse su tale collezione.\nNel senso immagina di avere un array di interi:\n\ncollezione: tutti gli interi\ntipo di dato: l‚Äôarray di interi e le operazioni che posso fare su quell‚Äôarray\nAllo stesso modo abbiamo:\ndizionario\nint, boolean, double ecc. (questi son tipi di dati PRIMITIVI)\n\nStruttura dati\nOrganizzazione dei dati che permette di memorizzare la collezione e supportare le operazioni di un tipo di dato usando meno risorse di calcolo possibile.\nQuindi il modo pi√π ottimale in cui io posso gestire il mio tipo di dato.\nHEAP E HEAPSORT (quindi ancora sui confronti)\nPropriet√† Heap\n\ncompleto fino al penultimo livello (struttura rafforzata: foglie sull‚Äôultimo livello tutte compatte a sinistra)\ngli elementi di S sono memorizzati nei nodi dell‚Äôalbero (ogni nodo v memorizza uno e un solo elemento, denotato con chiave(v))\nle chiavi devono avere una propriet√†, chiave(padre(v)) \\ge chiave(v)\nDi conseguenza altre propriet√†\nIl max √® contenuto nella radice\nCon n nodi l‚Äôaltezza √® O(log(n))\nUN heap pu√≤ essere rappresentato con un array di grandezza n\n\n\nFIX HEAP (O(log(n)))\nFixHeap(nodo v, Heap H)\n\tif(v non √® una foglia) then\n\t\tsia u il figlio di v con chiave massima\n\t\tif(chiave(v) &lt; chiave(u)) then\n\t\t\tscambia chiave(u) con chiave(v)\n\t\t\tFixHeap(u, H)\nVersione per l‚Äôarray\nFixHeap(i, A)\n\ts = 2i\n\td = 2i + 1\n\tn = Heapsize[A]\n\t\n\tif (s ‚â§ n e A[s] &gt; A[i]) then\n\t\tmassimo = s\n\telse massimo = i\n\t\n\tif (d ‚â§ n e A[d] &gt; A[i]) then\n\t\tmassimo = d\n\t\n\tif (massimo != i) then\n\t\tscambia A[i] con A[massimo]\n\t\n\tFixHeap(massimo, A)\nHeapify (O(n))\nHeapify(H)\n\tif (H non √® vuoto) then\n\t\tHeapify(sottoalbero sx di H)\n\t\tHeapify(sottoalbero dx di H)\n\t\tFixHeap(radice di H, H)\nComplessit√† (vedi meglio sul pdf)\n\nHeap Sort (O(nlog(n))\nCostruisco un heap con Heapify, scambio il primo elemento con l‚Äôultimo (rispettivamente il massimo e il minimo) e decremento ogni volta la porzione di array da guardare\nHeapSort(A)\n\tHeapify(A)   // O(n)\n\tHeapsize[A] = n\n\t\n\t// O(nlog(n))\n\tfor i = n down to 2 do  // l&#039;ultimo elemento non ha senso controllarlo\n\t\tScambia A[1] con A[i]\n\t\t\n\t\tHeapsize[A] = Heapsize[A] - 1\n\t\t\n\t\tFixHeap(1, A)   // mi serve per mettere il nuovo max all&#039;inizio\nAltezza albero in base alle foglie\n\n\n                  \n                  LEMMA \n                  \n                \n\nUn albero binario T con k  foglie, ha un altezza di almeno log_2(k)\n\n\nDIMOSTRAZIONE PER INDUZIONE SU K\n\n\nCASO BASE: k = 1\nQuando k = 1 l‚Äôalbero ha solo una foglia, che √® anche la radice, quindi l‚Äôaltezza dell‚Äôalbero √® 0, che √® uguale a log_2(1). QUESTO SODDISFA LA CONDIZIONE DEL LEMMA.\n\n\n\nCASO INDUTTIVO: k &gt; 1\nAssumiamo che il lemma sia vero per tutti gli alberi binari con meno di k foglie e tentiamo di dimostrare che lo sia per un albero binario con k foglie.\n\n\nNodo v\n\nconsideriamo il primo nodo v, un padre, che si trova pi√π vicino alla radice; v ha due figli (ed esiste perch√© abbiamo detto che k &gt; 1). In pratica se sappiamo di avere pi√π di una foglia, esister√† per forza un albero con due figli (nel nostro caso √® proprio v)\n\n\n\nSuddivisione dei figli:\n\nUno dei figli di v (nel nostro caso u) √® la radice di un sottoalbero con un numero di foglie compreso tra \\frac k 2 \\le NUMERO \\space\\space DI \\space\\space FOGLIE &lt; kNel senso, se io so che il mio albero in totale ha 3 foglie, vuol dire che:\n\nv esiste, lo abbiamo dimostrato prima\nu sar√† il padre di ALMENO 2 foglie e AL PI√ô k-1 foglie (perch√© &lt; k)\nl&#039;altro figlio sar√† direttamente una foglia\n\n\n\n\n\n\nAltezza dell‚Äôalbero T:\n\n\nL‚Äôaltezza di T √® ALMENO 1 + hdove:\n\n1 √® l‚Äôapprossimazione di tutti i nodi dalla radice fino a v (compreso)\nh √® l‚Äôaltezza del sottoalbero con radice in u\n\n\n\nPer il sottoalbero con radice in u applichiamo l‚Äôipotesi induttiva, perch√© ha &lt; k foglie e all‚Äôinizio abbiamo assunto che l‚Äôipotesi per chi ha &lt; k foglie fosse sempre vera, quindih = log_2\\left(\\frac k 2\\right)\nQUINDI sostituendo1 + log_2\\left(\\frac k 2\\right)$$$$= 1 + log_{2}(k) - log_{2}(2)$$$$= log_{2}(k)\n\n\n\n\n\n\nLOWER BOUND PER ALG BASATI SU CONFRONTI\nQuesta dimostrazione fa notare come il miglior algoritmo che si basa su confronti abbia costo \\Omega(nlog(n))\nConsideriamo l‚Äôalbero di decisione di un qualsiasi algoritmo che risolve il problema di ordinamento di n elementi\nL‚Äôaltezza h dell‚Äôalbero di decisione √® almeno log_{2}(n!)\nUtilizziamo la formula di Stirling: n! \\approx 2(\\pi \\space n)^{\\frac 1 2} \\times (\\frac n e)^n\n\n\nORDINAMENTO SENZA CONFRONTI\nInteger Sort (O(n + k))\n\nNel mio array trovo il min e il max.\nCreo un array di contatori in cui inserisco TUTTI gli elementi dal min al max.\nPer ogni valore che leggo nell‚ÄôArray originale incremento il suo contatore.\nUna volta finito di scorrere l‚Äôarray originale lo riscriver√≤ inserendo numeri, in ordine, basandomi sul contatore.\n\nAlgoritmo IntegerSort (X, k)\n1. Sia Y un array di dimensione k   // O(1)\n \n2. for i = 1 to k do        // O(k)  \n3.     Y[i] = 0       \n \n4. for i = 1 to n do        // O(n)\n5.     Y[X[i]] += 1   \n \n6. j = 1                    // O(1)\n7. for i = 1 to k do        // O(k)\n8.     while (Y[i] &gt; 0) do  // per i fissato,                                \n                            // #volte eseguite √® al pi√π 1 + Y[i] -&gt; O(k + n)\n9.         X[j] = i\n10.        j += 1\n11.        Y[i] -= 1\nSpiegazione di O(n+k)\n\n\n\n                  \n                  La sommatoria di Y[i] fa n perch√© io nei k contatori salver√≤ comunque n numeri\n                  \n                \n\nBucket Sort\nStessa idea dell‚Äôinteger ma\n\nabbiamo un array di appoggio con delle LISTE (e non contatori)\nquando trovo una chiave che gi√† √® presente, la ‚Äúappendo‚Äù nella lista\nordino scorrendo le liste\n\nBucketSort (X, k)\n1. Sia `Y` un array di dimensione `k`\n2. for i = 1 to k do          // creazione dell&#039;array con liste vuote\n3.\t   Y[i] = lista vuota\n \n3. for i = 1 to n do\n5.\t   appendi il record X[i] alla lista Y[chiave(X[i])]  \n       // appendo (inserisco alla fine) l&#039;elemento nella lista corretta\n \n4. for i = 1 to k do\n7.\t   copia ordinatamente in `X` gli elementi della lista Y[i]\n      // inserisco gli elementi nell&#039;array originale nell&#039;ordine corretto\n\n\n                  \n                  √à stabile perch√© appendo ogni volta gli elementi in una lista, quindi mantengo l&#039;ordine originale. \n                  \n                \n\nRadix Sort\nViene utilizzato per ordinare n interi compresi tra [1, k].\n\nPer ogni cifra presa in esame, viene utilizzata una passata del bucket sort.\nViene scelta una base b, che servir√† per costruire l‚Äôarray di appoggio nel bucket (avremo un array [0, b-1].\n\nSi parte dall‚Äôi-esima cifra meno significativa, e si inserisce quella cifra nel bucket\n\ncifra presa in considerazione = chiave\naltre cifre = informazioni satellite\n\nPoi, in base alla cifra successiva, SI SPOSTA L‚ÄôINTERO NUMERO, se necessario, IN UN ALTRO BUCKET.\n\nTipo, il numero 2397\n\nprima andr√† nel bucket 7\npoi verr√† spostato nel bucket 9\npoi nel 3\ne infine nel 2\n\n\n\n                  \n                  √à stabile \n                  \n                \n\nPerch√© per ogni cifra utilizziamo il bucket, e sappiamo che bucket ordina in base all‚Äôordine ‚Äúprecedente‚Äù; quindi quando visiteremo la i-esima cifra, allora sappiamo che si trover√† nella posizione corretta\n\n\nComplessit√† temporale\n\n\nNUMERO DI PASSATE DEL BUCKET SORT\n\nn numeri\nil massimo √® k\nbase b\nAllora il massimo numero (k) richiede circa log_{b}(k) \\ \\ \\text{passate}(es. 999 in b = 10 lo visito completamente in log_{10}(999) \\approx 3 passate)\n\n\n\nTEMPO PER OGNI PASSATA\n\nImpiego O(n) per distribuire gli n elementi nel bucket\nImpiego O(b) per gestire i bucket, ossia ‚Äúraccogliere‚Äù i valori che ho nei vari bucket (ricorda che io qui prendo l‚Äôintera lista e la copio, non la scorro mai per intero).\n\nQUINDI IL COSTO DI OGNI PASSATA √à O(n+b)\n\n\nTEMPO TOTALE DI ESECUZIONE\n\nDevo eseguire log_{b}(k)  passate\nOgni passata costa O(n+k)\n\nCOSTO TOTALE O((n+b) \\cdot log_{b}(k))\n\n\n\nCalcolo altezza albero\nIl nostro albero\n\nFormato da due sottoalberi con le rispettive altezze\n\nPer calcolare l‚Äôaltezza totale h = 1 + \\max \\{h_{s,} \\space \\space h_{d}\\}\nDove l‚Äô1 sta ad indicare la radice.\nPSEUDOCODICE\nAltezza(v)\n\tif(v == NULL) then return -1\n\t\n\tsx = Altezza(sx(v))  // O(n)\n\tdx = Altezza(dx(v))  // O(n)\n\t\n\treturn 1 + max{sx, dx}  // O(1)\nESEMPIO\n\nSe vedi, io la radice la conto (anche se ha altezza 0), quindi per bilanciare le foglie ritorneranno 0 1 + max\\{-1, -1\\} = 1 + (-1) = 0\n\nImplementazione Dizionario\nVogliamo far s√¨ che TUTTE le operazioni su un dizionario\n\ninsert\ndelete\nupdate\ncostino O(log(n)) (cosa che con Array e Liste non √® possibile)\n\nBinary Search Tree (BST)\nPropriet√†\n\nun nodo v ha una chiave(v)\nIl sottoalbero sx di v contiene TUTTI E SOLI elementi \\le chiave(v)\nIl sottoalbero dx di un nodo v contiene TUTTI E SOLI elementi \\ge chiave(v)\n\n\nESEMPIO\n\nOrdinamento crescente in un BST\n\nInorderTraversal(nodo)\n\tSe nodo != NULL then\n\t\tInorderTraversal(nodo.sottoalbero_sinistro)\n\t\tVISITA(nodo)\n\t\tInorderTraversal(nodo.sottoalbero_destro)\nDimostrazione\n\nOperazioni\nSearch\nCerco una chiave x\nParto dalla radice\n\nVisito il nodo v\n\nse chiave(v) == x ‚Üí la ritorno\nse chiave(v) &gt; x ‚Üí la cerco nel sottoalbero sx\nse chiave(v) &lt; x ‚Üí la cerco nel sottoalbero dx\n\n\n\nsearch(chave k)\n\tv &lt;- radice di T\n\t\n\twhile(v != NULL) do\n\t\tif (k == chiave(v)) then return elem(v)\n\t\telse if (k &lt; chiave(v)) then v &lt;- figlio sinistro di v\n\t\telse v &lt;- figlio destro di v\n\t\n\treturn NULL // se non ho trovato la chiave\nVersione Ricorsiva\nsearch(nodo v, chiave k)\n\tif (v == NULL) then return NULL\n\t\n\tif (k == chiave(v)) then return elem(v)\n\telse if (k &lt; chiave(v)) then\n\t\treturn search(sx(v), k)\n\telse \n\t\treturn search(dx(v), k)\nESEMPIO\nScrivo search(7)\n\nInsert\nL‚Äôidea √® quella di inserire l‚Äôelemento come foglia nella posizione corretta.\nPer far s√¨ che accada simuliamo una ricerca con la chiave da inserire, seguendo questi passi\n\ncreo un nuovo nodo u con elem = e e chiave = k, che dovr√≤ inserire\ncerco la chiave k nell‚Äôalbero, se non la trovo posso comunque identificare la foglia v che diventer√† il padre di u\nappendo u come figlio sinistro/destro di v cos√¨ da rispettare le propriet√† di ricerca\n\nESEMPIO\nScrivo insert(e, 8)\n\nDelete\nAbbiamo bisogno di  operazioni ausiliarie\n\nMin/Max\nPrecedessore/Successore\n\nMax (il mix √® simmetrico)\nIl max sar√† l‚Äôultimo figlio destro del sottoalbero dx della radice (non per forza una foglia, attenzione)\nMax(u)\n\tv &lt;- u\n\t\n\twhile(figlio destro di v != NULL) do\n\t\tv &lt;- figlio dx di v\n\t\n\treturn v\nVersione ricorsiva\nMax(u)\n\tif(dx(u) == NULL) then return u\n\t\n\treturn Max(dx(u))\nESEMPIO\nVoglio cercare il minimo dell‚Äôalbero con radice 15 e il massimo dell‚Äôalbero con radice 6\n\nPredecessore/Successore\nIl predecessore di un nodo v √® un nodo avente massima chiave \\le v\n\nNel senso, devo cercare l‚Äôelemento con chiave pi√π GRANDE tra tutte le chiavi pi√π PICCOLE di un nodo v\n\nIl predecessore di un nodo v √® un nodo avente minima chiave \\ge v\n\nNel senso, devo cercare l‚Äôelemento con chiave pi√π PICCOLA tra tutte le chiavi pi√π GRANDI di un nodo v\n\nPredecessore(u) \n\tif(u ha un figlio sinistro sin(u)) then\n\t\treturn max(sin(u))   // chiamo il max implementato prima\n\t\n\t// se non ha un figlio sx, il pred sta nei padri\n\twhile(padre(u) != NULL e u √® il figlio sx di suo padre) do\n\t\tu &lt;- padre(u)  // continuo a salire\n\treturn padre(u)  \n\t// se esco dal while vuol dire che u √® un figlio destro o la radice\n\nDelete\nSia u il nodo contenente l‚Äôelemento e da cancellare\nAbbiamo tre casi possibili\n\nu √® una foglia ‚Üí la rimuovo\nu √® un padre con un solo figlio ‚Üí lo rimuovo e collego il figlio al padre(u)\n\nu √® un padre con due figli\n\ncerco il predecessore/successore di u con AL PI√ô un figlio\nscambio u e pred/succ\nmi trovo nel caso 1 o 2\n\n\n\n\nPROBLEMA DEL BST\nEffettivamente tutte le operazioni costano quanto l‚Äôaltezza h dell‚ÄôalberoO(h)ma abbiamo due casi importanti\n\nBST BILANCIATO\ndove h = O(log(n))\nBST LINEARIZZATO\ndove h = O(n)\n\nAVL: soluzione al BST\nCon l‚ÄôAVL facciamo in modo di avere un altezza sempre pari a O(log(n))\nIntroduciamo il fattore di bilanciamento \\beta(v) che viene inserito in ogni nodo e si calcola come \\text{altezza sottoalbero sinistro} - \\text{altezza sottoalbero destro}\n\n\n                  \n                  Un albero √® bilanciato se ha |\\beta(v)| \\le 1 per ogni v\n                  \n                \n\nESEMPIO\n\nNumero nodi in alberi di fibonacci\nIn pratica, nel lemma:\n\nParto da una T_h\nposso calcolare il numero di nodi di T_h facendo numero \\ nodi (n_h)= F_{h + 3} - 1Infatti, ad esempio, con T_4, ho n_{h} = F_{7} - 1 = 13 - 1 = 12\n\n\n\n                  \n                  LUCATA \n                  \n                \n\nGli alberi di Fibonacci F_{h} sono il CASO LIMITE di un AVL di altezza h.\n\n\nDimostrazione altezza AVL\nRiscriviamo la formula di prima n_{h} = F_{h + 3} - 1\nSapendo che F_{k} = \\Theta(\\phi^{k})e che \\phi = 1.618...\nAllora possiamo scrivere che n_{h} = \\Theta(\\phi^{h +3}) - 1 = \\Theta(\\phi^{h})\nTroviamo h \\phi^{h} = n_{h} \\ \\implies \\ h = log_{\\phi}(n_{h})\nSappiamo che n_{h} \\le n , perch√© il numero MINIMO di nodi (n_h) per avere l‚Äôalbero di una certa altezza sar√† sempre \\le del numero MASSIMO di nodi (per la stessa altezza).\nPer esempio, T_3 ha come numero minimo di nodi 7, per√≤ io posso arrivare a scriverne anche 15 per avere sempre altezza 3.\nSapendo questo, allora h = \\Theta(log(n_{h})) = O(log(n))\nOperazioni AVL\nSearch\nIdentica a BST\nInsert e Delete\nQuando parliamo di AVL, facciamo riferimento al bilanciamento dell‚Äôintero albero.\nUn AVL bilanciato, a seguito di un inserimento o di un‚Äôeliminazione, potrebbe avere un nodo con un fattore di bilanciamento |\\beta(v)| = 2, rendendo l‚Äôintero albero sbilanciato.\nQuesto nodo viene chiamato nodo critico e per bilanciarlo vengono eseguite delle rotazioni.\nAbbiamo quattro casi fondamentali\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNome caso\\beta(v)SituazioneCosa faiSS+2Il problema si trova nel sottoalbero sinistro del figlio sinistroRotazione semplice a destraDD-2Il problema si trova sottoalbero destro del figlio destroRotazione semplice a sinistraSD+2Il problema si trova nel sottoalbero destro del figlio sinistroRotazione doppia: sinistra ‚Üí destraDS-2Nodo inserito nel sottoalbero sinistro del figlio destroRotazione doppia: destra ‚Üí sinistra\nCASO SS\n\nDevo eseguire una rotazione semplice a sx partendo dalla radice v\nAbbiamo due sottocasi (derivanti dall‚Äôaltezza effettiva di T_{2})\n\n\nL‚Äôaltezza di T_{2} √® h ‚Üí post rotazione l‚Äôalbero avr√† altezza h+2 (non pi√π h+3)\n\n\n\nL‚Äôaltezza di T_{2} √® h+1 ‚Üí l‚Äôaltezza dell‚Äôalbero post rotazione non cambia\n\n\n\n\n\n                  \n                  Osservazioni \n                  \n                \n\n\nL‚Äôinserimento di un elemento nell‚ÄôAVL (ossia l‚Äôaggiunta di una foglia ad un albero bilanciato), causa solo il sottocaso 1 (altrimenti vorrebbe dire che l‚ÄôAVL era gi√† sbilanciato).\nLa cancellazione di un elemento dall‚ÄôAVL (che necessariamente fa diminuire l‚Äôaltezza di qualche sottoalbero) pu√≤ causare sia 1 che 2.\n\n\n\nCASO SD\n\nNota come qui so che il problema me lo da il sottoalbero dx di z perch√© \\beta(z) = -1e quindi so che dx(z) ha un‚Äôaltezza maggiore a sx(z)\nQui applichiamo una doppia rotazione\n\na sx sul nodo z (figlio sinistro di nodo critico)\na dx sul nodo v (nodo critico)\n\n\n\n\n                  \n                  Osservazione \n                  \n                \n\nIl caso SD pu√≤ essere provocato sia da inserimenti (in T_2 o T_3), sia da cancellazioni che abbassano di 1 l‚Äôaltezza di T_4.\nInsert\n\nInserisco come nel BST\nRicalcolo il fattore di bilanciamento\nSe √® presente un nodo critico v, eseguo una rotazione su v\n\nESEMPIO: insert(10, e)\n\nDelete\n\nElimino come in BST (trovando predecessore/successore)\nRicalcolo il fattore di bilanciamento\nSe ho un nodo critico eseguo una rotazione (potrebbe essere necessario anche una doppia rotazione)\n\nESEMPIO: delete(18)\n\n\n\n                  \n                  Nota una cosa \n                  \n                \n\nL‚Äôeliminazione pu√≤ portare a casi in cui bisogna fare delle rotazioni ANCHE negli antenati del nodo critico iniziale.\nQuesto vuol dire che bisogna fare O(log(n)) rotazioni MA ogni rotazione ha costo costante quindi non intacca nel costo totale.\n\n\nDettagli importanti\n\n\nCode con priorit√†\nUn insieme S di n elementi utilizzato per mantenere ordinati questi elementi secondo delle propriet√†.\nOperazioni possibili\n\nfindMin() -&gt; elem\ninsert(elem e, chiave k)\ndelete (elem e)\ndeleteMin()\n\nOPERAZIONI AGGIUNTIVE\n\nincreaseKey(elem e, chiave d)\n\nincrementa della quantit√† d la chiave dell‚Äôelemento e in S\n\n\ndecreaseKey(elem e, chiave d)\n\nstessa cosa di prima ma decrementa\n\n\nmerge(CodaPriorit√† c_1, CodePriorit√† c_2) -&gt; CodaPriorit√†\n\nrestituisce una nuova coda con priorit√† c_{3} = c_{1} \\cup c_{2}\n\n\n\nCosto operazioni\n\nCome posso avere costi migliori?\nAbbiamo tre implementazioni efficienti.\nD-HEAP\n√à un albero d-ario con le seguenti propriet√†\n\ncompleto fino al PENULTIMO livello (struttura rafforzata)\nogni nodo v ha un elem(v)  e chiave(v) prese da un dominio ordinato\nSI BASA SUL MIN-HEAP, quindi \\text{chiave padre} \\le \\text{chiave figli}\nDa questo deriva che\nil min si trova nella radice ‚Üí findMin = O(1)\ncon n nodi ‚Üí h = \\Theta(log_d(n))\npu√≤ essere rappresentato tramite un vettore posizionale\n\nOperazioni su un D-HEAP\nMuovi in alto\nPrende un nodo e lo sposta in alto, mantenendo le propriet√† (lo faccio quando inserisco/rimuovo elementi).\nmuovi_in_alto(v)\n\twhile(v != radice e chiave(v) &lt; chiave(padre(v))) do\n\t\tscambia di posto v e padre(v)\nT(n) = O(log_{d}(n))\nMuovi in basso\nStessa cosa ma spostando in basso\nmuovi_in_basso(v)\n\trepeat\n\t\tsia u il figlio di v con minima chiave(u), se esiste\n\t\tif(v non ha figli o chiave(v) &lt;= chiave(u)) break\n\t\tscambia di posto v e u in T\nT(n) = O(log_d(n))\nOperazioni\nFindMin\nfindMin()\n\t&quot;restituisce l&#039;elemento nella radice di T&quot;\nT(n) = O(1)\nInsert\nInserisco un elemento nella foglia pi√π a sinistra disponibile e, se necessario, eseguo muovi_in_alto\nInsert(e, 8)\nT(n) \\ = \\ O(1) \\ + \\ O(log_{d}(n)) \\ = \\ O(log_{d}(n))\nDelete\nScambio il nodo con la foglia pi√π a destra\n\nelimino il nodo (che ora √® una foglia)\neseguo un muovi_in_basso sulla foglia spostata\n\ndelete(8)\nT(n) \\ = \\ O(1) \\ + \\ O(log_{d}(n)) \\ = \\ O(log_{d}(n))\ndelete(17)\n\nDecrease Key\nPrendo l‚Äôelemento, decremento la sua chiave e eseguo muovi_in_alto\nT(n) \\ = \\ O(1) \\ + \\ O(log_{d}(n)) \\ = \\ O(log_{d}(n))\nIncrease Key\nIncremento ed eseguo muovi_in_basso\n\nMerge\nIl merge su un d-heap √® molto costoso.\nAbbiamo due approcci\n\nCostruisco da 0 ‚Üí elimino le due strutture e ne creo una nuova da 0 (la utilizzo solo se non posso eseguire la seconda)\nInserimenti ripetuti ‚Üí inserisco la coda pi√π piccola in quella pi√π grande (eseguendo k inserimenti)\n\nCostruzione da 0 (Generalizzazione di Heapify)\n\nUnisco i due d-heap in un unico d-heap\nrendo ricorsivamente i sottoalberi degli heap con Heapify\neseguo muovi_in_basso sulla radice\n\n\n\nd \\ T(\\frac n d) √® l‚ÄôHeapify fatto su d figli\nO(d \\ log_{d}(n)) √® il muoviBasso fatto sulla radice\n\nInserimenti ripetuti\nInserisco uno ad uno gli elementi della coda con priorit√† pi√π piccola nella coda con priorit√† pi√π grande (k volte).\n\nRIEPILOGO\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFind MinInsertDeleteDelMinIncr. KeyDecr. KeyMergeArray non ord.Œò(n)O(1)O(1)Œò(n)O(1)O(1)O(n)Array ordinatoO(1)O(n)O(n)O(1)O(n)O(n)O(n)Lista non ordinataŒò(n)O(1)O(1)Œò(n)O(1)O(1)O(1)Lista ordinataO(1)O(n)O(1)O(1)O(n)O(n)O(n)d-HeapO(1)O(log_d(n))O(d \\ log_d(n))O(d \\ log_d(n))O(d \\ log_d(n))O(log_d(n))O(n)\nALBERI BINOMIALI\nUn albero binomiale B_{i} √® definito ricorsivamente in questo modo\n\nB_{0} ha solo la radice\nB_{i+1} √® ottenuto fondendo tra loro due B_{i}, ponendo la radice dell‚Äôuno come figlio della radice dell‚Äôaltro\n\n\nPropriet√† strutturali\n\nIn B_i, la i √® il numero massimo di figli (la d di prima)\nIl numero totale di nodi: 2^i\nL‚Äôaltezza: H(n) = h = log_{2}(n)\nGrado della radice: D(n) = log_{2}(n)\nOgni Albero B_i avr√† come figli i sottoalberi B_0,...,B_{i-1})\n\nHEAP BINOMIALI\nUn heap binomiali √® una foresta di alberi binomiali con le seguenti propriet√†\n\nnella foresta √® presente AL MASSIMO un B_{i}\nogni nodo ha un elemento e una chiave\nogni HEAP √® un MIN-HEAP, quindi con chiave(padre) \\le chiave(figli)\n\n\nCapire quanti alberi devo avere nella foresta in base ai nodi\n\nPrendo n (il numero di nodi)\nlo codifico in binario\nvedo in che posizione si trovano gli 1 ‚Üí per ogni posizione i avente 1 avr√≤ un B_{i}.\n\nEsempio: n = 13 13 = 1101quindi\n\nB_{0} ‚Üí SI\nB_{1} ‚Üí NO\nB_{2} ‚Üí SI\nB_{3} ‚Üí SI\nRappresentazione di n = 13\n\n\nDa questo consegue che in un heap binomiale ci sono AL PI√ô \\lceil log(n) \\rceil alberi binomiali, ciascuno con grado e altezza O(log(n))\nProcedure\nRistruttura\nQuando ho una struttura che vorrei fosse un heap binomiale MA NON RISPETTA LA PROPRIET√Ä DI UNICIT√Ä (un solo B_{i}), posso usare la ristruttura scorrendo da sx a dx\nristruttura()\n\ti = 0\n\t\n\twhile(esistono ancora due B_i) do\n\t\tfondi i due B_i costruendo un B_{i+1} \n\t\tmettendo la radice max come figlio della radice min\n\t\ti++\nT(n)\nESEMPIO\nVoglio formare un heap binomiale ma ho due B_0 , eseguo ristruttura(H)\n\nOperazioni\n\n\nfindMin()\n\nscorre gli heap controllando le varie radici e restituisce la min\n\n\n\ninsert(elem e, chiave k)\n\ninserisce l‚Äôelemento come un B_{0} e esegue la ristruttura se serve\n\n\n\ndeleteMin()\n\nelimina la radice min\ni sottoalberi destri diventano tanti nuovi B ‚Üí esegue ristruttura\n\n\n\n\ndecreaseKey(elem e, chiave d)\n\ndecrementa di d la chiave del nodo v contenente l‚Äôelemento e\neseguo se serve muovi_in_alto\n\n\n\n\ndelete(elem e)\n\neseguo un decreaseKey(e, -inf) ‚Üí cos√¨ rendo quel nodo talmente piccolo che diventa la radice del suo albero e anche il min dell‚ÄôHeap Binomiale\neseguo un deleteMin()\n\n\n\nincreaseKey(elem e, chiave d)\n\nchiama delete(e) e poi fa insert(e, k+d), dove k √® la chiave originale di e\n\n\n\nmerge(CodaPri.c1, CodaPri.c2) -&gt; CodaPri\n\nunisce c1 e c2 in un nuovo heap binomiale c3 e poi fa ristruttura per evitare doppioni\n\n\n\n\n\n\n                  \n                  Tutte le operazioni hanno costo T(n) = O(log(n)) e durante la ristrutturazione esistono AL PI√ô tre B_i per ogni i \\ge 0\n                  \n                \n\nHEAP FIBONACCI\nUna struttura dati avanzata per implementare una coda con priorit√†, progettata da Tarjan.\n\nL‚Äôidea √®: ‚Äúrimando le operazioni costose (come ribilanciamenti) e le faccio solo quando servono davvero‚Äù.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFind MinInsertDeleteDelMinIncrKeyDecrKeyMerged-HeapO(1)O(log(n))O(log(n))O(log(n))O(log(n))O(log(n))O(n)Heap binom.O(log(n))O(log(n))O(log(n))O(log(n))O(log(n))O(log(n))O(log(n))Heap fibona.O(1)O(1)O(log(n))*O(log(n))*O(log(n))*O(1)*O(1)Gli asterischi indicano che quella non √® la complessit√† nel caso peggiore ma la complessit√† in senso ammortizzato (solo intuizione).\nüí° Costo ammortizzato ‚Äì che significa?\n√à come dire:\n\n‚ÄúUna singola operazione potrebbe costare tanto, ma se ne faccio tante, in media costano poco‚Äù.\n\nServe per valutare le strutture in scenari reali, dove conta il costo totale su molte operazioni, non il caso peggiore singolo.\n\nGrafi\nI grafi sono strutture matematiche usate per rappresentare insiemi di oggetti (i nodi, o vertici) collegati tra loro da relazioni (chiamate archi).\nSi distunguono in\n\nNON ORIENTATO ‚Üí G = (V, E)\nDIRETTO ‚Üí D = (V, A)\nPESATO ‚Üí G = (V, E, w)\n\nTerminologia\nGRAFO NON DIRETTO\n\n\nG = (V, E), grafo non diretto\nn = |V| ‚Üí numero di vertici\nm = |E| ‚Üí numero di archi\n(u, v) ‚Üí √® un arco indicente ai due vertici e questi sono detti estremi\n\\delta(u) ‚Üí √® il grado di un vertice e indica quanti archi sono associati a quel vertice\nGrado di G ‚Üí max_{v \\in V}\\{\\delta(v)\\}\n\nGRAFO DIRETTO\n\n\nPrimi quattro punti identici\n\\delta_{in}(u) ‚Üí grado ENTRANTE in u, ossia gli archi che entrano in u\n\\delta_{out}(u) ‚Üí grado USCENTE in u, ossia gli archi che escono da u\nGrado ENTRANTE di G ‚Üí max_{v \\in V}\\{\\delta_{in}(v)\\}\nGrado USCENTE di G ‚Üí max_{v \\in V}\\{\\delta_{out}(v)\\}\n\nAltra terminologia\n\ncammino ‚Üí sequenza di nodi connessa da archi\nlunghezza di un cammino ‚Üí # di archi del cammino\ndistanza ‚Üí lunghezza del pi√π cammino tra due vertici\nG √® connesso ‚Üí esiste un cammino per ogni coppia di vertici\nciclo ‚Üí se esiste un cammino che parte da un nodo e ritorna in quel nodo\ndiametro ‚Üí massima distanza fra due nodi\n\nQuanti archi pu√≤ avere un grafo di n nodi?\n\nSCONNESSO ‚Üí 0\nCONNESSO E ACICLICO ‚Üí m = \\Omega(n) (ha almeno n-1 archi)\nCOMPLETO ‚Üí O(n^2)\n\n\n\n                  \n                  Teorema \n                  \n                \n\nSia T = (V,E) un albero; allora |E| = |V| - 1\n\n\n\n\n                  \n                  Definizione \n                  \n                \n\nDato un grafo G, un ciclo (rispettivamente un cammino) Euleriano √® un ciclo (rispettivamente un cammino non chiuso) di G che passa per tutti gli archi di G una e una sola volta.\n\n\nMETODI PER RAPPRESENTARE I GRAFI\nMatrici N \\times N\n\nUso delle variabili booleane e inserisco 1 negli incroci in cui ho collegamenti.\nOccupa spazio O(n^2).\nLISTE DI ADIACENZA\nUso una lista collegata per tenere conto dei collegamenti\nOccupa spazio O(n + m), dove n √® il numero di nodi e m √® il numero di archi\nALGORITMI DI VISITA DI UN GRAFO\nVISITA IN AMPIEZZA (BFS)\n\n\n                  \n                  FUNZIONAMENTO \n                  \n                \n\nDato un grafo G (non pesato) e un nodo s, trova tutte le distanze (o cammini minimi) da s verso OGNI ALTRO nodo v\n\n\nPSEUDOCODICE\n\nUtilizzo una coda ‚Üí gli elementi vengono messi in fondo\nEstraggo ogni volta il nodo in cima, lo pongo come figlio del nodo presente nell‚ÄôAlbero T\n\nBFS(vertice s)\n\tT &lt;- albero formato solo da s\n\tC &lt;- coda\n\t\n\tmarca il vertice s nel grafo; dist(s) &lt;- 0\n\tC.enqueue(s)\n\t\n\twhile(not C.isEmpty()) do\n\t\tu &lt;- C.dequeue()\n\t\tfor each (arco (u,v) in G) do\n\t\t\tif (v non √® marcato) then\n\t\t\t\tC.enqueue(v)\n\t\t\t\tmarca il verticev; dist(v) &lt;- dist(u) + 1 \n\t\t\t\trendi u il padre di v in T\n\t\n\treturn T\nESEMPIO VISIVO \nALBERO CONSEGUENTE\n\nCOSTO BFS\nMATRICE\n\n\n\n                  \n                  Spiegazione dell O(n^{2})\n                  \n                \n\n\n\n\nLISTA\n\nSe il grafo √® connesso io so che il numero di archi (m) √® maggiore o al massimo uguale al numero di nodi - 1 (n-1) m \\ge n-1e quindi O(m+n) = O(m)\nSe per√≤ il grafo √® completamente connesso, m \\le \\frac {n(n-1)} 2 allora O(m+n) = O(n^2)\nQuindi\n\nSE m = o(n^2) √® sempre meglio utilizzare la liste\nSE m = O(n^2) allora utilizza le matrici (perch√© la ricerca di un arco costa O(1)!!)\n\n\n\n                  \n                  Teorema \n                  \n                \n\n\nQuindi in pratica, il livello di un qualsiasi nodo v nell‚Äôalbero BFS CORRISPONDE al cammino minimo dal nodo v alla radice s.\nVISITA IN PROFONDIT√Ä (DFS)\nLa visita in profondit√† √® un algoritmo di esplorazione dei grafi che procede esplorando ogni cammino in profondit√† prima di tornare indietro e visitare altre strade.\nVERSIONE RICORSIVA\nDFSricorsiva(v)\n\tmarca e visita il vertice v \n\tfor each (arco(v, w)) do \n\t\taggiungi arco (v, w) a T\n\t\tDFSricorsiva(w, T)\n \nCHIAMATA(s, T)\n\tT &lt;- albero vuoto\n\tDFSricorsiva(s)\n\treturn T\nConsiderazioni\n\nAltra utilit√† per le DFS\nDFS con il clock\nPOsso utilizziare una variabile clock per tenere traccia\n\ndi quando un nodo viene scoperto (pre)\ndi quando un nodo viene abbandonato (post)\n\nDFS(v, T, clock)\n\tmarca e visita il vertice V\n\tpre(v) = clock\n\tclock++\n\t\n\tfor each (arco (v, w)) do\n\t\tif (w non √® marcato) then\n\t\t\taggiungi (v, w) a T\n\t\t\tDFS(w, T, clock)\n\t\n\tpost(v) = clock\n\tclock++\n \n \nChiamataDFS(s)\n\tT &lt;- albero vuoto\n\tclock  = 1\n\tChiamataDFS(s, T, clock)\n\treturn T\n\n\n                  \n                  Perch√© il clock lo incremento sia a riga 3 e riga 9\n                  \n                \n\n\nriga 3 la uso per far s√¨ che tutti i pre siano diversi tra loro\nriga 9 la uso per far s√¨ che sia i pre che i post siano diversi\n\n\n\nESEMPIO\n\nCosa fare quando ho dei nodi scollegati dal resto?\n\nPosso creare una foresta di alberi, in cui inserire tutti gli alberi che creo\nForestaDFS(grafo G)\n\tfor each nodo v do\n\t\timposta v come non marcato\n\t\n\tclock = 1\n\tF &lt;- foresta vuota\n\t\n\tfor each nodo v do\n\t\tif(v non √® marcato) \n\t\t\tT &lt;- albero vuoto\n\t\t\tDFS(v, T)   // l&#039;algoritmo che hai visto sopra\n\t\t\taggiungi T a F\n\t\n\treturn F\nSpiegazione\n\nnel for each se v non √® marcato vuol dire che\n\nho appena iniziato il for each\noppure che dopo la chiamata DFS non ho visitato quel nodo ‚Üí si trova in un altro nodo\nSCOLLEGATO dall‚Äôalbero appena visitato\n\n\n\nSe sono nel secondo caso, allora creer√≤ un nuovo albero, lo riempir√≤ e lo aggiunger√≤ a T.\nPropriet√†\n\n\nPer ogni coppia di nodi u e v, abbiamo rispettivamente\n\n[pre(u), post(u)]\n[pre(v), post(v)]\ne questi possono essere disgiunti oppure uno √® contenuto nell‚Äôaltro\n\n\n\nu √® antenato di v nell‚Äôalbero DFS, se pre(u) &lt; pre(v) &lt; post(v) &lt; post(u)(nella foto sopra abbiamo, per esempio, A antenato di G).\n\n\nusiamo i tempi di visita per riconoscere un tipo generico di arco (u,v) nel grafico\n\nIN AVANTI = (A, E),‚Ä¶\nALL‚ÄôINDIETRO = (F, B),‚Ä¶\nTRASVERSALI (necessitano un collegamento) = post(v) &lt; pre(u) = (H, G), (D, H)\n\n\nCome riconoscere la presenza di un ciclo in un grafo diretto\nEseguo una DFS e controllo se c‚Äô√® un arco all‚Äôindietro ‚Üí se c‚Äô√® allora abbiamo un ciclo.\n\n\n                  \n                  DEFINIZIONE: DAG \n                  \n                \n\nUn grafo diretto aciclico (DAG) √® un grafo diretto senza cicli (diretti)\n\nN.B.: sorgente e pozzo devono per forza esserci, altrimenti avrei un ciclo (es. se 7 non fosse un pozzo avrei un ciclo.)\n\n\n\n\n                  \n                  DEFINIZIONE: Ordinamento topologico \n                  \n                \n\nUn ordinamento topologico di un grafo diretto G=(V,E) √® una funzione biettiva \\sigma: V ‚Üí {1,2,..,n} tale che per ogni arco (u,v) \\in E, \\sigma(u) &lt; \\sigma(v)\nIn pratica se esiste un collegamento tra due nodi, metto prima il nodo che ha l‚Äôarco OUT e poi quello che ha l‚Äôarco IN.\nOvviamente metto la sorgente all‚Äôinizio e il pozzo alla fine.\nIL DAG DI PRIMA SI SCRIVEREBBE COS√å\n\n\n\nN.B.: solo i grafi DAG ammettono un ordinamento topologico\nQuesto perch√©, se la funzione biettiva prevedere che \\sigma(u) &lt; \\sigma(v) per ogni arco (u, v), se io ho un ciclo &lt;v_{0}, v_{1}, ..., v_{k}=v_{0}&gt; avr√≤ una situazione del genere \\sigma(v_{0}) &lt; \\sigma(v_{1}) &lt; ... &lt; \\sigma(v_{k-1} &lt; \\sigma(v_{k}) = \\sigma(v_{0})e questo vuol dire che \\sigma(v_0)&lt;\\sigma(v_1) \\ \\ MA \\ ANCHE \\ \\ \\sigma(v_{k} = v_{0}) &gt; \\sigma(v_{k-1})il che √® impossibile \\square\nAlgoritmo per calcolare l‚Äôordinamento topologico\nEseguo una DFS con il clock, non appena esco dal for each, il nodo prende il post e io lo inserisco nella con l‚Äôordinamento.\nIn pratica, inserisco nella lista l‚Äôelemento con il post pi√π basso ogni volta, e gli altri li inserisco sempre dalla cima.\nOrdinamentoTopologico (grafo G)\n\ttop = n; L &lt;- Lista vuota\n\tchiama visita DFS ma\n\t\tquando ha finito di visitare un nodo v\n\t\t\tsigma(v) = top; top -= 1\n\t\taggiungi v in testa a L\n\treturn L e sigma\nCOSTO \\Theta(n+m)\nVersione alternativa\nQui l‚Äôidea √®\n\ncostruisco un nuovo grafo G^{&#039;}\nrimuovo da G^{&#039;} ogni volta il vertice che non ha archi entranti\nlo aggiungo alla lista (faccio append)\nSE G^{&#039;} NON DIVENTA VUOTO, vuol dire che G non √® aciclico\n\nOrdinamentoTopologico(grafo G)\n\tGÃÇ &lt;- G\n\tord &lt;- lista vuota di vertici\n\t\n\twhile (esiste un vertice v senza archi entranti in GÃÇ) do\n\t\tappendi v come ultimo elemento di GÃÇ\n\t\trimuovi v da GÃÇ\n\t\n\tif (GÃÇ non √® diventato vuoto) then\n\t\terrore: G non √® aciclico\n\t\n\treturn ord\nCOMPONENTI FORTEMENTE CONNESSE\nUna componente fortemente connessa di un grafo G √® un insieme massimale di vertici C \\subseteq V tale che per ogni coppia di nodi u e v ‚Üí u √® raggiungibile da v e v √® raggiungibile da u\n\nIn pratica, se ho un ciclo tra due vertici ho una componente fortemente connessa tra quei vertici\n\n\n\nA √® una componente fortemente connessa di s√© stessa\nB e E sono una componente fortemente connessa\n\nLa cosa interessante √® che il grafo originale non era un DAG, ma il grafo delle componenti connesse si.\n\nVarie propriet√†\n\nSe eseguo una visita DFS a partire da u, questa termina solo quando ho finito di visitate tutti i nodi raggiungibili da u\n\n\n\n                  \n                  IDEA \n                  \n                \n\nQuindi per costruire il grafo delle componenti fortemente connesse conviene far partire le DFS dalla componente pozzo, una volta finita la DFS ‚Äúelimino‚Äù quella componente e ripeto.\n\n\n\n\nSe C e C&#039; sono due componenti e esiste un arco diretto C -&gt; C&#039;  allora il pi√π alto valore di post di C&#039; sar√† pi√π piccolo del pi√π alto valore di post di C\n\ne questo ha senso perch√© parto da C ‚Üí entro in C&#039; ‚Üí esco da C&#039; (ho il post) ‚Üí esco da C (ho il post)\n\n\nLa componente sorgente ha il post pi√π alto\n\n\nPer trovare una componente pozzo dopo aver trovato una sorgente, INVERTIAMO TUTTI GLI ARCHI\nL‚Äôidea qui √®\n\ntrovo la componente sorgente di G ‚Üí quella con il post pi√π alto\ncreo G&#039; ‚Üí inverto gli archi\nin G&#039; eseguo DFS partendo dalla componente con il post pi√π alto di G\n\nCODICE\n\nESEMPIO VISIVO\n\n\n\n                  \n                  Perch√© √® utile? \n                  \n                \n\nSe io costruisco il mio grafo delle componenti connesse PARTENDO da una pozzo, io sono SICURO che non ha archi uscenti, quindi rimarr√≤ confinato dentro quella componente.\nQuesto vuol dire che io partendo dal pozzo sono sicuro di visitare quella componente nella sua completezza, senza rischiare di uscire fuori.\n\n\n\nCammini minimi su grafi pesati\nSe ho un grafo orientato pesato (orientato e non), la distanza tra due nodi √® data dai pesi degli archi che passano per i due nodi.\nIl cammino minimo qui √® dato dal costo minimo degli archi presi in considerazione.\n\n\n                  \n                  Non √® per forza unico \n                  \n                \n\n\n\n                  \n                  NON ESISTE SEMPRE UN CAMMINO MINIMO TRA DUE NODI \n                  \n                \n\nPotremmo avere due nodi che non sono collegati da nessun arco/insieme di archi, allora d(u, v) = +\\infty\nSe ho un ciclo negativo tra due archi, potrei sfruttarlo per far diminuire la loro distanza, allora d(u, v) = -\\infty\nE QUESTA SECONDA COSA NON VA BENE\n\n\n\nPropriet√† dei cammini minimi\n\n\n                  \n                  Ogni sottocammino di un cammino minimo √® a sua volta un cammino minimo. \n                  \n                \n\nDimostrazione per assurdo: cut &amp; paste\n\nScelgo, erroneamente, il cammino orizzontale per u - v come ‚Äúminimo‚Äù.\nProvo a verificare la propriet√† di prima ‚Üí prendo due nodi x e y e controllo se il loro cammino √® minimo ‚Üí NO perch√© ho un collegamento diretto.\n\n\nDisuguaglianza triangolare\n\\forall u, v, x \\in V  \\ \\ \\ \\text{vale} \\ \\ \\ d(u,v) \\le d(u,x) + d(x, v)\n\nPer i grafi non pesati vale sempre (basta fare BFS)\nPer i grafi pesati vale solo se prendo il cammino minimo (serve Dijsktra)\n\nSPT (albero dei cammini minimi)\nT √® un SPT con sorgente s di un grafo G se\n\nT √® un albero radicato in s\nper ogni v \\in V vale che d_{T}(s, v) = d_{G}(s,v)\n\nSPT per grafi non pesati\nBasta eseguire una BFS\n\nSPT per grafi pesati: Dijsktra\nUsiamo questo algoritmo per calcolare i cammini minimi a singola sorgente su grafi pesati MA TUTTI I PESI DEGLI ARCHI DEVONO ESSERE NON NEGATIVI \\forall(u, v) \\Rightarrow w(u,v) \\ge 0\nApproccio greedy\n\n\nInizialmente do a tutti i nodi delle stime per eccesso ‚Üí D_{sv} = +\\infty\nOssia pongo che la loro distanza dalla radice s sia infinito\n\n\nL‚Äôunica stima esatta √® quella della radice ‚Üí la distanza da s√© stessa √® 0 ‚Üí D_{ss} = 0\n\n\nHo un insieme X in cui inserisco solo i nodi con le stime esatte (quindi i nodi di cui so il cammino minimo)\nInizialmente X = {s}\n\n\nUtilizzo una coda con priorit√† in cui, una volta visitato un nodo u (con la stima esatta, quindi messo in X), inserisco tutti i nodi che hanno archi entranti a partire da u e\n\nSe la stima di un nodo v √® +\\infty ‚Üí sto visitando quel nodo per la prima volta ‚Üí aggiorno la sua stima a D_{su} + w(u,v)\nSe la stima √® \\ne +\\infty ‚Üí l‚Äôho gi√† visitato ‚Üí confronto la sua stima precedente D_{sv} con la stima attuale D_{su} + w(u,v) e se quest‚Äôultima √® MINORE allora aggiorno la sua stima con D_{su} + w(u,v)altrimenti rimane identica\n\n\n\nQuando estraggo un nodo dalla coda con priorit√†, vuol dire che ha la stima esatta\n\nLo metto in X ‚Üí ogni volta in X viene inserito il nodo u appartenente a V - X\nLo metto in T, l‚ÄôSPT che voglio creare, come figlio del nodo con la stima corretta precedente\n\n\n\nCome funziona una stima non confermata?\nLa stima non confermata (presente nella coda) per un nodo y \\in V - X √® data da D_{sy} = min\\{D_{sx}+ w(x,y) : (x,y) \\in E, \\ x \\in X\\}\nDijsktra(G, s)\n\tX &lt;- insieme vuoto\n\tT &lt;- albero con radice in s\n\tcoda con priorit√† C\n\t\n\tfor each (vertice u in G) do\n\t\tD_su = +inf\n\t\n\tD_ss &lt;- 0\n\t\n\tC.insert(s)\n\t\n\twhile(not C isEmpty()) do\n\t\tu = C.deletemin()\n\t\tX = X ‚à™ {u}\n\t\t\n\t\tfor each (arco (u, v) in G) do\n\t\t\tif (D_sv == +inf) then\n\t\t\t\tD_sv = D_su + w(u,v)\n\t\t\t\trendi u padre di v in T\n\t\t\telse if (D_su + w(u,v) &lt; D_sv) then\n\t\t\t\tC.decreaseKey(v, D_sv - (D_su + w(u,v)))\n\t\t\t\tD_sv = D_su + w(u, v)\n\t\t\t\trendi u padre di v in T\n\t\n\treturn T \nLemma per Dijsktra\n\n\n                  \n                  LEMMA \n                  \n                \n\nQuando il nodo v viene estratto dalla coda con priorit√† vale:\n\nD_{sv} = d(s,v)\nil cammino da s a v nell‚Äôalbero corrente ha costo d(s,v) (cammino in G) (stima esatta)\n\nIn pratica, quando un nodo esce dalla coda con priorit√† la sua stima √® esatta.\n\n\nDIMOSTRAZIONE PER ASSURDO\nIpotizziamo un caso del genere\n\nSappiamo che la distanza da s a v √® minore della distanza da s a u a v, D_{sv} &lt; D_{su} + w(u, v)\nOra, ipotizziamo che Dijsktra abbiamo scelto la strada passante per u.\nRiprendiamo la disuguaglianza triangolare (ogni sottocammino di un cammino minimo √® un cammino minimo) e usiamola su D_{sv}\n\nIntroduciamo due nodi x e y per cui esiste un arco (x, y) \\in E.\nx si trova nell‚Äôinsieme X (quindi ha stima esatta), proprio come u.\nOra, sapendo che l‚Äôarco (x, v) ha sicuramente peso minore dell‚Äôarco (u, v) (per la disuguaglianza triangolare) ‚Üí possiamo dire che Dijsktra avrebbe dovuto estrarre il nodo y dalla coda, e non v\nQUINDI √® un assurdo ‚Üí il lemma √® vero\nComplessit√†\nEscludendo le operazioni sulla coda con priorit√† il costo √® O(m +n)\nSfruttando una coda con priorit√† con un Heap di Fibonacci (la migliore opzione), avremo come costi delle operazioni\n\nInsert = O(1)\nDelMin  = O(log(n))^{*}\nDecKey = O(1)^{*}  ‚Üí se utilizzo un puntatore diretto al nodo\n\nContando quindi che\n\neseguo n insert ‚Üí O(n)\neseguo n deleteMin ‚Üí O(n \\cdot log(n))^{*}\neseguo al pi√π m decreaseKey ‚Üí O(m)^{*}\n\nCOSTO TOTALE\nO(m+n) + O(m + n \\cdot log(n)) \\Rightarrow O(m + n \\cdot log(n))"},"UNI/ANNO-2/ALGORITMI-1/feedback-per-esame":{"slug":"UNI/ANNO-2/ALGORITMI-1/feedback-per-esame","filePath":"UNI/ANNO 2/ALGORITMI 1/feedback per esame.md","title":"feedback per esame","links":[],"tags":[],"content":"\nidea\ndescrizione+pseudocodice\nanalisi\nla descrizione deve aiutare il lettore a comprendere il codice\nanalisi di correttezza!= descrizione algoritmo\ncorrettezza/complessita:\ninsieme di proprieta che combinate ti fanno avere correttezza o bound di complessit√†\n11:00\nStudiare spiegazione correttezza di tutti gli algoritmi\n16:00 mi sembra assurdo\n\nRiepilogo delle lezioni precedenti ragionato\n\nobiettivo principale:\n\nintroduzione alle analisi e progettazione di algoritmi\n\n\nnozioni necessarie\n\nlessico\nsignificato algoritmi\ncomplessita\ncaso medio\n\n\ncostruzione di una prima toolbox per analizzare e progettare\n\ndivide and conquer o roba simile\n\n\nesempi illustri di problemi/algoritmi/strutture dati\n\nNozioni necessarie\n\nmodello di calcolo RAM a costi uniformi\ncomplessit√† nel caso peggiore e medio(da sapere solo che esiste)\nnotazione asintotica\n\nProblemi per fare esperienza\n\nzio paperone\ncalcolo fibonacci\n\nAltro strumento per correttezza\n\nEquazioni di ricorrenza\nQUALI SONO SEMPRE NELLO SCRITTO\nTeorema Master\nmetodo di iterazione\nalbero della ricorsione\n\nAlgoritmi\nDi ordinamento\n\nselection sort (\\Theta(n^2))\nmerge sort (\\Theta(nlogn)) D&amp;C\nquick sort\n\n(O(n^2))\n(\\theta(nlogn)) caso medio\n\n\nquick sort randomizzato\n\nO(nlogn)\ncaso medio vs algoritmi randomizzati\n\n\nHeap sort O(n(logn))\nbongo sort O(binglao)\n1:13\nlower Bound ordinamento\n\n\\Omega(nlogn) confronti nel caso peggiore\n\n\nInteger Sort(Bucket Sort)\n\nO(n+k) per [1,k] elementi\n1:16 guala fischia\n\n\nRadix sort O(n) se k e un polinomio O(n^c)\n\nRappresentazione di alberi e algoritmi di visita\n\nvisita in ampiezza BFS\nvisita in profondita DFS\nutilizzati per calcolare informazioni su alberi\n\nproblema del dizionario\n\ntipo di dato vs struttura dati\nBST O(h) h altezza\nAVL O(logn) per garatire che h e sempre logaritmico\n\nproblema della coda con priorita\n1:28\n\nd-heap heap\nbinomiali merge O(logn)\nheap di Fib(accenni solo complessita) O(1^*)\ncomplessita ammortizzata\n\nGrafi\n\nrappresentazione in memoria\n\nmatrici di adiacenza\\Theta(n^2) vs liste di adiacenza \\Theta(m+n)\nconviene usare le liste di adiacenza\n\n\nvisita BFS calc. SPT/ distanze singola sorgente (tutto con grafi non pesati)\n\nO(m+n)\n\n\nvisita DFS trovare ordinamento topologico per DAG\n\ncomponenti fortemente connesse\n\n\nalgoritmo di Dijkstra SPT/singola sorgente su grafi pesati \\geq 0  O(m+nlogn)\n\nESERCITAZIONI\n\nricerca binaria utile\nusando algoritmi che in tempo lineare trovavano informazioni sui suffissi e sui prefissi\n1:39\n"},"UNI/ANNO-2/ALGORITMI-1/fotoalg/README":{"slug":"UNI/ANNO-2/ALGORITMI-1/fotoalg/README","filePath":"UNI/ANNO 2/ALGORITMI 1/fotoalg/README.md","title":"README","links":[],"tags":[],"content":"Quartz v4\n\n‚Äú[One] who works with the door open gets all kinds of interruptions, but [they] also occasionally gets clues as to what the world is and what might be important.‚Äù ‚Äî Richard Hamming\n\nQuartz is a set of tools that helps you publish your digital garden and notes as a website for free.\nQuartz v4 features a from-the-ground rewrite focusing on end-user extensibility and ease-of-use.\nüîó Read the documentation and get started: quartz.jzhao.xyz/\nJoin the Discord Community\nSponsors\n\n  \n    \n  \n"},"UNI/ANNO-2/ALGORITMI-2/ALGORITMI-2-INDICE":{"slug":"UNI/ANNO-2/ALGORITMI-2/ALGORITMI-2-INDICE","filePath":"UNI/ANNO 2/ALGORITMI 2/ALGORITMI 2 INDICE.md","title":"ALGORITMI 2 INDICE","links":["UNI/ANNO-2/ALGORITMI-2/1.pdf","UNI/ANNO-2/ALGORITMI-2/2.pdf","UNI/ANNO-2/ALGORITMI-2/3.pdf","UNI/ANNO-2/ALGORITMI-2/4.pdf","UNI/ANNO-2/ALGORITMI-2/5.pdf","UNI/ANNO-2/ALGORITMI-2/6.pdf","UNI/ANNO-2/ALGORITMI-2/7.pdf","UNI/ANNO-2/ALGORITMI-2/8.pdf","UNI/ANNO-2/ALGORITMI-2/8.1.pdf","UNI/ANNO-2/ALGORITMI-2/9.pdf","UNI/ANNO-2/ALGORITMI-2/9.1.pdf"],"tags":[],"content":"LISTA DEI PDF:\n1.pdf\n2.pdf\n3.pdf\n4.pdf\n5.pdf\n6.pdf\n7.pdf\n8.pdf\n8.1.pdf\n9.pdf\n9.1.pdf"},"UNI/ANNO-2/ALGORITMI-2/ASD_compendio_Esercizi1_2":{"slug":"UNI/ANNO-2/ALGORITMI-2/ASD_compendio_Esercizi1_2","filePath":"UNI/ANNO 2/ALGORITMI 2/ASD_compendio_Esercizi1_2.md","title":"ASD_compendio_Esercizi1_2","links":["tags/archi","tags/augmentazioni","tags/macchine"],"tags":["archi","augmentazioni","macchine"],"content":"Compendio ASD ‚Äî Esercizi 1 &amp; 2 (versione compatta in Markdown)\n\nObiettivo: lista autosufficiente di argomenti per rispondere correttamente ai V/F, mini‚Äêprove e domande a tranello degli Esercizi 1 e 2. Include le AGGIUNTE FONDAMENTALI emerse dagli scritti.\n\n\nESERCIZIO 1\nMST (Minimum Spanning Tree)\n\nCycle property / Cut property\nDifferenze MST vs SPT (Shortest Path Tree)\nComplessit√† di Prim / Kruskal, e impatto delle strutture dati Union-Find\nCasi particolari (pesi tutti uguali, grafi completi, archi {1,2}, ecc.)\nAGGIUNTE FONDAMENTALI\n\nForme forti delle propriet√†\n\nCycle: l‚Äôarco pi√π pesante di un ciclo non appartiene ad alcun MST.\nCut: ogni arco strettamente minimo su un taglio appartiene a tutti gli MST; in caso di pari peso, ciascuno sta in almeno un MST.\n\n\nUnicit√† / non‚Äêunicit√†\n\nMST unico con pesi tutti distinti.\nCon pesi uguali: non unico (se pesi=1 ogni ST √® un MST).\n\n\nSPT ‚â† MST (anche con pesi positivi)\n\nSPT minimizza distanze da una sorgente, MST minimizza somma pesi degli archi: in generale diversi.\nCaso pesi=1: uno SPT fissato pu√≤ non coincidere con un MST fissato (insiemi di archi diversi).\n\n\nCorrettezza\n\nPrim via Cut property (arco minimo che attraversa il taglio =(S, V\\S) √® ‚Äúsicuro‚Äù).\nKruskal via Cycle/Cut + exchange argument (inserire archi in ordine crescente senza creare cicli).\n\n\nBound e casi {1,2}\n\nMassimizzare archi da 1; saper derivare limiti sul costo MST in funzione di |V| e archi di peso 1.\nGrafi completi: complessit√† (O(E\\log V)) con (E=\\Theta(V^2)).\n\n\n\n\n\nComplessit√† (promemoria)\n\nPrim: (O(E\\log V)) (heap binario); (O(E+V\\log V)) (Fibonacci heap).\nKruskal: (O(E\\log V)) + UF ammortizzato (O(\\alpha(V))).\n\n\nMax Flow / Min Cut\n\nTeorema max-flow min-cut\nComplessit√† Ford-Fulkerson (esponenziale o polinomiale con capacit√† intere)\nAGGIUNTE FONDAMENTALI\n\nGrafo residuo (G_f): archi forward con capacit√† (c-f) e backward con capacit√† (f). Bottleneck su un cammino aumentante.\nCondizione di ottimalit√†: nessun cammino (s\\leadsto t) in (G_f) ‚áî flusso massimo (‚áî esiste un min-cut con capacit√† = valore del flusso).\nEdmonds‚ÄìKarp (EK): sceglie cammini a minimo archi (BFS); augmentazioni (O(VE)) ‚áí tempo (O(VE^2)) (polinomiale).\nEstrazione del min-cut da un max-flow: prendi l‚Äôinsieme R dei vertici raggiungibili da (s) in (G_f) finale ‚áí il taglio ((R, V\\R)) √® minimo e (|f| = c(R,V\\R)).\nTerminazione di FF: con capacit√† intere termina (tempo pseudo‚Äêpolinomiale, dipende da (|f^*|)); con irrazionali pu√≤ non terminare.\n\n\n\nFrasi T/F tipiche\n\n‚ÄúC‚Äô√® un arco con capacit√† residua vicino a (t) ‚áí esiste un cammino aumentante‚Äù ‚Üí Falso (serve un percorso completo da (s) a (t)).\n‚ÄúAssenza di cammini aumentanti ‚áí flusso massimo‚Äù ‚Üí Vero.\n‚ÄúFF √® sempre polinomiale‚Äù ‚Üí Falso; EK s√¨, (O(VE^2)).\n‚ÄúIl flusso netto attraverso qualunque taglio vale (|f|)‚Äù ‚Üí Vero (definizione di valore del flusso).\n\n\nUnion-Find (Disjoint Set Union, DSU)\n\nQuickFind, QuickUnion, con/ senza euristiche, e complessit√† ammortizzate\nUso in Kruskal.\nAGGIUNTE FONDAMENTALI\n\nUnion-by-rank/size + path compression: costo ammortizzato (O(\\alpha(n))) per operazione; differenza da worst‚Äêcase.\nAltezza delle foreste: (\\Theta(\\log n)) senza compression (con rank/size); come costruire sequenze testimoni.\nLower bound: per (m) operazioni su (n) elementi, tempo totale (\\Omega(m+n)) √® inevitabile.\nImpatto in Kruskal: sorting (O(E\\log V)) domina; UF √® ‚Äúquasi (O(1))‚Äù ammortizzato.\n\n\n\nT/F rapidi\n\n‚Äúfind √® (O(1)) worst‚Äêcase con compression+rank‚Äù ‚Üí Falso (√® (O(\\alpha(n))) ammortizzato).\n‚ÄúQuickFind ha union (O(n))‚Äù ‚Üí Vero.\n‚ÄúUnion-by-size garantisce altezza (\\Theta(\\log n)) (senza compression)‚Äù ‚Üí Vero.\n\n\nProblemi Greedy/PD classici (pi√π rari in E1, ma compaiono)\n\nInterval Scheduling (ordinare per earliest finish time, exchange argument).\nLoad Balancing (due lower bound: media e job pi√π lungo) ‚Äî utile per 2-approx.\nAGGIUNTE UTILI\n\nInterval Partitioning: depth = macchine ottimo; greedy con priority queue.\n\n\n\n\nESERCIZIO 2 (promemoria integrato)\n\nFlussi (max-flow, min-cut, Ford‚ÄìFulkerson)\n\nEK (O(VE^2)) vs FF (pseudo‚Äêpolinomiale);\nMin-cut da (G_f) finale (raggiungibili da (s)) con sketch di correttezza;\nDefinizioni brevi: flusso, valore, residua, cammino aumentante, capacit√† di un taglio.\n\n\nMST (cut property, Prim)\n\nProof sketch di Prim via cut property; unicit√† con pesi distinti; controesempi MST‚â†SPT.\n\n\nScheduling (Interval Scheduling, Interval Partitioning, Load Balancing)\n\nIS: EFT + exchange argument; IP: depth + heap; LB per 2-approx del LB.\n\n\nLoad Balancing 2-approx\n\nDue LB (media e job max) ‚áí fattore 2.\n\n\nClassi di complessit√† (NP, riduzioni polinomiali, Vertex Cover)\n\nDefinizioni NP / NP-hard / NP-complete (certificato verificabile in tempo polinomiale).\nRiduzione polinomiale: funzione calcolabile in polinomiale che preserva s√¨/no.\nEsempi: 3-SAT ‚Üí Independent Set / Vertex Cover (idea di gadget).\nDecisione vs Ottimizzazione: perch√© si usa la versione decisione per NP-completezza.\n\n\n\n\nMicro-schemi ‚Äúpronti‚Äù (1‚Äì2 righe)\n\nCut property (proof sketch): arco strettamente minimo su un taglio √® sicuro; se manca dall‚ÄôMST, aggiungilo ‚Üí ciclo; sostituisci un arco sul taglio non pi√π leggero ‚áí costo non aumenta ‚áí contraddizione.\nCycle property (proof sketch): arco pi√π pesante di un ciclo pu√≤ essere rimosso e sostituito con altro del ciclo senza aumentare il costo ‚áí non appartiene ad alcun MST.\nMin-cut da max-flow: (R)=raggiungibili da (s) in (G_f) finale ‚áí tutti gli archi da (R) a (V\\R) sono saturi ‚áí (c(R,V\\R)=|f|) ‚áí taglio minimo.\n\n\nTabella flash complessit√†\n\nPrim: (O(E\\log V)) (binario); (O(E+V\\log V)) (Fibonacci).\nKruskal: (O(E\\log V)) + UF (O(\\alpha(V))) ammortizzato/operazione.\nUF (rank+compression): (O(m,\\alpha(n))) su (m) operazioni.\nFord‚ÄìFulkerson (capacit√† intere): termina; tempo pseudo‚Äêpolinomiale (dipende da (|f^*|)).\nEdmonds‚ÄìKarp: (O(VE^2)).\n\n\n(Suggerimento: stampa questa pagina e ripassa le frasi T/F e i micro‚Äêschemi: coprono la maggioranza dei tranelli.)"},"UNI/ANNO-2/ALGORITMI-2/Gay-7":{"slug":"UNI/ANNO-2/ALGORITMI-2/Gay-7","filePath":"UNI/ANNO 2/ALGORITMI 2/Gay 7.md","title":"Gay 7","links":[],"tags":[],"content":"Problema dei k-centri (2-approximation)\nDEFINIZIONE\n\nDati un set di n siti s_{1}, ..., s_{n} e un intero k &gt; 0.\nselezionare k centri C affinch√© la distanza tra un sito e il centro pi√π vicino sia minima.\n\n\n\n\n                  \n                   r(C) indica la distanza peggiore tra tutte le dist(s_i, C)\n                  \n                \n\nNel senso\n\ncalcola TUTTE le distanze dei siti dai centri pi√π vicini\nprendi la peggiore ‚Üí quella √® r(C)\ncos√¨ tu sai che il minimo raggio di copertura per coprire tutti i siti √® questo valore qui\n\n\n\nAlgoritmo greedy\nSceglie k volte il sito pi√π lontano da qualsiasi centro finora creato, e lo usa come prossimo centro.\n\n\n\n                  \n                   \n                  \n                \n\nL‚Äôalgoritmo greedy potrebbe non essere ottimo ma la sua soluzione non si discosta pi√π del doppio rispetto all‚Äôottimo.\nDIMOSTRAZIONE\n\nPer assurdo ipotizziamo che l‚Äôottimo sia molto pi√π piccolo r(C^{*}) &lt; \\frac1 2 r(C)\n\n\nossia il centro ottimale copre con sfere grandi la met√† di quelle del greedy\n\n\nCostruiamo sfere intorno ai centri trovati c \\in C, con raggio \\frac1 2 r(C)\n\n\nin questa nuova sfera deve esserci ALMENO un centro ottimo c_{i}^{*} altrimenti l‚Äôipotesi sarebbe sbagliata\n\n\nTutte le sfere, per costruzione, sono disgiunte (non si sovrappongono) e quindi in ognuna c‚Äô√® ESATTAMENTE un centro ottimale\n\n\nquindi c‚Äô√® una corrispondenza tra i centri di C e quelli di C*, in particolare |C| = |C^{*}|\n\n\nOra colleghiamo un sito s al suo centro\n\n\nprendiamo un sito s\nsia c_{i}^{*} il centro ottimo pi√π vicino a s\ne sia c_{i} il centro di C che ‚Äúsi abbina a c_{i}^{*}‚Äù (ossia che si trova nella stessa sfera)\nLA DISTANZA DI s dal centro c_{i} trovato dal greedy soddisfa dist(s,C) \\le dist(s, c_{i}^{*}) + dist(c_{i}^{*}, c_{i})\n\nla prima parte dist(s, c_{i}^{*}) √® al massimo r(C^{*}), per definizione\nla seconda parte dist(c_{i}^{*}, c_{i}) anche √® al massimo r(C^{*}), perch√© i due centri si trovano nella stessa sfera\n\n\n\n\nQUINDI la distanza totale √® dist(s, C) \\le 2 \\cdot r(C^{*})\nE QUESTO VALE PER OGNI SITO s\n\n\n"},"UNI/ANNO-2/ALGORITMI-2/LISTA-ARGOMENTI-UTILI":{"slug":"UNI/ANNO-2/ALGORITMI-2/LISTA-ARGOMENTI-UTILI","filePath":"UNI/ANNO 2/ALGORITMI 2/LISTA ARGOMENTI UTILI.md","title":"LISTA ARGOMENTI UTILI","links":[],"tags":[],"content":"Greedy\n\ninterval scheduling e interval partitioning\nUnion Find data structures\n\nQuick find\nQuick union\n\n\nMST\n\nbisogna ricordarsi a menadito la definizione\nricordarsi G non orientato\nsolo due algoritmi Kruskal e prim\nsenza roba inversa strana\n\n\nClustering di massimo spacing\n\ndefinizione\npk √© collegato con il MST\n\n\n\nProgrammazione Dinamica\n\nDefinire i sotto-problemi\ni vari principi\nWeighted independent set on paths\nWeighted interval scheduling\n\ngeneralizzazione di quello greedy\n\n\nLongest increasing subsequence\n\nil re delle taverne ubriaco\n\n\nHouse coloring problem\n\n1%\n\n\nSegmented Least squares\n\n10% che lo chiede\n\n\nKnapsack problem\n\n35% importante\n\n\nSequence Alignment/ edit distance\nBellman Ford cammini minimi per grafi con pesi negativi\n\nche problema risolve? che complessit√°.\nl‚Äôanalisi di bellman ford sullo scritto sicuro non lo chiede\n\n\n\nFlusso\n\nmax-flow /min cut problem\nFord FulKerson alg\n\nidea sull‚Äôanalisi\n\n\napplicazioni\n\nmatching su grafi bipartiti\ncammini disgiunti\n\nsenza analisi solo come si fa\n\n\nimage segmentation\n\ndefinizione del grafo ausiliario\n\n\nbaseball elimination\n\n0.5%\n\n\n\n\n\nNP-COMPLETEZZA\n\nriduzioni polinomiali\n\nIl loro obiettivo e per fare confronti su difficolt√† di problemi\n\n\nClassi\n\nP\nNP\nEXP\n\n\nP vs NP\nNP - completezza\nProblemi importanti che richiedono solo la definizione\n\nSAT\n3SAT\nVertex Cover\nindependent set\n2-partitioning,3-partitioning\n\nmeno importanti\n\n\n\n\n\nAlgoritmi di approssimazione\n\ndefinizione\n2-apx per load balancing\n2-apx per K center problem\n\nHash Tables\nbho"},"UNI/ANNO-2/ALGORITMI-2/LISTA-ARGOMENTI":{"slug":"UNI/ANNO-2/ALGORITMI-2/LISTA-ARGOMENTI","filePath":"UNI/ANNO 2/ALGORITMI 2/LISTA ARGOMENTI.md","title":"LISTA ARGOMENTI","links":[],"tags":[],"content":"\n\nGreedy\n\n\nInterval Scheduling\n\n\nInterval Partitioning\n\n\nUnion-Find (QuickFind, QuickUnion, varianti)\n\n\nMinimum Spanning Tree (MST)\n\n\nKruskal\n\n\nReverse-delete\n\n\nPrim\n\n\nClustering\n\n\n\n\nProgrammazione Dinamica\n\n\nInsiemi indipendenti di peso massimo\n\n\nInterval Scheduling con peso\n\n\nLongest Increasing Subsequence (LIS)\n\n\nSegmented Least Squares\n\n\nKnapsack\n\n\nSequence Alignment (e Hirschberg)\n\n\nShortest paths con pesi negativi\n\n\nBellman-Ford-Moore\n\n\n\n\nFlussi\n\n\nMax-flow / Min-cut\n\n\nFord-Fulkerson\n\n\n\n\nAlgoritmi di Approssimazione\n\n\nLoad Balancing (List Scheduling, LPT)\n\n\nk-center (2-approximation)\n\n\n\n\nRiduzioni Polinomiali\n\n\nIndependent Set ‚Üî Vertex Cover\n\n\nVertex Cover ‚Üí Set Cover\n\n\n3-SAT ‚Üí Independent Set\n\n\n\n"},"UNI/ANNO-2/ALGORITMI-2/LISTA-DI-COSA-CHIEDE":{"slug":"UNI/ANNO-2/ALGORITMI-2/LISTA-DI-COSA-CHIEDE","filePath":"UNI/ANNO 2/ALGORITMI 2/LISTA DI COSA CHIEDE.md","title":"LISTA DI COSA CHIEDE","links":["tags/archi","tags/macchine"],"tags":["archi","macchine"],"content":"ESERCIZIO 1\n\n\nMST (Minimum Spanning Tree)\n\nCycle property / Cut property\nDifferenze MST vs SPT (Shortest Path Tree)\nComplessit√† di Prim / Kruskal, e impatto delle strutture dati Union-Find\nCasi particolari (pesi tutti uguali, grafi completi, archi {1,2}, ecc.)\nAGGIUNTE FONDAMENTALI\n\nForme ‚Äúforti‚Äù delle propriet√†:\nCycle (heaviest-in-cycle non sta in alcun MST); Cut (ogni arco strettamente minimo sul taglio sta in tutti gli MST).\nUnicit√†/non-unicit√†: MST unico con pesi tutti distinti; con pesi uguali non unico (con pesi=1 ogni ST √® un MST).\nSPT ‚â† MST con esempi: saper costruire controesempi anche quando i pesi sono tutti positivi; caso ‚Äúpesi=1‚Äù: SPT fissato pu√≤ non coincidere con un MST fissato.\nCorrettezza di Prim via Cut property (schema di scambio) e di Kruskal via Cycle/Cut (exchange argument).\nBound e casi {1,2}: saper derivare/giustificare limiti sul costo dell‚ÄôMST e quando si massimizzano gli archi di peso 1.\n\n\n\n\n\nMax Flow / Min Cut\n\nTeorema max-flow min-cut\nComplessit√† Ford-Fulkerson (esponenziale o polinomiale con capacit√† intere)\nAGGIUNTE FONDAMENTALI\n\n\nGrafo residuo operativo: archi forward c‚àífc-fc‚àíf e backward fff; bottleneck; perch√© ‚Äúcapacit√† libera vicino a ttt‚Äù non implica per forza un cammino aumentante.\n\n\nCondizione di ottimalit√†: ‚Äúnessun cammino aumentante in GfG_fGf‚Äã‚Äù ‚áî flusso massimo (equivalenza col min-cut).\n\n\nEdmonds‚ÄìKarp (BFS): scelta del cammino a minimo archi, complessit√† O(VE2)O(VE^2)O(VE2), monotonia delle distanze residue.\n\n\nEstrazione del min-cut da un max-flow: insieme dei raggiungibili da sss in GfG_fGf‚Äã finale ‚áí\\Rightarrow‚áí taglio minimo (R,V‚Äâ‚Å£‚àñ‚Äâ‚Å£R)(R,V!\\setminus!R)(R,V‚àñR) con sketch di correttezza.\n\n\nTerminazione FF: con capacit√† intere termina (pseudo-polinomiale, dipende da ‚à£|f^*|; con capacit√† irrazionali pu√≤ non terminare.\n\n\n\n\n\n\nUnion-Find\n\n\nQuickFind, QuickUnion, con/ senza euristiche, e complessit√† ammortizzate\n\n\nUso in Kruskal.\n\n\nAGGIUNTE FONDAMENTALI\n\n\nUnion-by-rank/size + path compression: costo ammortizzato O(\\alpha(n)) per operazione; differenza da worst-case.\n\n\nAltezza delle foreste: \\Theta(\\log n)) senza compression (con rank/size); come costruire sequenze testimoni.\n\n\nLower bound generale: qualunque struttura simile richiede Œ©(m+n)\\Omega(m+n)Œ©(m+n) tempo totale su mmm operazioni.\n\n\nImpatto pratico in Kruskal: sorting O(E\\log V) + UF ‚Äúquasi O(1)‚Äù ammortizzato.\n\n\n\n\n\n\nProblemi Greedy o PD classici (pi√π rari in Esercizio 1, ma compaiono in qualche sessione)\n\n\nInterval Scheduling\n\n\nLoad Balancing\n\n\nAGGIUNTE UTILI (se compaiono)\n\n\nInterval Partitioning: concetto di depth = macchine ottimo; greedy con priority queue.\n\n\nProve lampo: exchange argument per IS; due lower bound (media e job pi√π lungo) per il 2-approx del Load Balancing.\n\n\n\n\n\n\n\nESERCIZIO 2\nS√¨, anche l‚ÄôEsercizio 2 ha pattern forti:\n\n\nFlussi (max-flow, min-cut, Ford-Fulkerson)\n\n\nAGGIUNTE FONDAMENTALI\n\n\nEdmonds‚ÄìKarp O(VE^2) e confronto con FF (pseudo-polinomiale).\n\n\nAlgoritmo per il min-cut da G_f e relativa giustificazione.\n\n\nDefinizioni ‚Äúbrevi‚Äù pronte: flusso, capacit√† di un taglio, residua, cammino aumentante, valore del flusso.\n\n\n\n\n\n\nMST (cut property, Prim)\n\n\nAGGIUNTE FONDAMENTALI\n\n\nProof sketch di Prim tramite cut property;\n\n\nUnicit√† con pesi distinti e non-unicit√† con pari peso;\n\n\nControesempi rapidi per falsificare affermazioni tipiche (MST=SPT, ecc.).\n\n\n\n\n\n\nScheduling (Interval Scheduling, Interval Partitioning, Load Balancing)\n\n\nAGGIUNTE FONDAMENTALI\n\n\nIS: ordinare per earliest finish time + exchange argument.\n\n\nIP: depth come lower bound e greedy ottimo con heap.\n\n\nLoad Balancing 2-approx: due LB (media, job max) e prova del fattore 2.\n\n\n\n\n\n\nLoad Balancing 2-approx\n\n\nClassi di complessit√† (NP, riduzioni polinomiali, Vertex Cover)\n\n\nAGGIUNTE FONDAMENTALI\n\n\nDefinizioni nette: NP, NP-hard, NP-complete; certificato verificabile in tempo polinomiale.\n\n\nRiduzione polinomiale (formale): funzione calcolabile in polinomiale che preserva s√¨/no.\n\n\nEsempi canonici: 3-SAT ‚Üí\\rightarrow‚Üí Independent Set / Vertex Cover (idea dei gadget).\n\n\nDecisione vs ottimizzazione: perch√© si riduce su versioni decisione per la NP-completezza.\n\n\n\n\n\n"},"UNI/ANNO-2/ALGORITMI-2/ORALE_GUIDA":{"slug":"UNI/ANNO-2/ALGORITMI-2/ORALE_GUIDA","filePath":"UNI/ANNO 2/ALGORITMI 2/ORALE_GUIDA.md","title":"ORALE_GUIDA","links":[],"tags":[],"content":"üìÖ Piano per l‚ÄôOrale (9 ‚Üí 11 settembre)\nüîπ 9 settembre (oggi pomeriggio/sera) ‚Üí Consolidamento Greedy, MST e Flussi\n\n\n15:30 ‚Äì 17:00 ‚Üí üìå MST\n\n\nDefinizione, propriet√† (cut/cycle).\n\n\nAlgoritmi Kruskal, Prim.\n\n\nTeoremi di correttezza (cut/cycle property).\n\n\n\n\n17:15 ‚Äì 18:00 ‚Üí üìå Union-Find\n\n\nQuickFind vs QuickUnion.\n\n\nEuristiche: union by size + path compression.\n\n\nComplessit√† ammortizzata.\n\n\n\n\n18:00 ‚Äì 18:30 ‚Üí ‚òï Pausa\n\n\n18:30 ‚Äì 20:00 ‚Üí üìå Max Flow / Min Cut\n\n\nDefinizione flusso, rete residua, augmenting path.\n\n\nLemma valore flusso, dualit√† debole.\n\n\nTeorema Max-flow = Min-cut.\n\n\nAlgoritmi Ford-Fulkerson ed Edmonds-Karp.\n\n\n\n\n20:00 ‚Äì 21:00 ‚Üí Cena\n\n\n21:00 ‚Äì 23:00 ‚Üí üìå Interval Scheduling &amp; Partitioning\n\n\nIS: greedy per fine, teorema di correttezza.\n\n\nIP: definizione, depth = n¬∞ minimo aule.\n\n\n\n\n23:15 ‚Äì 00:00 ‚Üí Ripasso orale a voce (simula domande).\n\n\n\nüîπ 10 settembre (giornata piena) ‚Üí Programmazione Dinamica e Approssimazioni\n\n\n09:00 ‚Äì 10:30 ‚Üí üìå Programmazione Dinamica (parte 1)\n\n\nTemplate generale DP.\n\n\nIndependent Set su cammino.\n\n\nWeighted Interval Scheduling.\n\n\n\n\n10:30 ‚Äì 11:00 ‚Üí ‚òï Pausa\n\n\n11:00 ‚Äì 12:30 ‚Üí üìå Programmazione Dinamica (parte 2)\n\n\nKnapsack (ricorrenza + traceback).\n\n\nLongest Increasing Subsequence.\n\n\nSegmented Least Squares.\n\n\n\n\n12:30 ‚Äì 14:00 ‚Üí Pranzo\n\n\n14:00 ‚Äì 15:30 ‚Üí üìå Edit Distance / Sequence Alignment\n\n\nRicorrenza.\n\n\nHirschberg (spazio lineare).\n\n\n\n\n15:30 ‚Äì 16:00 ‚Üí Pausa\n\n\n16:00 ‚Äì 17:30 ‚Üí üìå Shortest Paths con pesi negativi\n\n\nBellman-Ford.\n\n\nDifferenze con Dijkstra.\n\n\nLemmi sui cicli negativi.\n\n\n\n\n17:30 ‚Äì 18:00 ‚Üí Pausa\n\n\n18:00 ‚Äì 19:00 ‚Üí üìå Approssimazioni\n\n\nLoad Balancing: List Scheduling (2-approx), LPT (4/3).\n\n\nk-center: algoritmo greedy, 2-approx.\n\n\n\n\n19:00 ‚Äì 20:30 ‚Üí Cena + relax\n\n\n21:00 ‚Äì 22:30 ‚Üí üìå Riduzioni Polinomiali\n\n\nIS ‚Üî VC.\n\n\nVC ‚â§p SC.\n\n\n3-SAT ‚â§p IS.\n\n\nP, NP, EXP.\n\n\n\n\n22:30 ‚Äì 23:00 ‚Üí Flashcard orali (domande rapide).\n\n\n\nüîπ 11 settembre (mattina ‚Üí ripasso finale)\n\n\n07:45 ‚Äì 08:30 ‚Üí Ripasso a voce dei teoremi fondamentali:\n\n\nCut/Cycle property.\n\n\nMax-flow Min-cut.\n\n\nCorrettezza Interval Scheduling.\n\n\nBound List Scheduling.\n\n\nRiduzione IS ‚Üî VC.\n\n\n\n\n08:30 ‚Äì 08:50 ‚Üí Respiro + pausa (niente pi√π studio).\n\n\n09:00 ‚Üí Orale üöÄ\n\n"},"UNI/ANNO-2/ALGORITMI-2/PIANO":{"slug":"UNI/ANNO-2/ALGORITMI-2/PIANO","filePath":"UNI/ANNO 2/ALGORITMI 2/PIANO.md","title":"PIANO","links":[],"tags":[],"content":"üîπ 7 settembre (stasera, 20:30 ‚Äì 01:00) ‚Üí Focus MST e Flussi\n\n\n20:30 ‚Äì 21:30 ‚Üí üìå MST\n\n\nDefinizione MST.\n\n\nCut property / Cycle property.\n\n\nUnicit√† con pesi distinti.\n\n\nKruskal e Prim (idea, pseudocodice, complessit√†).\n\n\n\n\n21:30 ‚Äì 22:15 ‚Üí üìå Union-Find\n\n\nMakeSet, Find, Union.\n\n\nQuickFind vs QuickUnion.\n\n\nUnion by size + path compression.\n\n\n\n\n22:30 ‚Äì 00:00 ‚Üí üìå Max Flow / Min Cut\n\n\nDefinizione flusso, rete residua.\n\n\nLemma valore del flusso.\n\n\nDualit√† debole.\n\n\nTeorema Max-flow = Min-cut.\n\n\nAugmenting Path Theorem.\n\n\nComplessit√† Ford-Fulkerson (esponenziale / polinomiale se capacit√† intere).\n\n\n(Se hai tempo: pseudocodice Ford-Fulkerson).\n\n\n\n\n00:00 ‚Äì 00:45 ‚Üí üìå Interval Scheduling &amp; Partitioning\n\n\nIS: definizione, greedy ordinando per tempo di fine, teorema di correttezza.\n\n\nIP: definizione, Depth = numero minimo aule.\n\n\n\n\n00:45 ‚Äì 01:00 ‚Üí Ripasso rapido di quello visto, a voce ad alta voce (allenamento orale).\n\n\n\nüîπ 8 settembre (giornata piena) ‚Üí consolidamento e DP\n\n\n09:00 ‚Äì 10:30 ‚Üí üìå Load Balancing\n\n\nDefinizione makespan.\n\n\nAlgoritmo List Scheduling (2-approx).\n\n\nLPT (4/3 approx).\n\n\nComplessit√†.\n\n\n\n\n10:45 ‚Äì 12:30 ‚Üí üìå Programmazione Dinamica (parte 1)\n\n\nTemplate generale DP (sotto-problema, ricorrenza, casi base, complessit√†).\n\n\nIndependent Set su cammino.\n\n\nWeighted Interval Scheduling.\n\n\n\n\n12:30 ‚Äì 13:00 ‚Üí pausa pranzo.\n\n\n14:00 ‚Äì 15:30 ‚Üí üìå Programmazione Dinamica (parte 2)\n\n\nKnapsack.\n\n\nEdit Distance / Sequence Alignment.\n\n\nRicostruzione soluzioni (traceback).\n\n\n\n\n15:45 ‚Äì 17:00 ‚Üí üìå Riduzioni polinomiali\n\n\nDefinizione X ‚â§p Y.\n\n\nIS ‚Üî VC.\n\n\nVC ‚â§p Set Cover.\n\n\n3-SAT ‚â§p IS.\n\n\n\n\n17:15 ‚Äì 18:00 ‚Üí üìå Teoremi fondamentali ripetuti ad alta voce\n\n\nCut/Cycle property.\n\n\nMax-Flow Min-Cut.\n\n\nAugmenting Path Theorem.\n\n\nCorrettezza greedy IS.\n\n\nDepth di IP.\n\n\nBound List Scheduling.\n\n\n\n\n18:00 ‚Äì 19:30 ‚Üí üìå Allenamento pratico\n\n\nScegli 2 compiti vecchi.\n\n\nProva a scrivere solo risposte secche a Esercizio 1 e 2 (5 righe max).\n\n\n\n\nDopo cena (21:00 ‚Äì 23:30) ‚Üí üìå Allenamento DP (Esercizio 3)\n\nProva a scrivere schema ricorrenza + casi base + complessit√† per 2-3 esercizi di prova.\n\n\n\n23:30 ‚Äì 00:30 ‚Üí üìå Ripasso notturno\n\nFlashcard/memoria attiva: leggi le definizioni e cerca di ripeterle a memoria.\n\n\n"},"UNI/ANNO-2/ALGORITMI-2/STUDIO-2":{"slug":"UNI/ANNO-2/ALGORITMI-2/STUDIO-2","filePath":"UNI/ANNO 2/ALGORITMI 2/STUDIO 2.md","title":"STUDIO 2","links":[],"tags":[],"content":"GREEDY\n\nin ogni passo scegli la soluzione migliore a breve termine (la scelta locale ottimale), sperando che porti anche alla soluzione globale ottimale.\n\nInterval scheduling\n\ndefinizione\n\nDati in input n intervalli: I_1 ,...,I_n\nI_i¬† ha tempo di inizio S_i¬† e tempo di fine f_i¬†\nDue intervalli sono compatibili se non si sovrappongono¬†\nTrovare il sottoinsieme di intervalli compatibili con cardinalit√† massima\n\nSoluzione greedy\n\nordina  gli intervalli per tempo di fine\nComplessit√†: O(n \\ log n)\n\n\nTeoremi\n\n\nInterval partitioning\n\ndefinizione\n\nDati in input un insieme di n intervalli (lezioni): j_1,...,j_n\nLezione j inizia a s_j e finisce a f_j¬†\nTrovare il minimo numero di classi per schedulare tutte le lezioni affinch√© non ci siano due lezioni contemporaneamente nella stessa classe( ovvero le lezioni nella stessa classe devono essere compatibili)\n\nSoluzione greedy\n\nordina per tempo di inizio s_i\nComplessit√†: O(n \\ log n)\n\nTeoremi\n\n\nUnion Find Struttura dati\n\ndefinizione\n\nMantenere una collezione di insiemi disgiunti contenenti elementi distinti durante l‚Äôesecuzione di una sequenza di operazioni del seguente tipo:¬†\n\nMakeset(x) = crea il nuovo insieme x = {x} di nome x¬†\nUnion(A,B) = unisce gli insiemi A, B in un unico insieme di nome A (distrugge quelli vecchi)¬†\nFind(x) = restituisce il nome dell‚Äôinsieme che contiene l‚Äôelemento x (si suppone di accedere direttamente all‚Äôelemento x)\n\n\n\nQuickFind\n\nUsiamo una foresta di alberi di altezza 1 per rappresentare gli insiemi disgiunti. In ogni albero:¬†\n\nRadice = nome dell‚Äôinsieme\nFoglie = elementi ( incluso l‚Äôelemento rappresentativo, il cui valore √® nella radice e da il nome all‚Äôinsieme stesso)\n\nImplementazione delle varie operazioni\n\nMakeset(elem e) T(n) = O(1)\n\nCrea un albero composto da due nodi: una radice e una foglia. Memorizza e sia nella foglia che nella radice come nome dell‚Äôalbero\n\n\nUnion(name a, name b) T(n) = O(n)¬†\n\nSostituisce tutti i puntatori delle foglie di B alla radice di B con puntatori alla radice di A. cancella la vecchia radice di B.\n\n\nFind(elem e) --&gt; name T(n) = O(1)\n\nAccede alla foglia x corrispondente all‚Äôelemento e. da tale nodo segue il puntatore al padre che √® la radice dell‚Äôalbero e restituisce il nome memorizzato in tale radice\n\n\n\nQuickFind bilanciato\n\n\n                  \n                  troppi cambi di puntatori con troppe union fanno venire un costo complessivo di O(n^2)\n                  \n                \n\n\n\nUnion by size\n\nNell‚Äôunione degli insiemi A e B attacchiamo¬† gli elementi dell‚Äôinsieme con cardinalit√† minore a quello di cardinalit√† maggiore e se necessario modifichiamo la radice dell‚Äôalbero ottenuto\nsi ottiene complessit√† T_{amm}=O(log \\ n)\n\n\n\nTeoremi\n\n\nQuickUnion\n\ndefinizione\nUsiamo una foresta di alberi di altezza anche maggiore di 1 per rappresentare gli insiemi disgiunti. In ogni albero:¬†\n\nRadice = elemento rappresentativo dell‚Äôinsieme¬†\nRimanenti nodi = altri elementi( escluso l‚Äôelemento nella radice)\n\nImplementazione delle varie operazioni\n\nMakeset(x) = O(1)\nUnion(A,B) = O(1)\nFind(x) = O(n)\n\nQuickUnion con Union-By-Size\n\n\nla find costa O(n) per risolverlo applichiamo l‚Äôeuristica UBS\nNell‚Äôunione degli insiemi A e B, rendiamo la radice dell‚Äôalbero con meno nodi figlia della radice dell‚Äôalbero con pi√π nodi e cambiamo il nome se necessario¬†\nL‚Äôoperazione find richiede tempo O(log n)\n\nQuickUnion con Union-By-Size+ Compressione dei Cammini\n\n\nQuando eseguo find e attraverso il cammino da x alla radice, comprimo il cammino, ovvero rendo tutti i nodi del cammino figli della radice\n\nMinimum spanning tree\n\ndefinizione\n\nDato un grafo connesso e non orientato G=(V,E,W), pesato sugli archi.¬†\nun MST √® un sottoinsieme di archi T \\subseteq E tale che ci sia\n\nuno spanning ovvero un albero (V,T) connesso e aciclico che include tutti i nodi di V\ne un minimum ovvero il peso totale, ovvero la sommatoria di tutti gli archi di T sia minimizzata\n\n\n\ndefinizioni\n\nCiclo: set di archi della seguente forma:¬† a-b,b-c,...,y-z,z-a\nCut: Partizione sui vertici V che forma due insiemi disgiunti S e  V\\textbackslash S\nCutset: associato a un taglio S abbiamo un cutset D che √® un sottoinsieme di archi con esattamente un nodo in S  e l‚Äôaltro in V\\textbackslash S\n\nPropriet√†\n\n\n\nSe G ha pesi distinti allora esiste un unico MST\n\n\n\n\nCycle-cut intersection\n\n\nL‚Äôintersezione tra un cutset e un ciclo ha cardinalit√† pari\nIl motivo √® geometrico: un ciclo non pu√≤ ‚Äúentrare‚Äù in una parte del grafo senza poi ‚Äúuscire‚Äù lo stesso numero di volte, altrimenti non riuscirebbe a richiudersi.\n\n\n\n\nCut property\n\n\nSia S un qualunque taglio e sia e l‚Äôarco del cutset dal costo minimo rispetto agli archi che attraversano quel taglio¬†\n\nAllora esiste un MST che contiene e\n\n\n\n\n\n\nCycle property\n\n\nSia C un qualsiasi ciclo¬† e sia f l‚Äôarco appartenente al ciclo di peso massimo. rispetto agli archi che appartengono a quel ciclo\n\nAllora esiste un MST che non contiene f\n\n\n\n\n\nTeoremi\n\n\nKruskal\n\nalgoritmo che risolve MST\nsi basa sulla  cycle property\n\ndefinizione\n\nInizia con T= \\varnothing , considera gli archi in ordine crescente di peso, viene inserito l‚Äôarco e a T se non genera un ciclo¬†\nUn implementazione efficiente di questo algoritmo utilizza la UnionFind\nFunziona ordinando tutti gli archi in ordine crescente di peso e vengono aggiunti uno alla volta se non creano cicli.\nQui entra in gioco la Cycle Property: se un arco √® il pi√π pesante in un ciclo, non serve prenderlo. Kruskal infatti ‚Äúscarta‚Äù implicitamente questi archi perch√©, quando un arco formerebbe un ciclo, non lo aggiunge.\n\nSoluzione greedy\n\ntempo O(m\\ log \\ n)\n\n\nTeoremi\n\n\n\nCorrettezza di Kruskal\n\n\nCut property\n\nDato un qualsiasi cut (partizione dei vertici in due insiemi), l‚Äôarco di peso minimo che attraversa quel cut appartiene a tutti gli MST.\nQuindi, se prendiamo gli archi in ordine crescente, ogni volta che troviamo il pi√π piccolo che connette due componenti diverse (cio√® non crea ciclo), stiamo proprio scegliendo un ‚Äúarco minimo di un certo cut‚Äù.\nQuesto garantisce che quell‚Äôarco deve stare in almeno un MST ‚Üí la scelta √® sempre ‚Äúsicura‚Äù.\n\n\n\nCycle property\n\nIn un ciclo, l‚Äôarco di peso massimo non appartiene a nessun MST.\nQuindi, se durante l‚Äôalgoritmo troviamo che un arco crea un ciclo, essendo l‚Äôultimo che stiamo considerando (quello di peso maggiore nel ciclo, dato che stiamo andando in ordine crescente), possiamo scartarlo con certezza.\n\n\n\nogni arco aggiunto √® giustificato dalla cut property,\n\n\nogni arco scartato √® giustificato dalla cycle property.\n\n\nPrim\ndefinizione\n\nInizia da un nodo radice s e fa crescere un albero T in modo greedy da s verso l‚Äôesterno, ad ogni passo aggiunge a T l‚Äôarco meno costoso che ha esattamente un estremo in T\n\nSoluzione greedy\n\nMantiene l‚Äôinsieme dei nodi esplorati S¬†\nUsa una coda con priorit√† per mantenere i nodi inesplorati¬†\nPer ogni nodo inesplorato la priorit√† √® l‚Äôattachment cost \\ a[v] = costo dell‚Äôarco meno costoso incidente a v che ha l‚Äôaltro estremo in S\n\nParte da un nodo e costruisce l‚Äôalbero estendendolo passo passo.\nAd ogni passo sceglie l‚Äôarco pi√π leggero che attraversa il taglio tra i vertici gi√† inclusi e quelli ancora fuori.\nQui si usa la Cut Property: l‚Äôarco pi√π leggero che attraversa un taglio appartiene sempre a qualche MST, quindi √® sicuro includerlo.\n\n\n\nO(m+nlogn)\n\nProgrammazione dinamica\n\ndividi il problema in sotto-problemi sovrapposti e usa i risultati salvati (memoization/tabulation) per evitare ricalcoli.\n\nIndependent Set\n\ndefinizione\n\nDato un cammino G di n nodi. Ogni nodo v_i ha peso w_i\nTrovare un insieme indipendente di peso massimo ovvero un insieme S tale che:¬†\n\n\n\nS √® un insieme indipendente¬†¬†\n\n\n\n\nw(S) = somma dei pesi dei nodi in S, √® pi√π grande possibile\n\n\n\n\nUn insieme indipendente di G √® un sottoinsieme di nodi che non contiene due nodi adiacenti, ovvero per ogni coppia di nodi del insieme i due nodi non sono collegati da un arco.\n\nSoluzione dinamica\n\nG_j : sotto-cammino composto dai primi j vertici di G\nSotto-problema j : calcolare il peso del miglior insieme indipendente per G_j\n\nOPT[ j ] : valore della soluzione sotto-problema j, ovvero peso dell‚Äôinsieme indipendente di peso massimo di G_j¬†\nOPT[1] = w_1 ; OPT[2] = max\\{ w_1 , w_2\\}\nOPT[j] = max\\{ OPT[ j-1], w_j+OPT[ j-2]\\}\n\n\n\nInterval scheduling con peso\n\ndefinizione\n\nDati n intervalli chiamati job j_1,...,j_n¬†\nJob j¬† inizia a s_j e finisce a f_j , e ha peso w_j &gt; 0.¬†\nDue job sono compatibili se non si sovrappongono¬†\nTrovare il sottoinsieme di job compatibili di peso massimo\n\nSoluzione dinamica\n\nordino i job per finish time in modo crescente\np( j ) = pi√π grande indice i &lt; j tale che job i sia compatibile con job j\n\nsotto-problema j:\nOPT[ j ] = peso massimo di un qualsiasi sottoinsieme di job compatibili costituito solo dai job 1,2,..,j\n\nLa soluzione cercata si trova in OPT[ n ]¬†\n\nCaso 1. OPT[ j ] non seleziona j:¬†\n\nAllora l‚Äôottimo di j deriva¬† dall‚Äôottimo dei primi j-1esimi job¬†\n\n\n\n\nCaso 2. OPT[ j ] seleziona j:¬†\n\nColleziona il costo di w_j¬†\nNon pu√≤ usare i job incompatibili \\{ p(j) +1, p(j)+2, ..., j-1\\}.\nDeve contenere una soluzione ottima per i job compatibili rimanenti 1, 2 , .., p(j)\n\n\n\nO(n\\ log \\ n)\n\nKnapsack problem\n\ndefinizione\n\nDati n elementi:¬†\nL‚Äôelemento i fornisce un valore v_i e pesa w_i¬†\nValore di un sottoinsieme di oggetti = somma dei valori dei singoli oggetti¬†\nLo zaino ha peso limite W¬†\nRiempire lo zaino in modo tale da massimizzare il valore degli oggetti trasportati, ma non superare il limite W\n\nSoluzione dinamica\nDef sotto problemi\n\nOPT[ i , w] = valore ottimo del knapsack problem con oggetti¬† 1,.., i con peso limite w\nGoal: OPT[ n, W]\nCaso 1. OPT[ i, w ] non seleziona i:¬†\n\nOPT [ i, w] seleziona i migliori \\{1,2,..,i-1\\} con peso limite w¬†\n\n\nCaso 2. OPT[ i, w ] seleziona i:¬†\n\nColleziona il valore v_i¬†¬†\nNuovo peso limite = w-w_i¬†¬†¬†\nOPT[ i, w ] seleziona i migliori \\{1,2,...i-1\\} con nuovo peso limite\n\n\n\n\nO(nW) tempo e spazio\n\nSoluzione per il recupero\n\n\ntrace back parte dalla fine della matrice dove si ha la soluzione ottima e prende di volta in volta la condizione massima tenendo conto che pu√≤ prendere oppure no quel determinato peso\n\n\nSequence Alignment\n\n\ndefinizione\ndefinizione di edit distance\n\noperazioni di allineamento che portano a un costo minimo che include\nGap penalty Œ¥; mismatch penalty Œ±_{pq}\nCost= somma delle penalit√† gap e mismatch\nsequence alignment definizione\nDate 2 stringhe¬† x_1x_2...x_n \\ e \\  y_1y_2...y_n trovare un allineamento di costo minimo¬†¬†\nUn allineamento M √® un insieme di coppie ordinate x_i-y_j affinch√© ogni carattere appaia al massimo in una coppia e senza incroci¬†\nIl costo di un allineamento M √®:\n\n\nSoluzione dinamica\ndefinisco sotto-problemi\nOPT[ i,j ] = costo minimo di allineamento delle stringhe di prefisso x_1x_2...x_i e y_1y_2...y_j\nGoal. OPT[ m,n ]\nCaso 1. OPT[ i,j]¬† matcha¬† x_i-y_j¬†¬†¬†\n\nPaga mismatch per x_i-y_j + costo minimo per allineare¬† x_1x_2...x_{i-1} e y_1y_2...y_{j-1}¬†¬†(costo pu√≤ anche essere 0)\nCaso 2a. OPT[ i,j ] lascia x_i non matchata¬†\nPaga gap per x_i + costo minimo per allineare¬†¬† x_1x_2...x_{i-1} e y_1y_2...y_j¬†¬†¬†\nCaso 2b. OPT[ i,j ] lascia y_j non matchata¬†\nPaga gap per y_j + costo minimo per allineare¬† x_1x_2...x_i e y_1y_2...y_{j-1}\n\nO(mn)\n\nmigliorie con Hirschberg‚Äôs algorithm\n\nsi pu√≤ ridurre il costo spaziale in O(m+n)\n\nMax-flow e min-cut\n\ndefinizione\nUna rete di flusso √® una tupla G=(V,E,s,t,c):¬†\n\n\nGrafo diretto (V,E) con una sorgente s e un pozzo t¬†\n\n\nCapacit√† c(e) ‚â• 0 per ogni arco e\nper risolvere questo problema dobbiamo definire cosa sono\n\n\nst-cut\n\npartizione (A,B) di nodi con s ‚àà A¬† e t ‚àà B\nLa capacit√† di un st-cut √® la somma delle capacit√† degli archi che vanno da A in B\n\n\n\n\nmin-cut\n\nTrovare un taglio di capacit√† minima\nIl min-cut √® quello che fornisce il limite pi√π stretto, cio√® il collo di bottiglia minimo del grafo.\n\n\n\nst-flow\n\nUn st-flow f √® una funzione che soddisfa:¬†\n\n\n\n\nil valore di un st-flow √®\n\n\n\nmax-flow\n\nproblema dove si vuole trovare un flusso dal valore massimo\n\n\n\nResidual network definizione\n\nArco originale\n\ne=(u,v) ‚àà E\nFlow f(e)\nCapacity c(e)\n\n\nArco al contrario e^{reverse} = (v,u)\n\nundo del flusso inviato\n\n\nresidual capacity:\n\n\n\n\nResidual network. G_f =(V,E_f , s, t, c_f)¬†\n\nE_f = { e : f(e) &lt; c(e)}¬†\\ \\ ¬† U \\ \\¬† {e : f(e^{reverse}) &gt; 0}\nPropriet√† chiave : f‚Ä≤ √® un flusso valido¬† in G_f se f+f‚Ä≤ √® un flusso valido in G\nAugmenting path definizione:\n\n\n\nUn cammino aumentante √® un cammino semplice s‚Üùt nella rete residua G_f¬†¬†\n\n\nDef bottleneck capacity:¬†\n\nLa capacit√† di bottleneck di un cammino aumentante¬† P √® la capacit√† minima residua di un arco in P¬†\nPropriet√† chiave:¬†\nSia f un flusso e P¬† un cammino aumentante in G_f allora, dopo aver chiamato f‚Äô ‚Üê AUGMENT( f,c,P), l‚Äôf‚Äô risultante √® un flusso e val(f‚Äô) = val(f) + bottleneck(Gf,P)\n\nFord-Fulkerson\n\n\nInizia con f(e) = 0 per ogni arco e ‚àà E¬†\n\n\nTrova un cammino s‚Üùt P nella rete residua G_f¬†¬†\n\n\nAumenta il flusso lungo il cammino P¬†\n\n\ncontinua a cercare cammini aumentanti nel grafo residuoG_f, e aggiorna il flusso lungo quei cammini, finch√© non esistono pi√π cammini da s a t nel grafo residuo.\n\n\nLemma del valore del flusso.¬†\n\nSia f un flusso qualsiasi e sia (A,B) un taglio qualsiasi. Allora, il valore del flusso f √® uguale al flusso netto attraversante il taglio (A,B)\n\n\n\n\nDualit√† debole:¬†\n\nSia f un qualsiasi flusso¬† e sia (A,B) un qualsiasi taglio .¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†\n\nAllora,¬†¬† val(f) ‚â§ cap(A,B).¬†\n\n\n\n\n\nCorollario:¬†\n\nSia f un qualsiasi flusso e (A,B) un qualsiasi taglio. se val(f) = cap(A,B), allora f √® un max flow e (A,B) √® un min cut¬†\n\n\n\nMax-flow min-cut theorem:¬†\n\nIl valore di un flusso massimo = capacit√† di un taglio minimo¬†\n\n\n\nAugmenting path theorem :¬†\n\nUn flow f √® un max flow se non ha cammini aumentanti¬†¬†\n\n\n\nTeorema:¬†\n\nDato un qualsiasi max flow f, possiamo calcolare il min cut (A,B)¬† in O(m) tempo\n\n\n\n\n\n                  \n                  ALTRA COSA FONDAMENTALE: il numero di cammini aumentanti pu√≤ essere ESPONENZIALE rispetto all&#039;input.\n                  \n                \n\n\n\n\nL‚Äôobiettivo principale √® scegliere dei cammini aumentanti tali che\n\npossano essere trovati in modo efficiente (quindi in O(m)),\nvengano eseguite poche iterazioni (e quindi pochi aumenti),\n\nPer farlo possiamo sceglierli con\n\nuna bottleneck capacity molto grande ‚Üí cos√¨ ogni aumento contribuisce MOLTO al flusso totale,\npochi archi ‚Üí riduci la probabilit√† di dover ‚Äútornare indietro‚Äù,\n\nVerso l‚Äôalgoritmo Partendo dai due punti precedenti, l‚Äôidea √® questa\n\nUsiamo un parametro \\Delta ‚Üí √® un valore grande,\nCostruisco un sottografo G_{f}(\\Delta) contenente SOLO gli archi che hanno capacit√† \\ge \\Delta,\nIn questo modo ogni cammino aumentante nel nuovo grafo ha una bottleneck capacity \\ge \\Delta\n\n,\n\nPSEUDOCODICE\nCome scegliere il successivo cammino aumentante in Ford-Fulkerson? Scegli quello che usa meno archi (il pi√π corto) ‚Üí usa la BFS. &gt;Scegliendo i pi√π corti saturi velocemente gli archi ‚Äúcolli di bottiglia‚Äù\n\n\n\n\nAlgoritmi di approssimazione\ndefinizione\n\nUn Œ±-approximation algorithm per un problema di ottimizzazione √® un algoritmo polinomiale che per tutte le istanze del problema produce una soluzione il cui valore √® compreso entro un fattore Œ±¬† rispetto al valore di una soluzione ottima\nMinimization problem:¬†voglio minimizzare un costo\nŒ± ‚â• 1¬†\nPer ogni soluzione restituita x, cost(x) ‚â§ Œ±¬† OPT(x)¬†\nMaximization problem: voglio massimizzare un valore\nŒ± ‚â§ 1¬†\nPer ogni soluzione restituita x, value(x) ‚â• Œ± OPT(x)\n\nLoad balancing\n\ndefinizione\nDate m identiche macchine, n ‚â• m jobs, job j ha processing time t_j.¬†\n\nJob j deve essere eseguito contiguamente su una macchina¬†\nUna macchina pu√≤ processare al pi√π un job alla volta¬†\nAssegnare ogni job a una macchina affinch√© il make span sia minimo\nDef load:¬†\nSia S[i] il sottoinsieme di job assegnati alla macchina i.¬†\nIl load¬† della macchina i √® L[i] = Œ£_{j \\ ‚àà \\ S[i]}¬† \\ t_j .¬†\n\nDef make span:¬†\n\nIl make span √® il valore massimo di load di ogni macchina L = max_i L[i]\n\nSoluzione List Scheduling Algo\n\nConsidera i job in un qualche ordine fisso¬†\nAssegna il job j alla macchina i il cui carico √® finora il pi√π piccolo\nComplessit√†:¬†\n\nO(n log n)¬†\nUsando una coda con priorit√† per i carichi L[k]¬†\n\n\n\nDimostrazioni e lemma\n\n\n\n\n\n\nLoad balancing LPT(Longest Processing Time)\ndefinizione\n\nOrdina n jobs in ordine decrescente di tempo di processione\nci√≤ lo rende molto pi√π vicino alla soluzione ottima\n\nTeoremi\n\n\nRIDUZIONI POLINOMIALI\nDefinizione\nUna riduzione polinomiale √® un metodo per trasformare un problema X in un altro problema Y, in modo che:\n\nqualsiasi istanza di X possa essere risolta tramite:\n\nun numero polinomiale di operazioni standard, pi√π\nun numero polinomiale di chiamate a un ‚Äúoracolo‚Äù che risolve Y.\nSi scrive:\n\n\nX \\leq_P Y\nrisolvere Y implica poter risolvere X in tempo polinomiale\n\n3 propriet√† importanti\n\nProgettazione di algoritmi:\nSe X \\leq_P Y e Y √® risolvibile in tempo polinomiale, allora anche X lo √®.\nDimostrare difficolt√† (intractability):\nSe X \\leq_P Y e X non √® risolvibile in tempo polinomiale, allora neanche Y lo √®.\nEquivalenza:\nSe X \\leq_P Y e Y \\leq_P X, allora X \\equiv_P Y.\nSignifica che hanno la stessa complessit√† polinomiale (si risolvono in polinomiale se e solo se l‚Äôaltro lo √®).\n\nEsempi di riduzioni\n1. Independent Set con Vertex Cover\n\ndescriviamo prima il problema dell‚Äôindipendent set\nIndependent Set (IS): Dato un grafo G=(V,E) e un intero k, esiste un sottoinsieme di k vertici non adiacenti tra loro?\n\nproblema del Vertex Cover\nVertex Cover (VC): Dato G=(V,E) e un intero k, esiste un sottoinsieme di k vertici che copre tutti gli archi?\n\n\nVogliamo dimostrare che IS \\equiv_P IS.\n(‚áí) Da Independent Set a Vertex Cover\n\nSupponiamo che S sia un IS di dimensione k.\nAllora V‚àíS ha dimensione n‚àík.\nConsideriamo un arco (u,v)‚ààE(u,v)\n\nPoich√© S √® indipendente, non pu√≤ contenere entrambi i vertici u,v.\nQuindi almeno uno dei due appartiene a V-S.\n\n\nDunque V‚àíS √® un vertex cover di dimensione n-k\n\n(‚áê) Da Vertex Cover a Independent Set\n\nSupponiamo che V‚àíS sia un VC di dimensione n‚àík.\nAllora S ha dimensione k.\nConsideriamo un arco (u,v)‚ààE(u,v).\n\nPoich√© V‚àíS √® un VC, almeno uno tra u,v√® in V‚àíS.\nQuindi non possono essere entrambi in S.\n\n\nDunque S √® un independent set di dimensione k.\n\n2. Set Cover con Vertex Cover\n\ndescriviamo prima il problema del Set Cover\nSet Cover (SC): Dato un insieme universo U, una collezione di sottoinsiemi S_1, ..., S_m‚Äã, e un intero k, esistono al pi√π k sottoinsiemi che coprono tutto U?\n\n\nVogliamo dimostrare che VC \\leq_P SC.\nCostruzione della riduzione\nDato un grafo G=(V,E) e un intero k:\n\nUniverso:\nU = E \\quad (\\text{gli archi del grafo diventano gli elementi dell‚Äôuniverso})\nFamiglia di sottoinsiemi:\nPer ogni vertice v \\in V, definiamo:\nS_v = \\{ e \\in E : e \\text{ √® incidente a } v \\}\nParametro:\nManteniamo lo stesso valore k.\n\nCos√¨ otteniamo un‚Äôistanza di Set Cover (U, \\mathcal{S}, k)\n(‚áí) Se G ha un Vertex Cover di dimensione k\n\nSupponiamo che X \\subseteq V sia un VC con |X|=k.\nConsideriamo \\mathcal{Y} = \\{ S_v : v \\in X \\}\nOgni arco √® coperto da almeno un vertice in X, quindi \\mathcal{Y} √® un set cover di dimensione k.\n\n(‚áê) Se (U, \\mathcal{S}, k) ha un Set Cover di dimensione k\n\nSupponiamo che \\mathcal{Y} \\subseteq \\mathcal{S} sia un set cover di dimensione k.\nSia X = \\{ v \\in V : S_v \\in \\mathcal{Y} \\}.\nPoich√© ogni arco e appartiene ad almeno un sottoinsieme S_v, significa che v \\in X copre quell‚Äôarco.\nQuindi X √® un VC di dimensione k.\n\n\n3. 3-SAT con Independent Set\n\ndescriviamo prima il problema del 3-SAT\n3-SAT: Formula booleana in CNF con clausole di 3 letterali ciascuna. La formula √® soddisfacibile?\n\n\nVogliamo dimostrare che 3-SAT \\leq_P IS.\nCostruzione della riduzione\n\nNodi:\nPer ogni clausola della formula, aggiungiamo 3 nodi (uno per ogni letterale).\nArchi interni:\nI 3 nodi di una clausola vengono collegati in un triangolo.\n‚Üí garantisce che al massimo 1 letterale possa essere scelto dall‚Äôinsieme indipendente.\nArchi tra clausole:\nCollegare ogni letterale con la sua negazione (es: x_i‚Äã con \\neg x_i).\n‚Üí impedisce di selezionare contemporaneamente un letterale e la sua negazione.\nParametro:\nk = |\\Phi| \\quad (\\text{cio√® una scelta per ogni clausola}).\n\nDimostrazione\n(‚áí) Se \\Phi √® soddisfacibile\n\nEsiste una assegnazione che rende vera ogni clausola.\nPer ciascuna clausola, scegliamo un letterale che risulta vero.\nQuesti nodi non saranno collegati fra loro (per costruzione), quindi formano un independent set di dimensione k.\n\n(‚áê) Se G contiene un independent set di dimensione k\n\nOgni triangolo rappresenta una clausola.\nPer avere un IS di dimensione k, dobbiamo scegliere esattamente un nodo per triangolo.\nI letterali scelti non possono essere contraddittori (perch√© IS esclude coppie collegate).\nAssegniamo true a quei letterali ‚Üí tutte le clausole sono soddisfatte.\nDunque \\Phi √® soddisfacibile.\n\n\n\n\nTransitivit√†: Se X \\leq_P Y \\ X‚â§P‚ÄãY \\ e \\ Y‚â§_PZ \\ Y \\leq_P Z.\n‚Üí Esempio:\n\\text{3-SAT} \\leq_P \\text{IS} \\leq_P \\text{VC} \\leq_P \\text{SC}\n\n\nP: problemi di decisione per i quali esiste un algoritmo polinomiale che li risolve.\n‚Üí Sono i problemi ‚Äúfacili da risolvere‚Äù.\n\n\nNP: problemi di decisione per i quali esiste un certificatore polinomiale.\n‚Üí Non sappiamo se sono facili da risolvere, ma se qualcuno ci d√† una soluzione candidata (certificato), possiamo verificarla velocemente.\n\n\nEXP: problemi di decisione per i quali esiste un algoritmo esponenziale che li risolve.\n‚Üí In pratica: anche se non troviamo algoritmi migliori, con una brute force in tempo esponenziale si riescono a risolvere.\n\n\nP \\subseteq NP\nNP \\subseteq EXP"},"UNI/ANNO-2/ALGORITMI-2/STUDIO":{"slug":"UNI/ANNO-2/ALGORITMI-2/STUDIO","filePath":"UNI/ANNO 2/ALGORITMI 2/STUDIO.md","title":"STUDIO","links":[],"tags":[],"content":"GREEDY\n\nin ogni passo scegli la soluzione migliore a breve termine (la scelta locale ottimale), sperando che porti anche alla soluzione globale ottimale.\n\nInterval scheduling\n\ndefinizione\n\nDati in input n intervalli: I_1 ,...,I_n\nI_i¬† ha tempo di inizio S_i¬† e tempo di fine f_i¬†\nDue intervalli sono compatibili se non si sovrappongono¬†\nTrovare il sottoinsieme di intervalli compatibili con cardinalit√† massima\n\nSoluzione greedy\n\nordina  gli intervalli per tempo di fine\nComplessit√†: O(n \\ log n)\n\n\nTeoremi\n\n\nInterval partitioning\n\ndefinizione\n\nDati in input un insieme di n intervalli (lezioni): j_1,...,j_n\nLezione j inizia a s_j e finisce a f_j¬†\nTrovare il minimo numero di classi per schedulare tutte le lezioni affinch√© non ci siano due lezioni contemporaneamente nella stessa classe( ovvero le lezioni nella stessa classe devono essere compatibili)\n\nSoluzione greedy\n\nordina per tempo di inizio s_i\nComplessit√†: O(n \\ log n)\n\n\nTeoremi\n\n\n\nUnion Find Struttura dati\n\ndefinizione\n\nMantenere una collezione di insiemi disgiunti contenenti elementi distinti durante l‚Äôesecuzione di una sequenza di operazioni del seguente tipo:¬†\n\nMakeset(x) = crea il nuovo insieme x = {x} di nome x¬†\nUnion(A,B) = unisce gli insiemi A, B in un unico insieme di nome A (distrugge quelli vecchi)¬†\nFind(x) = restituisce il nome dell‚Äôinsieme che contiene l‚Äôelemento x (si suppone di accedere direttamente all‚Äôelemento x)\n\n\n\nQuickFind\n\nUsiamo una foresta di alberi di altezza 1 per rappresentare gli insiemi disgiunti. In ogni albero:¬†\n\nRadice = nome dell‚Äôinsieme\nFoglie = elementi ( incluso l‚Äôelemento rappresentativo, il cui valore √® nella radice e da il nome all‚Äôinsieme stesso)\n\nImplementazione delle varie operazioni\n\nMakeset(elem e) T(n) = O(1)\n\nCrea un albero composto da due nodi: una radice e una foglia. Memorizza e sia nella foglia che nella radice come nome dell‚Äôalbero\n\n\nUnion(name a, name b) T(n) = O(n)¬†\n\nSostituisce tutti i puntatori delle foglie di B alla radice di B con puntatori alla radice di A. cancella la vecchia radice di B.\n\n\nFind(elem e) --&gt; name T(n) = O(1)\n\nAccede alla foglia x corrispondente all‚Äôelemento e. da tale nodo segue il puntatore al padre che √® la radice dell‚Äôalbero e restituisce il nome memorizzato in tale radice\n\n\n\nQuickFind bilanciato\n\n\n                  \n                  troppi cambi di puntatori con troppe union fanno venire un costo complessivo di O(n^2)\n                  \n                \n\n\n\nUnion by size\n\nNell‚Äôunione degli insiemi A e B attacchiamo¬† gli elementi dell‚Äôinsieme con cardinalit√† minore a quello di cardinalit√† maggiore e se necessario modifichiamo la radice dell‚Äôalbero ottenuto\nsi ottiene complessit√† T_{amm}=O(log \\ n)\n\n\n\nTeoremi\n\n\nQuickUnion\n\ndefinizione\nUsiamo una foresta di alberi di altezza anche maggiore di 1 per rappresentare gli insiemi disgiunti. In ogni albero:¬†\n\nRadice = elemento rappresentativo dell‚Äôinsieme¬†\nRimanenti nodi = altri elementi( escluso l‚Äôelemento nella radice)\n\nImplementazione delle varie operazioni\n\nMakeset(x) = O(1)\nUnion(A,B) = O(1)\nFind(x) = O(n)\n\nQuickUnion con Union-By-Size\n\n\nla find costa O(n) per risolverlo applichiamo l‚Äôeuristica UBS\nNell‚Äôunione degli insiemi A e B, rendiamo la radice dell‚Äôalbero con meno nodi figlia della radice dell‚Äôalbero con pi√π nodi e cambiamo il nome se necessario¬†\nL‚Äôoperazione find richiede tempo O(log n)\n\nQuickUnion con Union-By-Size+ Compressione dei Cammini\n\n\nQuando eseguo find e attraverso il cammino da x alla radice, comprimo il cammino, ovvero rendo tutti i nodi del cammino figli della radice\n\nMinimum spanning tree\n\ndefinizione\n\nDato un grafo connesso e non orientato G=(V,E,W), pesato sugli archi.¬†\nun MST √® un sottoinsieme di archi T \\subseteq E tale che ci sia\n\nuno spanning ovvero un albero (V,T) connesso e aciclico che include tutti i nodi di V\ne un minimum ovvero il peso totale, ovvero la sommatoria di tutti gli archi di T sia minimizzata\n\n\n\ndefinizioni\n\nCiclo: set di archi della seguente forma:¬† a-b,b-c,...,y-z,z-a\nCut: Partizione sui vertici V che forma due insiemi disgiunti S e  V\\textbackslash S\nCutset: associato a un taglio S abbiamo un cutset D che √® un sottoinsieme di archi con esattamente un nodo in S  e l‚Äôaltro in V\\textbackslash S\n\nPropriet√†\n\n\n\nSe G ha pesi distinti allora esiste un unico MST\n\n\n\n\nCycle-cut intersection\n\n\nL‚Äôintersezione tra un cutset e un ciclo ha cardinalit√† pari\nIl motivo √® geometrico: un ciclo non pu√≤ ‚Äúentrare‚Äù in una parte del grafo senza poi ‚Äúuscire‚Äù lo stesso numero di volte, altrimenti non riuscirebbe a richiudersi.\n\n\n\n\nCut property\n\n\nSia S un qualunque taglio e sia e l‚Äôarco del cutset dal costo minimo rispetto agli archi che attraversano quel taglio¬†\n\nAllora esiste un MST che contiene e\n\n\n\n\n\n\nCycle property\n\n\nSia C un qualsiasi ciclo¬† e sia f l‚Äôarco appartenente al ciclo di peso massimo. rispetto agli archi che appartengono a quel ciclo\n\nAllora esiste un MST che non contiene f\n\n\n\n\n\nTeoremi\n\n\nKruskal\n\nalgoritmo che risolve MST\nsi basa sulla  cycle property\n\ndefinizione\n\nInizia con T= \\varnothing , considera gli archi in ordine crescente di peso, viene inserito l‚Äôarco e a T se non genera un ciclo¬†\nUn implementazione efficiente di questo algoritmo utilizza la UnionFind\nFunziona ordinando tutti gli archi in ordine crescente di peso e vengono aggiunti uno alla volta se non creano cicli.\nQui entra in gioco la Cycle Property: se un arco √® il pi√π pesante in un ciclo, non serve prenderlo. Kruskal infatti ‚Äúscarta‚Äù implicitamente questi archi perch√©, quando un arco formerebbe un ciclo, non lo aggiunge.\n\nSoluzione greedy\n\ntempo O(m\\ log \\ n)\n\n\nTeoremi\n\n\n\nCorrettezza di Kruskal\n\n\nCut property\n\nDato un qualsiasi cut (partizione dei vertici in due insiemi), l‚Äôarco di peso minimo che attraversa quel cut appartiene a tutti gli MST.\nQuindi, se prendiamo gli archi in ordine crescente, ogni volta che troviamo il pi√π piccolo che connette due componenti diverse (cio√® non crea ciclo), stiamo proprio scegliendo un ‚Äúarco minimo di un certo cut‚Äù.\nQuesto garantisce che quell‚Äôarco deve stare in almeno un MST ‚Üí la scelta √® sempre ‚Äúsicura‚Äù.\n\n\n\nCycle property\n\nIn un ciclo, l‚Äôarco di peso massimo non appartiene a nessun MST.\nQuindi, se durante l‚Äôalgoritmo troviamo che un arco crea un ciclo, essendo l‚Äôultimo che stiamo considerando (quello di peso maggiore nel ciclo, dato che stiamo andando in ordine crescente), possiamo scartarlo con certezza.\n\n\n\nogni arco aggiunto √® giustificato dalla cut property,\n\n\nogni arco scartato √® giustificato dalla cycle property.\n\n\nReverse-delete algo\ndefinizione\n\nSi comporta in modo complementare all‚Äôalgoritmo di Kruskal:¬†\nParte con T= G, considera gli archi in ordine decrescente di peso,¬† l‚Äôarco e viene rimosso solo se rimuovendolo il grafo resta connesso\n\nPrim\ndefinizione\n\nInizia da un nodo radice s e fa crescere un albero T in modo greedy da s verso l‚Äôesterno, ad ogni passo aggiunge a T l‚Äôarco meno costoso che ha esattamente un estremo in T\n\nSoluzione greedy\n\nMantiene l‚Äôinsieme dei nodi esplorati S¬†\nUsa una coda con priorit√† per mantenere i nodi inesplorati¬†\nPer ogni nodo inesplorato la priorit√† √® l‚Äôattachment cost \\ a[v] = costo dell‚Äôarco meno costoso incidente a v che ha l‚Äôaltro estremo in S\n\nParte da un nodo e costruisce l‚Äôalbero estendendolo passo passo.\nAd ogni passo sceglie l‚Äôarco pi√π leggero che attraversa il taglio tra i vertici gi√† inclusi e quelli ancora fuori.\nQui si usa la Cut Property: l‚Äôarco pi√π leggero che attraversa un taglio appartiene sempre a qualche MST, quindi √® sicuro includerlo.\n\n\n\nO(m+nlogn)\n\nClustering\n\ndefinizione\n\nDato un insieme U di n elementi etichettati p_1,....,p_n e un intero k, dividere gli oggetti in k sottoinsiemi non vuoti affinch√© lo spacing sia massimo¬†\nSpacing = distanza minima tra una qualsiasi coppia di punti in cluster diversi¬†¬†\nLa distanza viene espressa da una funzione\n\n\nSoluzione greedy\n\nLa procedura √® corrispondente all‚Äôalgo di Kruskal, solo che poi bisogna togliere i k-1 archi pi√π pesanti dal grafo\n\n\nProgrammazione dinamica\n\ndividi il problema in sotto-problemi sovrapposti e usa i risultati salvati (memoization/tabulation) per evitare ricalcoli.\n\nIndependent Set\n\ndefinizione\n\nDato un cammino G di n nodi. Ogni nodo v_i ha peso w_i\nTrovare un insieme indipendente di peso massimo ovvero un insieme S tale che:¬†\n\n\n\nS √® un insieme indipendente¬†¬†\n\n\n\n\nw(S) = somma dei pesi dei nodi in S, √® pi√π grande possibile\n\n\n\n\nUn insieme indipendente di G √® un sottoinsieme di nodi che non contiene due nodi adiacenti, ovvero per ogni coppia di nodi del insieme i due nodi non sono collegati da un arco.\n\nSoluzione dinamica\n\nG_j : sotto-cammino composto dai primi j vertici di G\nSotto-problema j : calcolare il peso del miglior insieme indipendente per G_j\n\nOPT[ j ] : valore della soluzione sotto-problema j, ovvero peso dell‚Äôinsieme indipendente di peso massimo di G_j¬†\nOPT[1] = w_1 ; OPT[2] = max\\{ w_1 , w_2\\}\nOPT[j] = max\\{ OPT[ j-1], w_j+OPT[ j-2]\\}\n\n\n\n\nRicostruire la soluzione\n\nInterval scheduling con peso\n\ndefinizione\n\nDati n intervalli chiamati job j_1,...,j_n¬†\nJob j¬† inizia a s_j e finisce a f_j , e ha peso w_j &gt; 0.¬†\nDue job sono compatibili se non si sovrappongono¬†\nTrovare il sottoinsieme di job compatibili di peso massimo\n\nSoluzione dinamica\n\nordino i job per finish time in modo crescente\np( j ) = pi√π grande indice i &lt; j tale che job i sia compatibile con job j\n\nsotto-problema j:\nOPT[ j ] = peso massimo di un qualsiasi sottoinsieme di job compatibili costituito solo dai job 1,2,..,j\n\nLa soluzione cercata si trova in OPT[ n ]¬†\n\nCaso 1. OPT[ j ] non seleziona j:¬†\n\nAllora l‚Äôottimo di j deriva¬† dall‚Äôottimo dei primi j-1esimi job¬†\n\n\n\n\nCaso 2. OPT[ j ] seleziona j:¬†\n\nColleziona il costo di w_j¬†\nNon pu√≤ usare i job incompatibili \\{ p(j) +1, p(j)+2, ..., j-1\\}.\nDeve contenere una soluzione ottima per i job compatibili rimanenti 1, 2 , .., p(j)\n\n\n\n\nO(n\\ log \\ n)\n\nIn pratica:\nTop-down pu√≤ essere pi√π veloce su input piccoli o quando molte scelte vengono potate.\nBottom-up √® pi√π prevedibile e sicuro per input grandi.\n\nTeoremi\n\nLongest increasing subsequences\n\ndefinizione\n\nData una sequenza di n oggetti¬†i_1,..., i_n¬†¬†\nL‚Äôoggetto i_i ha valore s_i¬†¬†\nTrovare una sotto-sequenza di cardinalit√† massima affinch√© per ogni coppia di oggetti i,j con i &lt; j appartenenti alla sotto-sequenza vale che S_i &lt; S_j\n\nSoluzione dinamica\nDef sotto problema\n\nOPT[ j ] = lunghezza della longest increasing subsequence di S[1] , ... , S[j] che termina con S[j]\nLa soluzione cercata √® il max_{i=1,2,..,n} OPT[i]\nIl caso base √® OPT[1]\n\nsuch that=tale che\n\nO(n^2)\n\nSegmented least squares\n\n\ndefinizione di least Squares\nDati n punti sul piano: (x_1,y_1),...,(x_n,y_n)\nTrovare una retta y= ax+b che minimizza la somma degli errori quadratici:\n\n\ndefinizione di SEGMENTED least Squares\n\nI punti si trovano approssimativamente¬† su una sequenza di diversi segmenti¬†\nDati n punti sul piano: (x_1,y_1),...,(x_n,y_n) \\ con\\  x_1&lt;x_2&lt;...&lt;x_n¬†\nTrova una sequenza di linee che minimizza f(x)\nf(x) = E + c L per una qualche costante c&gt;0, dove:¬†\nE = somma delle somme degli errori quadratici di ogni segmento¬†\nL = numero di segmenti\n\nSoluzione dinamica\nDef sotto problemi\n\nOPT[ j ] = costo minimo per i punti¬†p_1,...,p_j\ne_{ij} = SSE per i punti p_i, p_{i+1}, ..., p_j\nPer calcolare OPT[ j ] :¬†\nL‚Äôultimo segmento utilizza i punti p_i, p_{i+1}, ..., p_j per qualche i&lt;j\nCosto = e_{ij} + c + OPT[ j-1 ]\n\n\nPrecalcolando le sommatorie della formula di sopra il tempo diventa O( n^2) altrimenti √® O( n^3)\n\nTeoremi\n\nKnapsack problem\n\ndefinizione\n\nDati n elementi:¬†\nL‚Äôelemento i fornisce un valore v_i e pesa w_i¬†\nValore di un sottoinsieme di oggetti = somma dei valori dei singoli oggetti¬†\nLo zaino ha peso limite W¬†\nRiempire lo zaino in modo tale da massimizzare il valore degli oggetti trasportati, ma non superare il limite W\n\nSoluzione dinamica\nDef sotto problemi\n\nOPT[ i , w] = valore ottimo del knapsack problem con oggetti¬† 1,.., i con peso limite w\nGoal: OPT[ n, W]\nCaso 1. OPT[ i, w ] non seleziona i:¬†\n\nOPT [ i, w] seleziona i migliori \\{1,2,..,i-1\\} con peso limite w¬†\n\n\nCaso 2. OPT[ i, w ] seleziona i:¬†\n\nColleziona il valore v_i¬†¬†\nNuovo peso limite = w-w_i¬†¬†¬†\nOPT[ i, w ] seleziona i migliori \\{1,2,...i-1\\} con nuovo peso limite\n\n\n\n\nO(nW) tempo e spazio\n\nSoluzione per il recupero\n\n\ntrace back parte dalla fine della matrice dove si ha la soluzione ottima e prende di volta in volta la condizione massima tenendo conto che pu√≤ prendere oppure no quel determinato peso\n\n\nTeoremi\n\nSequence Alignment\n\n\ndefinizione\ndefinizione di edit distance\n\noperazioni di allineamento che portano a un costo minimo che include\nGap penalty Œ¥; mismatch penalty Œ±_{pq}\nCost= somma delle penalit√† gap e mismatch\nsequence alignment definizione\nDate 2 stringhe¬† x_1x_2...x_n \\ e \\  y_1y_2...y_n trovare un allineamento di costo minimo¬†¬†\nUn allineamento M √® un insieme di coppie ordinate x_i-y_ij affinch√© ogni carattere appaia al massimo in una coppia e senza incroci¬†\nIl costo di un allineamento M √®:\n\n\nSoluzione dinamica\ndefinisco sotto-problemi\nOPT[ i,j ] = costo minimo di allineamento delle stringhe di prefisso x_1x_2...x_i e y_1y_2...y_j\nGoal. OPT[ m,n ]\nCaso 1. OPT[ i,j]¬† matcha¬† x_i-y_j¬†¬†¬†\n\nPaga mismatch per x_i-y_j + costo minimo per allineare¬† x_1x_2...x_{i-1} e y_1y_2...y_{j-1}¬†¬†(costo pu√≤ anche essere 0)\nCaso 2a. OPT[ i,j ] lascia x_i non matchata¬†\nPaga gap per x_i + costo minimo per allineare¬†¬† x_1x_2...x_{i-1} e y_1y_2...y_j¬†¬†¬†\nCaso 2b. OPT[ i,j ] lascia y_j non matchata¬†\nPaga gap per y_j + costo minimo per allineare¬† x_1x_2...x_i e y_1y_2...y_{j-1}\n\n\nO(mn)\n\nSoluzione per il recupero\n\nper il recupero si limita a partire dal punto m,n ovvero entrambi alla lettera finale e da li si risale effettuando il traceback, si termina una volta raggiunto 0,0\nse vai ‚Üë o a ‚Üê devi pagare la gap penalty\ninvece se vai in diagonale no\nmigliorie con Hirschberg‚Äôs algorithm\n\nsi pu√≤ ridurre il costo spaziale in O(m+n)\n\n\n\nper calcolare OPT[m,n] ci basta utilizzare due colonne per volta\nl‚Äôalgoritmo inizia scegliendo la met√† della stringa Y\ncalcola in forward con f(*,j) e poi in backward invertendo gli archi calcola g(*,j)\ncon j=|Y|/2 parte intera inferiore\nScegli q = \\arg\\min_i (f(i,n/2)+g(i,n/2))\n\nQuel punto √® la cella di taglio: il cammino ottimo passa da l√¨.\n\n\npoi da l√¨ ricorsivamente andiamo a calcolare la prima met√† e la seconda met√†\n\nx_1,...x_q e y_1,....,y_j\nx_{q+1},...x_m e y_{j+1},....,y_n\n\n\n\nTeorema\n\nShortest paths with negative weights\n\ndefinizione\n\nDato un grafo diretto G = (V,E), con lunghezza degli archi arbitraria l_{vw} ( pu√≤ essere anche negativa) trovare un cammino minimo da un nodo sorgente s o un nodo destinazione t\nDefinizione di vari lemma\n\n\nSe qualche cammino v‚Üùt contiene un ciclo negativo allora non esiste un cammino minimo v‚Üùt\nSe G non ha cicli negativi allora esiste un cammino minimo v‚Üùt che √® un cammino semplice (ed ha ‚â§ n-1 archi)\n\nSoluzione dinamica\ndefinizione sotto-problemi\nOPT[ i, v] = lunghezza del cammino minimo v‚Üùt che usa ‚â§ i archi\nGoal. OPT[ n-1, v] per ogni nodo v\nCaso 1. cammino minimo¬† v‚Üùt¬† usa ‚â§ i-1 archi¬†\n\nOPT[ i, v ] = OPT[ i-1, v ]¬†\nCaso 2. cammino minimo¬†v‚Üùt¬† usa esattamente i archi¬†\nSe (v,w) √® il primo arco nel cammino minimo v‚Üùt comporta un costo di l_{vw}¬†\n\nquindi w √® adiacente a v\n\n\nPoi seleziona il miglior cammino w‚Üùt che usa ‚â§ i-1 archi\n\n\ncomplessit√† O( m n )¬† tempo e O( n^2) spazio\n\nBellman-Ford-Moore algorithm\n\nversione migliorata\nManteniamo due array invece che una matrice:\nd[v] = lunghezza del cammino v‚Üùt pi√π breve che abbiamo trovato finora.¬†\nsuccessor[v] = prossimo nodo nel cammino v‚Üùt\nOttimizzazione della performance:¬†\nSe d[w] non viene aggiornato nella passata i-1, non c‚Äô√® motivo di considerare gli archi entranti in w nella passata i.\n\n‚úÖ convenzione implicita.\nIl codice non lo dice, ma la logica del ciclo assicura che a iterazione i stai effettivamente usando distanze valide fino a i‚àí1 \\ archi\nad ogni passata aggiorni i nodi che si trovano a quel determinato numero i di archi\ncosto O( m n) tempo e O(n) spazio\n\n\nBellman-Ford-Moore algorithm con controllo dei cicli negativi\n\nVari teoremi e lemmi\nLemma\n\n\nSe qualche cammino v‚Üùt contiene un ciclo negativo allora non esiste un cammino minimo v‚Üùt\n\n\n\nSe G non ha cicli negativi allora esiste un cammino minimo v‚Üùt che √® un cammino semplice (ed ha ‚â§ n-1 archi)\n\n\n\nPer ogni nodo v : d[v] √® la stima della lunghezza di qualche cammino¬† v‚Üùt\n\n\nPer ogni nodo v : d[v] √® monotona non crescente\n\nviene aggiornata solo per valori minori\n\n\n\nDopo la passata i, d[v] ‚â§ lunghezza del cammino minimo v‚Üùt che usa ‚â§ i archi\n\n\n\n\nOgni ciclo diretto W nel grafo dei successori √®¬†un ciclo negativo\n\n\n\n\nSe esiste un ciclo negativo l‚Äôultimo algoritmo realizzato lo segnala\n\n\n\n\nTeorema\n\n\nsulla complessit√†\n\n\n\nAssumendo che non ci siano cicli negativi, Bellman-Ford-Moore calcola la lunghezza del cammino minimo in O( m n) tempo e O(n) spazio\n\nLemma 2+Lemma 5\n\n\n\nAssumendo che non ci siano cicli negativi, Bellman-Ford-Moore calcola il cammino pi√π corto per tutti i nodi in O( m n) tempo e O(n) spazio\n\n\n\nMax-flow e min-cut\n\ndefinizione\nUna rete di flusso √® una tupla G=(V,E,s,t,c):¬†\n\n\nGrafo diretto (V,E) con una sorgente s e un pozzo t¬†\n\n\nCapacit√† c(e) ‚â• 0 per ogni arco e\nper risolvere questo problema dobbiamo definire cosa sono\n\n\nst-cut\n\npartizione (A,B) di nodi con s ‚àà A¬† e t ‚àà B\nLa capacit√† di un st-cut √® la somma delle capacit√† degli archi che vanno da A in B\n\n\n\n\nmin-cut\n\nTrovare un taglio di capacit√† minima\nIl min-cut √® quello che fornisce il limite pi√π stretto, cio√® il collo di bottiglia minimo del grafo.\n\n\n\nst-flow\n\nUn st-flow f √® una funzione che soddisfa:¬†\n\n\n\n\nil valore di un st-flow √®\n\n\n\nmax-flow\n\nproblema dove si vuole trovare un flusso dal valore massimo\n\n\n\nResidual network definizione\n\nArco originale\n\ne=(u,v) ‚àà E\nFlow f(e)\nCapacity c(e)\n\n\nArco al contrario e^{reverse} = (v,u)\n\nundo del flusso inviato\n\n\nresidual capacity:\n\n\n\n\nResidual network. G_f =(V,E_f , s, t, c_f)¬†\n\nE_f = { e : f(e) &lt; c(e)}¬†\\ \\ ¬† U \\ \\¬† {e : f(e^{reverse}) &gt; 0}\nPropriet√† chiave : f‚Ä≤ √® un flusso valido¬† in G_f se f+f‚Ä≤ √® un flusso valido in G\nAugmenting path definizione:\n\n\n\nUn cammino aumentante √® un cammino semplice s‚Üùt nella rete residua G_f¬†¬†\n\n\nDef bottleneck capacity:¬†\n\nLa capacit√† di bottleneck di un cammino aumentante¬† P √® la capacit√† minima residua di un arco in P¬†\nPropriet√† chiave:¬†\nSia f un flusso e P¬† un cammino aumentante in G_f allora, dopo aver chiamato f‚Äô ‚Üê AUGMENT( f,c,P), l‚Äôf‚Äô risultante √® un flusso e val(f‚Äô) = val(f) + bottleneck(Gf,P)\n\n\nFord-Fulkerson\n\n\nInizia con f(e) = 0 per ogni arco e ‚àà E¬†\n\n\nTrova un cammino s‚Üùt P nella rete residua G_f¬†¬†\n\n\nAumenta il flusso lungo il cammino P¬†\n\n\ncontinua a cercare cammini aumentanti nel grafo residuoG_f, e aggiorna il flusso lungo quei cammini, finch√© non esistono pi√π cammini da s a t nel grafo residuo.\n\n\n\nLemma del valore del flusso.¬†\n\nSia f un flusso qualsiasi e sia (A,B) un taglio qualsiasi. Allora, il valore del flusso f √® uguale al flusso netto attraversante il taglio (A,B)\n\n\n\n\nDualit√† debole:¬†\n\nSia f un qualsiasi flusso¬† e sia (A,B) un qualsiasi taglio .¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†\n\nAllora,¬†¬† val(f) ‚â§ cap(A,B).¬†\n\n\n\n\n\nCorollario:¬†\n\nSia f un qualsiasi flusso e (A,B) un qualsiasi taglio. se val(f) = cap(A,B), allora f √® un max flow e (A,B) √® un min cut¬†\n\n\n\nMax-flow min-cut theorem:¬†\n\nIl valore di un flusso massimo = capacit√† di un taglio minimo¬†\n\n\n\nAugmenting path theorem :¬†\n\nUn flow f √® un max flow se non ha cammini aumentanti¬†¬†\n\n\n\nTeorema:¬†\n\nDato un qualsiasi max flow f, possiamo calcolare il min cut (A,B)¬† in O(m) tempo\n\n\n\n\n\n                  \n                  ALTRA COSA FONDAMENTALE: il numero di cammini aumentanti pu√≤ essere ESPONENZIALE rispetto all&#039;input.\n                  \n                \n\n\n\n\nL‚Äôobiettivo principale √® scegliere dei cammini aumentanti tali che\n\npossano essere trovati in modo efficiente (quindi in O(m)),\nvengano eseguite poche iterazioni (e quindi pochi aumenti),\n\nPer farlo possiamo sceglierli con\n\nuna bottleneck capacity molto grande ‚Üí cos√¨ ogni aumento contribuisce MOLTO al flusso totale,\npochi archi ‚Üí riduci la probabilit√† di dover ‚Äútornare indietro‚Äù,\n\nVerso l‚Äôalgoritmo Partendo dai due punti precedenti, l‚Äôidea √® questa\n\nUsiamo un parametro \\Delta ‚Üí √® un valore grande,\nCostruisco un sottografo G_{f}(\\Delta) contenente SOLO gli archi che hanno capacit√† \\ge \\Delta,\nIn questo modo ogni cammino aumentante nel nuovo grafo ha una bottleneck capacity \\ge \\Delta\n\n,\n\nPSEUDOCODICE\n\n\nCOSTO\n\n\nCome scegliere il successivo cammino aumentante in Ford-Fulkerson? Scegli quello che usa meno archi (il pi√π corto) ‚Üí usa la BFS. &gt;Scegliendo i pi√π corti saturi velocemente gli archi ‚Äúcolli di bottiglia‚Äù\n\n\nMax-flow Min-cut theorem\n\n\n\nAlgoritmi di approssimazione\ndefinizione\n\nUn Œ±-approximation algorithm per un problema di ottimizzazione √® un algoritmo polinomiale che per tutte le istanze del problema produce una soluzione il cui valore √® compreso entro un fattore Œ±¬† rispetto al valore di una soluzione ottima\nMinimization problem:¬†voglio minimizzare un costo\nŒ± ‚â• 1¬†\nPer ogni soluzione restituita x, cost(x) ‚â§ Œ±¬† OPT(x)¬†\nMaximization problem: voglio massimizzare un valore\nŒ± ‚â§ 1¬†\nPer ogni soluzione restituita x, value(x) ‚â• Œ± OPT(x)\n\nLoad balancing\n\ndefinizione\nDate m identiche macchine, n ‚â• m jobs, job j ha processing time t_j.¬†\n\nJob j deve essere eseguito contiguamente su una macchina¬†\nUna macchina pu√≤ processare al pi√π un job alla volta¬†\nAssegnare ogni job a una macchina affinch√© il make span sia minimo\nDef load:¬†\nSia S[i] il sottoinsieme di job assegnati alla macchina i.¬†\nIl load¬† della macchina i √® L[i] = Œ£_{j \\ ‚àà \\ S[i]}¬† \\ t_j .¬†\n\nDef make span:¬†\n\nIl make span √® il valore massimo di load di ogni macchina L = max_i L[i]\n\nSoluzione List Scheduling Algo\n\nConsidera i job in un qualche ordine fisso¬†\nAssegna il job j alla macchina i il cui carico √® finora il pi√π piccolo\n\n\n\nComplessit√†:¬†\n\nO(n log n)¬†\nUsando una coda con priorit√† per i carichi L[k]¬†\n\n\n\nDimostrazioni e lemma\n\n\n\n\n\n\nLoad balancing LPT(Longest Processing Time)\ndefinizione\n\nOrdina n jobs in ordine decrescente di tempo di processione\nci√≤ lo rende molto pi√π vicino alla soluzione ottima\n\n\nTeoremi\n\n\nk-center problem 2-approximation\n\ndefinizione\nProblema dei k-centri (2-approximation)\nDEFINIZIONE\n\nDati un set di n siti s_{1}, ..., s_{n} e un intero k &gt; 0.\nselezionare k centri C affinch√© la distanza tra un sito e il centro pi√π vicino sia minima.\n\n\n\n                  \n                   r(C) indica la distanza peggiore tra tutte le dist(s_i, C)\n                  \n                \n\nNel senso\n\ncalcola TUTTE le distanze dei siti dai centri pi√π vicini\nprendi la peggiore ‚Üí quella √® r(C)\ncos√¨ tu sai che il minimo raggio di copertura per coprire tutti i siti √® questo valore qui\n\n\n\nAlgoritmo greedy\nSceglie k volte il sito pi√π lontano da qualsiasi centro finora creato, e lo usa come prossimo centro.\n\n\n\n                  \n                   \n                  \n                \n\nL‚Äôalgoritmo greedy potrebbe non essere ottimo ma la sua soluzione non si discosta pi√π del doppio rispetto all‚Äôottimo.\nDIMOSTRAZIONE\n\nPer assurdo ipotizziamo che l‚Äôottimo sia molto pi√π piccolo r(C^{*}) &lt; \\frac1 2 r(C)\n\n\nossia il centro ottimale copre con sfere grandi la met√† di quelle del greedy\n\n\nCostruiamo sfere intorno ai centri trovati c \\in C, con raggio \\frac1 2 r(C)\n\n\nin questa nuova sfera deve esserci ALMENO un centro ottimo c_{i}^{*} altrimenti l‚Äôipotesi sarebbe sbagliata\n\n\nTutte le sfere, per costruzione, sono disgiunte (non si sovrappongono) e quindi in ognuna c‚Äô√® ESATTAMENTE un centro ottimale\n\n\nquindi c‚Äô√® una corrispondenza tra i centri di C e quelli di C*, in particolare |C| = |C^{*}|\n\n\nOra colleghiamo un sito s al suo centro\n\n\nprendiamo un sito s\nsia c_{i}^{*} il centro ottimo pi√π vicino a s\ne sia c_{i} il centro di C che ‚Äúsi abbina a c_{i}^{*}‚Äù (ossia che si trova nella stessa sfera)\nLA DISTANZA DI s dal centro c_{i} trovato dal greedy soddisfa dist(s,C) \\le dist(s, c_{i}^{*}) + dist(c_{i}^{*}, c_{i})\n\nla prima parte dist(s, c_{i}^{*}) √® al massimo r(C^{*}), per definizione\nla seconda parte dist(c_{i}^{*}, c_{i}) anche √® al massimo r(C^{*}), perch√© i due centri si trovano nella stessa sfera\n\n\n\n\nQUINDI la distanza totale √® dist(s, C) \\le 2 \\cdot r(C^{*})\nE QUESTO VALE PER OGNI SITO s\n\n\n\nRIDUZIONI POLINOMIALI\nDefinizione\nUna riduzione polinomiale √® un metodo per trasformare un problema X in un altro problema Y, in modo che:\n\nqualsiasi istanza di X possa essere risolta tramite:\n\nun numero polinomiale di operazioni standard, pi√π\nun numero polinomiale di chiamate a un ‚Äúoracolo‚Äù che risolve Y.\nSi scrive:\n\n\nX \\leq_P Y\nrisolvere Y implica poter risolvere X in tempo polinomiale\n\n3 propriet√† importanti\n\nProgettazione di algoritmi:\nSe X \\leq_P Y e Y √® risolvibile in tempo polinomiale, allora anche X lo √®.\nDimostrare difficolt√† (intractability):\nSe X \\leq_P Y e X non √® risolvibile in tempo polinomiale, allora neanche Y lo √®.\nEquivalenza:\nSe X \\leq_P Y e Y \\leq_P X, allora X \\equiv_P Y.\nSignifica che hanno la stessa complessit√† polinomiale (si risolvono in polinomiale se e solo se l‚Äôaltro lo √®).\n\nEsempi di riduzioni\n1. Independent Set con Vertex Cover\n\ndescriviamo prima il problema dell‚Äôindipendent set\nIndependent Set (IS): Dato un grafo G=(V,E) e un intero k, esiste un sottoinsieme di k vertici non adiacenti tra loro?\n\nproblema del Vertex Cover\nVertex Cover (VC): Dato G=(V,E) e un intero k, esiste un sottoinsieme di k vertici che copre tutti gli archi?\n\n\nVogliamo dimostrare che IS \\equiv_P IS.\n(‚áí) Da Independent Set a Vertex Cover\n\nSupponiamo che S sia un IS di dimensione k.\nAllora V‚àíS ha dimensione n‚àík.\nConsideriamo un arco (u,v)‚ààE(u,v)\n\nPoich√© S √® indipendente, non pu√≤ contenere entrambi i vertici u,v.\nQuindi almeno uno dei due appartiene a V-S.\n\n\nDunque V‚àíS √® un vertex cover di dimensione n-k\n\n(‚áê) Da Vertex Cover a Independent Set\n\nSupponiamo che V‚àíS sia un VC di dimensione n‚àík.\nAllora S ha dimensione k.\nConsideriamo un arco (u,v)‚ààE(u,v).\n\nPoich√© V‚àíS √® un VC, almeno uno tra u,v √® in V‚àíS.\nQuindi non possono essere entrambi in S.\n\n\nDunque S √® un independent set di dimensione k.\n\n2. Set Cover con Vertex Cover\n\ndescriviamo prima il problema del Set Cover\nSet Cover (SC): Dato un insieme universo U, una collezione di sottoinsiemi S_1, ..., S_m‚Äã, e un intero k, esistono al pi√π k sottoinsiemi che coprono tutto U?\n\n\nVogliamo dimostrare che VC \\leq_P SC.\nCostruzione della riduzione\nDato un grafo G=(V,E) e un intero k:\n\nUniverso:\nU = E \\quad (\\text{gli archi del grafo diventano gli elementi dell‚Äôuniverso})\nFamiglia di sottoinsiemi:\nPer ogni vertice v \\in V, definiamo:\nS_v = \\{ e \\in E : e \\text{ √® incidente a } v \\}\nParametro:\nManteniamo lo stesso valore k.\n\nCos√¨ otteniamo un‚Äôistanza di Set Cover (U, \\mathcal{S}, k)\n(‚áí) Se G ha un Vertex Cover di dimensione k\n\nSupponiamo che X \\subseteq V sia un VC con |X|=k.\nConsideriamo \\mathcal{Y} = \\{ S_v : v \\in X \\}\nOgni arco √® coperto da almeno un vertice in X, quindi \\mathcal{Y} √® un set cover di dimensione k.\n\n(‚áê) Se (U, \\mathcal{S}, k) ha un Set Cover di dimensione k\n\nSupponiamo che \\mathcal{Y} \\subseteq \\mathcal{S} sia un set cover di dimensione k.\nSia X = \\{ v \\in V : S_v \\in \\mathcal{Y} \\}.\nPoich√© ogni arco e appartiene ad almeno un sottoinsieme S_v, significa che v \\in X copre quell‚Äôarco.\nQuindi X √® un VC di dimensione k.\n\n\n3. 3-SAT con Independent Set\n\ndescriviamo prima il problema del 3-SAT\n3-SAT: Formula booleana in CNF con clausole di 3 letterali ciascuna. La formula √® soddisfacibile?\n\n\nVogliamo dimostrare che 3-SAT \\leq_P IS.\nCostruzione della riduzione\n\nNodi:\nPer ogni clausola della formula, aggiungiamo 3 nodi (uno per ogni letterale).\nArchi interni:\nI 3 nodi di una clausola vengono collegati in un triangolo.\n‚Üí garantisce che al massimo 1 letterale possa essere scelto dall‚Äôinsieme indipendente.\nArchi tra clausole:\nCollegare ogni letterale con la sua negazione (es: x_i‚Äã con \\neg x_i).\n‚Üí impedisce di selezionare contemporaneamente un letterale e la sua negazione.\nParametro:\nk = |\\Phi| \\quad (\\text{cio√® una scelta per ogni clausola}).\n\nDimostrazione\n(‚áí) Se \\Phi √® soddisfacibile\n\nEsiste una assegnazione che rende vera ogni clausola.\nPer ciascuna clausola, scegliamo un letterale che risulta vero.\nQuesti nodi non saranno collegati fra loro (per costruzione), quindi formano un independent set di dimensione k.\n\n(‚áê) Se G contiene un independent set di dimensione k\n\nOgni triangolo rappresenta una clausola.\nPer avere un IS di dimensione k, dobbiamo scegliere esattamente un nodo per triangolo.\nI letterali scelti non possono essere contraddittori (perch√© IS esclude coppie collegate).\nAssegniamo true a quei letterali ‚Üí tutte le clausole sono soddisfatte.\nDunque \\Phi √® soddisfacibile.\n\n\n\n\nTransitivit√†: Se X \\leq_P Y \\ X‚â§P‚ÄãY \\ e \\ Y‚â§_PZ \\ Y \\leq_P Z.\n‚Üí Esempio:\n\\text{3-SAT} \\leq_P \\text{IS} \\leq_P \\text{VC} \\leq_P \\text{SC}\n\n\nP: problemi di decisione per i quali esiste un algoritmo polinomiale che li risolve.\n‚Üí Sono i problemi ‚Äúfacili da risolvere‚Äù.\n\n\nNP: problemi di decisione per i quali esiste un certificatore polinomiale.\n‚Üí Non sappiamo se sono facili da risolvere, ma se qualcuno ci d√† una soluzione candidata (certificato), possiamo verificarla velocemente.\n\n\nEXP: problemi di decisione per i quali esiste un algoritmo esponenziale che li risolve.\n‚Üí In pratica: anche se non troviamo algoritmi migliori, con una brute force in tempo esponenziale si riescono a risolvere.\n\n\nP \\subseteq NP\nNP \\subseteq EXP"},"UNI/ANNO-2/ALGORITMI-2/domande_ripasso":{"slug":"UNI/ANNO-2/ALGORITMI-2/domande_ripasso","filePath":"UNI/ANNO 2/ALGORITMI 2/domande_ripasso.md","title":"domande_ripasso","links":[],"tags":[],"content":"Domande di ripasso ASD\nGreedy ‚Äì Interval Scheduling / Partitioning\n\nPerch√© l‚Äôordinamento per tempo di fine √® l‚Äôunico greedy corretto per Interval Scheduling?\nCos‚Äô√® la depth di un‚Äôistanza di Interval Partitioning e perch√© fornisce un lower bound al numero di aule?\nSpiega in 3 righe la differenza tra IS e IP e quali sono i rispettivi criteri greedy.\n\nUnion-Find\n\nDifferenze di complessit√† tra QuickFind, QuickUnion, e QuickUnion + UBS/Path compression.\nSpiega perch√© in QuickFind con union-by-size ogni elemento pu√≤ cambiare id al massimo log n volte.\nMostra una sequenza di union che porta a un albero di altezza log n in QuickUnion con union-by-size.\nIn che modo Union-Find viene usato nell‚Äôalgoritmo di Kruskal?\n\nMST (Kruskal, Prim, propriet√†)\n\nEnuncia la cut property e spiega in 2 righe come giustifica Kruskal.\nEnuncia la cycle property e spiega in 2 righe come giustifica Kruskal.\nPerch√© se i pesi sono distinti l‚ÄôMST √® unico?\nMST e SPT coincidono? In quali casi s√¨?\n√à possibile che l‚Äôarco pi√π pesante del grafo appartenga a un MST? Motivare.\nCosa fa l‚Äôalgoritmo reverse-delete e su quale propriet√† si basa?\n\nClustering (da MST)\n\nCos‚Äô√® lo spacing di un clustering?\nPerch√© togliere i k‚àí1 archi pi√π pesanti dall‚ÄôMST produce il clustering a spacing massimo?\n\nProgrammazione dinamica classica\n\nScrivi la ricorrenza per il Weighted Interval Scheduling e spiega il ruolo di p(j).\nScrivi la ricorrenza per Independent Set su cammino.\nSpiega come funziona il traceback nel knapsack problem.\nCos‚Äô√® il vantaggio dell‚Äôalgoritmo di Hirschberg rispetto alla DP classica per sequence alignment?\nScrivi la ricorrenza del Bellman‚ÄìFord in termini di numero massimo di archi usati.\n\nMax Flow / Min Cut\n\nEnuncia il teorema max-flow min-cut.\nDefinisci la rete residua e il concetto di cammino aumentante.\nPerch√© Ford‚ÄìFulkerson pu√≤ essere esponenziale? In quali casi √® polinomiale?\nCome si calcola un min-cut a partire da un flusso massimo?\nPerch√© Edmonds‚ÄìKarp √® polinomiale? Qual √® la sua complessit√†?\n\nAlgoritmi di approssimazione\n\nDefinisci cos‚Äô√® un algoritmo di Œ±-approssimazione per un problema di minimizzazione.\nQuali sono i due lower bound usati per analizzare il problema del load balancing?\nPerch√© l‚Äôalgoritmo LPT (Longest Processing Time) funziona meglio di list scheduling semplice?\nEnuncia la strategia greedy 2-approssimata per il problema del k-center.\n\nRiduzioni polinomiali / Complessit√†\n\nDefinisci formalmente una riduzione polinomiale X ‚â§P Y.\nMostra come si riduce Independent Set ‚Üî Vertex Cover.\nMostra come si riduce Vertex Cover ‚â§p Set Cover.\nDescrivi la costruzione della riduzione 3-SAT ‚â§p Independent Set.\nCosa significa X ‚â°P Y?\nQual √® la differenza tra P, NP ed EXP?\n"},"UNI/ANNO-2/BASE-DI-DATI/1.riassunto_mysql_sql_ddl_dml_numerato-1":{"slug":"UNI/ANNO-2/BASE-DI-DATI/1.riassunto_mysql_sql_ddl_dml_numerato-1","filePath":"UNI/ANNO 2/BASE DI DATI/1.riassunto_mysql_sql_ddl_dml_numerato 1.md","title":"1.riassunto_mysql_sql_ddl_dml_numerato 1","links":[],"tags":[],"content":"Riassunto Lezione: MySQL - SQL DDL e DML\n1. Introduzione: Contenuti della lezione\nLa lezione tratta i seguenti argomenti:\n\nSQL e DBMS\nMySQL e sua installazione\nDDL (Data Definition Language)\nDML (Data Manipulation Language)\nVincoli di integrit√†\n\n\n2. SQL: Cos‚Äô√® e a cosa serve\nSQL (Structured Query Language) √® un linguaggio:\n\nNato come SEQUEL nel 1974.\nStandard de facto dal 1983.\nStandardizzato a partire dal 1986 con aggiornamenti successivi.\n\nSQL include:\n\nDDL: per creare e modificare la struttura del database (es. tabelle).\nDML: per inserire, modificare, cancellare e leggere dati.\n\nEsempio:\n\nDDL: CREATE TABLE studenti (...)\nDML: INSERT INTO studenti VALUES (...)\n\n\n3. DBMS: Sistema di Gestione di Basi di Dati\nUn DBMS (Database Management System) √® un software che gestisce dati in modo:\n\nAffidabile (garanzia di integrit√† e backup)\nCondiviso (pi√π utenti possono accedere)\nEfficiente (ottimizza l‚Äôuso delle risorse)\nSicuro (accessi protetti)\nPersistente (i dati non si perdono)\n\n\n4. MySQL: Un DBMS relazionale\nMySQL √®:\n\nUn RDBMS (Relational DBMS) open source di Oracle.\nEstremamente diffuso.\nDisponibile in versione gratuita (community) e commerciale (enterprise).\nAssociato al tool grafico MySQL Workbench.\n\nCaratteristiche:\n\nScritto in C/C++, usa engine InnoDB (supporta transazioni e vincoli FK).\nInterfacciabile con C, Java, Python.\nNessun limite specifico su tabelle/dimensione (dipende dall‚ÄôOS).\nHa fork come MariaDB.\n\n\n5. Ranking dei DBMS\nNel grafico DB-Engines Ranking (slide 10), si osserva la popolarit√† nel tempo:\nOracle, MySQL e SQL Server sono tra i pi√π usati. MySQL ha una posizione stabile e alta.\n\n6. Installazione di MySQL\nDisponibile su:\nwww.mysql.com/it/downloads/\nUsare MySQL Installer for Windows (Community Edition - GPL).\n\n7. Accesso da Terminale\nConnessione da terminale:\nmysql -u nome_utente -p\nOpzioni:\n\n-P porta\n-h host\n\n\n8. Comandi SQL di Base\n\nSHOW DATABASES; ‚Üí mostra i database esistenti\nUSE nomedb; ‚Üí seleziona un database\nCREATE DATABASE nomedb; ‚Üí crea un database\nDROP DATABASE nomedb; ‚Üí elimina un database\nEXIT; ‚Üí esce dalla sessione\n\nNota: ogni comando termina con ;\n\n9. Domini in SQL\nI domini sono insiemi di valori ammissibili per un attributo.\nTipi:\n\nElementari (predefiniti): es. interi, stringhe, date\nDefiniti dall‚Äôutente: utili per riusabilit√†\n\n\n10. Tipi di dato elementari\nNumerici:\n\nTINYINT: da -128 a 127\nSMALLINT: da -32.768 a 32.767\nINT: da -2.147.483.648 a 2.147.483.647\nFLOAT(M,D), DOUBLE(M,D): decimali con precisione\n\nAlfanumerici:\n\nCHAR(x): stringa a lunghezza fissa\nVARCHAR(x): lunghezza variabile\nTEXT: fino a 65.535 byte\nBLOB: oggetti binari (es. immagini)\n\nNota: Non creare indici su TEXT e BLOB\nTemporali:\n\nDATE: yyyy-mm-dd\nTIME: hh:mm:ss\nDATETIME: data e ora\nYEAR: solo anno\nTIMESTAMP(x): data e ora con precisione variabile\n\n\n11. Creazione di Domini (SQL standard, non MySQL)\nCREATE DOMAIN Voto AS SMALLINT DEFAULT NULL \nCHECK (value &gt;= 18 AND value &lt;= 30);\n\n12. Creazione e Cancellazione Tabelle (DDL)\nCREATE TABLE nome (\n  attributo tipo opzioni,\n  ...\n);\nDROP TABLE nome;\nChi crea la tabella ne possiede tutti i diritti. La tabella inizialmente √® vuota.\n\n13. Storage Engine: InnoDB vs MyISAM\nInnoDB:\n\nSupporta transazioni\nSupporta chiavi esterne\nPi√π robusto\n\nMyISAM:\n\nPi√π efficiente e veloce\nMeno sicuro (no transazioni)\nConsuma meno spazio\n\n\n14. Specificare l‚Äôengine nella creazione\nCREATE TABLE nome (\n  attributo tipo,\n  ...\n) ENGINE=InnoDB;\n\n15. Esempio completo di creazione\nCREATE TABLE emp (\n  empno INT NOT NULL PRIMARY KEY AUTO_INCREMENT,\n  ename VARCHAR(30) NOT NULL,\n  sal FLOAT(4,2)\n);\nDROP TABLE emp;\nIn questo esempio:\n\nempno √® la chiave primaria e si incrementa automaticamente.\nename √® obbligatorio (NOT NULL)\nsal √® uno stipendio con 4 cifre totali di cui 2 decimali.\n\nRiassunto Lezione: MySQL - SQL DDL e DML (Parte 2)\n16. DDL - Valori di Default\n\n√à possibile specificare un valore di default per un attributo.\nUsato quando non viene fornito un valore in fase di inserimento.\nSintassi: default &lt;valore&gt; oppure default null.\nEsempio:\nNumeroFigli SMALLINT DEFAULT 0\n\n\n\n17. Esempio Creazione Tabella con FK\nCREATE TABLE emp (\n  emp_id INT NOT NULL PRIMARY KEY AUTO_INCREMENT,\n  dept_id CHAR(2) NOT NULL,\n  emp_name VARCHAR(30) NOT NULL,\n  deptno INT NOT NULL,\n  sal FLOAT(4,2) NOT NULL,\n  FOREIGN KEY (deptno) REFERENCES dept(dptno)\n    ON UPDATE CASCADE\n    ON DELETE NO ACTION\n) ENGINE=InnoDB;\n \nDROP TABLE emp;\n\n18. Modifica Schema - ALTER\nALTER TABLE nome ADD nome_attributo tipo;\nALTER TABLE nome RENAME nuovo_nome;\nCREATE TABLE IF NOT EXISTS nome (...);\nModifiche avanzate:\nALTER TABLE NomeTabella\n  ALTER COLUMN NomeAttributo SET DEFAULT val;\n  ADD CONSTRAINT NomeVincolo ...;\n  DROP CONSTRAINT NomeVincolo;\n  ADD COLUMN nuovo_attr tipo;\n  DROP COLUMN nome_attr;\n\n19. Comando DROP\nRimuove componenti:\nDROP &lt;schema | domain | table | view | assertion&gt; nome_elemento [RESTRICT | CASCADE];\n\nRESTRICT: blocca se ci sono dipendenze.\nCASCADE: elimina anche le dipendenze.\n\n\n20. Indici\nGli indici migliorano le prestazioni, ma sono componenti fisici, non logici.\nCREATE INDEX indnome ON emp(ename);\nDROP INDEX indnome ON emp;\n\n21. DML - Manipolazione dei Dati\nI principali comandi:\n\nINSERT\nUPDATE\nDELETE\n\n\n22. INSERT\nINSERT INTO NomeTabella [(ListaAttributi)] VALUES (...);\nINSERT INTO NomeTabella SELECT ...;\nEsempio:\nINSERT INTO Dipartimento(NomeDip, Citt√†)\nVALUES (&#039;Produzione&#039;, &#039;Torino&#039;);\nOppure:\nINSERT INTO ProdottiMilanesi\nSELECT codice, descrizione FROM Prodotto WHERE LuogoProd = &#039;Milano&#039;;\n\n23. UPDATE\nUPDATE nome_tabella\nSET attr1 = val1, attr2 = val2\nWHERE condizione;\nEsempi:\nUPDATE emp SET job = &#039;salesman&#039;, sal = 1.1 * sal WHERE ename = &quot;Wilson&quot;;\n \nUPDATE emp\nSET sal = (SELECT 2 * AVG(sal) FROM emp WHERE job = &#039;salesman&#039;)\nWHERE job = &#039;salesman&#039;;\nAttenzione: SQL √® orientato agli insiemi, non riga per riga.\n\n24. DELETE\nDELETE FROM nome_tabella WHERE condizione;\n\nSenza WHERE elimina tutte le righe.\nCon vincoli referenziali, attenzione alle politiche CASCADE.\n\n\n25. Vincoli Intra-relazionali\n\nNOT NULL\nUNIQUE (attr, attr)\nPRIMARY KEY (attr) ‚Äì unica, tutti gli attributi NOT NULL\n\nEsempio:\nNome CHAR(20) NOT NULL,\nCognome CHAR(20) NOT NULL,\nUNIQUE (Nome, Cognome)\n\n26. Vincoli Referenziali (FK)\nFOREIGN KEY (colonne) REFERENCES tabella(colonne)\nON DELETE CASCADE | SET NULL | SET DEFAULT | NO ACTION\nON UPDATE CASCADE | ...\nEsempio:\nCREATE TABLE Impiegato (\n  Matricola CHAR(6) PRIMARY KEY,\n  Nome CHAR(20) NOT NULL,\n  Cognome CHAR(20) NOT NULL,\n  Stipendio INT DEFAULT 0,\n  UNIQUE (Cognome, Nome),\n  FOREIGN KEY (Nome, Cognome)\n    REFERENCES Anagrafica(Nome, Cognome)\n) ENGINE=InnoDB;\n\n27. Politiche Referenziali\n\n\nUPDATE\n\nCASCADE: propaga la modifica\nSET NULL: imposta a NULL\nSET DEFAULT: imposta valore di default\nNO ACTION: blocca l‚Äôoperazione\n\n\n\nDELETE\n\nstesso comportamento con rimozione\n\n\n\n\n28. Vincoli Generici: CHECK\nCHECK (condizione)\nEsempio:\nCHECK (sesso IN (&#039;M&#039;,&#039;F&#039;))\n \nCHECK (Stipendio &lt;= (SELECT Stipendio FROM Impiegato J WHERE Superiore = J.Matricola))\n\n29. Asserzioni\nPermettono vincoli trasversali su pi√π tabelle.\nCREATE ASSERTION AlmenoUnImpiegato\nCHECK (1 &lt;= (SELECT COUNT(*) FROM Impiegato));\n\n30. Controllo dei Vincoli\n\nIMMEDIATE: controllo subito dopo l‚Äôoperazione.\nDEFERRED: controllo alla fine della transazione.\n\nModifica:\nSET CONSTRAINTS NomeVincolo IMMEDIATE;\nSET CONSTRAINTS NomeVincolo DEFERRED;\n"},"UNI/ANNO-2/BASE-DI-DATI/2.-riassunto_SQL_interrogazioni-2":{"slug":"UNI/ANNO-2/BASE-DI-DATI/2.-riassunto_SQL_interrogazioni-2","filePath":"UNI/ANNO 2/BASE DI DATI/2. riassunto_SQL_interrogazioni 2.md","title":"2. riassunto_SQL_interrogazioni 2","links":[],"tags":[],"content":"SQL ‚Äì Interrogazioni: Riassunto Dettagliato\nüåê Introduzione alle Interrogazioni in SQL\nIn SQL, le interrogazioni (query) permettono di ottenere informazioni dai dati memorizzati nei database. La filosofia √® dichiarativa: non si dice come ottenere i dati, ma quali dati si vogliono.\n\nEsempio pratico: voglio sapere lo stipendio mensile di chi si chiama ‚ÄúRossi‚Äù. Dico solo cosa voglio ottenere, non come calcolarlo.\n\nIl DBMS (Database Management System) riceve la query e la ottimizza, trasformandola nel suo linguaggio interno.\n\nüèóÔ∏è Struttura di base di una query SQL\nLa sintassi √® la seguente:\nSELECT ListaAttributi\nFROM ListaTabelle\n[WHERE Condizione]\nPu√≤ includere:\n\nAlias per rinominare colonne o tabelle\nOperazioni aritmetiche nei risultati\n\nEsempio:\nSELECT Stipendio/12 AS SalarioMensile\nFROM Impiegato\nWHERE Cognome = &#039;Rossi&#039;;\nQuesta query restituisce il salario mensile di chi si chiama Rossi.\nüëâ Con SELECT * si selezionano tutti gli attributi della tabella.\n\nüìÑ Duplicati e DISTINCT\nA differenza dell‚Äôalgebra relazionale, SQL ammette duplicati.\nPer eliminarli:\nSELECT DISTINCT Citt√†\nFROM Persona;\nRestituisce l‚Äôelenco delle citt√† senza ripetizioni.\n\nüîç Selezione e Proiezione\nConcetti fondamentali nell‚Äôinterrogazione dei dati:\n\nSelezione (WHERE): filtra le righe.\nProiezione (SELECT): sceglie le colonne da mostrare.\n\nEsempi:\n\n\nNome e Reddito delle persone &lt; 30 anni:\nSELECT Nome, Reddito\nFROM Persone\nWHERE Eta &lt; 30;\n\n\nTutti gli attributi di persone &lt; 30 anni:\nSELECT *\nFROM Persone\nWHERE Eta &lt; 30;\n\n\nSolo Nome e Reddito di tutte le persone:\nSELECT Nome, Reddito\nFROM Persone;\n\n\n\nüè∑Ô∏è Alias e abbreviazioni\nGli alias servono a rinominare colonne o tabelle temporaneamente:\nSELECT Reddito/2 AS RedditoSemestrale\nFROM Persone\nWHERE Nome = &#039;Luigi&#039;;\nAlias per tabelle:\nSELECT p.nome, p.reddito\nFROM persone p\nWHERE p.eta &lt; 30;\nüëâ Questo rende le query pi√π leggibili, soprattutto quando si usano join o pi√π tabelle.\n\nüßÆ Espressioni nella SELECT\nNella lista degli attributi (target list) si possono inserire anche espressioni:\nSELECT Reddito/2 AS RedditoSemestrale\nFROM Persone\nWHERE Nome = &#039;Luigi&#039;;\n\nüìå Clausola WHERE\nServe per filtrare i dati. Gli operatori supportati sono:\n\nConfronto: =, &lt;&gt;, !=, &lt;, &gt;, &lt;=, &gt;=\nIntervalli: BETWEEN x AND y\nListe: IN (...)\nPattern: LIKE\nNull: IS NULL, IS NOT NULL\nLogici: NOT, AND, OR\n\nPattern con LIKE:\n\n_ = un carattere qualsiasi\n% = qualsiasi numero di caratteri (anche zero)\n\nSELECT *\nFROM Impiegato\nWHERE Cognome LIKE &#039;_o%i&#039;; -- es. Rossi, Rosi, Porti\n\n‚ö†Ô∏è Gestione dei Valori NULL\nI valori NULL indicano l‚Äôassenza di un valore. Non si pu√≤ usare = per confrontarli.\nEsempio: trovare impiegati con et√† &gt; 40 o senza et√†:\nSELECT *\nFROM Impiegati\nWHERE Eta &gt; 40 OR Eta IS NULL;\nTabella d‚Äôesempio:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMatricolaCognomeFilialeEt√†5555RossiRoma456666NeriRomaNULL\n\nüîó JOIN e prodotti cartesiani\nSe nella clausola FROM compare una sola tabella, possiamo fare selezioni, proiezioni e alias.\nSe invece compare pi√π di una tabella, SQL esegue un join, ovvero unisce i dati delle tabelle:\nSELECT *\nFROM Impiegato, Dipartimento\nWHERE Impiegato.Dipart = Dipartimento.Nome;\nQuesto √® un inner join implicito (prodotto cartesiano + filtro).\n\nüìö Conclusione\nLa lezione copre:\n\nCome scrivere query base con SELECT\nCome filtrare dati con WHERE\nCome usare DISTINCT, LIKE, IS NULL, IN, BETWEEN\nCome calcolare espressioni nei risultati (SalarioMensile)\nCome unire pi√π tabelle con JOIN\n\nSQL ‚Äì Interrogazioni: Riassunto Dettagliato (Slide 25‚Äì50)\nüîÑ Selezione, Proiezione e JOIN\nQuery con una sola tabella:\nPermettono selezione, proiezione e ridenominazione.\nQuery con pi√π tabelle:\nConsentono di effettuare JOIN (unione logica) e prodotti cartesiani.\nEsempio:\nSELECT Impiegato.Nome, Impiegato.Cognome, Dipartimento.Citt√†\nFROM Impiegato, Dipartimento\nWHERE Impiegato.Dipart = Dipartimento.Nome;\n\nüîó JOIN in SQL\nJOIN = unire righe da pi√π tabelle quando c‚Äô√® una relazione logica tra loro.\nJOIN esplicito con WHERE\nSELECT *\nFROM Tabella1, Tabella2\nWHERE Tabella1.colonna = Tabella2.colonna;\nJOIN con sintassi estesa\nSELECT ...\nFROM T1 [tipo_join] JOIN T2 ON condizione\nTipo di JOIN:\n\nINNER JOIN (default)\nLEFT [OUTER] JOIN\nRIGHT [OUTER] JOIN\nFULL [OUTER] JOIN\n\nEsempi reali:\n\nPadri di persone che guadagnano pi√π di 20\n\nSELECT DISTINCT Padre\nFROM Persone, Paternita\nWHERE Figlio = Nome AND Reddito &gt; 20;\n\nPersone che guadagnano pi√π dei padri:\n\nSELECT f.Nome, f.Reddito, p.Reddito\nFROM Persone p, Paternita, Persone f\nWHERE p.Nome = Padre AND Figlio = f.Nome AND f.Reddito &gt; p.Reddito;\n\nüß≠ Ordinamento con ORDER BY\nSintassi:\nSELECT Nome, Reddito\nFROM Persone\nWHERE Eta &lt; 30\nORDER BY Nome ASC; -- o DESC\nEsempio:\nOrdina i nomi delle persone &lt; 30 anni in ordine alfabetico crescente.\n\nüîÅ Unione, Intersezione, Differenza\nUNION\nUnisce i risultati di due SELECT.\nSELECT * FROM A\nUNION\nSELECT * FROM B;\nPer mantenere duplicati: UNION ALL\nEXCEPT\nRestituisce righe di A che non sono in B:\nSELECT * FROM A\nEXCEPT\nSELECT * FROM B;\nINTERSECT\nRestituisce righe comuni tra A e B:\nSELECT * FROM A\nINTERSECT\nSELECT * FROM B;\n\nüî¢ Operatori Aggregati\nUsati per calcoli su insiemi di righe.\nFunzioni:\n\nAVG() media\nCOUNT() conteggio\nMAX() massimo\nMIN() minimo\nSUM() somma\n\nEsempio:\nSELECT COUNT(*) FROM Impiegato WHERE Nome = &#039;Rossi&#039;;\nSELECT MAX(sal), MIN(sal), MAX(sal)-MIN(sal) FROM emp;\n\nüìä GROUP BY\nServe a raggruppare le righe in sottoinsiemi per calcolare aggregazioni per gruppo.\nEsempio:\nSELECT Dipart, MAX(Stipendio)\nFROM Impiegato\nGROUP BY Dipart;\nConteggio figli per padre:\nSELECT Padre, COUNT(*) AS NumFigli\nFROM Paternita\nGROUP BY Padre;\n\n‚úÖ GROUP BY e vincoli\n√à obbligatorio includere nella GROUP BY tutti gli attributi che non sono funzioni aggregate nella SELECT.\nEsempio corretto:\nSELECT Padre, AVG(f.Reddito), p.Reddito\nFROM Persone f\nJOIN Paternita ON Figlio = Nome\nJOIN Persone p ON Padre = p.Nome\nGROUP BY Padre, p.Reddito;\n\n‚ö†Ô∏è GROUP BY con NULL\nSELECT B, COUNT(*) FROM R GROUP BY B;\nSELECT A, COUNT(*) FROM R GROUP BY A;\nSELECT A, COUNT(B) FROM R GROUP BY A;\n\nCOUNT(*) conta tutte le righe\nCOUNT(B) esclude NULL in B\n\n\nüßæ HAVING: Condizioni sui Gruppi\nQuando usare HAVING?\nSe la condizione si applica ai gruppi (non alle singole righe), va usata HAVING dopo GROUP BY.\nEsempio:\nSELECT Dipart, SUM(Stipendio) AS SommaStipendi\nFROM Impiegati\nGROUP BY Dipart\nHAVING SUM(Stipendio) &gt; 100;\nAltro esempio:\nPadri i cui figli hanno un reddito medio &gt; 25\nSELECT Padre, AVG(f.Reddito)\nFROM Persone f JOIN Paternita ON Figlio = Nome\nGROUP BY Padre\nHAVING AVG(f.Reddito) &gt; 25;"},"UNI/ANNO-2/BASE-DI-DATI/3.-riassunto_SQL_interrogazioni-3":{"slug":"UNI/ANNO-2/BASE-DI-DATI/3.-riassunto_SQL_interrogazioni-3","filePath":"UNI/ANNO 2/BASE DI DATI/3. riassunto_SQL_interrogazioni 3.md","title":"3. riassunto_SQL_interrogazioni 3","links":[],"tags":[],"content":"MySQL ‚Äì Viste e Accessi\n1. Viste in MySQL\nCos‚Äô√® una vista?\nUna vista √® una tabella virtuale che non contiene dati propri, ma li ricava da una o pi√π tabelle reali (dette di base).\n√à definita tramite una query SQL.\nSintassi:\nCREATE VIEW NomeVista [(ListaAttributi)] AS SELECT ... \n[WITH [LOCAL | CASCADED] CHECK OPTION];\n\nLa query deve restituire lo stesso numero e ordine di attributi della vista.\nNon sono ammesse dipendenze ricorsive (una vista che richiama se stessa).\n\nEsempio:\nCREATE VIEW ImpiegatiAmmin (Matricola, Nome, Cognome, Stipendio) AS\nSELECT Matricola, Nome, Cognome, Stipendio\nFROM Impiegato\nWHERE Dipart = &#039;Amministrazione&#039; AND Stipendio &gt; 10;\nAggiornabilit√†:\n\nLe viste possono essere modificabili solo in certi casi:\n\nDevono derivare da una sola tabella.\n√à preferibile che contengano una chiave primaria.\nSe sono costruite con JOIN, le modifiche non sono permesse.\n\n\n\n\n2. Vantaggi e Svantaggi delle Viste\n‚úÖ Vantaggi:\n\nNon occupano spazio fisico.\nSicurezza: si possono escludere colonne sensibili.\nComodit√†: semplificano le query e migliorano la leggibilit√† e performance.\n\n‚ùå Svantaggi:\n\nModifiche rischiose: UPDATE e DELETE possono causare errori o inconsistenze.\nDifficolt√† di mantenimento: specialmente in contesti complessi.\n\n\n3. Interrogazioni e Aggiornamenti sulle Viste\nLe viste si usano come normali tabelle:\nSELECT * FROM ImpiegatiAmmin;\nCon WITH CHECK OPTION si garantisce che i dati modificati rimangano compatibili con la definizione della vista:\nCREATE VIEW ImpiegatiAmminPoveri AS\nSELECT * FROM ImpiegatiAmmin\nWHERE Stipendio &lt; 50\nWITH CHECK OPTION;\nEsempio di update non valido:\nUPDATE ImpiegatiAmminPoveri\nSET Stipendio = 60\nWHERE Nome = &#039;Paola&#039;;\n\n4. Esempi di Interrogazioni Complesse con le Viste\nProblema:\nSELECT AVG(COUNT(DISTINCT Ufficio))\nFROM Impiegato\nGROUP BY Dipart;\n‚ùå Non valido.\nSoluzione con vista:\nCREATE VIEW DipartUffici(NomeDip, NroUffici) AS\nSELECT Dipart, COUNT(DISTINCT Ufficio)\nFROM Impiegato\nGROUP BY Dipart;\n \nSELECT AVG(CAST(NroUffici AS DECIMAL(5,2))) AS NumeroMedioUffici\nFROM DipartUffici;\n\n5. Viste Ricorsive (MySQL 8+)\nUsate per strutture gerarchiche (es. alberi genealogici).\nDato:\nPaternita(Padre, Figlio)\nObiettivo:\nTrovare tutti gli antenati (viste ricorsive).\nWITH RECURSIVE Discendenza(Antenato, Discendente) AS (\n  SELECT Padre, Figlio FROM Paternita\n  UNION ALL\n  SELECT D.Antenato, P.Figlio\n  FROM Discendenza D, Paternita P\n  WHERE D.Discendente = P.Padre\n)\nSELECT * FROM Discendenza;\n\n6. Funzioni Scalari\nRestituiscono un valore per ogni riga (ennupla).\nTipologie:\n\nTemporali: CURRENT_DATE, EXTRACT(YEAR FROM ...)\nStringhe: CHAR_LENGTH(), LOWER()\nConversioni: CAST()\n\n\n7. Funzioni Condizionali\nNULLIF():\nSELECT NULLIF(25, 26);  -- ‚Üí 25\nSELECT NULLIF(25, 25);  -- ‚Üí NULL\nCOALESCE():\nSELECT Nome, Cognome, COALESCE(Dipart, &#039;Ignoto&#039;)\nFROM Impiegato;\nCASE:\nSELECT Targa,\n  CASE Tipo\n    WHEN &#039;Auto&#039; THEN 2.58 * KWatt\n    WHEN &#039;Moto&#039; THEN 22.00 + 1.00 * KWatt\n    ELSE NULL\n  END AS Tassa\nFROM Veicolo\nWHERE Anno &gt; 1975;\n\n8. Controllo degli Accessi in MySQL\n\nUtenti possono essere locali o definiti dal sistema.\nI privilegi sono associati a:\n\nRisorsa (tabella, attributo‚Ä¶)\nUtente che concede e riceve\nAzione permessa\nPossibilit√† di trasferire il privilegio\n\n\n\nComandi principali:\nCREATE USER ..., GRANT ..., REVOKE ...;\n\n9. Ruoli\nUn ruolo √® un insieme di privilegi, utile per assegnare autorizzazioni a gruppi.\nCREATE ROLE nome_ruolo;\nDROP ROLE nome_ruolo;\n\n10. Privilegi e Sicurezza\nTipi di privilegi:\n\nSELECT, INSERT, UPDATE, DELETE\nREFERENCES, USAGE, DROP, ALTER\n\nEsempi:\nGRANT SELECT ON Dipartimento TO Stefano;\nREVOKE SELECT ON Dipartimento FROM Stefano;\nMiglior pratica:\nCreare viste con solo le colonne necessarie, per limitare l‚Äôaccesso senza complicare la gestione dei privilegi."},"UNI/ANNO-2/BASE-DI-DATI/BASE-DI-DATI-PROGETTO-PIANO":{"slug":"UNI/ANNO-2/BASE-DI-DATI/BASE-DI-DATI-PROGETTO-PIANO","filePath":"UNI/ANNO 2/BASE DI DATI/BASE DI DATI PROGETTO PIANO.md","title":"BASE DI DATI PROGETTO PIANO","links":[],"tags":[],"content":"Perfetto! Basandomi sulle linee guida ufficiali del progetto e sul tuo obiettivo di lavorare 2 ore a settimana fino al 1¬∞ luglio, ti propongo una divisione in step settimanali, dove ogni attivit√† √® orientata all‚Äôapprendimento pratico e alla produzione dei materiali richiesti.\n\nüìÖ Piano completo settimanale con divisione in step (8 settimane)\nüîπ SETTIMANA 1 ‚Äì Definizione progetto e assegnazione (Fase 1)\n‚úÖ Obiettivi:\n\n\nScegliere un dominio (es. gestione eventi, biblioteca, coworking‚Ä¶).\n\n\nDefinire componenti del gruppo.\n\n\nScrivere:\n\n\nDescrizione del dominio applicativo.\n\n\nObiettivi funzionali del sistema (cosa far√†).\n\n\n\n\nInviare documento al docente per approvazione.\n\n\nüìÑ Output da produrre:\n\n\nDocumento .docx con:\n\n\nTitolo del progetto.\n\n\nNomi ed email.\n\n\nDominio + obiettivi.\n\n\n\n\n\nüîπ SETTIMANA 2 ‚Äì Documento dei requisiti (parte 1, Fase 2a-f)\n‚úÖ Obiettivi:\n\n\nScrivere:\n\n\nMotivazioni e obiettivi del progetto.\n\n\nFonti per l‚Äôacquisizione requisiti (es. finzione di interviste, regolamenti).\n\n\nGlossario dei termini.\n\n\n\n\nüìÑ Output da produrre:\n\nSezione a‚Äìf del documento requisiti in .docx.\n\n\nüîπ SETTIMANA 3 ‚Äì Documento dei requisiti (parte 2, Fase 2g‚Äìi)\n‚úÖ Obiettivi:\n\n\nDefinire:\n\n\nClassi di utenza (es. admin, utente, gestore‚Ä¶).\n\n\nOperazioni sui dati (inserisci, cancella, cerca‚Ä¶).\n\n\nDimensionamento dei dati (stima tabelle, accessi).\n\n\nVincoli d‚Äôintegrit√†.\n\n\n\n\nüìÑ Output da produrre:\n\nSezione g‚Äìi del documento requisiti + completamento documento requisiti.\n\n\nüîπ SETTIMANA 4 ‚Äì Diagramma E-R (schema scheletro e raffinamento, Fase 2.2)\n‚úÖ Obiettivi:\n\n\nDisegnare:\n\n\nSchema scheletro.\n\n\nPrimo livello di raffinamento.\n\n\nVersione non ristrutturata.\n\n\n\n\nüìÑ Output da produrre:\n\nDiagramma E-R in PDF (da draw.io, dbdiagram.io, Lucidchart‚Ä¶).\n\n\nüîπ SETTIMANA 5 ‚Äì Ristrutturazione schema E-R e inizio progettazione logica (Fase 3.1)\n‚úÖ Obiettivi:\n\n\nFinalizzare lo schema E-R ristrutturato.\n\n\nRistrutturare:\n\n\nEliminare ridondanze.\n\n\nEliminare generalizzazioni.\n\n\nAccorpare entit√†/relazioni.\n\n\nDefinire identificatori.\n\n\n\n\nüìÑ Output da produrre:\n\nE-R finale + nota testuale sulle modifiche/ristrutturazioni fatte.\n\n\nüîπ SETTIMANA 6 ‚Äì Schema logico e relazionale + forme normali (Fase 3.1c-d)\n‚úÖ Obiettivi:\n\n\nScrivere:\n\n\nSchema logico (con descrizione entit√† e chiavi).\n\n\nSchema relazionale.\n\n\nAnalisi delle forme normali fino alla 3NF.\n\n\n\n\nüìÑ Output da produrre:\n\nDocumento schema relazionale e normalizzazione.\n\n\nüîπ SETTIMANA 7 ‚Äì Implementazione SQL (Fase 3.2)\n‚úÖ Obiettivi:\n\n\nScrivere:\n\n\nScript SQL per CREATE TABLE.\n\n\nDati di esempio con INSERT INTO.\n\n\nCREATE VIEW per ogni classe di utenza.\n\n\n15 query SQL (JOIN, GROUP BY, subquery‚Ä¶).\n\n\n2 query per persona tradotte in algebra o calcolo relazionale.\n\n\n\n\nüìÑ Output da produrre:\n\nFile .sql completo con: creazione tabelle, inserimenti, viste e query.\n\n\nüîπ SETTIMANA 8 ‚Äì Revisione finale e invio\n‚úÖ Obiettivi:\n\n\nRivedere tutta la documentazione.\n\n\nUnire:\n\n\nDocumento requisiti.\n\n\nDiagrammi E-R.\n\n\nSchema relazionale.\n\n\nScript SQL.\n\n\nTraduzioni algebra/calcolo.\n\n\n\n\nInviare il tutto al docente.\n\n\nüìÑ Output da produrre:\n\nPacchetto finale pronto per la consegna (PDF + SQL).\n\n\nüì¶ Materiali finali da consegnare (riassunto)\n\n\nDocumento requisiti (.docx o PDF).\n\n\nDiagramma E-R (PDF o PNG).\n\n\nSchema relazionale e normalizzazione (.docx o PDF).\n\n\nScript SQL (tabelle, viste, dati, query).\n\n\nTraduzione algebra/calcolo di 2 query per persona.\n\n"},"UNI/ANNO-2/BASE-DI-DATI/BASI-DI-DATI-INDICE":{"slug":"UNI/ANNO-2/BASE-DI-DATI/BASI-DI-DATI-INDICE","filePath":"UNI/ANNO 2/BASE DI DATI/BASI DI DATI INDICE.md","title":"BASI DI DATI INDICE","links":["UNI/ANNO-2/BASE-DI-DATI/BASI-LEZ.1","UNI/ANNO-2/BASE-DI-DATI/BASI-LEZ.2","UNI/ANNO-2/BASE-DI-DATI/BASI-LEZ.3","UNI/ANNO-2/BASE-DI-DATI/BASI-LEZ.4","UNI/ANNO-2/BASE-DI-DATI/BASI-LEZ.5","ciao/content/UNI/ANNO-2/BASE-DI-DATI/fotobasi/BASI-LEZ.6","UNI/ANNO-2/BASE-DI-DATI/1.riassunto_mysql_sql_ddl_dml_numerato-1"],"tags":[],"content":"BASI LEZ.1\nBASI LEZ.2\nBASI LEZ.3\nBASI LEZ.4\nBASI LEZ.5\nBASI LEZ.6\n1.riassunto_mysql_sql_ddl_dml_numerato 1"},"UNI/ANNO-2/BASE-DI-DATI/BASI-GUIDA":{"slug":"UNI/ANNO-2/BASE-DI-DATI/BASI-GUIDA","filePath":"UNI/ANNO 2/BASE DI DATI/BASI GUIDA.md","title":"BASI GUIDA","links":[],"tags":[],"content":"Perfetto Rosario! Ho analizzato tutti gli esami che hai caricato. Ora ti preparo una lista completa e dettagliata di ci√≤ che devi studiare per superare l‚Äôesame di Basi di Dati e di Conoscenza, partendo da zero. Divider√≤ il tutto per macro-argomenti, includendo i concetti teorici, pratici e gli esercizi che ricorrono frequentemente. Pronto? Ecco cosa studiare:\n\nüß† 1. Modello Entit√†-Relazione (E-R)\nObiettivi:\n\n\nCapire come modellare una realt√† con entit√†, relazioni, attributi.\n\n\nCostruire schemi E-R a partire da specifiche testuali.\n\n\nEvitare ridondanze.\n\n\nCosa studiare:\n\n\nEntit√† forti e deboli, attributi semplici e composti, identificatori.\n\n\nRelazioni 1:1, 1:N, N:M e loro rappresentazione.\n\n\nGerarchie tra entit√† (specializzazione/generalizzazione).\n\n\nEsempi ricorrenti: Ricette, Auto Usate, Prenotazioni Esami, Visite Mediche, Libri in Biblioteca.\n\n\nüõ† Esercizi:\n\nCostruisci schemi E-R per: auto usate, visite mediche, database di ricette, prenotazioni esami, biblioteche, figure geometriche.\n\n\nüß± 2. Modello Relazionale\nObiettivi:\n\n\nDerivare lo schema relazionale da uno schema E-R.\n\n\nIdentificare chiavi primarie e straniere.\n\n\nRappresentare relazioni complesse con attributi.\n\n\nCosa studiare:\n\n\nCome trasformare entit√†, relazioni e gerarchie in tabelle.\n\n\nRappresentare molti-a-molti, uno-a-molti, gerarchie.\n\n\nRiconoscere dipendenze funzionali implicite.\n\n\nüõ† Esercizi:\n\nDeriva lo schema relazionale da tutti gli E-R dei compiti d‚Äôesame.\n\n\nüîç 3. Algebra Relazionale\nObiettivi:\n\n\nSaper manipolare insiemi di dati a livello teorico.\n\n\nScrivere query in algebra relazionale.\n\n\nCosa studiare:\n\n\nSelezione (œÉ), proiezione (œÄ), join, unione, differenza, ridenominazione, prodotto cartesiano.\n\n\nCombinare operatori per rispondere a query complesse.\n\n\nüõ† Esercizi:\n\n\nScrivi in algebra relazionale query come:\n\n\n‚Äútutti i piatti che contengono uova‚Äù\n\n\n‚Äúi libri di fisica nella macroarea di scienze‚Äù\n\n\n‚Äúi docenti dei vari corsi con i crediti‚Äù\n\n\n\n\n\nüíæ SQL (Structured Query Language)\nObiettivi:\n\n\nScrivere query SQL a partire da uno schema relazionale.\n\n\nEvitare select nidificate (spesso vietate).\n\n\nCosa studiare:\n\n\nSELECT, FROM, WHERE, GROUP BY, HAVING, JOIN\n\n\nCalcoli aggregati (COUNT, AVG, SUM, ecc.)\n\n\nOrdinamento, filtri, condizioni logiche.\n\n\nüõ† Esercizi:\n\n\nRicette: ingredienti, quantit√†, piatti vegan.\n\n\nAuto: proprietari precedenti, auto usate per CAP.\n\n\nEsami: studenti prenotati per appello, docenti.\n\n\nLibri: libri in prestito, libri per genere/macroarea.\n\n\n\nüìê Normalizzazione (1NF, 2NF, 3NF, BCNF)\nObiettivi:\n\n\nCapire cosa sono le anomalie nei dati.\n\n\nApplicare le forme normali e decomporre relazioni complesse.\n\n\nCosa studiare:\n\n\nDefinizione di 1NF, 2NF, 3NF, BCNF.\n\n\nDipendenze funzionali.\n\n\nDecomposizione senza perdita e con conservazione delle dipendenze.\n\n\nüõ† Esercizi:\n\n\nDecomposizioni come nei casi:\n\n\nAppelli con corsi, macroaree e media voti.\n\n\nProgetti/dipendenti/uffici.\n\n\nLibri/prestiti/utenti.\n\n\n\n\n\nüßÆ Concetti trasversali da padroneggiare\n\n\nTraduzione testo ‚Üí E-R ‚Üí Schema relazionale ‚Üí SQL/Algebra.\n\n\nRiconoscimento pattern ricorrenti: molti-a-molti, uso di join, attributi di relazione.\n\n\nGestione vincoli (es. massimo 5 libri in prestito, docente pu√≤ insegnare max 2 corsi).\n\n\n\nüìö Materiale consigliato\n\n\nLibro consigliato (se lo hai, fammi sapere il titolo).\n\n\nSlides/dispense del corso.\n\n\nEsercitazioni passate (quelle che hai caricato vanno benissimo).\n\n\n\nSe vuoi posso trasformare questa guida in un PDF o checklist, oppure aiutarti a costruire un piano di studio con tempi e priorit√†. Fammi sapere!"},"UNI/ANNO-2/BASE-DI-DATI/BASI-LEZ.1":{"slug":"UNI/ANNO-2/BASE-DI-DATI/BASI-LEZ.1","filePath":"UNI/ANNO 2/BASE DI DATI/BASI LEZ.1.md","title":"BASI LEZ.1","links":[],"tags":[],"content":"Principi sulla Base di dati\n\nmetodi di accesso facilitati\nintegrazione\nlocalizzazione\npersistenza\ncondivisione\naffidabilit√†\nprivatezza\nriutilizzo in applicazioni\n\nRuolo del Database Managment System\n√à un ambiente che produce base di dati e consente la gestione delle risorse l‚Äôaccesso ecc‚Ä¶\nStrutturazione dei dati\nIl mondo che ci circonda √® astratto e vario quindi dobbiamo avere dei sistemi di progettazione per generalizzare e strutturare i dati.\nmodello di dati\nUn modello di dati √® un sistema rappresentativo di dati attraverso una struttura\ncome alberi grafi ecc‚Ä¶\nUn modello applicato alle base di dati √® lo schema entit√†/relazionale e un modello relazionale"},"UNI/ANNO-2/BASE-DI-DATI/BASI-LEZ.2":{"slug":"UNI/ANNO-2/BASE-DI-DATI/BASI-LEZ.2","filePath":"UNI/ANNO 2/BASE DI DATI/BASI LEZ.2.md","title":"BASI LEZ.2","links":[],"tags":[],"content":"Differenza tra Dato e Informazione\nDato: in informatica e una singola informazione codificabile, come un bit\nInformazione: notizia, dato o elemento che consente di avere conoscenza su fatti o situazioni\nUna informazione sono un insieme di dati collegati ad esempio da una loro logica\nDefinizione di sistema informativo\nComponente di una organizzazione che gestisce le informazioni\nUn sistema informativo va studiato in base al contesto in cui esso e inserito\nDatabase\ne una collezione di dati all‚Äôinterno di un sistema informativo\n\nha il compito non solo di memorizzarli ma anche di rappresentarli con le corrette relazioni\n\nDBMS(Database Management System)\nIl nome del software dato per gestire i dati del Database con collezioni di dati che siano(non per forza):\n\nGrandi\nPersistenti nel tempo\ncondivisi tra pi√π utenti\n\nriducendo\n\nridondanza dei dati\ninconsistenza dei dati\nUn DBMS deve in particolare garantire\n\n\n\n\naffidabilit√†, evitare errori\nprivatezza dei dati\nefficienza e quindi un sistema efficace\n\nAlcuni esempi di DBMS\nüìç DB2\nüìç Oracle\nüìç SQLServer\nüìç Postgres\nüìç MySQL\nüìç SQLite\nData Independence\n√à alla base del concetto di gestione dei database\n\nconcetto che i dati hanno una loro indipendenza logica\nse cambio sistema o computer posso comunque usare i dati\n\nArchiviazione dei file\nApproccio senza DBMS\nDi solito un comune programma senza uso di database salva le informazioni e i dati all‚Äôinterno del file system\nOgni file e composto da record all‚Äôinterno di questi record abbiamo memorizzati i vari dati elementari come\n\nattributi\ncampi\npi√π programmi possono condividere gli stessi file attraverso file condivisi\nI file possono avere diversi formati che sono incompatibili e quindi li rendono pi√π difficili da condividere su diversi programmi\n\n\nApproccio con DBMS\nIl DBMS fa da intermediario in modo indipendente dalle applicazioni che vengono usate\nesso offre una interfaccia che saranno le applicazioni a dover usare e a cui si dovranno adattare\nGrazie a questo approccio riusciamo a ridurre i tempi di progettazione e si semplifica e standardizza\n"},"UNI/ANNO-2/BASE-DI-DATI/BASI-LEZ.3":{"slug":"UNI/ANNO-2/BASE-DI-DATI/BASI-LEZ.3","filePath":"UNI/ANNO 2/BASE DI DATI/BASI LEZ.3.md","title":"BASI LEZ.3","links":[],"tags":[],"content":"DBMS vs File System\nil DBMS non √® l‚Äôunico modo efficiente per gestire un insieme di dati bens√¨ ne esistono molti e dipendono dall‚Äôutilizzo che ne vogliamo fare\nun esempio sono i File System\nI DBMS non sono usati per un solo scopo ma per scopi diversi e presenta un dizionario con la descrizione dei vari dati centralizzata\nModello di dati\nUn modello di dati √® un insieme di regole e costrutti e viene usato per creare schemi per i database con descrizioni dei dati, i loro vincoli ecc‚Ä¶\ncostituito pi√π precisamente definito anche da Ullman da:\n\ncostrutti sintattici per definire i dati\nregole semantiche per interpretare i dati\nlinguaggi per manipolare i dati\n\nConosceremo due tipi di modelli\nLogico\nHa lo scopo di descrivere il modo in cui i dati sono organizzati nel DBMS in un modo che sia visibile all‚Äôutente si divide a sua volta in diversi tipi\n\nGerarchico e reticolare\n\nutilizzato in modo esplicito per puntatori e record\n\n\nModello ad oggetti\n\nl‚Äôinformazione √® sottoforma di oggetti\nmercato di nicchia\n\n\nRelazionale\n\ni riferimenti che ci sono tra i dati in strutture differenti sono rappresentate con dei valori, questi riferimenti vengono detti relazioni\ndescrivono i concetti nel mondo reale\n\n\n\nConcettuale\nUn modello definito √® lo schema E-R e il modello classi associazioni UML\n\nSchemi e istanze\nin ogni base di dati esistono schemi e istanze\nSchema\n\ndescrive la struttura del database non varia troppo nel tempo\n\nle intestazioni ad esempio\n\n\n\n\nIstanza\n\nI valori stessi che variano molto nel tempo\n\nad esempio il corpo di ciascuna tabella\n\n\n\n\nArchitettura standard di un DBMS\n√à a tre livelli\n\n\nschema logico\n\ndescrizione della base di dati nel modello logico del DBMS\n\n\nschema fisico\n\nrappresentazione dello schema logico per mezzo di strutture di memorizzazione\n\ntipo memorizzazione dei byte con un vettore ecc‚Ä¶\n\n\n\n\nschema esterno\n\ndescrizione di parte della base di dati in un modello logico\n\nschema costituito da ad esempio una funzione\nf(i) = \\sum_{j=1}^{m} a_{i,j}\nvista personalizzata su dati\n\n\n\n\n\nIndipendenza fisica\nlogica\nPer fare operazioni su dati abbiamo il  DML\n\nData Manipulation Language\nAttraverso Query Language\nEsempio di DML con una determinata istanza\nSeleziona i campi docenti dalla tabella orario che abbiano solo aula=N1\n\nSELECT docente\nFROM orario\nWHERE aula = &#039;N1&#039;;\nPer fare operazioni su schemi abbiamo DDL\n\nData Definition Language\nEsempio di DDL con una creazione di una tabella\n\nCREATE table orario(\n\tinsegnamento char(20);\n\tdocente char(20);\n\taula char(4);\n\tora char(5);\n\t)\nDiversi tipi di linguaggi in un DBMS\n\nLinguaggi testuali interattivi come SQL\ncomandi immersi in un linguaggio ospite come Java C Spark etc‚Ä¶\ncomandi immersi in un linguaggio ad hoc con altre funzionalita\ninterfacce amichevoli senza codici\n\nEsempio di Query che generano tabelle\nSELECT corso,aula,piano\nFROM aule,corsi\nWHERE Aula=&#039;N3&#039;\nAND piano=&#039;Terra&#039;;\nTransazioni\nProprieta acide\n\nle vedremo nelle prossime lezioni\nTransazioni insieme di piccole transazioni che devo fare tutte\ncome il prelievo dal conto corrente che fa transazioni che tolgono soldi mettono ecc‚Ä¶\n"},"UNI/ANNO-2/BASE-DI-DATI/BASI-LEZ.4":{"slug":"UNI/ANNO-2/BASE-DI-DATI/BASI-LEZ.4","filePath":"UNI/ANNO 2/BASE DI DATI/BASI LEZ.4.md","title":"BASI LEZ.4","links":[],"tags":[],"content":"Modello Relazionale\nVenne introdotto per favorire l‚Äôindipendenza dei dati\nQuesto modello si basa su un concetto matematico di relazione, ogni relazione √® di tipo naturale con una rappresentazione su tabelle\nConcetto di relazione\nD_1...D_n sono insiemi di domini\nad esempio\n\nstringhe\ndate\ninteri\ntutti i numeri dal 18 al 21‚Ä¶\nIl prodotto cartesiano √® definito come tutte le n-uple (d1,‚Ä¶dn)\ntali che ciascun elemento d1\\in D1, d2 \\in D2 ‚Ä¶ dn \\in Dn\nper cui una relazione su una serie di questi domini √® un sottoinsieme dei vari prodotti cartesiani\n\n?=sottoinsieme\n\nPropriet√† dell‚Äôinsieme\nuna relazione √® un insieme; quindi:\n\nnon c‚Äô√® ordinamento fra le n-uple;\nle n-uple sono distinte\nciascuna n-upla √® ordinata: l‚Äô i-esimo valore proviene dall‚Äô i-esimo dominio\n\nEsempio pratico\n\nPrecisazione sulla funzione\nuna relazione √® una collezione di n-uple dove una n-upla √® una associazione tra un attributo e un dominio corrispondente\nEsempio pratico 2\nRappresentazione di una relazione tramite tabella\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNomeCognomeMatricolaVoto medioMarioRossi124LuigiBianchi228RosaRossa326\nSe ùë° √® una tupla su ùëø e A √® un attributo, con A ‚àà X allora t[A] indica il valore di t su A.\nEsempio: se t √® la prima tupla allora‚Ä¶\nt[Cognome] -&gt; \\ ‚Äô Rossi‚Äô\nci dar√†\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNomeCognomeMatricolaVoto medioMarioRossi124LuigiBianchi228RosaRossa326\nRegole su tabelle e relazioni\nUna tabella rappresenta una relazione se\n\ni valori di ogni colonna sono fra loro omogenei\nle righe sono diverse fra loro\nle intestazioni delle colonne sono diverse tra loro\nIn una tabella che rappresenta una relazione\nl‚Äôordinamento tra le righe √® irrilevante\nl‚Äôordinamento tra le colonne √® irrilevante\n\nEsempi e Disempi\n\nRiferimenti\ni riferimenti su relazioni diverse (tabelle) avvengono tramite valori che hanno lo scopo di creare dei riferimenti\nstudenti\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMatricolaCognomeNomeData di nascita6554RossiMario05/12/19788765NeriPaolo03/11/19769283VerdiLuisa12/11/19793456RossiMaria01/02/1978\nesami\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStudenteVotoCorso34563004345624029283280165542601\ncorsi\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCodiceTitoloDocente01AnalisiMario02ChimicaBruni04ChimicaVerdiDELLE TABELLE COS√¨ AVRANNO UNA RELAZIONE COS√¨ ‚Üí\n\nVantaggi ecc(riscrivi meglio dopo)\n\nindipendenza dalle strutture fisiche (si potrebbe avere anche con puntatori di alto livello) che possono cambiare dinamicamente\nsi rappresenta solo ci√≤ che √® rilevante dal punto di vista dell‚Äôapplicazione\nl‚Äôutente finale vede gli stessi dati dei programmatori\ni dati sono portabili pi√π facilmente da un sistema ad un altro\ni puntatori sono direzionali\n\nDefinizioni varie\nSchema di relazione\nviene detto con il nome R con un insieme di attributi come A1‚Ä¶An\nR(A1‚Ä¶An)\nSchema di base di dati\ninsieme di schemi di relazione\nR=(R1(X1)‚Ä¶Rk(Xk))\nESEMPIO\n\nSchema di relazione\nSTUDENTI(Matricola, Cognome, Nome, Data di Nascita)\nSchema di basi di dati\nSTUDENTI(Matricola, Cognome, Nome, Data di Nascita)\nESAMI(Matricola, Voto, Corso)\nCORSO(Codice, Titolo, Docente)\n\n\nQui abbiamo uno schema R(X) che rappresenta la singola tabella mentre invece r di ennuple su X indica i veri e propri dati al suo interno\nper quanto riguarda l‚Äôistanza su uno schema R delle base di dati indica l‚Äôinsieme delle varie tabelle\n\nIstanza celestino invece schema la cosa verde\nStrutture nidificate\nVoglio rappresentare uno scontrino di questo tipo, possiamo vedere che sono nidificate perch√© abbiamo una tabella in un‚Äôaltra\n\nPer farlo creo delle tabelle di questo tipo con delle relazioni\n\nStruttura rigida conseguenze\nspesso possiamo avere informazioni incomplete dovute alla rigidezza del DBMS\nVari esempi\n\nSe l‚Äôinformazione √® incompleta non conviene mettere ad esempio 0\nnelle base di dati viene usato NULL per indicare un valore non presente o mancante"},"UNI/ANNO-2/BASE-DI-DATI/BASI-LEZ.5":{"slug":"UNI/ANNO-2/BASE-DI-DATI/BASI-LEZ.5","filePath":"UNI/ANNO 2/BASE DI DATI/BASI LEZ.5.md","title":"BASI LEZ.5","links":[],"tags":[],"content":"I vincoli d‚Äôintegrit√† sono regole che una base di dati deve rispettare per garantire la correttezza e la coerenza delle informazioni. Esistono basi di dati che, pur essendo sintatticamente corrette, contengono informazioni non valide per l‚Äôapplicazione.\n\nI vincoli servono proprio a evitare questi casi, assicurando che i dati riflettano la realt√† del sistema che rappresentano.\nI vincoli sono quindi delle funzioni booleane che associano ad ogni istanza un valore vero o falso.\nTipologie di vincoli\nI vincoli si distinguono in:\n\nVincoli intrarelazionali, che riguardano singole relazioni:\n\nVincoli di dominio: limitano i valori ammessi per un attributo (es. un voto deve essere compreso tra 18 e 30).\nVincoli di ennupla: stabiliscono condizioni sui valori degli attributi all‚Äôinterno di una singola ennupla (sono indipendenti dalle altre ennuple).\n\n\nVincoli interrelazionali, che regolano le relazioni tra diverse tabelle:\n\nVincoli di integrit√† referenziale: impongono che i valori di un attributo in una tabella siano presenti come chiave primaria in un‚Äôaltra.\n\n\n\nVincoli di ennupla\nI vincoli di ennupla garantiscono che i dati all‚Äôinterno di una riga siano logicamente coerenti tra loro.\nUn esempio √® quello di una tabella di stipendi, dove il valore lordo deve essere sempre la somma di netto e ritenute.\n\nChiavi e schemi di relazione\nLe chiavi servono a identificare univocamente ogni riga (o ennupla) di una tabella.\nSenza le chiavi, potremmo avere dati duplicati e perdere la possibilit√† di distinguere in modo chiaro un‚Äôentit√† da un‚Äôaltra.\nEsistono diverse tipologie di chiavi:\n\nSuperchiave: un insieme di attributi che distingue univocamente ogni ennupla.\nChiave primaria: una superchiave scelta per identificare le righe, su cui non sono ammessi valori nulli.\nChiavi alternative: altre superchiavi possibili ma non scelte come chiave primaria\n\nLa chiave in questo caso √® TUTTA {Cognome, Nome, Nascita} perch√©:\n\nRossi, Mario, 5/12/78 compare solo una volta. ‚úÖ\nRossi, Mario, 3/11/76 compare solo una volta. ‚úÖ\nNeri, Piero, 10/7/79 compare solo una volta. ‚úÖ\nNeri, Mario, 3/11/76 compare solo una volta. ‚úÖ\nRossi, Piero, 5/12/78 compare solo una volta. ‚úÖ\nSe vedi io ho scelto una chiave per cui tutte le RIGHE sono diverse TRA LORO.\n\n\n\nAd esempio, considera una tabella Studenti:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMatricolaNomeCognomeData di Nascita12345MarioRossi01-02-200012346LucaBianchi03-04-200112345MarioNeri01-02-2000\n\n{Matricola} √® una superchiave perch√© identifica ogni studente, ed √® minimale perch√© nell‚Äôinsieme c‚Äô√® solo un elemento.\n{Matricola, Cognome} √® anch‚Äôessa una superchiave, ma include un attributo ridondante (basta la Matricola da sola).\n\nVincoli, schemi e istanze\nUn database rappresenta una parte del mondo reale e deve rispettare alcune regole per essere considerato corretto.\n\nVincoli: regole che assicurano la validit√† dei dati.\nSchema: struttura del database con le sue tabelle e relazioni.\nIstanza: un insieme di dati che devono rispettare i vincoli dello schema.\nUn‚Äôistanza √® considerata valida se soddisfa i vincoli, anche se pu√≤ rispettare accidentalmente altri vincoli ‚Äúper caso‚Äù.\nes. magari impongo come vincolo solo la matricola, ma a culo anche il cognome pu√≤ essere usato (quindi ‚Äúper caso‚Äù).\n\n\nUna relazione (tabella) non pu√≤ avere due righe uguali, quindi deve sempre esistere almeno una chiave per distinguerle.\nSi prediligono sempre superchiavi ‚Äúminimali‚Äù\nChiavi e valori nulli\nLa presenza di valori nulli in una chiave crea problemi, perch√© impedisce di identificare univocamente una riga e di realizzare riferimenti da altre tabelle.\nPer questo motivo, nelle chiavi primarie non sono ammessi valori nulli.\nVincoli di integrit√† referenziale\nI dati tra tabelle diverse devono essere coerenti.\nPer esempio, una tabella delle infrazioni stradali deve contenere solo codici di vigili presenti nella tabella dei vigili.\n\nSe un valore della colonna ‚ÄúVigile‚Äù non trova corrispondenza nella tabella ‚ÄúVigili‚Äù, si ha una violazione del vincolo di integrit√† referenziale.\n\nOppure stessa cosa con provincia e numero.\nQuindi, un vincolo di integrit√† referenziale fra gli attributi X di una relazione R1 e un‚Äôaltra relazione R2 impone ai valori su X in R1 di comparire come valori della chiave primaria di R2.\nVIOLAZIONE\n\nGestione delle violazioni dei vincoli referenziali\nQuando un‚Äôoperazione minaccia l‚Äôintegrit√† referenziale, il sistema pu√≤ adottare diverse strategie:\n\nRifiutare l‚Äôoperazione, bloccando la modifica.\nEliminazione in cascata, rimuovendo tutti i dati correlati.\n\nIntroduzione di valori nulli, per mantenere il riferimento senza violare il vincolo.\nCos√¨ non devo eliminare TUTTA la riga nelle varie tabelle ma posso far s√¨ che dalla tabella principale non posso accedere a quella secondaria.\n\nQuesti meccanismi garantiscono che il database rimanga coerente anche in presenza di operazioni di aggiornamento o eliminazione."},"UNI/ANNO-2/BASE-DI-DATI/BASI-LEZ.6":{"slug":"UNI/ANNO-2/BASE-DI-DATI/BASI-LEZ.6","filePath":"UNI/ANNO 2/BASE DI DATI/BASI LEZ.6.md","title":"BASI LEZ.6","links":[],"tags":[],"content":"üß† Cos‚Äô√® un Modello di Dati?\nQuando ci troviamo a progettare un database, dobbiamo innanzitutto chiederci: come rappresentare la realt√† con i dati? Per farlo, ci serviamo di un modello dei dati, ovvero un insieme di regole e strumenti che ci permettono di organizzare le informazioni, definirne la struttura, e capire come interagiscono tra loro.\nUn modello di dati √® un po‚Äô come una mappa: non rappresenta tutto nei minimi dettagli, ma fornisce una visione chiara dei concetti fondamentali e delle loro connessioni.\nüß± Esempio\nPensa al gestionale di una palestra. I dati che vuoi rappresentare sono: iscritti, abbonamenti, corsi, allenatori, prenotazioni. Il modello di dati ti aiuter√† a organizzare tutto ci√≤ in modo logico e coerente, evitando confusione e ridondanza.\nüîç Tipi di Modelli\nI modelli si dividono in due grandi categorie:\n1. Modelli Logici\nSono quelli usati nei DBMS, i software che gestiscono i database (come MySQL, PostgreSQL, Oracle‚Ä¶). Descrivono come sono organizzati i dati nel sistema informatico.\nEsempi di modelli logici:\n\n\nRelazionale (il pi√π comune): i dati sono organizzati in tabelle.\n\n\nGerarchico: struttura ad albero.\n\n\nReticolare: struttura a grafo.\n\n\nA oggetti: simile alla programmazione a oggetti.\n\n\n2. Modelli Concettuali\nSono pi√π astratti: servono per rappresentare la realt√† senza preoccuparsi di come sar√† implementata. Sono ideali per la fase di analisi e progettazione.\nIl pi√π noto √® il modello Entit√†-Relazione (ER), che descrive:\n\n\nQuali sono gli oggetti rilevanti (entit√†)\n\n\nCome sono collegati (relazioni)\n\n\nQuali informazioni portano (attributi)\n\n\nModelli moderni:\n\nModello ER Esteso (EER): include costrutti avanzati come l‚Äôereditariet√†.¬†\nUML (Unified Modeling Language): un linguaggio standardizzato per la progettazione dei dati;¬†\nModello concettuale¬†‚Üí dati e relazioni attraverso uno schema;¬†\nModello logico¬†‚Üí descrive il modo attraverso il quale i dati sono organizzati negli archivi del calcolatore;¬†\nModello fisico¬†‚Üí descrive come i dati sono registrati nelle memorie di massa.\n\nCome passare da un modello all‚Äôaltro\n\nLa progettazione di un database avviene in 3 fasi, che rappresentano livelli crescenti di dettaglio:\n\nProgettazione Concettuale\n\nCosa vogliamo rappresentare?\nQuali sono gli oggetti? Come si collegano tra loro?\nEsempio: Studente, Esame, Corso.\n\n\nProgettazione Logica\n\nCome trasformare quei concetti in strutture logiche?\nSi usano tabelle, chiavi primarie, tipi di dato.\n\n\nProgettazione Fisica\n\nDove e come salvare i dati su disco?\nOttimizzazione della memorizzazione, prestazioni, indici.\n\n\n\nüìê Il Modello Entit√†-Relazione (ER)\n√à un modello concettuale che ci aiuta a rappresentare una realt√† attraverso:\n\nEntit√†\nRelazioni\nAttributi\nCardinalit√†\nChiavi\n\n√à molto usato perch√© separa l‚Äôanalisi logica dalla tecnologia, permettendo di lavorare sulla struttura prima di pensare al database vero e proprio.\n\nüì¶ ENTIT√Ä: cosa sono?\nUn‚Äôentit√† √® un oggetto, concreto o astratto, che ha significato proprio e rilevanza nel contesto che si sta studiando.Sono l‚Äôastrazione di quello che poi diventer√† una tabella\nüßæ Esempi:\n\nIn una scuola: Studente, Corso, Docente\nIn un e-commerce: Cliente, Ordine, Prodotto\nIn una banca: Conto, Cliente, Movimento\n\nOgni entit√† √® rappresentata da un tipo entit√† (es. Studente) e da istanze (es. Mario Rossi).\n\nüîó RELAZIONI: come si collegano le entit√†?\nUna relazione (o relationship) rappresenta un legame logico tra due o pi√π entit√†.\nüßæ Esempio:\nNel contesto universitario:\n\nStudente partecipa alla relazione Sostenere con Esame.\nOppure in un autosalone:\nPersona e Automobile sono collegate dalla relazione Possiede.\n\nUna persona pu√≤ possedere pi√π auto.\nOgni auto √® posseduta da una persona.\n\nLe relazioni possono anche:\n\n\nEssere unidirezionali (si rappresenta un solo verso)\nEssere ricorsive: un‚Äôentit√† si collega con s√© stessa.\nad esempio manager √® una istanza dell‚Äôentit√† dipendente e pu√≤ avere una relazione con un‚Äôaltra istanza\n\nCoinvolgere pi√π di due entit√† (relazioni ternarie o pi√π).\n\n\n\nüìé ATTRIBUTI: cosa descrive un‚Äôentit√† o relazione?\nGli attributi sono informazioni specifiche associate a un‚Äôentit√† o a una relazione. Servono a descriverne le caratteristiche.\nüßæ Esempio:\nPer l‚Äôentit√† Automobile, possiamo avere:\n\nnumero_telaio (univoco)\nmodello\nproduttore\ncilindrata\nprezzo\n\n\nin questo caso abbiamo studente che ha cognome+nome con chiave primaria\nAttributi nelle relazioni\n\nNella relazione tu hai gli attributi che riguardano la singola azione\n\nPROPRIET√Ä DEL MODELLO RELAZIONALE¬†\n\nOgni entit√† deve avere una¬†chiave primaria.¬†\nLa¬†chiave primaria¬†√® un attributo speciale che¬†identifica in modo univoco ogni istanza dell‚Äôentit√†.¬†\n\nLa chiave primaria non pu√≤ avere valori ripetuti;¬†\n\n\n\nDOMINIO di un attributo¬†\nIl¬†dominio¬†definisce quali valori un attributo pu√≤ assumere.¬†\nCaratteristiche del dominio:¬†\n\nTipo di dato¬†‚Üí (numero, testo, data, ecc.).¬†\nLunghezza¬†‚Üí Quanti caratteri o cifre pu√≤ contenere.¬†\nIntervallo¬†‚Üí Quali valori sono accettabili.¬†\nVincoli¬†‚Üí Regole aggiuntive sui valori (es. ‚Äúdeve essere maggiore di zero‚Äù).¬†\nSupporto del valore NULL¬†‚Üí Se l‚Äôattributo pu√≤ essere lasciato vuoto o meno.¬†\nValore di default¬†‚Üí Valore che viene assegnato automaticamente se non specificato.¬†\n\nPropriet√† delle Chiavi Primarie e Chiavi Esterne¬†\nChiave primaria:¬†\n\nDeve essere¬†univoca¬†‚Üí Non si possono avere due record con lo stesso valore.¬†\nI valori NULL non sono ammessi¬†‚Üí Ogni record deve avere una chiave primaria.¬†\n\nChiave esterna:¬†\n\nCollega una tabella a un‚Äôaltra (ma questo lo vedrai pi√π avanti).¬†\nDeve avere lo stesso¬†tipo di dato, lunghezza e formato¬†della chiave primaria a cui si riferisce.¬†\n\nEsempio del vigile della scorsa lezione, una chiave che fa riferimento a un‚Äôaltra chiave.¬†\n\n\n\nEntit√† forti ed entit√† deboli¬†\n\nEntit√† forti¬†‚Üí Hanno una¬†chiave primaria¬†e possono esistere¬†senza dipendere da altre entit√†.¬†\nEntit√† deboli¬†‚Üí¬†Non hanno una chiave primaria¬†e devono essere collegate a un‚Äôentit√† forte per avere senso.¬†\n\nMovimento non ha senso se sta da sola deve per forza dipendere da altro\nUn‚Äôentit√† debole¬†esiste solo¬†se esiste l‚Äôentit√† forte a cui √® collegata.\n\nüîê CHIAVI: come si identificano le entit√†?\nUna chiave primaria √® un attributo (o pi√π) che identifica univocamente ogni istanza dell‚Äôentit√†.\nüßæ Esempi:\n\nüîê CHIAVI ARTIFICIALI E IDENTIFICATORI PROGRESSIVI\nSpesso, anche quando abbiamo attributi che potrebbero identificare univocamente un‚Äôentit√† (come il numero di telaio di un‚Äôauto o il codice fiscale di una persona), si preferisce usare un identificatore numerico progressivo, detto chiave artificiale.\nQuesto per semplicit√†: √® pi√π efficiente, facile da ricordare e non cambia nel tempo.\nüßæ Esempio:\nInvece di usare numero_telaio, posso assegnare a ogni auto un ID auto-incrementante:\n\nAuto 1 ‚Üí ID = 1\nAuto 2 ‚Üí ID = 2\nAnche se le due auto hanno modelli e targhe diverse, le identifico tramite un intero semplice.\n\n\nüìè PROPRIET√Ä DELLE CHIAVI\nLe chiavi primarie devono seguire delle regole:\n\nNon possono essere vuote (no NULL)\nDevono essere univoche\nOgni entit√† deve avere una chiave primaria\n\nPer le chiavi esterne (cio√® attributi che collegano entit√† diverse), valgono alcune condizioni:\n\nDevono avere stesso tipo, lunghezza e formato della chiave primaria a cui si riferiscono.\n\n\nüßç‚Äç‚ôÇÔ∏è ENTIT√Ä FORTI E DEBOLI\nLe entit√† forti sono quelle che possono esistere da sole, mentre le entit√† deboli hanno senso solo in relazione a un‚Äôaltra entit√†.\nüßæ Esempio reale (banca):\n\nCliente ‚Üí entit√† forte: esiste a prescindere.\nConto ‚Üí anch‚Äôessa forte: identificata da num_conto.\nMovimento ‚Üí entit√† debole: un versamento o un prelievo ha senso solo se associato a un conto.\n\nSpesso si pu√≤ trasformare un‚Äôentit√† debole in forte aggiungendo un ID numerico progressivo.\n\n\nüî¢ MOLTEPLICIT√Ä E CARDINALIT√Ä\nLa molteplicit√† indica quanti elementi di un‚Äôentit√† possono essere collegati a un‚Äôaltra entit√† attraverso una relazione.\nNotazione:\n\n(1,1): obbligatorio e unico\n(0,N): facoltativo e multiplo\n(1,N): obbligatorio e multiplo\n(0,1): facoltativo e unico\nDa questa combinazione derivano tre tipi di relazioni:\n\n\nüîÅ RELAZIONI 1:1\nUn‚Äôistanza di una entit√† pu√≤ essere collegata al massimo a una dell‚Äôaltra, e viceversa.\nüßæ Esempio:\n\nüîÄ RELAZIONI 1:N\nUn‚Äôistanza di una entit√† pu√≤ essere collegata a pi√π istanze dell‚Äôaltra, ma non viceversa.\nüßæ Esempio:\n\n\nüîÅ RELAZIONI N:N\nUn‚Äôistanza pu√≤ essere collegata a pi√π istanze da entrambi i lati.\nüßæ Esempio:\n\n\nüß¨ EREDITARIET√Ä e RELAZIONE IS-A\nNel mondo reale, alcune entit√† sono sottoinsiemi di altre: sono pi√π specializzate.\nLa relazione IS-A (√® un) serve per rappresentare questo.\nüßæ Esempi:\n\n\nLa propriet√† √® transitiva: un FuoriCorso √® anche uno Studente e quindi una Persona."},"UNI/ANNO-2/BASE-DI-DATI/DATA-BASE":{"slug":"UNI/ANNO-2/BASE-DI-DATI/DATA-BASE","filePath":"UNI/ANNO 2/BASE DI DATI/DATA BASE.md","title":"DATA BASE","links":[],"tags":[],"content":"CREATE DATABASE progetto_basi;\nUSE progetto_basi;\ncreate table SEDE_AMA(\n    codice_sede INT AUTO_INCREMENT PRIMARY KEY,\n    indirizzo VARCHAR(100) NOT NULL,\n    cap SMALLINT NOT NULL\n);\ncreate table CLIENTE(\n    codice_fiscale VARCHAR(16) PRIMARY KEY,\n    nome VARCHAR(100) NOT NULL,\n    cognome VARCHAR(100) NOT NULL,\n    email VARCHAR(100) NOT NULL,\n    password VARCHAR(64) NOT NULL,\n    numero_telefono INT NOT NULL,\n    indirizzo VARCHAR(100),\n    cap SMALLINT,\n    token_spid VARCHAR(24),\n    data_nascita DATE NOT NULL\n);\n \ncreate table LISTA_CAP(\n    codice_sede INT,\n    CAP SMALLINT,\n    PRIMARY KEY(codice_sede, CAP),\n    FOREIGN KEY(codice_sede) REFERENCES SEDE_AMA(codice_sede)\n);\n \n \ncreate table LAVORATORE(\n    CID_lavoratore INT AUTO_INCREMENT PRIMARY KEY,\n    nome VARCHAR(100) NOT NULL,\n    cognome VARCHAR(100) NOT NULL,\n    email VARCHAR(100) NOT NULL,\n    password VARCHAR(64) NOT NULL,\n    data_nascita DATE NOT NULL,\n    ruolo ENUM(&#039;in_sede&#039;, &#039;corriere&#039;)\n);\n \ncreate table PRENOTAZIONE(\n    codice_prenotazione INT AUTO_INCREMENT PRIMARY KEY,\n    foto TEXT NOT NULL,\n    descrizione TEXT,\n    tipologia_servizio VARCHAR(100) NOT NULL,\n    data_prenotazione DATE NOT NULL,\n    orario_prenotazione TIME NOT NULL,\n    stato_prenotazione VARCHAR(100) NOT NULL,\n    costo_prenotazione DECIMAL(8,2) NOT NULL,\n    codice_fiscale VARCHAR(16) NOT NULL,\n    codice_sede INT NOT NULL,\n    CID_lavoratore INT NOT NULL,\n    FOREIGN KEY (codice_fiscale) REFERENCES CLIENTE(codice_fiscale),\n    FOREIGN KEY (codice_sede) REFERENCES SEDE_AMA(codice_sede),\n    FOREIGN KEY (CID_lavoratore) REFERENCES LAVORATORE(CID_lavoratore)\n);\n \ncreate table VALUTAZIONE(\n    codice_prenotazione INT PRIMARY KEY,\n    voto TINYINT NOT NULL,\n    CHECK (voto BETWEEN 1 AND 5),\n    commento VARCHAR(200),\n    FOREIGN KEY(codice_prenotazione) REFERENCES PRENOTAZIONE(codice_prenotazione)\n);\n \ncreate table VEICOLO(\n    targa VARCHAR(7) PRIMARY KEY,\n    tipologia VARCHAR(30),\n    CID_lavoratore INT,\n    carico_massimo DECIMAL(8,2),\n    stato ENUM (&#039;disponibile&#039;,&#039;occupato&#039;,&#039;manutenzione&#039;),\n    FOREIGN KEY (CID_lavoratore) REFERENCES LAVORATORE(CID_lavoratore)\n);\n \ncreate table TURNO(\n    id_turno INT AUTO_INCREMENT PRIMARY KEY,\n    data_turno DATE NOT NULL,\n    orario_inizio TIME NOT NULL,\n    orario_fine TIME NOT NULL,\n    pausa_inizio TIME NOT NULL,\n    pausa_fine TIME NOT NULL\n);\n \ncreate table TURNO_SETTIMANALE(\n    CID_lavoratore INT,\n    id_turno INT,\n    PRIMARY KEY(CID_lavoratore, id_turno),\n    FOREIGN KEY (CID_lavoratore) REFERENCES LAVORATORE(CID_lavoratore),\n    FOREIGN KEY (id_turno) REFERENCES TURNO(id_turno)\n);\n \ncreate table ORARIO(\n    id_orario INT AUTO_INCREMENT PRIMARY KEY,\n    orario_inizio TIME NOT NULL,\n    orario_fine TIME NOT NULL,\n    inizio_pausa TIME NOT NULL,\n    fine_pausa TIME NOT NULL,\n    data DATE NOT NULL\n);\n \ncreate table ORARIO_SETTIMANALE(\n    id_orario INT,\n    codice_sede INT,\n    PRIMARY KEY(id_orario,codice_sede),\n    FOREIGN KEY (id_orario) REFERENCES ORARIO(id_orario),\n    FOREIGN KEY (codice_sede) REFERENCES SEDE_AMA(codice_sede)\n);\nQuery\nINSERT INTO TURNO(data_turno, orario_inizio, orario_fine, pausa_inizio, pausa_fine)\nVALUES (&#039;2025-06-09&#039;, &#039;08:00&#039;, &#039;18:00&#039;, &#039;12:00&#039;, &#039;13:00&#039;),\n\t   (&#039;2025-06-10&#039;, &#039;08:30&#039;, &#039;17:30&#039;, &#039;12:00&#039;, &#039;13:00&#039;),\n       (&#039;2025-06-11&#039;, &#039;9:30&#039;, &#039;17:30&#039;, &#039;12:00&#039;, &#039;14:00&#039;);\n \n \nINSERT INTO SEDE_AMA(indirizzo,cap)\nVALUES(&#039;Via Calderon de la Barca‚ÄØ87&#039;,00142),\n      (&#039;Via del Verano‚ÄØ74&#039;,00185),\n      (&#039;Via Capo d‚ÄôAfrica‚ÄØ23B&#039;,00184);\n \n \nINSERT INTO CLIENTE\nVALUES (&#039;DSNFR1DVG810JDED&#039;, &#039;Paolo&#039;, &#039;Rossi&#039;, &#039;paolorossi@gmail.com&#039;, &#039;Paol.1456&#039;, 333567541, &#039;Via dei Corazzieri 110&#039;, 00143, &#039;A7X9F2KD3LQ8Z1MV5T6W4B0J&#039;, &#039;1998-09-06&#039;),         \n\t   (&#039;RSSMRA79P15H501T&#039;, &#039;Maria&#039;, &#039;Rossi&#039;, &#039;maria.rossi@example.com&#039;, &#039;Mari@2024&#039;, 328456789, &#039;Via Appia Nuova 200&#039;, 00179, &#039;L9X3C7DMT0WJ8ZQP5N2R6KAY&#039;, &#039;1979-03-15&#039;),\n\t   (&#039;BNCLGU88S10F205K&#039;, &#039;Luigi&#039;, &#039;Bianchi&#039;, &#039;luigi.bianchi@email.com&#039;, &#039;Luig#1988&#039;, 347112233, &#039;Viale Trastevere 50&#039;, 00153, &#039;Z4E1W8NRK6MP3TQX9V7JB2YD&#039;, &#039;1988-11-10&#039;),\n\t   (&#039;VRDGPP95L20C351U&#039;, &#039;Giuseppe&#039;, &#039;Verdi&#039;, &#039;giuseppe.verdi@demo.it&#039;, &#039;Gius$1995&#039;, 339998877, &#039;Piazza Bologna 10&#039;, 00162, &#039;Q2K7LPX43JM9AHYTF6WDEN8Z&#039;, &#039;1995-07-20&#039;);\n \n \nINSERT INTO LISTA_CAP (codice_sede, CAP)\nVALUES (1, 00142),\n       (1, 00143),\n       (2, 00185),\n       (3, 00184);\n \n \nINSERT INTO LAVORATORE (nome, cognome, email, password, data_nascita, ruolo) VALUES (&#039;Luca&#039;, &#039;Neri&#039;, &#039;luca.neri@ama.it&#039;, &#039;X8t9bP2q&#039;, &#039;1985-05-10&#039;, &#039;corriere&#039;), (&#039;Elena&#039;, &#039;Rizzo&#039;, &#039;elena.rizzo@ama.it&#039;, &#039;aD4r9T6z&#039;, &#039;1992-07-15&#039;, &#039;in_sede&#039;), (&#039;Marco&#039;, &#039;Gallo&#039;, &#039;marco.gallo@ama.it&#039;, &#039;P3kLm8vQ&#039;, &#039;1988-10-22&#039;, &#039;corriere&#039;);\n    \n \n   \nINSERT INTO PRENOTAZIONE (foto, descrizione, tipologia_servizio, data_prenotazione, orario_prenotazione, stato_prenotazione, costo_prenotazione, codice_fiscale, codice_sede, CID_lavoratore) \nVALUES (&#039;foto1.jpg&#039;, &#039;Divano a 3 posti&#039;, &#039;ritiro a domicilio&#039;, &#039;2025-06-12&#039;, &#039;09:00&#039;, &#039;attiva&#039;, 35.00, &#039;RSSMRA79P15H501T&#039;, 1, 1), \n       (&#039;foto2.jpg&#039;, &#039;Lavatrice vecchia&#039;, &#039;ritiro a domicilio&#039;, &#039;2025-06-13&#039;, &#039;10:00&#039;, &#039;completata&#039;, 40.00, &#039;BNCLGU88S10F205K&#039;, 2, 3), \n\t   (&#039;foto3.jpg&#039;, &#039;Materasso matrimoniale&#039;, &#039;consegna in sede&#039;, &#039;2025-06-14&#039;, &#039;11:00&#039;, &#039;attiva&#039;, 0.00, &#039;VRDGPP95L20C351U&#039;, 3, 2);\n \n \nINSERT INTO VEICOLO (targa, tipologia, CID_lavoratore, carico_massimo, stato)\nVALUES \n(&#039;AB123CD&#039;, &#039;Furgone&#039;, 1, 1200.50, &#039;disponibile&#039;),\n(&#039;EF456GH&#039;, &#039;Camioncino&#039;, 3, 1500.00, &#039;occupato&#039;),\n(&#039;IJ789KL&#039;, &#039;Furgone&#039;, NULL, 1100.75, &#039;manutenzione&#039;);\n \nINSERT INTO VALUTAZIONE (codice_prenotazione, voto, commento)\nVALUES \n(2, 5, &#039;Tutto perfetto&#039;);\n \nINSERT INTO TURNO_SETTIMANALE (CID_lavoratore, id_turno)\nVALUES \n(1, 1),\n(2, 2),\n(3, 3);\n \nINSERT INTO ORARIO(orario_inizio,orario_fine,inizio_pausa,fine_pausa,data)\nVALUES (&#039;08:00&#039;,&#039;18:00&#039;,&#039;12:00&#039;,&#039;13:00&#039;,&#039;2025-06-09&#039;),\n        (&#039;08:00&#039;,&#039;18:00&#039;,&#039;12:00&#039;,&#039;13:00&#039;,&#039;2025-06-10&#039;),\n        (&#039;08:00&#039;,&#039;18:00&#039;,&#039;12:00&#039;,&#039;13:00&#039;,&#039;2025-06-11&#039;);\n        \nINSERT INTO ORARIO_SETTIMANALE (id_orario, codice_sede)\nVALUES \n(1, 1),\n(2, 2),\n(3, 3);\n \nSELECT * FROM TURNO;\nSELECT * FROM CLIENTE;\nSELECT * FROM SEDE_AMA;\nINDICI\nCREATE INDEX idx_prenotazione_cliente ON PRENOTAZIONE(codice_fiscale);\nCREATE INDEX idx_prenotazione_lavoratore ON PRENOTAZIONE(CID_lavoratore);\nCREATE INDEX idx_prenotazione_sede ON PRENOTAZIONE(codice_sede);\n \nCREATE INDEX idx_cliente_email ON CLIENTE(email);\nCREATE INDEX idx_cliente_telefono ON CLIENTE(numero_telefono);\n \nCREATE INDEX idx_veicolo_stato ON VEICOLO(stato);\n \nCREATE INDEX idx_lavoratore_ruolo ON LAVORATORE(ruolo);\nIDEE VISTE\n\nVistaPrenotazioniClienti\n\nMostra tutte le prenotazioni effettuate con i dati anagrafici dei clienti (nome, cognome, email).\n\n\n\nCREATE VIEW VistaPrenotazioniClienti AS\nSELECT C.nome,C.cognome,C.email \nFROM\n PRENOTAZIONE P JOIN CLIENTE C ON P.codice_fiscale=C.codice_fiscale;\n\nVistaPrenotazioniCompletate\n\nElenco delle prenotazioni con stato ‚Äúcompletata‚Äù, includendo eventuali valutazioni.\n\n\n\nCREATE VIEW VistaPrenotazioniCompletate AS\n\tSELECT P.*, \n\t       V.voto,\n\t       V.commento\n\tFROM PRENOTAZIONE P \n\tLEFT JOIN VALUTAZIONE V ON P.codice_prenotazione = V.codice_prenotazione\n    WHERE P.stato_prenotazione = &#039;completata&#039;;\n\nVistaDisponibilitaVeicoli\n\nElenco dei veicoli attualmente disponibili, con informazioni sull‚Äôautista assegnato (se presente).\n\n\n\nCREATE VIEW VistaDisponibilitaVeicoli AS\n\tSELECT V.*,\n\t\t   L.nome,\n           L.cognome,\n           L.ruolo\n    FROM VEICOLO V \n    LEFT JOIN LAVORATORE L ON V.CID_lavoratore = L.CID_lavoratore\n    WHERE V.stato = &#039;disponibile&#039;;\n\nVistaOrariSede\n\nRaccoglie gli orari settimanali associati a ciascuna sede AMA, per facilitarne la consultazione.\n\n\n\nCREATE VIEW VistaOrariSede AS\n\tSELECT S.*,\n           O.*\n    FROM ORARIO_SETTIMANALE OS\n    JOIN SEDE_AMA S ON OS.codice_sede = S.codice_sede\n    JOIN ORARIO O ON OS.id_orario = O.id_orario;\n\nVistaTurniLavoratori\n\nMostra i turni assegnati a ciascun lavoratore, con date e fasce orarie.\n\n\n\nCREATE VIEW VistaTurniLavoratori AS\n\tSELECT L.*,\n           T.*\n    FROM TURNO_SETTIMANALE TS\n    JOIN LAVORATORE L ON L.CID_lavoratore = TS.CID_lavoratore\n    JOIN TURNO T ON T.id_turno = TS.id_turno;\n\nVistaClientiAttivi\n\nElenco dei clienti che hanno effettuato almeno una prenotazione negli ultimi 30 giorni.\n\n\n\nCREATE VIEW VistaClientiAttivi AS\n\tSELECT * \n\tFROM CLIENTE C \n\tJOIN PRENOTAZIONE P ON C.codice_fiscale = P.codice_fiscale\n    WHERE P.data_prenotazione &gt;= CURDATE() - INTERVAL 30 DAY; \n\nVistaPrenotazioniPerCAP\n\nRestituisce le quantit√† di prenotazioni suddivise per CAP dei clienti diversi, utile per analisi geografiche.\n\n\n\nCREATE VIEW VistaPrenotazioniPerCAP AS\n\tSELECT C.cap, COUNT(DISTINCT C.codice_fiscale) as conta_cap\n\tFROM CLIENTE C \n\tJOIN PRENOTAZIONE P ON C.codice_fiscale = P.codice_fiscale\n    GROUP BY C.cap;\n\nVistaValutazioniClienti\n\nMostra per ogni cliente le valutazioni lasciate, includendo commento e voto, ordinate per data.\n\n\n\nCREATE VIEW VistaValutazioniClienti AS\n\tSELECT C.nome,\n\t\t   P.data_prenotazione,\n\t\t   V.voto,\n\t\t   V.commento\n\tFROM CLIENTE C \n\tJOIN PRENOTAZIONE P ON C.codice_fiscale = P.codice_fiscale \n\tJOIN VALUTAZIONE V ON P.codice_prenotazione = V.codice_prenotazione\n    ORDER BY P.data_prenotazione DESC;\n\nVistaPrenotazioniLavoratore\n\nElenco di tutte le prenotazioni prese in carico da ciascun lavoratore, con info sul cliente e il tipo di servizio.\n\n\n\nCREATE VIEW VistaPrenotazioniLavoratore AS\n\tSELECT P.tipologia_servizio,\n\t\t   C.nome,\n\t\t   C.cognome,\n\t\t   C.numero_telefono,\n\t\t   L.nome,\n\t\t   L.cognome\n\tFROM PRENOTAZIONE P \n\tJOIN LAVORATORE L ON P.CID_lavoratore = L.CID_lavoratore \n\tJOIN CLIENTE C ON C.codice_fiscale=P.codice_fiscale\n\tORDER BY L.nome;\n\nVistaStatisticheSedi\n\nConta quante prenotazioni ha gestito ogni sede AMA, utile per report interni.\n\n\n\nCREATE VIEW VistaStatisticheSedi AS\n\tSELECT  P.codice_sede, COUNT(P.codice_sede) as numero_prenotazioni_per_sede\n\tFROM PRENOTAZIONE P\n\tGROUP BY P.codice_sede;\n\nVistaClientiSenzaPrenotazioni\n\nElenca i clienti registrati che non hanno mai effettuato una prenotazione.\n\n\n\nCREATE VIEW VistaClientiSenzaPrenotazioni AS\n\tSELECT C.nome,\n\t\t   C.cognome\n\tFROM CLIENTE C \n\tLEFT JOIN PRENOTAZIONE P ON C.codice_fiscale = P.codice_fiscale\n\tWHERE P.codice_prenotazione IS NULL;\n\nVistaVeicoliAssegnati\n\nRaccoglie tutti i veicoli con relativo lavoratore assegnato, filtrando solo quelli in uso o occupati.\n\n\n\nCREATE VIEW VistaVeicoliAssegnati AS\n\tSELECT V.targa,\n\t       V.stato,\n\t       L.nome\n\tFROM VEICOLO V \n\tJOIN LAVORATORE L ON V.cid_lavoratore = L.cid_lavoratore\n\tWHERE V.stato = &quot;occupato&quot; or V.stato = &quot;disponibile&quot;;\n\nVistaOrariCompletiPerSede\n\nCombina le informazioni sugli orari, le pause e le sedi in un‚Äôunica vista consultabile.\n\n\n\nCREATE VIEW VistaOrariCompletiPerSede AS\n\tSELECT O.orario_inizio,\n\t       O.orario_fine,\n\t       O.inizio_pausa,\n\t       O.fine_pausa,\n\t       S.codice_sede\n\tFROM SEDE_AMA S \n\tJOIN ORARIO_SETTIMANALE OS ON S.codice_sede = OS.codice_sede \n\tJOIN ORARIO O ON O.id_orario = OS.id_orario;\n\nVistaPrenotazioniConFoto\n\nRestituisce solo le prenotazioni che hanno foto associate, utile per verifiche operative.\n\n\n\nCREATE VIEW VistaPrenotazioniConFoto AS\n\tSELECT P.*\n\tFROM PRENOTAZIONE P\n\tWHERE P.foto IS NOT NULL;\n\n\nVistaPrenotazioniPerDataEOra\n\nMostra tutte le prenotazioni ordinate per data e orario, utile per pianificare gli interventi giornalieri.\n\n\n\nCREATE VIEW VistaPrenotazioniPerDataOra AS\n\tSELECT *\n\tFROM PRENOTAZIONE\n    ORDER BY data_prenotazione ,orario_prenotazione ;\n\nVistaPrenotazioniConCosto\n\nElenco delle prenotazioni che hanno un costo maggiore di zero, quindi solo quelle a pagamento.\n\n\n\nCREATE VIEW VistaPrenotrazioniConCosto AS\n    SELECT *\n    FROM PRENOTAZIONE\n    WHERE PRENOTAZIONE.costo_prenotazione &gt; 0;\n\nVistaLavoratoriCorrieriAttivi\n\nMostra solo i lavoratori con ruolo ‚Äúcorriere‚Äù che sono attualmente associati a veicoli.\n\n\n\nCREATE VIEW VistaCorrieriAttivi AS\n    SELECT *\n    FROM LAVORATORE AS L\n    WHERE L.ruolo = &quot;corriere&quot; AND EXISTS (\n\t    SELECT *\n\t    FROM VEICOLO AS V\n\t    WHERE L.CID_lavoratore = V.CID_lavoratore\n\t    );\n\nVistaClientiConValutazioniAlte\n\nRestituisce i clienti che hanno lasciato solo valutazioni pari o superiori a 4.\n\n\n\nCREATE VIEW VistaClientiConValutazioniAlte AS\n    \n\tSELECT *\n    \n\tFROM CLIENTE AS C\n    \n\tWHERE EXISTS (\n\t\t ¬† ¬† SELECT *\n\t\t¬† ¬† FROM VALUTAZIONE AS V\n\t\t¬† ¬† JOIN PRENOTAZIONE AS P ON P. codice_prenotazione = \n\t\t¬† ¬† V.codice_prenotazione\n\t\t¬† ¬† WHERE P.codice_fiscale = C.codice_fiscale AND V.voto &gt;= 4);\n\nVistaPrenotazioniConDettagliCompleti\n\nUnisce informazioni da pi√π tabelle (cliente, lavoratore, sede, veicolo) per ogni prenotazione.\n\n\n\nCREATE VIEW VistaPrenotazioniConDettagliCompleti AS\n    SELECT P.*, C.codice_fiscale AS codice_fiscale_cliente,\n    C.numero_telefono AS numero_telefono_cliente,\n    L.CID_lavoratore, L.email AS email_lavoratore, L.ruolo AS\n     ruolo_lavoratore,\n    V.targa AS targa_veicolo, V.tipologia AS tipologia_veicolo,\n    S.indirizzo AS indirizzo_sede\n    FROM PRENOTAZIONE P\n    JOIN CLIENTE C ON P.codice_fiscale = C.codice_fiscale\n    JOIN LAVORATORE L ON P.CID_lavoratore = L.CID_lavoratore\n    JOIN SEDE_AMA S ON P.codice_sede = S.codice_sede\n    JOIN VEICOLO V ON ¬† ¬† ¬† ¬†V.CID_lavoratore = L.CID_lavoratore;\n\nVistaSediConOrariDisponibili\n\nElenco delle sedi che hanno almeno un orario settimanale associato.\n\n\n\nCREATE VIEW VistaSediConOrariDisponibili AS\n\tSELECT *\n\tFROM SEDE_AMA AS S\n\tWHERE EXISTS(\n\t    SELECT *\n\t    FROM ORARIO_SETTIMANALE AS O\n\t    WHERE O.codice_sede = S.codice_sede);\n\nVistaVeicoliInManutenzione\n\nMostra i veicoli attualmente nello stato ‚Äúmanutenzione‚Äù, con eventuale assegnazione lavoratore.\n\n\n\nCREATE VIEW VistaVeicoliInManutenzione AS\n\tSELECT *\n\tFROM VEICOLO AS V\n\tWHERE V.stato = &quot;manutenzione&quot;;"},"UNI/ANNO-2/BASE-DI-DATI/DIPENDENZE-TRANSITIVE":{"slug":"UNI/ANNO-2/BASE-DI-DATI/DIPENDENZE-TRANSITIVE","filePath":"UNI/ANNO 2/BASE DI DATI/DIPENDENZE TRANSITIVE.md","title":"DIPENDENZE TRANSITIVE","links":[],"tags":[],"content":"üß† Strategia pratica da usare in esame\n\n\nTrova le chiavi candidate\n\n\nTrova tutte le FD\n\n\nPer ogni forma normale:\n\n\n1NF: valori atomici?\n\n\n2NF: ci sono FD su parte della chiave?\n\n\n3NF: ci sono FD transitive?\n\n\n\n\n\nüß© Riepilogo visivo\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nForma NormaleCriterioObiettivo1NFNessun attributo multivaloreTabelle leggibili e gestibili2NFNessuna dipendenza parzialeElimina ripetizioni legate alla chiave3NFNessuna dipendenza transitivaElimina duplicazione di dati derivati\nüõ†Ô∏è Come normalizzare in BCNF\n1. Identifica la FD che viola la BCNF\n\nDeve essere X ‚Üí Y con X non superchiave\n\n2. Decomponi in due relazioni:\n\n\nUna con: X ‚Üí Y\n\n\nL‚Äôaltra con: gli attributi rimanenti\n\n\nüîß Esempio:\nRelazione:\n \n`Esami(Matricola, CodiceCorso, Aula) \n \nFD: \nCodiceCorso ‚Üí Aula Matricola, \nCodiceCorso ‚Üí tutti`\n‚Üí CodiceCorso non √® una chiave, ma determina Aula ‚áí violazione BCNF\nDecomposizione:\n\n\nCorso(CodiceCorso, Aula)\n\n\nEsami(Matricola, CodiceCorso)\n\n\n‚úÖ Ora entrambe sono in BCNF\nüî∑ 1. Lossless join\n\nDopo la decomposizione, se faccio un join tra le nuove relazioni, devo ottenere esattamente i dati originali.\n\n‚úÖ √à obbligatorio. Se perdi dati ‚Üí decomposizione non accettabile.\nBCNF\nüß© La tua situazione:\nHai una tabella con:\nnome, cognome ‚Üí chiave primaria   telefono ‚Üí attributo non primo\nOra immagini una dipendenza:\ntelefono ‚Üí nome\n\nüîç Analisi passo per passo:\n1. nome, cognome √® chiave primaria ‚úÖ\n‚Üí quindi √® una superchiave\n2. telefono non √® superchiave ‚ùå\n‚Üí perch√© non identifica univocamente le righe (pi√π persone potrebbero avere lo stesso numero, o viceversa)\n3. nome √® parte della chiave ‚Üí attributo primo ‚úÖ\n\nüéØ Domanda:\n\nLa dipendenza telefono ‚Üí nome √® accettabile in 3NF?\n√à accettabile in BCNF?\n\n\n‚úÖ In 3NF: SI!\nPerch√©:\n\n\ntelefono ‚Üí nome\n\n\ntelefono non √® superchiave ‚ùå\n\n\nma nome √® attributo primo ‚úÖ\n‚û°Ô∏è La 3NF lo accetta\n\n\n\n‚ùå In BCNF: NO!\nPerch√©:\n\n\nIn BCNF, ogni lato sinistro (X) di una dipendenza deve essere superchiave\n\n\ntelefono non √® superchiave ‚ùå\n‚û°Ô∏è Violazione della BCNF\n\n\n\n‚úÖ Conclusione finale\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFormaLa tua dipendenza telefono ‚Üí nome √® accettata?3NF‚úÖ S√¨, perch√© nome √® attributo primoBCNF‚ùå No, perch√© telefono non √® superchiave\n\nüí° In pratica:\n\nLa 3NF √® pi√π flessibile, ma pu√≤ nascondere anomalie\nLa BCNF elimina tutte le dipendenze ‚Äúsospette‚Äù, anche se servono pi√π tabelle\n\n"},"UNI/ANNO-2/BASE-DI-DATI/ORALE-NON-DEL-PATATA":{"slug":"UNI/ANNO-2/BASE-DI-DATI/ORALE-NON-DEL-PATATA","filePath":"UNI/ANNO 2/BASE DI DATI/ORALE NON DEL PATATA.md","title":"ORALE NON DEL PATATA","links":[],"tags":[],"content":"TRANSAZIONI\nUna transazione √® un‚Äôunit√† logica di elaborazione in un database, composta da una sequenza di operazioni che devono essere eseguite tutte insieme, oppure nessuna.\nprevedono\n\n\nun begin transaction che √® l‚Äôinizio\n\n\nuna serie di operazioni come\n\nupdate\ninsert\nselect \ndelete\n\n\n\npossono terminare o con un\n\ncommit work se tutto va bene\nrollback work se qualcosa va storto si possono fare operazioni di\n\n\n\nUNDO: ripristina i dati prima dell‚Äôerrore.\n\n\nREDO: ripete un‚Äôoperazione persa dopo un crash.\nLog: BS=5, AS=10\nquesto log tiene salvato che BS=5 se fai undo torna al valore del log\n\n\nSTART TRANSACTION;\nUPDATE ContoCorrente SET Saldo = Saldo - 100 WHERE NumConto = 1001;\nUPDATE ContoCorrente SET Saldo = Saldo + 100 WHERE NumConto = 2002;\nCOMMIT;\nACID delle transazioni\nle transazioni devono garantire 4 propriet√† fondamentali\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPropriet√†SignificatoAtomicit√†Garantisce che il blocco di operazioni venga eseguito tuttoConsistenzaRispetta i vincoli del DBIsolamentoNessuna interferenza tra transazioniDurabilit√†Una volta fatto commit, le modifiche restano in memoria fisica\nGaranzia delle propriet√†\nPer garantire tali propriet√† occorre effettuare controlli su\n\naffidabilit√† (per atomicit√† e durabilit√†),\nconcorrenza (per isolamento),\nesecuzione delle operazioni (consistenza)\nquesti controlli vengono fatti dal gestore delle transazioni\nil controllo sull‚Äôaffidabilit√† viene facilitato da un file di log che contiene vari checkpoint dei dati che sono gi√† stati salvati nel database\n\nmolto spesso le modifiche vengono messe sul log e dopo in memoria fisica(modalit√† differita)\n\n\nil DBMS ha una copia del database detta dump\n\nGestione dei guasti\naffiancato al gestore delle transazione abbiamo il recovery manager\n\ncolui che ha il compito di gestire il ripristino dai vari errori\nci sono 2 tipi di guasti\nSOFT\n\ndifferenza di informazioni tra memoria principale e secondaria\n\nquella principale(RAM) ha una perdita ma quella secondaria(HDD) no\n\n\n\n\nHARD\n\nsia in primaria che secondaria ma il contenuto e salvato nella memoria stabile\n\nlog e dump\n\n\n\n\n\nLe operazioni di ripresa si dividono in 2 tipi\n\na caldo (4 fasi) guasto ‚Äúsoft‚Äù\n\ncerca ultimo checkpoint nel log\ncostruisce due insiemi di operazioni\n\nundo, operazioni da disfare\nredo, operazioni da rifare\n\n\nnel log cancella tutte le operazioni che sono state inserite andando a ritroso UNDO\nparte dal punto in cui si ferma l‚ÄôUNDO e avanza nuovamente nel log rifacendo le operazioni con il REDO\n\n\na freddo guasto ‚Äúhard‚Äù\n\nripristini da un dump\nsuccessivamente riprendi il log e rifai tutte le operazioni fino al crash\nappena avviene il crash fai una ripresa a caldo\n\n\n\nGestione della concorrenza\ntra pi√π transazioni potrebbero esserci problemi di concorrenza, quest‚Äôultima √® gestita da degli scheduler che dirigono le varie transazioni\nNormalizzazione\nLe forme normali nelle basi di dati (o normalizzazione dei database) sono una serie di linee guida progettate per organizzare i dati in una base di dati relazionale per minimizzare la ridondanza e migliorare l‚Äôintegrit√† dei dati.\n1NF\n\natomicit√†\n\nno ripetizioni\nno attributi multivalore\nvalore atomico= valore indivisibile se lo dividi non va bene\n\n\n\n2NF\n\ndeve essere gi√† in 1NF\nnon dipendenze parziali\nA,X‚Üí B con solo per√≤ A‚Üí B e non X‚Üí B  cos√¨ √® parziale\n\n3NF\n\ndeve essere gi√† in 2NF\neliminare dipendenze transitive\nA‚Üí B B‚Üí C e non abbiamo che A‚Üí C questo non va bene\n\nBCNF Boyce-Codd\n√à una forma pi√π ristretta della 3NF\n√® in BCNF se\n\nper ogni dipendenza funzionale non banale A‚Üí B A risulta una super chiave\nUna dipendenza funzionale A‚ÜíB √® non banale se B non √® un sottoinsieme di A.\n\n\nTIPOLOGIE DI DIPENDENZE FUNZIONALI\ndef: √® una relazione in cui un insieme di attributi determina un altro insieme di attributi\n\nTRANSITIVA\n\nse ho A‚Üí C io posso arrivare a C esclusivamente da un altro attributo non chiave B‚Üí C con A‚Üí B\n\n\nPARZIALE\n\nA,C‚Üí X con X che dipende funzionalmente solo o da A o da C\n\n\nCOMPLETA\n\nda A posso derivare tutti √® una superchiave\n\n\nBANALE\n\nSe ho una dipendenza A‚Üí B e B √® sottoinsieme di A\n\n\n\nSONO USATE PER\n\nnormalizzazione dei dati\n- integrit√† dei dati\nstruttura del database solida\n\nALGEBRA RELAZIONALE\nL‚Äô algebra relazionale √® un insieme di operazioni utilizzate per manipolare e interrogare i dati nelle basi di dati relazionali in un modo formale\nTIPI DI OPERAZIONI\n\nSELEZIONE œÉ\n\nEstrae le righe che soddisfano una condizione (filtra le tuple).\n\n\nPROIEZIONE œÄ\n\nEstrae alcune colonne di una relazione, eliminando i duplicati.\n\n\nRINOMINAZIONE œÅ\n\nRinomina il nome della relazione e/o dei suoi attributi\n\n\nUNIONE ‚à™\n\nUnisce due relazioni con lo stesso schema, restituendo tutte le tuple distinte.\n\n\nDIFFERENZA ‚àí\n\nRestituisce le tuple che sono nella prima relazione ma non nella seconda.\n\n\nPRODOTTO CARTESIANO √ó\n\nCombina ogni tupla della prima relazione con tutte quelle della seconda.\n\n\n\npoi anche una serie di operazioni che derivano da queste elementari\n\nINTERSEZIONE ‚à©\n\nRestituisce le tuple presenti in entrambe le relazioni.\n\n\nJOIN NATURALE ‚ãà\n\nCombina due relazioni sulle colonne con lo stesso nome (e valore uguale).\n\n\nLEFT JOIN =‚ãà\n\nCome il join naturale, ma include tutte le tuple della relazione sinistra, anche senza corrispondenze.\n\n\nRIGHT JOIN ‚ãà=\n\nCome il join naturale, ma include tutte le tuple della relazione destra, anche senza corrispondenze.\n\n\nTHETA JOIN ‚ãà_ROBA\n\nJoin condizionato su una qualsiasi condizione booleana Œ∏ (es: A.id = B.cod AND A.anno &gt; 2020).\n\n\nDIVISIONE √∑\n\nRestituisce le tuple della prima relazione che sono associate a tutte le tuple della seconda (usata in query del tipo ‚Äútutti‚Äù).\n\n\n\nCALCOLO RELAZIONALE\nApproccio che sfrutta la logica del primo ordine per esprimere le query\nlinguaggio dichiarativo\n\ndiverso dall‚Äôalgebra relazionale\nusa formule per indicare le condizioni che le tuple devono soddisfare per essere prese nelle query\n\nDUE VARIANTI\nTRC\n\ncalcolo relazionale sulle tuple\nutilizza delle variabili\n\nesse sono le tuple in esame\nSintassi Generale:\n\\{t ‚à£ œÜ(t)\\}\n\n\nt rappresenta\n\\varphi \\ t rappresenta una formula logica da rispettare\nDove: Esempio:\nConsideriamo una relazione Dipendenti con attributi (DID,Nome,Salario).\nTrova i nomi e i salari dei dipendenti che guadagnano pi√π di 50000.\n\\{t. Nome,t. Salario ‚à£ t ‚àà Dipendenti ‚àß t. Salario &gt; 50000\\}\n\nDRC\n\ncalcolo relazionale sui domini\nqui si lavora su singole variabili che rappresentano attributi singoli\nSintassi Generale:\n\\{(x1, x2,‚Ä¶, xn) ‚à£ œÜ(x1, x2,‚Ä¶, x_n)\\}\nDove:\nEsempio: Consideriamo la stessa relazione Dipendenti(DID,Nome,Salario).\nTrova i nomi e i salari dei dipendenti che guadagnano pi√π di 50000.\n\\{(N, S) ‚à£ ‚àÉDID (Dipendenti(DID, N, S) ‚àß S &gt; 50000)\\}\n\nTRIGGER\nUn trigger √® un oggetto del database che:\nsi attiva automaticamente al verificarsi di un certo evento su una tabella.\n\nINSERT\nDELETE,\nUPDATE\nesegue una serie di istruzioni SQL in risposta a quell‚Äôevento.\n\nAbbiamo due tipi di TRIGGER\nBEFORE ‚Üí che si attiva prima dell‚Äôesecuzione dell‚Äôoperazione,\nAFTER ‚Üí che si attiva dopo,\nSINTASSI\nCREATE TRIGGER nome_trigger\n{BEFORE | AFTER} {INSERT | UPDATE | DELETE}\nON nome_tabella\nFOR EACH ROW\nBEGIN\n   -- istruzioni SQL da eseguire\nEND;\nESEMPIO\nImmagina una tabella Ordini e vogliamo registrare un log ogni volta che viene inserito un nuovo ordine:\nCREATE TRIGGER verifica_eta_cliente \nBEFORE INSERT ON CLIENTE \nFOR EACH ROW  \nBEGIN \n     IF NEW.data_nascita &gt; CURDATE() - INTERVAL 18 YEAR THEN \nSIGNAL SQLSTATE &#039;45000&#039; SET MESSAGE_TEXT = &#039;Il cliente deve essere maggiorenne  (almeno 18 anni)&#039;;  \nEND IF;  \nEND; \nINDEX\n√à una struttura dati usata per avere accesso in tempo costante a determinati dati nel database. Quando fai spesso query del tipo:\nSELECT * FROM Studenti WHERE matricola = 12345;\nSe la tabella ha 10 milioni di righe, senza indice il DB deve scorrere tutte le righe.\nCon un indice su matricola, il DB va a cercare come in un dizionario: sa subito dove guardare. SINTASSI\nCREATE INDEX nome_indice  ON nome_tabella (colonna);\nEsempio pratico:\nCREATE INDEX idx_matricola ON Studenti (matricola);\nHAVING\nServe per filtrare i gruppi dopo che hai fatto un GROUP BY.\nViene utilizzato perch√© dopo un GROUP BY non puoi usare WHERE per filtrare su funzioni aggregate (COUNT(), SUM(), ecc.), ma serve l‚Äôhaving\nESEMPIO\nSELECT Cliente, SUM(Importo) AS TotaleOrdini\nFROM Ordini\nGROUP BY Cliente\nHAVING SUM(Importo) &gt; 200;\nWHERE\nServe per filtrare le righe di una tabella, selezionando solo quelle che rispettano una certa condizione.\nESEMPIO\nSELECT *\nFROM Studenti\nWHERE Corso = &#039;Informatica&#039;;\nSicurezza delle Query\nVoglio\n\nrisultati concreti\ntempo costante\n\nPotenza espressiva\nTutto ci√≤ che posso fare con algebra relazionale posso farlo anche con il calcolo.\nTuttavia il calcolo tende ad essere pi√π dichiarativo.\n\nChiusure\n\nLa chiusura di un insieme di attributi X rispetto a un insieme di dipendenze funzionali F √® l‚Äôinsieme di tutti gli attributi che X determina tramite F.\n\nSi indica come: X^+_F \\quad \\text{oppure semplicemente} \\quad X^+\n\n\n                  \n                  ESEMPIO \n                  \n                \n\nImmagina di avere le seguenti DF\n\n\nKL \\rightarrow M\nM \\rightarrow N\nB \\rightarrow P\nV \\rightarrow O\nC \\rightarrow S\n\n\nVogliamo calcolare (KL)^+\nüõ† Passo 1 ‚Äî inizializzazione: (KL)^+ = \\{ K, L \\}\nüõ† Passo 2 ‚Äî applichiamo le DF:\n\n\nKL ‚Üí M ‚áí possiamo aggiungere M: (KL)^+ = \\{ K, L, M \\}\nM ‚Üí N ‚áí M c‚Äô√® ‚Üí aggiungiamo N: (KL)^+ = \\{ K, L, M, N \\}\n\n\nChiave minimale (chiave candidata)\nUna chiave minimale √® un insieme minimo di attributi che riesce a determinare tutta la relazione. Se togli un qualsiasi attributo da essa, gli altri da soli non determinano pi√π tutto.\nNel senso che, se io tolgo una chiave qualsiasi dalla chiusura, dentro l‚Äôinsieme non ho pi√π tutti gli attributi presenti nella DF.\n\n\n                  \n                  Per esempio \n                  \n                \n\n\nKL \\rightarrow M\nM \\rightarrow N\nL \\rightarrow P\nP \\rightarrow O\n\n\n\nDa questo deriva che (KL)^+ = \\{ K, L, M, N, P, O \\}\nQuesta √® sia una superchiave (perch√© determina tutti gli attributi) sia una chiave minimale (non ci sono ridondanze).\nSe tolgo L da KL, ottengo solo K., ma con K da solo, non riesco pi√π a determinare P e O.\nQuindi KL √® minimale: ogni suo attributo √® necessario per determinare tutta la relazione.\nInsieme minimale di DF,\nn insieme minimale di DF √® un insieme di dipendenze funzionali equivalente all‚Äôoriginale, che permette di derivare tutti gli attributi senza ridondanze. ESEMPIO Insieme base delle DF\n1Ô∏è‚É£ `A ‚Üí B`   2Ô∏è‚É£ `B ‚Üí C`   3Ô∏è‚É£ `A ‚Üí C`   4Ô∏è‚É£ `C ‚Üí D`\nVari passi da seguire\n\nEliminare, se possibile, attributi doppi a destra (es. A -&gt; CB, vedi se puoi eliminarne uno),\nEliminare, se possibile, attributi doppi a sinistra,\nEliminare DF ridondanti (in questo caso A -&gt; C),\n\nQUINDI COME RISULTATO ABBIAMO\n1Ô∏è‚É£ `A ‚Üí B`   2Ô∏è‚É£ `B ‚Üí C`   3Ô∏è‚É£ `C ‚Üí D`\nüü† Schema E-R (Entity-Relationship)\nLo schema E-R √® un modello concettuale che descrive i dati e le relazioni tra essi in modo astratto, indipendente dal database fisico. Utilizza entit√†, attributi e associazioni per rappresentare le informazioni e i legami tra i dati.\n\nServe per progettare il database partendo dai concetti reali, prima di tradurlo in uno schema relazionale.\n\nüü¢ Schema relazionale\nLo schema relazionale rappresenta il modello logico del database. Descrive le tabelle (relazioni), specificando gli attributi e i vincoli (come chiavi primarie e chiavi esterne), e viene ottenuto a partire dallo schema E-R.‚Äù\n\n√à il modello direttamente implementabile nei DBMS relazionali.\n"},"UNI/ANNO-2/BASE-DI-DATI/PROGETTO-BASI":{"slug":"UNI/ANNO-2/BASE-DI-DATI/PROGETTO-BASI","filePath":"UNI/ANNO 2/BASE DI DATI/PROGETTO BASI.md","title":"PROGETTO BASI","links":["mailto:luca.gugliotta@students.uniroma2.eu","mailto:samuele.desantis@students.uniroma2.eu"],"tags":[],"content":"Titolo del progetto:\nMyAma ‚Äì Gestione prenotazioni per rifiuti ingombranti\n\nComponenti del gruppo:\n\n\nLuca Gugliotta ‚Äì  luca.gugliotta@students.uniroma2.eu\n\n\nSamuele De Santis ‚Äì samuele.desantis@students.uniroma2.eu\n\n\n\nDescrizione del dominio applicativo\nIl progetto riguarda la realizzazione di un sistema informativo per un portale AMA (ispirato all‚ÄôAzienda Municipale Ambiente), pensato per consentire ai cittadini la prenotazione del ritiro o la consegna in sede di rifiuti ingombranti.\nIl portale permette la gestione completa degli utenti, dei lavoratori, delle sedi AMA, dei veicoli impiegati e delle prenotazioni. Il sistema tiene conto della disponibilit√† dei lavoratori e dei vincoli logistici, come il codice di avviamento postale (CAP) e la capacit√† dei veicoli.\n\nObiettivi funzionali del sistema\nIl sistema dovr√† permettere di:\n\n\nConsentire la registrazione dei clienti (codice fiscale, nome, cognome, email, password, numero di telefono).\n\n\nConsentire la registrazione dei lavoratori AMA (CID, nome, cognome, data di nascita, ruolo, email, orari lavorativi, numero di telefono).\n\n\nConsentire ai clienti di prenotare un ritiro a domicilio oppure scegliere di portare il rifiuto presso una sede.\n\n\nCalcolare il costo della prenotazione in base alla tipologia del rifiuto e al peso stimato.\n\n\nPermettere l‚Äôupload di una foto del rifiuto per valutazioni preliminari.\n\n\nValidare la disponibilit√† di lavoratori e veicoli per le prenotazioni a domicilio.\n\n\nPermettere la scelta di data, ora e luogo, con limitazioni sul CAP servito.\n\n\nVisualizzare l‚Äôelenco delle sedi AMA disponibili in base alla zona del cliente.\n\n\nGestire un archivio delle tipologie di rifiuti, con relativi costi e categorie.\n\n\nGestire le assegnazioni dei lavoratori e dei veicoli alle singole prenotazioni.\n\n\nObiettivi secondari utili\n\n\nGestione dello storico delle prenotazioni per ciascun cliente, con visualizzazione di stato, data, costo e modalit√† (ritiro o consegna).\n\n\nReportistica interna per AMA, con statistiche su:\n\nNumero di ritiri per zona o sede;\nTipologie di rifiuti pi√π frequenti;\nCarico di lavoro medio per lavoratore.\n\n\n\nSistema di notifica simulato per comunicare conferme, modifiche o annullamenti delle prenotazioni (tramite flag o campo nel database).\n\n\nValutazione del servizio da parte del cliente dopo il ritiro, con voto (1‚Äì5) e commento.\n\n\nControllo del carico massimo dei veicoli, per evitare che vengano assegnati a prenotazioni eccedenti la capacit√†.\n\n\nGestione dei CAP serviti da ogni sede, per mostrare solo le opzioni valide durante la prenotazione.\n\n\nUtenti\nRuoli dei rispettivi utenti\n\nCliente\n\n√à il cittadino che accede al portale per usufruire dei servizi AMA.\nPu√≤:\n\nRegistrarsi tramite SPID o credenziali classiche.\nEffettuare prenotazioni di ritiro a domicilio o consegna in sede.\nVisualizzare solo le sedi e gli orari compatibili con il proprio CAP.\nCaricare la foto del rifiuto, specificarne tipologia e peso.\nVisualizzare lo storico delle proprie prenotazioni.\nCancellare una prenotazione (rispettando i limiti di tempo previsti).\nLasciare una valutazione del servizio dopo il ritiro.\n\n\nNon pu√≤:\n\nAccedere ai dati di altri utenti o lavoratori.\nVisualizzare informazioni riservate (es. disponibilit√† veicoli o altri ritiri).\n\n\n\n\nLavoratore AMA\n\n√à il dipendente che gestisce operativamente i ritiri e le consegne.\n√à suddiviso in:\n\nAutista: associato a uno o pi√π veicoli, si occupa dei ritiri a domicilio.\n\nVisualizza le prenotazioni assegnate nel proprio turno.\nRegistra l‚Äôavvenuto ritiro o eventuali problemi (es. mancata consegna).\n\n\nOperatore di sede: lavora nei punti di raccolta AMA.\n\nGestisce le consegne dirette in sede da parte dei clienti.\nVerifica i dati del rifiuto e li registra nel sistema.\n\n\n\n\nI lavoratori AMA:\n\nNon possono modificare le prenotazioni.\nNon hanno accesso ai dati anagrafici dei clienti (salvo CAP e contatti operativi).\nOperano solo negli orari definiti nel loro profilo.\n\n\n\n\nAmministratori e gestori del database\n\nSono figure tecniche con privilegi completi.\nPossono:\n\nGestire e aggiornare i dati di sistema.\nAssegnare o revocare ruoli e accessi.\nMonitorare l‚Äôattivit√† del sistema.\nIntervenire su malfunzionamenti, errori o frodi.\n\n\nNon possono:\n\nPrenotare ritiri o agire come clienti o lavoratori nel flusso operativo normale.\n\n\n\n\n\nParte seconda: Raccolta e analisi dei Requisiti\nIl progetto √® destinato a due tipi di utenti:\n\ncittadini di roma\n\ni veri e propri clienti, questo progetto ha lo scopo di facilitare richieste di prenotazione per gettare rifiuti ingombranti nei modi pi√π semplici e pi√π corretti per l‚Äôambiente\n√® previsto che i clienti abbiano una visione ampia di tutti i servizi che pu√≤ offrire la piattaforma MyAma e che possa interagirvi facilmente\n\n\ni lavoratori\n\navere una piattaforma che consente a loro di lavorare in maniera uniforme e organizzata\nsenza mancanze di dettagli e informazioni\n\n\n\nFONTI\nüìö Fonti di riferimento (generiche e specifiche)\n1. Normative e leggi\n\n\nD.Lgs. 152/2006 ‚Äì Codice dell‚ÄôAmbiente\nüëâ Riferimento normativo nazionale che disciplina la gestione dei rifiuti (compresi quelli urbani e ingombranti).\nüîó Normattiva Codice dell‚ÄôAmbiente\n\n\nRegolamenti AMA\nüëâ In particolare, quelli relativi a servizi di ritiro rifiuti ingombranti e RAEE (disponibili sul sito ufficiale).\nüîó AMA Roma ‚Äì Ritiro ingombranti\nüîó Regolamenti di servizio AMA (PDF)\n\n\nRegolamenti comunali di Roma Capitale\nüëâ Documenti e delibere riguardanti la gestione dei rifiuti urbani.\nüîó Deliberazioni Comune di Roma\n\n\n\n2. Prassi operative AMA (dedotte e documentate)\n\n\nLe procedure AMA attualmente prevedono:\n\n\nPrenotazioni via telefono o moduli online.\n\n\nScambi interni non digitalizzati.\n\n\nGestione manuale di orari e disponibilit√† (fonte: simulazione utente + sito AMA).\n\n\nNessuna integrazione diretta con SPID o strumenti avanzati (visibile dalla UX del sito).\n\n\n\n\n\n3. Dati realistici dedotti dall‚Äôanalisi comparativa\n\n\nPratiche comuni in aziende di gestione rifiuti municipali (AMA o analoghe).\n\n\nEsperienze utente documentate in forum, reclami, richieste di semplificazione (es. su Reddit, segnalazioni social o portali tipo RomaLido.org).\n\n\nOperazioni di inserimento¬†\n\nInserimento di un nuovo cliente (con SPID o credenziali manuali).\nInserimento di un nuovo lavoratore AMA (autista o operatore di sede).\nInserimento di una nuova prenotazione da parte del cliente\n\nInserimento della foto del rifiuto nella prenotazione.\nInserimento dei dettagli del rifiuto: tipologia, peso stimato, categoria.\n\n\nInserimento di una nuova sede AMA nel sistema.\nInserimento di un nuovo veicolo disponibile per i ritiri.\nAssegnazione automatica o manuale di un lavoratore e di un veicolo a una prenotazione.\nInserimento di turni/orari lavorativi associati ai dipendenti.\nInserimento di una valutazione del servizio da parte del cliente.\nInserimento delle zone (CAP) servite da ciascuna sede.\nOperazioni di aggiornamento¬†\nModifica delle informazioni anagrafiche del cliente o del lavoratore.\nModifica dello stato della prenotazione (attiva, completata, cancellata).\nAggiornamento dei dati relativi al rifiuto (es. peso modificato dopo verifica).\nAggiornamento del costo totale sulla base della tipologia e peso.\nModifica dell‚Äôorario o della sede selezionata dal cliente.\nAggiornamento della disponibilit√† dei lavoratori in base ai turni.\nAggiornamento della disponibilit√† dei veicoli.\nModifica dei CAP serviti da ciascuna sede.\nAggiornamento della valutazione inserita (entro limiti temporali).\nInserimento di eventuali note interne da parte dei lavoratori AMA.\n\nOperazioni di cancellazione¬†\n\n\nCancellazione di una prenotazione da parte del cliente (entro i termini).\n\n\nRimozione di un lavoratore non pi√π attivo nel sistema.\n\n\nCancellazione di un veicolo dismesso o non pi√π utilizzabile.\n\n\nEliminazione di una sede (solo se non associata a prenotazioni attive).\n\n\nEliminazione di una tipologia di rifiuto non pi√π gestita.\n\n\nAnnullamento di un‚Äôassociazione lavoratore-veicolo su una determinata prenotazione.\n\n\nCancellazione di valutazioni non conformi o segnalate.\n\n\nCancellazione di un cliente su richiesta\nOperazioni di visualizzazione\n\n\nVisualizzazione delle prenotazioni effettuate da un cliente.\n\n\nVisualizzazione dello storico dei ritiri/consegne da parte di un lavoratore.\n\n\nVisualizzazione delle sedi disponibili in base al CAP inserito.\n\n\nVisualizzazione dei costi associati a ciascuna tipologia di rifiuto.\n\n\nVisualizzazione dei veicoli disponibili e assegnati.\n\n\nVisualizzazione degli orari disponibili per il ritiro/consegna.\n\n\nVisualizzazione dello stato di una prenotazione.\n\n\nVisualizzazione della valutazione media del servizio.\n\n\nVisualizzazione della cronologia completa per scopi di report.\n\n\nIl sistema MyAma prevede tre classi distinte di utenza, ciascuna con specifici privilegi di accesso e operativit√† nel sistema:\n\n\nClienti\n\n\nAccedono tramite SPID o credenziali.\n\n\nPossono effettuare prenotazioni, caricare dati, consultare lo storico, cancellare o modificare le richieste.\n\n\nHanno visibilit√† solo sui propri dati.\n\n\n\n\nLavoratori AMA\n\n\nDivisi in Autisti (gestiscono i ritiri a domicilio) e Operatori di sede (gestiscono i conferimenti diretti).\n\n\nPossono visualizzare le prenotazioni assegnate e segnarne l‚Äôesito.\n\n\nNon possono modificare i dati anagrafici o gestionali.\n\n\n\n\nAmministratori\n\n\nGestiscono il sistema, i ruoli, i dati e le configurazioni.\n\n\nPossono accedere a tutte le sezioni, eseguire controlli, backup e manutenzione.\n\n\n\n\nOgni classe ha permessi specifici, impostati per garantire sicurezza, tracciabilit√† e integrit√† dei dati.\n‚úÖ Assunzioni\n\nGli utenti che si registrano come clienti devono essere maggiorenni e far parte dei comuni associati ad AMA.\nGli autisti sono sempre associati ad almeno un veicolo per effettuare i ritiri.\nI CAP inseriti nelle prenotazioni devono essere tra quelli serviti da almeno una sede.\nUn lavoratore pu√≤ essere assegnato a una sola prenotazione per fascia oraria.\nOgni foto del rifiuto viene caricata in formato valido (.jpg, .png) e non supera una dimensione predefinita di 10mb.\nLe prenotazioni possono essere cancellate solo 2 ore prima dell‚Äôorario previsto per il ritiro o la consegna.\nI veicoli hanno una capacit√† massima espressa in kg e non possono eccedere tale limite nella somma dei ritiri assegnati.\n\n\nüõ°Ô∏è Vincoli di integrit√†\n1. Vincoli di chiave primaria\n\nOgni tabella (utenti, prenotazioni, rifiuti, veicoli, ecc.) ha un identificatore univoco.\n2. Vincoli di chiave esterna\nLe prenotazioni fanno riferimento:\n\na un cliente registrato (FK su Clienti);\na una sede AMA (FK su Sedi);\na un lavoratore (se assegnato);\na un veicolo (se assegnato).\n3. Vincoli di dominio\n\n\nI CAP devono essere numerici e compresi tra 00010 e 00199 (esempio di range per Roma).\nIl peso del rifiuto deve essere &gt; 0.\nLe email devono contenere il carattere @.\nLe password devono avere almeno 8 caratteri e almeno 1 carattere speciale.\nLe valutazioni devono essere comprese tra 1 e 5.\n4. Vincoli di unicit√†\nIl codice fiscale dei clienti √® univoco.\nIl CID dei lavoratori AMA √® univoco.\nIl numero targa dei veicoli √® univoco.\n5. Vincoli temporali\nLa data di ritiro/consegna deve essere successiva alla data di prenotazione.\nUna valutazione pu√≤ essere inserita solo dopo la conclusione del servizio.\n6. Vincoli di integrit√† referenziale\nL‚Äôeliminazione di un cliente comporta anche la cancellazione delle sue prenotazioni\nSe una sede viene rimossa, le prenotazioni collegate vanno gestite\n\nSCHEMA E-R\nper gli attributi obbligatori *\n\nPrenotazione\n\nPK: codice prenotazione\nfoto rifiuto\ndescrizione oggetto\nCliente FK\nlavoratore preso FK\ntipo prenotazione\n\nsede o veicolo\n\n\nData prenotazione\norario prenotazione\nVeicolo FK\nSede associata FK\nstato prenotazione\n\nattiva o completata o terminata\n\n\ncosto prenotazione\n\n\nvalutazioni\n\nId valutazione\nCodice prenotazione FK\nvotazione da 1 a 5\nunique su stato prenotazione\n\n\nCliente\n\nPK: Codice Fiscale*\nNome*\nCognome*\nE-mail*\nPassword*\nData di nascita*\nIndirizzo di domicilio*\nCap di domicilio*\nToken per accesso con SPID\nnumero di telefono\n\n\nturni del lavoratore\n\nid tabella\nFK lavoratore\ndata turno\norario inizio\norario fine\npausa inizio\npausa fine\n\n\nLavoratore\n\nPK: CID(Codice Identificativo Dipendente)*\nNome*\nCognome*\nE-mail*\nPassword*\nData di nascita*\nRuolo\n\nin sede\ncon veicolo\n\n\n\n\nVeicolo\n\nPK: Targa*\nTipologia\nCarico massimo consentito\nStato\n\ndisponibile\nin uso\nin riparazione\n\n\nFK lavoratore con veicolo\nFK su prenotazione\n\n\nSede Ama\n\nPK: codice sede\nindirizzo*\nFK tabella orari\nFK lavoratori in sede\n\n\ncap serviti dalla sede\n\nid cap\nNumero CAP\nCodice sede FK\n\n\norari sede ama\n\ndata\nora\nid sede\n\n\n\nDizionario dei Dati - Schema AMA\n\nDizionario dei Dati¬†\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nENTIT√ÄDESCRIZIONEATTRIBUTICHIAVI PRIMARIEPrenotazioneContiene tutte le informazioni relative a una prenotazione effettuata- Foto_rifiuto¬†    - Descrizione_oggetto¬†    - Tipo_prenotazione ¬†    - Data_prenotazione¬†    - Orario_prenotazione ¬†    - Stato_prenotazione ¬†    - Costo_prenotazioneData, Orario, ClienteValutazioneValutazioni associate a prenotazioni concluse- Data_valutazione¬†    - Voto_valutazioneData, Cliente, PrenotazioneClientePersona registrata nel sistema come cliente- Codice_fiscale¬†    - Nome¬†    - Cognome ¬†    - E-mail¬†    - Password ¬†    - Data_di_nascita ¬†    - Indirizzo_domicilio ¬†    - CAP_domicilio¬†    - Token_SPID¬†    - TelefonoCodice_fiscaleLavoratoreDipendente dell‚ÄôAMA con ruolo specifico- Nome¬†    - Cognome¬†    - E-mail¬†    - Password¬†    - Data_di_nascita¬†    - RuoloE-mail, Data_di_nascitaTurnoContiene i turni assegnati ai lavoratori- Data_turno¬†    - Orario_inizio¬†    - Orario_fine¬†    - Pausa_inizio¬†    - Pausa_fineData, Orario_inizio, Orario_fine, lavoratoreVeicoloVeicolo disponibile o in uso per le prenotazioni- Targa ¬†    - Tipologia¬†    - Carico_massimo¬†    - StatoTargaSede AMASede operativa AMA con lavoratori assegnati- Indirizzo¬†    - CAPIndirizzo, CAPLista CAPAssocia CAP ai territori serviti da ciascuna sede- CAPCAP, Sede AMAOrarioMostra gli orari di ciascuna sede- Ora¬†    - Inizio_pausa¬†    - Fine_pausa¬†    - DataData, Sede AMA\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRelazioneDescrizioneEntit√† coinvolteAttributieffettuareCollega ciascun cliente alle prenotazioni da lui effettuateCliente ‚Äì Prenotazione‚ÄîottenereUna prenotazione pu√≤ essere associata a una valutazionePrenotazione ‚Äì Valutazione‚ÄîscrivereCollega ogni cliente alla valutazione che ha scrittoCliente ‚Äì Valutazione‚ÄîingaggiareCollega ogni prenotazione al lavoratore assegnatoPrenotazione ‚Äì Lavoratore‚ÄîutilizzareCollega un lavoratore al veicolo assegnatoLavoratore ‚Äì Veicolo‚ÄîgestireCollega ciascuna sede AMA alle prenotazioni che gestisceSede AMA ‚Äì Prenotazione‚ÄîservireSpecifica quali CAP sono serviti da ogni sede AMASede AMA ‚Äì Lista CAP‚ÄîlavorareCollega un lavoratore alla sede in cui operaLavoratore ‚Äì Sede AMA‚ÄîrispettareCollega ciascun lavoratore ai turni che deve rispettareLavoratore ‚Äì Turno‚ÄîavereCollega ogni sede AMA ai suoi orari di apertura e chiusuraSede AMA ‚Äì Orario‚Äî\nSCHEMA LOGICO\n\nüìò Dizionario delle Entit√† (schema ristrutturato)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEntit√†DescrizioneAttributiChiave primariaClienteCittadino registrato per effettuare prenotazionicodice_fiscale, nome, cognome, email, password, data_nascita, indirizzo_domicilio, cap, telefono, token_spidcodice_fiscaleLavoratoreDipendente AMA, operatore o autistacid, nome, cognome, email, password, data_nascita, ruolocidVeicoloVeicolo usato dai lavoratori per i ritiri a domiciliotarga, tipologia, carico_massimo, stato, cid_lavoratore*targaOrariOrario di apertura e pausa associato a una sedeid_orari, data, ora_inizio, ora_fine, inizio_pausa, fine_pausa, codice_sede*id_orariTurnoTurno lavorativo assegnato a un lavoratoreid_turno, data, ora_inizio, ora_fine, inizio_pausa, fine_pausa, cid_lavoratore*id_turnoSedeSede AMA fisicacodice_sede, indirizzo, capcodice_sedeLista_CAPAssociazione tra CAP e sedi che li servonocodice_sede*, capcodice_sede*, capPrenotazionePrenotazione effettuata dal cliente per il ritiro o la consegna in sedecodice_prenotazione, foto_rifiuto, descrizione_oggetto, tipologia_servizio, data, orario, stato_prenotazione, costo, codice_fiscale_cliente*, cid_lavoratore*, codice_sede*codice_prenotazioneValutazioneFeedback fornito dal cliente dopo il serviziocodice_prenotazione*, voto, commentocodice_prenotazione* (PK + FK)\n\nüìó Dizionario delle Relazioni\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRelazioneDescrizioneEntit√† CoinvolteAttributieffettuareUn cliente pu√≤ effettuare pi√π prenotazioniCliente ‚Äì Prenotazione‚ÄîottenereOgni prenotazione pu√≤ avere una valutazionePrenotazione ‚Äì Valutazione‚ÄîscrivereOgni cliente pu√≤ scrivere una valutazioneCliente ‚Äì Valutazione‚ÄîingaggiareOgni prenotazione ha un lavoratore assegnatoPrenotazione ‚Äì Lavoratore‚ÄîutilizzareOgni lavoratore pu√≤ essere associato a un veicoloLavoratore ‚Äì Veicolo‚ÄîgestireOgni sede gestisce pi√π prenotazioniSede ‚Äì Prenotazione‚ÄîservireUna sede serve uno o pi√π CAPSede ‚Äì Lista_CAP‚ÄîlavorareUn lavoratore √® associato a una sedeLavoratore ‚Äì Sede‚ÄîrispettareUn lavoratore √® associato ai turni lavorativiLavoratore ‚Äì Turno‚ÄîavereUna sede ha orari giornalieri di apertura/chiusuraSede ‚Äì Orari‚Äî\n\n‚úÖ Tutti i riferimenti sono coerenti con lo schema E-R fin"},"UNI/ANNO-2/BASE-DI-DATI/Studio-esame":{"slug":"UNI/ANNO-2/BASE-DI-DATI/Studio-esame","filePath":"UNI/ANNO 2/BASE DI DATI/Studio esame.md","title":"Studio esame","links":[],"tags":[],"content":"Programma Esame Basi di Dati e di Conoscenza - Prof. Vocca\nObiettivo\nSuperare con successo l‚Äôesame scritto attraverso lo studio mirato di modellazione, normalizzazione, algebra relazionale e SQL, con particolare attenzione agli esercizi presenti nei compiti passati.\n\n‚ú® Argomenti da Studiare\n1. Modellazione Concettuale (ER)\n\n\nEntit√†, attributi, identificatori\n\n\nRelazioni (cardinalit√†, ruoli)\n\n\n- Generalizzazioni e aggregazioni\n\nEsercizi comuni: visite mediche, ricette, quadri, teatri, progetti aziendali, ecc.\n\n2. Traduzione ER ‚Üí Schema Relazionale\n\n\nTabelle da entit√† e relazioni\n\n\nRappresentazione N:N con attributi\n\n\nGerarchie (ISA)\n\n\nListe ordinate e sequenze\n\n\n3. Normalizzazione e Modellazione Logica\n\n\nDipendenze funzionali\n\n\nChiavi candidate e primarie\n\n\nForme Normali: 1NF, 2NF, 3NF, BCNF\n\n\nDecomposizioni corrette\n\n\nEsempi di normalizzazione completa\n\n\n4. SQL\n\n\nSELECT con JOIN, GROUP BY, HAVING\n\n\nSubquery (correlate e non)\n\n\nClausole: IN, ALL, EXISTS, NOT EXISTS\n\n\nEsercizi frequenti:\n\n\nProdotti con max/min quantit√†\n\n\nAppelli condivisi da studenti\n\n\nEventi e prenotazioni filtrati\n\n\n\n\n5. Algebra Relazionale\n\n\nOperatori: selezione, proiezione, join, differenza, divisione\n\n\nTraduzione di interrogazioni SQL in algebra\n\n\nEsercizi con 2+ tabelle\n\n\n6. Vincoli e Integrit√†\n\n\nCHECK complessi\n\n\nIntegrit√† referenziale\n\n\nAnomalie e vincoli logici\n\n\n\nüóìÔ∏è Piano di Studio (4 settimane)\nSettimana 1: Basi della Modellazione\n\n\nGiorno 1-2: Entit√† e Attributi\n\n\nGiorno 3: Relazioni, Cardinalit√†\n\n\nGiorno 4: Gerarchie, ISA\n\n\nGiorno 5-6: ER ‚Üí Schema Relazionale\n\n\nGiorno 7: Esercizi di modellazione\n\n\nSettimana 2: Normalizzazione\n\n\nGiorno 8-9: Dipendenze funzionali, chiavi\n\n\nGiorno 10: 1NF, 2NF, 3NF\n\n\nGiorno 11: BCNF, decomposizioni\n\n\nGiorno 12-13: Casi pratici\n\n\nGiorno 14: Simulazione\n\n\nSettimana 3: SQL e Algebra\n\n\nGiorno 15-16: SQL base e subquery\n\n\nGiorno 17: EXISTS, ALL, MIN/MAX\n\n\nGiorno 18: Algebra relazionale - teoria\n\n\nGiorno 19: Algebra relazionale - esercizi\n\n\nGiorno 20-21: Esercizi misti SQL + Algebra\n\n\nSettimana 4: Ripasso e Simulazioni\n\n\nGiorno 22: Vincoli di integrit√†\n\n\nGiorno 23-24: Casi completi (ER ‚Üí SQL)\n\n\nGiorno 25: Compito simulato\n\n\nGiorno 26: Correzione errori\n\n\nGiorno 27-28: Ripasso mirato\n\n\n\nüîπ Suggerimenti\n\n\nParti sempre da carta e penna per ER e normalizzazione.\n\n\nEsegui query SQL direttamente su un DBMS (come MySQL o SQLite).\n\n\nVerifica sempre i vincoli logici impliciti e la correttezza semantica delle query.\n\n\nRipeti gli esercizi dei compiti precedenti almeno 2 volte.\n\n\nFammi sapere se vuoi anche un foglio Excel spuntabile o un PDF impaginato!"},"UNI/ANNO-2/BASE-DI-DATI/fotobasi/BASI-LEZ.6":{"slug":"UNI/ANNO-2/BASE-DI-DATI/fotobasi/BASI-LEZ.6","filePath":"UNI/ANNO 2/BASE DI DATI/fotobasi/BASI LEZ.6.md","title":"BASI LEZ.6","links":[],"tags":[],"content":"üß† Introduzione al Modello Entit√†-Relazione (ER)\nQuando si progetta una base di dati, lo scopo √® rappresentare in modo efficace una certa realt√† ‚Äî ad esempio un‚Äôazienda, una scuola, un sito web ‚Äî attraverso i dati. Per fare ci√≤ si usano dei modelli: strumenti astratti che ci aiutano a descrivere i dati, a organizzarli, e a rappresentarne le relazioni.\nI modelli dei dati sono un po‚Äô come i linguaggi: ci offrono regole e costrutti per esprimere concetti. Esistono modelli logici, che sono quelli implementati nei sistemi di gestione dei database (DBMS) ‚Äî come il modello relazionale, il gerarchico, il reticolare, o quello a oggetti. E poi ci sono i modelli concettuali, pi√π astratti, che vengono usati nelle prime fasi della progettazione. Tra questi, il pi√π famoso √® proprio il modello Entit√†-Relazione, spesso abbreviato in ER.\n\nüèóÔ∏è Fasi della Progettazione di una Base di Dati\nLa progettazione di una base di dati avviene su tre livelli:\n\n\nProgettazione concettuale: rappresenta i concetti del mondo reale. √à come se ci chiedessimo: Quali sono gli oggetti fondamentali di questa realt√†? Come si relazionano tra loro?\n\n\nProgettazione logica: trasforma la visione concettuale in una forma pi√π tecnica, adatta al DBMS. Se prima parlavamo di concetti, ora parliamo di tabelle, chiavi e relazioni.\n\n\nProgettazione fisica: si occupa dei dettagli su come i dati sono memorizzati su disco (es. struttura degli indici, partizionamento, ecc.).\n\n\nImmagina di voler creare un database per un‚Äôuniversit√†. A livello concettuale definisci entit√† come Studente, Corso, Esame. A livello logico, crei le tabelle corrispondenti. A livello fisico, decidi come archiviare queste tabelle nel sistema.\n\nüîç Il Modello Entit√†-Relazione: Cos‚Äô√® e Come Funziona\nIl modello ER √® uno strumento per descrivere in modo astratto i dati e le loro relazioni. √à utile perch√© ci permette di progettare indipendentemente dal tipo di database o dal linguaggio che useremo per implementarlo.\n‚úÖ Entit√†\nUn‚Äôentit√† √® un oggetto del mondo reale che vogliamo rappresentare. Pu√≤ essere una cosa concreta (una persona, un‚Äôauto) o astratta (una prenotazione, un esame). L‚Äôimportante √® che abbia senso anche presa da sola.\nEsempi:\n\nStudente, con attributi come nome, cognome, matricola.\nAutomobile, con numero di telaio, marca, modello.\nConto corrente, con numero conto, tipo, saldo.\n\nOgni entit√† pu√≤ avere istanze: ogni singolo studente √® un‚Äôistanza dell‚Äôentit√† Studente.\n\nüîó Relazioni\nUna relazione rappresenta un collegamento logico tra due o pi√π entit√†. √à il modo in cui esprimiamo che gli oggetti del nostro mondo interagiscono.\nEsempio: La relazione Possiede tra Persona e Automobile. Ogni persona pu√≤ possedere una o pi√π auto, e ogni auto deve essere posseduta da una persona.\nAltri esempi:\n\nStudente - Iscritto - Corso\nDipendente - Lavora per - Azienda\nAutore - Scrive - Libro\n\nLe relazioni possono anche:\n\nEssere ricorsive (un‚Äôentit√† si relaziona con s√© stessa, es. Persona - Essere Genitore - Persona)\nCoinvolgere pi√π entit√† (relazioni ternarie, es. Chirurgo - Effettua - Intervento - In - Sala Operatoria)\n\n\nüßæ Attributi\nOgni entit√† (o relazione) ha attributi, che sono le propriet√† descrittive.\nEsempio: Per l‚Äôentit√† Automobile, gli attributi potrebbero essere:\n\nnumero telaio\nmodello\ncilindrata\nprezzo\n\nGli attributi hanno formato (stringa, numero, data), dimensione, possono essere obbligatori o opzionali, e hanno un dominio (insieme dei valori possibili).\n\nüîê Chiavi Primarie e Artificiali\nUna chiave primaria √® un attributo (o un insieme di attributi) che identifica univocamente ogni istanza di un‚Äôentit√†.\nEsempio:\n\nPer Automobile, potrebbe essere il numero di telaio.\nPer Studente, potrebbe essere la combinazione di nome, cognome e data di nascita (anche se √® meglio usare qualcosa di unico, come la matricola).\n\nA volte usiamo chiavi artificiali, cio√® ID numerici progressivi che non hanno significato ma servono solo a identificare univocamente (es. ID_cliente).\nAnche le relazioni possono avere attributi: ad esempio, nella relazione Acquistare tra Persona e Automobile, potremmo avere attributi come data_acquisto, prezzo.\n\nüß± Entit√† Forti e Deboli\n\nEntit√† forte: ha una propria chiave primaria, pu√≤ esistere autonomamente.\nEntit√† debole: non ha una chiave autonoma, ha senso solo se associata a un‚Äôentit√† forte.\n\nEsempio:\n\nConto √® un‚Äôentit√† forte.\nMovimento bancario √® un‚Äôentit√† debole, perch√© esiste solo in relazione a un conto.\n\nSpesso si assegna un ID anche alle entit√† deboli per renderle forti.\n\nüî¢ Molteplicit√† e Cardinalit√†\nLa molteplicit√† definisce quanti oggetti possono partecipare a una relazione. Si usa una notazione come (1,1), (0,N), ecc.\n\n1:1 ‚Üí un oggetto si collega a uno solo (es. Persona - CartaIdentit√†)\n1:N ‚Üí uno si collega a molti (es. Cliente - Ordina - Ordini)\nN:N ‚Üí molti a molti (es. Studente - Frequenta - Corso)\n\n\nüë®‚Äçüë©‚Äçüëß Ereditariet√† e IS-A\nNel modello ER possiamo modellare sottoinsiemi di entit√† tramite l‚Äôassociazione IS-A, cio√® una relazione di ereditariet√†.\nEsempio:\n\nPersona pu√≤ essere specializzata in Studente, che a sua volta pu√≤ essere specializzato in Fuori corso.\nLe entit√† figlie ereditano gli attributi della madre (es. Studente eredita nome, cognome da Persona).\n\nNon si rappresentano di nuovo nel diagramma, ma sono implicitamente ereditati.\nNota: nel modello ER classico, non si pu√≤ avere ereditariet√† multipla (cio√® un‚Äôentit√† figlia non pu√≤ avere due padri).\n\nüß¨ Generalizzazione\nLa generalizzazione √® l‚Äôoperazione inversa alla specializzazione: si parte da pi√π entit√† specifiche e si uniscono in una entit√† pi√π generale.\nEsempio:\n\nProfessore, Studente, Tecnico ‚Üí tutti possono essere generalizzati come Persona.\n\nLe entit√† figlie possono essere:\n\nDisgiunte: un‚Äôistanza √® solo in una sottoclasse.\nOverlapping: un‚Äôistanza pu√≤ essere in pi√π sottoclassi.\nComplete: tutte le istanze della superclasse appartengono a una sottoclasse.\nIncomplete: alcune istanze non appartengono a nessuna sottoclasse.\n\n\nQuesta √® la panoramica completa dei primi 40 concetti del corso. Fammi sapere se vuoi che continui con le slide successive o se vuoi trasformare questo in una presentazione, un‚Äôinfografica o un file PDF!"},"UNI/ANNO-2/FONDAMENTI/FONDAMENTI-DI-INFORMATICA-INDICE":{"slug":"UNI/ANNO-2/FONDAMENTI/FONDAMENTI-DI-INFORMATICA-INDICE","filePath":"UNI/ANNO 2/FONDAMENTI/FONDAMENTI DI INFORMATICA INDICE.md","title":"FONDAMENTI DI INFORMATICA INDICE","links":["UNI/ANNO-2/FONDAMENTI/FONDAMENTI-LEZ.1","UNI/ANNO-2/FONDAMENTI/FONDAMENTI-LEZ.2","UNI/ANNO-2/FONDAMENTI/FONDAMENTI-LEZ.3","UNI/ANNO-2/FONDAMENTI/FONDAMENTI-LEZ.4","UNI/ANNO-2/FONDAMENTI/FONDAMENTI-LEZ.5","UNI/ANNO-2/FONDAMENTI/FONDAMENTI-LEZ.6","UNI/ANNO-2/FONDAMENTI/FONDAMENTI-LEZ.7","UNI/ANNO-2/FONDAMENTI/FONDAMENTI-LEZ.8","UNI/ANNO-2/FONDAMENTI/FONDAMENTI-LEZ.9","UNI/ANNO-2/FONDAMENTI/FONDAMENTI-LEZ.10","UNI/ANNO-2/FONDAMENTI/FONDAMENTI-LEZ.11","UNI/ANNO-2/FONDAMENTI/FONDAMENTI-LEZ.12","UNI/ANNO-2/FONDAMENTI/FONDAMENTI-LEZ.13","UNI/ANNO-2/FONDAMENTI/FONDAMENTI-LEZ.14","UNI/ANNO-2/FONDAMENTI/FONDAMENTI-LEZ.15","UNI/ANNO-2/FONDAMENTI/FONDAMENTI-LEZ.16","UNI/ANNO-2/FONDAMENTI/FONDAMENTI-LEZ.17","UNI/ANNO-2/FONDAMENTI/FONDAMENTI-LEZ.18","UNI/ANNO-2/FONDAMENTI/FONDAMENTI-LEZ.19","UNI/ANNO-2/FONDAMENTI/FONDAMENTI-LEZ.20","UNI/ANNO-2/FONDAMENTI/FONDAMENTI-LEZ.21","UNI/ANNO-2/FONDAMENTI/FONDAMENTI-LEZ.22","UNI/ANNO-2/FONDAMENTI/FONDAMENTI-LEZ.23","UNI/ANNO-2/FONDAMENTI/FONDAMENTI-LEZ.24","UNI/ANNO-2/FONDAMENTI/FONDAMENTI-LEZ.25","UNI/ANNO-2/FONDAMENTI/FONDAMENTI-LEZ.26","UNI/ANNO-2/FONDAMENTI/FONDAMENTI-LEZ.27","UNI/ANNO-2/FONDAMENTI/FONDAMENTI-LEZ.28","UNI/ANNO-2/FONDAMENTI/FONDAMENTI-LEZ.29"],"tags":[],"content":"sito appunti\nFONDAMENTI LEZ.1\nFONDAMENTI LEZ.2\nFONDAMENTI LEZ.3\nFONDAMENTI LEZ.4\nFONDAMENTI LEZ.5\nFONDAMENTI LEZ.6\nFONDAMENTI LEZ.7\nFONDAMENTI LEZ.8\nFONDAMENTI LEZ.9\nFONDAMENTI LEZ.10\nFONDAMENTI LEZ.11\nFONDAMENTI LEZ.12\nFONDAMENTI LEZ.13\nFONDAMENTI LEZ.14\nFONDAMENTI LEZ.15\nFONDAMENTI LEZ.16\nFONDAMENTI LEZ.17\nFONDAMENTI LEZ.18\nFONDAMENTI LEZ.19\nFONDAMENTI LEZ.20\nFONDAMENTI LEZ.21\nFONDAMENTI LEZ.22\nFONDAMENTI LEZ.23\nFONDAMENTI LEZ.24\nFONDAMENTI LEZ.25\nFONDAMENTI LEZ.26\nFONDAMENTI LEZ.27\nFONDAMENTI LEZ.28\nFONDAMENTI LEZ.29"},"UNI/ANNO-2/FONDAMENTI/FONDAMENTI-LEZ.1":{"slug":"UNI/ANNO-2/FONDAMENTI/FONDAMENTI-LEZ.1","filePath":"UNI/ANNO 2/FONDAMENTI/FONDAMENTI LEZ.1.md","title":"FONDAMENTI LEZ.1","links":[],"tags":[],"content":"problemi risolti automaticamente\n\n\n                  \n                  Cos&#039;√® un problema? \n                  \n                \n\n√à la descrizione di un insieme di oggetti chiamati dati, ognuno di questi dati √® collegato da un insieme di relazioni, derivati da essi abbiamo l‚Äôinsieme di oggetti soluzioni\nperci√≤ avremmo:\n\nOggetti di partenza: dati\n-Oggetti a cui dobbiamo arrivare: soluzione\n\n\n\nEsempio di problema:\nSomma: dati due interi n e k trovare un terzo intero s tale che s=n+k\ntrovare la somma di 3+2 √® una istanza del problema\nInfatti possiamo dire che il problema Somma con i vari dati e oggetti la coppia (3,2) √® una istanza del problema Somma\nRisolvere un problema\nRisolvere un problema si tratta di trovare un metodo che sia in grado di risolvere qualunque istanza del problema ma\nEsistono istanze\n\nfacili\n\n2+2\n\n\ndifficili\n\nquando ad esempio non bastano le dita\n\n\nimpossibili\n\ntipo \\sqrt{-1}\nRisolvere autonomamente un problema attraverso un metodo che sia\n\n\ndiviso in passi elementari e finiti\nche portano alla soluzione\nchiunque pu√≤ avere la sua soluzione elementare poich√© dipende dal soggetto(se sei un matematico un passo elementare √® anche fare un integrale triplo)\n√à necessario quindi definire un procedimento che data una qualunque istanza del problema sia in grado mediante azioni di trovare la soluzione di quell‚Äôistanza\n\n\n\n                  \n                  cosa si intende per procedimento? \n                  \n                \n\n√à la descrizione di un insieme di azioni unita alla specifica dell‚Äôordine di svolgimento di quest‚Äôultime\n\nricorda che le azioni devono essere semplici definite e elementari\n\n\n\nStandard di istruzioni per Turing\n\nuna istruzione √® elementare se la scelgo in un insieme di esse di piccole dimensioni\nl‚Äôistruzione deve scegliere poche soluzioni possibili\nOgni istruzione deve poter essere eseguita utilizzando quantit√† di memoria limitata\n\n\nCosa significa poco?\nsignifica che deve essere costante indipendentemente dall‚Äôistanza e dall‚Äôinput\nData una istruzione essa sar√† composta da\n\nuna sola condizione\nuna sola azione\nL‚Äôinsegnante fa un esempio sulla somma dei numeri e ci mostra come per farla abbiamo bisogno di passi elementari definiti e generici che ci portano a questo\n\n\n\n\nIn questo esempio √® necessario rispettare caratteristiche come leggere scrivere e interpretare\nindipendentemente da quanto siano grandi i numeri dobbiamo effettuare una somma dovuto al confronto in una tabella 10*10 e eventualmente sommare un resto quindi avremo 10*10*2 e per sommare abbiamo bisogno di ricordare 3 cose, numero1 numero2 e il resto\nil tutto si pu√≤ ricondurre in\nse sono vere certe condizioni allora esegui queste azioni\nRisolvere un problema in modo autonomo\nQuando abbiamo una soluzione per ogni istanza del problema attraverso un procedimento che pu√≤ essere eseguito da un automa\n\nqualcuno in grado di risolvere il procedimento senza sapere tutto del problema\npossiamo quindi eseguire queste istruzioni per ottenere un risultato in modo autonomo\nper scrivere Meno posso dividere in stati una istruzione con q0 e q1 che indicano resto 0 e 1\nquindi se ho\nSe r=0 e leggo‚Ä¶\navr√≤ &lt;q_0,(9,5),4,q_1,Sinistra&gt;\nabbiamo 2 condizioni e 3 istruzioni quindi si definisce una QUINTUPLA\nnon √® proprio una macchina di Turing perch√© non stiamo specificando cosa fare ad ogni passaggio per ogni rispettivo nastro\n\nMacchina di Turing\nho 3 nastri che scorrono all‚Äôinfinito con delle celle alcune vuote alcune piene\nLe frecce indicano testine di lettura e scrittura\n\navremo quindi definite le varie istruzioni per Turing con &lt;q_0,(9,5,[]),(9,5,4),q_1,(S,S,S)&gt;\nLe varie q si chiamano stati interni\nle prime 2 sono di lettura le ultime 3 di scrittura\nS,S,S sta per sinistra sinistra sinistra per ogni nastro\nL‚Äôesecuzione di queste quintuple si chiama computazione\nle macchine singole si chiamano con T_{nomeoperazione}\nscritte in linguaggio Macchina e vengono eseguite da macchine \nricapitolando:\nmacchina: ESECUTORE\nMacchina: LINGUAGGIO DEI PROCEDIMENTI\nQuali problemi possiamo risolvere con questo sistema?\nlo vedremo al corso"},"UNI/ANNO-2/FONDAMENTI/FONDAMENTI-LEZ.10":{"slug":"UNI/ANNO-2/FONDAMENTI/FONDAMENTI-LEZ.10","filePath":"UNI/ANNO 2/FONDAMENTI/FONDAMENTI LEZ.10.md","title":"FONDAMENTI LEZ.10","links":[],"tags":[],"content":"Un modello realistico\n√à definito da istruzioni input e output FINITI definito da Turing\npossiamo definire che per ogni modello di calcolo realistico M\n\nM √® Turing equivalente\nossia L √® decidibile\\accettabile nel modello M ‚áê&gt; L √® decidibile\\accettabile nel modello Macchina di Turing \n\nsi pu√≤ trovare una definizione simile con\nun linguaggio L √® accettabile oppure decidibile se e solo se √® accettabile o decidibile per la macchina Macchina di Turing\nLa tesi di Church-Turing\nSostiene che non esiste un modello di calcolo pi√π potente della Macchina di Turing\ndando la definizione precedente\ninoltre M deve essere un modello ‚Äúragionevole‚Äù\n\novvero basato sul concetto di operazione elementare\n√à una tesi e non un Teorema\n\nIn sostanza dice\n√® calcolabile tutto e solo ci√≤ che pu√≤ essere calcolato dalla Macchina di Turing\nModello di calcolo\nogni linguaggio di programmazione rappresenta un modello di calcolo\nEsempio di Pascal minimo\nlinguaggio inventato da lei con meno cose basato su Pascal\ncosa abbiamo:\n\nvariabile(semplice)\nvariabili(strutturate)\n\narray\ninsiemi(set)\n\nsono tipo array\n\n\n\n\ncostanti\nche istruzioni abbiamo?\nassegnazione a‚Üêb;\nistruzioni condizionali:\n\nif (condizione) then\n\tistruzione 1;\n\t............;\n\tistruzione h;\nend; // lo uso per &quot;skippare&quot; l&#039;if se non si verifica\nelse begin\n\t.....;\nend;\n\nistruzioni di loop:\n\nwhile (condizione) do begin\n\t......;\nend;\n\nreturn\n\nVogliamo dimostrare che questo modello di calcolo √® Turing equivalente\nIn particolare, viene mostriamo come ‚Äútrasformare‚Äù un programma in PascalMinimo in una macchina di Turing di tipo trasduttore\nabbiamo una macchina P \\ in \\ PM \\rightarrow T \\in \\tau\nandiamo a trasformare le istruzioni che non ci piacciono per far si che ci piacciano sulla Macchina di Turing quindi andiamo a:\n\nEliminare array dalle condizioni\nSe abbiamo l‚Äôistruzione\n\nif (A[j] = 0) then\nLa facciamo diventare\nausilA &lt;- A[j];\nif (ausilA = 0) then\nCodice effettivo\nScriviamo una sola istruzione in ciascuna riga del programma e numeriamo le righe\nQuesto codice\ninput: array A di n elementi interi; intero k;\n \np ‚Üê 1; i ‚Üê 1;\n \nwhile (i ‚â§ n) do\n\tif (A[i] &gt; p) then \n\t\tp ‚Üê A[i];\nend;\n \nif (p &gt; k) then \n\tris ‚Üê k;\nelse\n\tris ‚Üê p;\n \noutput ris;\nOra andiamo a precisare le righe di codice e a modificare tutte quelle istruzioni per far si che siano adatte alla macchina di Turing\n1) p ‚Üê 1; \n2) i ‚Üê 1;\n \n3) while (i ‚â§ n) do\n4)   ausilA ‚Üê A[i];\n5)   if (ausilA &gt; p) then\n6)     p ‚Üê A[i];\n7)   i ‚Üê i+1;\n   end;   // qui possono non mettere numeri (sotto capirai perch√©)\n \n8) if (p &gt; k) then\n9)    ris ‚Üê k;\n10) else ris ‚Üê p;  // gli else credo di poterli scrivere su una sola riga\n11) output ris;\nOGNI RIGA √à UNO STATO DIFFERENTE\nandiamo a creare un trasduttore che lo replichi\nDefiniamo i Nastri\novviamente potremmo usarne solo 1 ma ci√≤ complicherebbe le cose in modo assurdo\nGeneralmente\nUn trasduttore GENERALE per un problema in PascalMinimo usa:\n\nnastro di input\nnastro di output\nun nastro per ogni variabile di tipo array sul quale memorizzare, in unario, l‚Äôindice dell‚Äôarray al quale voglio accedere (nella foto sotto quello con tutti &quot;1&quot;)\n\nper separare i vari elementi dell‚Äôarray uso un carattere speciale $\n\n\n\nIn questo caso\nAVR√í 8 NASTRI\n\n5 nastri per le variabili semplici\n\nN_{p} per p\nN_{i} per i\nN_{ausilA} per ausilA\nN_{k} per k\nN_{ris} per ris\n\n\n1 nastro N_{A} per la variabile di tipo array\n1 nastro per N_{indA} per l‚Äôindice con il quale accedere all‚Äôarray\n1 nastro di lavoro\n\nin questo esempio per l‚Äôarray usa i dollari invece nei lucidi prende per scontato che sia tutto su una cella\nDescrizione quintuple ad alto livello\nqueste sono meta quintuple ovvero una serie di quintuple ma che si racchiudono in una sola quintupla intuitiva e semplice che ha al suo interno\n\nlo stato attuale\nl‚Äôazione da svolgere ad alto livello\nlo stato successivo\nle testine saranno su fermo perch√© prendiamo per scontato che si sia gi√† mosso tutto nel mentre\npraticamente non conto le quintuple intermedie\n\n\nConversioni di Quintuple effettive\nandiamo a creare delle quintuple che passano da stato in stato seguendo un classico esecutore di codici\nquindi partiamo dallo stato q1 per poi andare nello stato successivo q_{i+1}\nQuintupla di assegnazione\n\nAssegnazione con Array\nSe la riga contiene un‚Äôistruzione di assegnazione che coinvolte una variabile A di tipo array\n\nviene copiato su N_{indA} in unario il valore dell‚Äôindice dell‚Äôelemento A cui si vuole accedere (la foto di prima con tutti &quot;1&quot;)\nci si posiziona sull‚Äôelemento nel nastro contenente A (cosa che ti ho spiegato prima)\nsi esegue l‚Äôassegnazione dopo la quale T entra nello stato q_{i+1}\n\n\nQuintupla di condizione if then\nQuando la riga contiene un‚Äôistruzione If (condizione) then..., viene calcolata la condizione\n\nse √® vera allora T entra nello stato q_{i+1},\naltrimenti entra nello stato dell‚Äôistruzione da eseguire quando √® falsa\n\n\nQuintupla con ciclo loop while\nQuando la riga contiene un‚Äôistruzione While (condizione) do..., viene calcolata la condizione\n\nse √® vera T entra nello stato q_{i+1} e poi di seguito fino all‚Äôultima istruzione del loop per poi rientrare in q_i (in pratica una volta finito il loop ritorno nello stato iniziale del loop e quindi al punto 1))\naltrimenti entra nello stato corrispondente allo stato dell‚Äôistruzione da eseguire dopo il loop\n\n"},"UNI/ANNO-2/FONDAMENTI/FONDAMENTI-LEZ.11":{"slug":"UNI/ANNO-2/FONDAMENTI/FONDAMENTI-LEZ.11","filePath":"UNI/ANNO 2/FONDAMENTI/FONDAMENTI LEZ.11.md","title":"FONDAMENTI LEZ.11","links":["UNI/ANNO-2/FONDAMENTI/FONDAMENTI-LEZ.5"],"tags":[],"content":"la scorsa lezione abbiamo visto il teorema 3.5\noggi vedremo il contro esempio con il teorema 3.6\nche dice:\nPer ogni macchina di Turing deterministica T di tipo riconoscitore ad un nastro esiste un programma AT scritto in accordo alle regole del linguaggio PascalMinimo tale che: per ogni parola x, se T(x) termina nello stato finale qF ‚àà {qA,qR} allora l‚Äôesecuzione di AT con input x restituisce q_F in output e se l‚Äôesecuzione di AT con input x restituisce q_A in output allora T(x) termina nello stato finale q_A\nPer dimostrarlo ci serve una macchina di Turing Universale\nUtilizzeremo una macchina di Turing Universale per poi convertirla in un programma U in PascalMinimo\nU che deve avere come input:\n\nuna descrizione D\n\nil codice della macchina di Turing\n\n\nuna T \\in \\vartheta \\wedge x \\in \\{0,1\\}^*\nLa nostra macchina T sar√† invece definita da &lt;Q_1,S_1,S_2,Q_2,M&gt;\n\nquindi avremo una cosa tale che l‚Äôesecuzione di U con input la descrizione di una macchina di Turing T e un input x per T simula la computazione U(T,x)\nAvr√≤ un insieme di quintuple P\nQuello che faccio √® dare un numero ad ogni quintupla dell‚Äôinsieme P per tenerle ordinate\nOra la quintupla H-esima sar√† ad esempio formata da &lt;q_{h1},S_{h1},q_{h2},m_h&gt;\nDefinisco le prime P e mi accorgo che se le divido in strati posso creare degli array\n\nad esempio posso avere la prima fetta che √® un array di tutti gli stati iniziali\nposso quindi fare Q_1[h] e giungere alla posizione di quel determinato stato iniziale di quella determinata quintupla\nquindi avr√≤\n\nQ1\nS1\nS2\nQ2\nM\n\nQuindi al nostro programma U passiamo tutti gli array, in input avremo:\nQ1[],S1[],S2[],Q2[],M[]\nOra abbiamo definito la struttura ma mancano i nastri\nessi saranno un array\nogni cella del nastro rappresenta un elemento dell‚Äôarray\nPer far partire una macchina di Turing dobbiamo definire\n\nla testina t‚Üê1\nlo stato di inizio q‚Üêq0\nabbiamo dei delimitatori del nastro di input pc‚Üê1 uc‚Üên\n\nche stanno per prima cella e ultima cella\n\n\n\nUna macchina universale ha il compito di trovare la quintupla e eseguirla\nquindi per farlo in Pascal minimo abbiamo l‚Äôobbligo di creare un while che terminer√† quando si finir√† negli stati q_A o q_R\nDescrizione dell‚Äôinput:\nIn input viene fornita la descrizione di T\n\n(negli array Q1, S1, S2, Q2 e M e nelle variabili q0, qA \\ e \\ qR)\ne del suo input (nell‚Äôarray N)\n\n\nCodice\nt &lt;- 1;   // variabile in cui memorizzo la posizione della testina (inizialmente 1)\nq &lt;- q_0;   // variabile in cui memorizziamo lo stato interno (inizialmente q_0)\n \nprimaCella &lt;- 1; \nultimaCella &lt;- n;  // inizio e fine del nastro di input\n \n// la macchina universale cercava le quintuple e le eseguiva ciclicamente, quindi la riproduco col while\nwhile(q != q_a AND q != q_r) do begin //&lt;- qui fa quello che dicevo prima\n    j &lt;- 1;\n    trovata &lt;- false;\n    while (trovata = false AND j &lt;= k) do   // k √® il numero di quintuple\n        if (q = Q_1[i] AND N[t] = S_1[j]) then \n            trovata &lt;- true;\n        else j &lt;- j+1;\n    end                   //&lt;- in questo ciclo che finisce qui cerchiamo \n\t\t\t\t\t\t  //la quintupla da eseguire\n    if (trovata = vero) then begin   //&lt;- quintupla trovata\n        N[t] &lt;- S_2[j];\n        q &lt;- Q_2[j];\n        t &lt;- t+M[j];\n        \n    // pc/uc (lo usa la prof per non riscrivere tutte queste righe sotto)\n        if (t &lt; primaCella) then begin   //&lt;- leggi il commento * sotto\n            primaCella &lt;- t;\n            N[t] &lt;- [];\n        end\n        if (t &lt; ultimaCella) then begin\n            ultimaCella &lt;- t;\n            N[t] &lt;- [];\n        end\n    end\n    else q &lt;- q_r;\nend\nOutput: q;\n \nCommento &quot;*&quot;\nin caso di scrittura si potrebbe andare a sinistra o a destra degli elementi dell‚Äôarray e quindi ‚Äúuscire‚Äù dalle celle definite nel nastro, visto che il nastro √® infinito dobbiamo posizionare dei blank al posto delle celle vuote nel nastro facendo N[t]=\\square\nCome simulare una macchina non deterministica attraverso un algoritmo in PascalMinimo\nQuesto algoritmo simula la coda di rondine con ripetizioni che si trova a qui\nLa chiamiamo U_{ND} , esso avr√† i seguenti dettagli:\n\nun contatore i inizializzato a 1\nsimula tutte le computazioni deterministiche di i istruzioni\n\nse una di esse accetta, allora accetta\naltrimenti; se tutte rigettano, allora rigetta\n\n\nse non fa nulla delle due incrementa i\n\nCodice in PascalMinimo\n\nSchema di come funziona la Ricorsione\n\nCodice pazzurdo da NON ricordare\n\nCosa bisogna ricordare?\n\nESISTONO LE FUNZIONI RICORSIVE IN PascalMinimo\nESISTONO LE FUNZIONI IN PascalMinimo\n\nle funzioni sono praticamente le simulazioni delle macchine di Turing\n\n\n"},"UNI/ANNO-2/FONDAMENTI/FONDAMENTI-LEZ.12":{"slug":"UNI/ANNO-2/FONDAMENTI/FONDAMENTI-LEZ.12","filePath":"UNI/ANNO 2/FONDAMENTI/FONDAMENTI LEZ.12.md","title":"FONDAMENTI LEZ.12","links":[],"tags":[],"content":"Grammatica\nfino ad ora abbiamo avuto a che fare con macchine che dato un linguaggio lo riconoscono e svolgono dei compiti\nIniziamo ora ad approcciarci alla grammatica che ha come scopo quello di generare tutte le parole di un linguaggio\n\ngrammatica √® il nome del modello generativo\nnelle lezioni a venire compresa questa chiariremo le seguenti cose:\ncome sono definite le grammatiche\ncome fanno a generare linguaggi e in che senso\nquali propriet√† hanno\nche relazione c‚Äô√® tra grammatiche e macchine di Turing\n\nCome sono definite\nLe Grammatiche sono una quadrupla G=&lt;V_t,V_n,P,S&gt; che sono rispettivamente:\n\n\nV_t  √® l‚Äôinsieme dei simboli terminali (che corrisponde all‚Äôalfabeto Œ£) .\n\nEsempio: se voglio descrivere parole fatte solo da a \\ e \\ b, allora avr√≤ V_T=\\{a,b\\}\n\n\n\nV_n √® l‚Äôinsieme dei simboli non terminali\n\nvengono usate come lettere temporanee per facilitare le trasformazioni\nalla fine dell‚Äôoutput non appaiono\nnon fanno parte dell‚Äôinsieme \\Sigma\n\n\n\nS ‚àà V_n √® un particolare simbolo non terminale detto assioma\n\nl‚Äôassioma √® l‚Äôinizio del processo di produzione\nTutte le derivazioni iniziano da S, quindi √® il punto di partenza.\n\n\n\nP √® l‚Äôinsieme delle produzioni\n\nLe produzioni sono le regole che permettono di sostituire simboli non terminali con altri simboli (terminali o non).\nOgni produzione √® una coppia:(\\alpha, \\beta) \\in (V_T \\cup V_N)^* \\times (V_T \\cup V_N)^*\ndove:\nŒ± e Œ≤ sono stringhe (parole) di simboli terminali e/o non terminali.\nL‚Äôasterisco * indica che possono essere stringhe di lunghezza arbitraria, anche vuote.\nCondizione importante: Œ± deve contenere almeno un simbolo non terminale, altrimenti non avrebbe senso trasformarla.\n\n\n\nalmeno una produzione √® nella forma S \\rightarrow \\beta\n\n\nObiettivo della grammatica\ngenerare parole di V_T^*\n\na partire dall‚Äôassioma\napplicando una dopo l‚Äôaltra le varie produzioni in P\n\nAlcune notazioni che ci servono per fare gli esercizi\nPartiamo da un piccolo esempio\nse abbiamo \\alpha e \\beta che sono due parole ad esempio \\alpha=001 e \\beta=abba la concatenazione \\alpha\\beta sar√† 001abba\nNotazione di derivazione e produzione\ndefinisce una grammatica come prima ovvero\nG=&lt;V_t,V_n,P,S&gt;\nse abbiamo poi x,y che sono \\in(V_T \\cup \\ V_N)^*:  scriviamo X \\xRightarrow[G]{} Y , questo si dice che x se derivato porta a y nella grammatica G ad esempio se avviene ci√≤:\n\nX = \\alpha_1 a \\alpha_2, \\quad Y = \\alpha_1 \\beta \\alpha_2 \\text{ con } \\alpha_1, \\alpha, \\alpha_2, \\beta \\in (V_T \\cup V_N)^*\ne ovviamente per avere in output y dobbiamo avere una produzione cos√¨\n\n\\alpha\\rightarrow \\beta\ninvece prendendo ci√≤ che √® stato detto prima in modo identico possiamo definire che con pi√π proiezioni e quindi derivazioni possiamo raggiungere un risultato y\n\n\nse abbiamo  x,y  \\in(V_T \\cup \\ V_N)^*:  scriviamo X \\xRightarrow[*]{G} Y , diciamo che y deriva da x se esiste una sequenza di parole x_1,x_2,...x_n \\in(V_T \\cup V_N) tali che\nX \\xRightarrow[G]{} x_1 \\xRightarrow[G]{} x_2 \\xRightarrow[G]{} \\cdots \\xRightarrow[G]{} x_n \\xRightarrow[G]{} Y\nuna parola y\\in V_T^* si dice generata da G se  S \\xRightarrow[*]{G} Y\npiccole note:\nper (V_T \\cup \\ V_N)^* , si intende l‚Äôinsieme di tutte le frasi di terminali e non\nuna parola generata da G si dice forma di frase\n\nDefinizione di linguaggio generato da G\nIl linguaggio generato da G, che indichiamo con L(G), √® l‚Äôinsieme delle parole generate da G, ossia\nL(G) = \\left\\{ y \\in V_T^* : S \\xRightarrow[G]{*} Y \\right\\}\n\nnotare che y √® una parola che appartiene all‚Äôinsieme di tutti i terminali quindi che sono nella grammatica\n\nUltime notazioni prima di fare 1000 esercizi\n\nSe due o pi√π produzioni hanno la stessa parte sinistra esse si possono raggruppare mediante il simbolo | (da leggere come ‚Äò‚Äòoppure‚Äô‚Äô)\n\nad esempio, le due produzioni S ‚Üí a e S ‚Üí b possono essere scritte nella forma S ‚Üí a | b\n\n\n\\epsilon rappresenta la parola vuota (ossia, la parola che non contiene alcun carattere)\n\nuna produzione che porta a \\epsilon tipo \\alpha \\rightarrow \\epsilon si dice \\epsilon -produzione\nun linguaggio vuoto √® segnato da questo simbolo : \\Lambda\n\n\n\nEsercizi"},"UNI/ANNO-2/FONDAMENTI/FONDAMENTI-LEZ.13":{"slug":"UNI/ANNO-2/FONDAMENTI/FONDAMENTI-LEZ.13","filePath":"UNI/ANNO 2/FONDAMENTI/FONDAMENTI LEZ.13.md","title":"FONDAMENTI LEZ.13","links":[],"tags":[],"content":"Classifiche delle grammatiche di Chomsky\nChomsky defin√¨ 3 tipi di grammatiche:\n\nG_0\nG_1\nG_2\nG_3\n\n\nOgni grammatica interna √® sottoinsieme di quella esterna\nG3 ‚äÜ G2 ‚äÜ G1‚äÜ G0\nOgni grammatica genera un linguaggio L_{i}\ncon L3 ‚äÜ L2 ‚äÜ L1‚äÜ L0\nDefiniamo le varie grammatiche\n\nDi tipo 0 sono illimitate senza vincoli come quelle viste finora\nDi tipo 1 se\n\nper ogni proiezione tipo \\alpha \\rightarrow \\beta abbiamo che \\alpha \\leq \\beta\ntipo aBA ‚Üí c non √® ammessa in una grammatica di tipo 1\n\n\nDi tipo 2 se\n\nla parte sinistra della produzione √® un solo carattere non terminale\nquindi abbiamo una forma A \\rightarrow \\alpha con A \\in V_N \\ e \\ \\alpha \\in (V_T \\cup V_N)*\naB ‚Üí cd non √® ammesso\nquesta grammatica si dice context-free\n\n\nDi tipo 3 se\n\nla parte sinistra √® un solo simbolo non terminale e quella destra un solo simbolo terminale\nossia, le produzioni di una grammatica di tipo 3 hanno tutte la forma A ‚Üí a oppure A \\rightarrow aB con A,B \\in V_N \\ e \\  a\\in V_T\nviene detta grammatica regolare\n\nin poche parole:\n\no un solo simbolo terminale\noppure un simbolo terminale seguito da un non terminale\n\n\n\n\n\n\n\n\n\n                  \n                  La parola vuota \\epsilon √® solo nella grammatica di tipo 0\n                  \n                \n\nTuttavia possiamo comunque prendere le grammatiche &gt;0 e estenderle per generare lo stesso linguaggio della grammatica di partenza con in pi√π la parola vuota\naggiungiamo quindi un nuovo non terminale S‚Äô che assumer√† il ruolo di assioma (e, dunque il vecchio assioma S non sar√† pi√π assioma perch√© S&#039; lo subentra )\ninseriamo poi la produzione S‚Äô ‚Üí \\epsilon inseriamo la produzioneS‚Äô \\rightarrow S\nprocediamo a dimostrare\nTeorema per G1\n\nUna epsilon produzione √® quando abbiamo una produzione nella forma \\alpha \\rightarrow \\epsilon\nquindi praticamente dice che non posso avere \\alpha \\rightarrow S perch√© non rispetterebbe le regole\nci√≤ per√≤ non ci vieta di togliere questa limitazione per ogni t&gt;1\nTeorema per G2\n\npraticamente quello che dice √® che se rimuoviamo le epsilon produzioni dalla grammatica otteniamo una grammatica normalissima con il tipo t&gt;1 allora significa che possiamo estendere con epsilon quindi rispondiamo alla cosa detta prima\nQuesto teorema non si applica a G1 perch√© non si rispetterebbe la regola del ‚áê\nTeorema G3\n\nESEMPIO 4\n\nQuindi praticamente dobbiamo generare tutte parole uguali una a fianco dell‚Äôaltra\ncon tali produzioni\n\n\nESERCIZIO\n"},"UNI/ANNO-2/FONDAMENTI/FONDAMENTI-LEZ.14":{"slug":"UNI/ANNO-2/FONDAMENTI/FONDAMENTI-LEZ.14","filePath":"UNI/ANNO 2/FONDAMENTI/FONDAMENTI LEZ.14.md","title":"FONDAMENTI LEZ.14","links":[],"tags":[],"content":"Noi vogliamo Dimostrare che la nostra Grammatica genera esattamente e soltanto il linguaggio L = \\{ xx : x ‚àà \\{a,b\\}^+\\}\nieri abbiamo dimostrato che L\\subseteq L(G)\noggi dimostriamo che L(G) \\subseteq L\nper poi arrivare alla conclusione che  L(G) = L\nInizio dimostrazione\niniziamo a precisare che non si pu√≤ fare fin dall‚Äôinizio S \\rightarrow X poich√© finiremmo in una sorta di blocco\n\nnon potremmo mai generare alcuna parola in \\{a,b\\}^{+}\nnon potremmo mai togliere il non terminale X\nnon potremmo pi√π aggiungere caratteri a o b a sinistra di X\nandiamo per√≤ a fare n produzioni di tipo\n\nquello che poi possiamo fare √® slidare le lettere dell‚Äôalfabeto oppure togliere la X,(puoi vederlo nella lezione scorsa)\nuna volta fatti i vari swap ecc‚Ä¶ appena arrivo alla sitauzione\n\nSull‚Äôultimo devo utilizzare una tra le due produzioni\nU_{x1}X \\rightarrow x1\n\nGrammatiche e macchine di Turing\nDue definizioni importanti\nGRAMMATICA\nLa grammatica √® un modello di calcolo e descrivere come si possono generare le parole appartenenti a un insieme di parole\nMACCHINA DI TURING\nLa Macchina di Turing √® un modello di calcolo e una macchina di Turing descrive come si fa a riconoscere le parole appartenenti a un insieme di parole.\n\n\n                  \n                  Vogliamo dimostrare che i due modelli di calcolo sono equivalenti \n                  \n                \n\nOssia che\n\nse un linguaggio √® accettato da una macchina di Turing allora esiste una grammatica (di tipo 0) che lo genera\nse un linguaggio √® generato da una grammatica (di tipo 0) allora esiste una macchina di Turing che lo accetta.\n\n\n\nNB: Il tipo non √® troppo importante, ma se proprio devo sceglierlo la scelgo di tipo 0 dato che ho meno vincoli.\nci√≤ da inizio al teorema G.4\nTeorema G.4\nChe vuole dimostrare che per ogni tipo di linguaggio accettabile L esiste una grammatica G tale che L=L(G) con G di tipo 0\nPer dimostrare questo teorema ci serve un altro teorema\nIl teorema burlone pasticcione dell‚Äôesercizio che non far√≤\nQuesto teorema ci dice che\n\nSe abbiamo una macchina riconoscitore T a un nastro\n\ncon alfabeto {0,1}\n\n\nesiste una macchina di Turing T‚Äô con un solo nastro semi-infinito e che non scrive mai il blank \\square tale che, per ogni x \\in \\{0,1\\}^* , o_T(X)=o_{T&#039;}(X)\nquindi sostanzialmente abbiamo due macchine\nuna con e una senza blank\nuna con un solo nastro infinito e una con un nastro finito che ha un punto di inizio ma a destra √® infinito\nessi avranno stesso output\n\nContinuiamo con il teorema G.4\nDefiniamo una macchina di Turing che accetta L, definita con\nT = ( \\{0,1\\}, \\ Q, \\ P_{T}, \\ q_{0}, \\ \\{q_A, q_R\\} )\nDove:\n\n\\{0,1\\} √® l‚Äôalfabeto\nQ √® l‚Äôinsieme degli stati\nP_{T} √® il programma (insieme delle transizioni)\n\nle transizioni erano i passaggi di stato\n\n\nq_{0} √® lo stato iniziale\n{q_A, q_R} sono gli stati finali (accetta/rifiuta)\n\n‚û° E assumiamo che:\n\nT abbia un solo nastro\nIl nastro sia semi-infinito (va solo a destra)\nT non scriva mai il blank\n\nDefinita la macchina di Turing procediamo a definire una grammatica G\nG = (V_{T}, \\ V_{N}, \\ P_{G}, \\ S)\ndove rispettivamente abbiamo:\n\nV_{T}‚Äã=\\{0,1,a,\\square \\} = simboli terminali\nV_N = \\{ S, A, C, D, X, U_0, U_1 \\} \\cup \\{ q_i \\} \\cup \\{ q_A, q_R \\} = simboli non terminali\n\nS √® l‚Äôassioma\nq_{i} sono gli stati della macchina Turing\nU_0, U_1 rappresentano 0 e 1 sotto forma ‚Äúcodificata‚Äù\na, \\square servono per ‚Äúsegnare‚Äù o ‚Äúgestire‚Äù parti della configurazione del nastro\n\n\nP_{G} = insieme delle produzioni (verr√† descritto dopo)\n\nOra l‚Äôidea √® quella di fare una simulazione del comportamento di T con la grammatica G\nLa simulazione avviene in 3 fasi precise\nFASE 1\nCerchiamo di generare una parola formata da:\na \\ Q_{0} \\ xdove\n- x \\in \\{0,1\\}^{*} √® l‚Äôinput\n- q_{0} √® lo stato iniziale\n- a √® un marcatore/ancora che divide la parte ‚Äúdi sinistra‚Äù (simulazione) da quella ‚Äúdi destra‚Äù,\nFASE 2\nAndiamo a simulare la computazione di T su x\n\nla grammatica andr√† ad applicare le sue produzioni per simulare le varie quintuple(o transizioni) di T\n\nuna produzione=un passo della macchina di Turing\n\n\n\nFASE 3\nSe la simulazione termina in q_A non ci serve sapere altro quindi togliamo tutto e lasciamo solo x  sul nastro\nFase 1 approfondita\n(Ricordiamo che la macchina vuole ):\nRiconoscere se una stringa √® della forma xx, cio√® due copie consecutive di una parola x.\nPer generare quanto detto creiamo le seguenti produzioni\n\n\n\n                  \n                  spiegazione delle produzioni passo per passo \n                  \n                \n\n1‚Äô) S ‚Üí 0 U‚ÇÄ A ‚óª | 1 U‚ÇÅ A ‚óª | a Q‚ÇÄ ‚óª\n\n\nQuesta regola serve per iniziare la costruzione della stringa:\n\n\nS ‚Üí 0 U‚ÇÄ A ‚óª significa: se il primo simbolo √® 0, mettilo e attacca U‚ÇÄ (un marcatore che ricorda che il simbolo era un 0) e continua con A.\n\n\nS ‚Üí 1 U‚ÇÅ A ‚óª simile ma per il 1\n\n\nS ‚Üí a Q‚ÇÄ ‚óª √® il caso base: nessun simbolo da costruire ‚Üí vado direttamente a simulare\n\n\n\n\n‚û°Ô∏è Serve a costruire l‚Äôinizio della configurazione: input + a Q‚ÇÄ + copia + blank\n\n2‚Äô) U‚ÇÄ 0 ‚Üí 0 U‚ÇÄ, U‚ÇÄ 1 ‚Üí 1 U‚ÇÄ\n\n\nSposta U‚ÇÄ a destra attraverso i simboli, lasciandoli invariati.\n\n\nServe a far scorrere U‚ÇÄ fino a raggiungere X (che segna il punto in cui iniziare a copiare la seconda met√†).\n\n\n\n3‚Äô) U‚ÇÅ 0 ‚Üí 0 U‚ÇÅ, U‚ÇÅ 1 ‚Üí 1 U‚ÇÅ\n\n\nIdentico a 2‚Äô, ma per i simboli U‚ÇÅ (che rappresentano una copia di 1)\n\n\n‚û°Ô∏è U‚ÇÄ e U‚ÇÅ sono segnaposto per copiare, e scorrono verso destra finch√© non incontrano X.\n\n4‚Äô) U‚ÇÄ X ‚Üí X0, U‚ÇÅ X ‚Üí X1\n\n\nQuando U‚ÇÄ o U‚ÇÅ incontrano X, iniziano a scrivere il simbolo copiato a destra di X.\n\n\nEs: U‚ÇÄ X ‚Üí X 0 ‚Üí vuol dire: ‚Äúho letto uno 0, quindi lo scrivo accanto a X‚Äù\n\n\nIdem con 1\n\n\n\n\n\n5‚Äô) U‚ÇÄ X ‚Üí a Q‚ÇÄ 0, U‚ÇÅ X ‚Üí a Q‚ÇÄ 1\n\n\nInvece di lasciare X, si inserisce a Q‚ÇÄ tra le due met√† della stringa.\n\n\nSi sta ‚Äúcompletando‚Äù la configurazione iniziale: la testina √® sul primo simbolo della seconda met√†, lo stato iniziale √® Q‚ÇÄ, e tutto a sinistra √® la prima met√†.\n\n\n‚û°Ô∏è Questo √® il punto di transizione tra la generazione dell‚Äôinput e la simulazione della macchina.\n\n\nFase 2 approfondita\nDopo la fase 1 abbiamo quindi una parola che pone un inizio per poi fare la simulazione vera e propria attraverso varie produzioni\nx \\ a \\ Q_{0} \\ x \\ \\square\ndove\n\ni primi 3 li abbiamo visti prima\nil secondo x √® la copia dell‚Äôinput\n\\square √® il simbolo blank che serve esclusivamente per indicare la fine della parola scritta sul nastro\ncon le produzioni lavoreremo solo con gli ultimi 3\nOra la grammatica G deve simulare le transizioni della macchina T attraverso le varie produzioni\n\nSostanzialmente con una macchina di Turing abbiamo principalmente 2 transizioni\n\n&lt;q_{i1}, \\ h_{1}, \\ h_{2}, \\ q_{i2}, \\ sx&gt;\n&lt;q_{i1}, \\ h_{1}, \\ h_{2}, \\ q_{i2}, \\ dx&gt;\n\nPer effettuare scrittura e spostamento le produzioni sono le seguenti\nLo fa utilizzando produzioni del tipo\nb q·µ¢‚ÇÅ h‚ÇÅ ‚Üí q·µ¢‚ÇÇ b h‚ÇÇ\n(per la mossa a sinistra)\nOppure\nq·µ¢‚ÇÅ h‚ÇÅ b ‚Üí q·µ¢‚ÇÇ h‚ÇÇ b\n(per la mossa a destra)\n\nq oltre a essere uno stato √® anche una testina\nCome funzionano:\nQuello che abbiamo prima della produzione quindi prima della \\rightarrow √® la struttura della quintupla prima di effettuarla dove quindi avremo ad esempio:\nb √® un ‚Äúplaceholder‚Äù per qualsiasi simbolo che √® nell‚Äôalfabeto come 0,1 o blank\nq·µ¢‚ÇÅ √® lo stato attuale prima della transizione, e indica dove si trova la testina (che √® posizionata su h‚ÇÅ)\nh‚ÇÅ √® il simbolo da dover leggere\ninvece dopo la produzione avremmo:\nh‚ÇÇ √® quello che ho scritto al posto di h‚ÇÅ\nb √® sempre quello stesso simbolo\nq·µ¢‚ÇÇ √® lo stato in cui siamo entrati ed √® anche la testina (ad esempio CHE SI TROVA A SINISTRA DIb PERCH√â CI SIAMO SPOSTATI A SX.)\nPossiamo fare due esempi uno per lo spostamento a sx e uno a dx\n\n\n\n                  \n                  spostamento a sx \n                  \n                \n\nüü¶ ESEMPIO 1: Spostamento a SINISTRA\nSupponiamo di avere la quintupla:\n‚ü®q‚ÇÅ, 1, 0, q‚ÇÇ, sx‚ü©\n\nSignifica: ‚ÄúSe sono nello stato q‚ÇÅ e leggo 1, scrivo 0, passo a q‚ÇÇ, e mi sposto a sinistra‚Äù.\nüß± Configurazione PRIMA:\n... b q‚ÇÅ 1 ...\n\nDove:\n\n\nq‚ÇÅ √® lo stato/testina sulla cella che contiene 1\n\n\nb √® il simbolo a sinistra (pu√≤ essere 0, 1 o ‚óª)\n\n\nüéØ Produzione corrispondente nella grammatica:\nb q‚ÇÅ 1 ‚Üí q‚ÇÇ b 0\n\nüß± Configurazione DOPO:\n... q‚ÇÇ b 0 ...\n\n‚úÖ La testina (q‚ÇÇ) si √® spostata a sinistra, 1 √® stato sovrascritto con 0, e l‚Äôordine dei simboli cambia per riflettere la nuova posizione.\n\n\n\n\n\n                  \n                  spostamento a dx \n                  \n                \n\nüü© ESEMPIO 2: Spostamento a DESTRA\nSupponiamo di avere la quintupla:\n‚ü®q‚ÇÅ, 1, 0, q‚ÇÇ, dx‚ü©\n\nSignifica: ‚ÄúSe sono nello stato q‚ÇÅ e leggo 1, scrivo 0, passo a q‚ÇÇ, e mi sposto a destra‚Äù.\nüß± Configurazione PRIMA:\n... q‚ÇÅ 1 b ...\n\n\n\nq‚ÇÅ √® la testina sulla cella con 1\n\n\nb √® il simbolo a destra (qualunque simbolo del nastro)\n\n\nüéØ Produzione corrispondente nella grammatica:\nq‚ÇÅ 1 b ‚Üí 0 q‚ÇÇ b\n\nüß± Configurazione DOPO:\n... 0 q‚ÇÇ b ...\n\n‚úÖ La testina (q‚ÇÇ) si √® spostata a destra, 1 √® stato sostituito con 0, e q‚ÇÇ si trova ora sopra il simbolo b.\n\n\nüîÅ Riepilogo Visuale\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTipo spostamentoPRIMAProduzioneDOPOSinistrab q‚ÇÅ 1b q‚ÇÅ 1 ‚Üí q‚ÇÇ b 0q‚ÇÇ b 0Destraq‚ÇÅ 1 bq‚ÇÅ 1 b ‚Üí 0 q‚ÇÇ b0 q‚ÇÇ b\nAndiamo a creare delle definizioni per le varie m(mosse)\nMossa verso sx\nPer una quintupla generica che va verso sinistra \\in P_T\n&lt;q·µ¢‚ÇÅ, h‚ÇÅ, h‚ÇÇ, q·µ¢‚ÇÇ, f&gt;\navremo una generica produzione di questo tipo \\in P_{G}\nQ·µ¢‚ÇÅ h‚ÇÅ ‚Üí Q·µ¢‚ÇÇ h‚ÇÇ\n\n\n                  \n                  cosa succede se leggiamo blank dopo l&#039;ultimo carattere a dx? \n                  \n                \n\navremo sicuramente una quintupla di questo tipo&lt;q·µ¢‚ÇÅ, ‚óª, h‚ÇÇ, q·µ¢‚ÇÇ, sx&gt;\nDovremmo scrivere h_2 sul blank e aggiungere un nuovo blank a destra cos√¨ da rispettare le prerogative del nastro\nquindi avremmo una produzione di questo tipo:\nb Q·µ¢‚ÇÅ ‚óª ‚Üí Q·µ¢‚ÇÇ b h‚ÇÇ ‚óª\n\n\nMossa fermo\nPer ogni quintupla &lt;q·µ¢‚ÇÅ, h‚ÇÅ, h‚ÇÇ, q·µ¢‚ÇÇ, f&gt; in P_{T}\nP_{G} contiene le produzioni Q·µ¢‚ÇÅ h‚ÇÅ ‚Üí Q·µ¢‚ÇÇ h‚ÇÇ\nsemplicemente non ci andiamo a muovere tra i simboli\n\n\n                  \n                  E se avessimo una quintupla del tipo &lt;q·µ¢‚ÇÅ, ‚óª, h‚ÇÇ, q·µ¢‚ÇÇ, f&gt;?\n                  \n                \n\nAvremo una produzione del tipo Q·µ¢‚ÇÅ ‚óª ‚Üí Q·µ¢‚ÇÇ h‚ÇÇ ‚óª\n\n\nMossa verso dx\nPer ogni quintupla &lt;q·µ¢‚ÇÅ, h‚ÇÅ, h‚ÇÇ, q·µ¢‚ÇÇ, ds&gt; in P_{T}\nP_{G} contiene le produzioni Q·µ¢‚ÇÅ h‚ÇÅ ‚Üí h‚ÇÇ Q·µ¢‚ÇÇ\n\n\n                  \n                  E se avessimo una quintupla del tipo &lt;q·µ¢‚ÇÅ, ‚óª, h‚ÇÇ, q·µ¢‚ÇÇ, dx&gt;?\n                  \n                \n\nAvremo una produzione del tipo Q·µ¢‚ÇÅ ‚óª ‚Üí h‚ÇÇ Q·µ¢‚ÇÇ ‚óª\n\n\nAlcune osservazioni importati\n\n\nLe produzioni della fase 2 possono essere applicate solo a parole che contengono Q‚ÇÄ\n(cio√®: solo dopo che X √® stato rimosso dalla parola iniziale generata nella fase 1)\nSe noti, guarda le varie produzioni\n\nCON LA VERDE genero X\nCON LA ROSSA rimuovo X e ho Q‚ÇÄ\n\n\nOgni parola generata durante la fase 2 contiene uno e un solo simbolo q·µ¢, cio√® uno stato\nAnche perch√© q·µ¢ rappresenta la testina e il nastro √® unico ‚Üí quindi ho una sola testina\n\n\nLa struttura della parola x a Q‚ÇÄ x ‚óª\nNel processo di generazione, la grammatica costruisce parole della forma:\n\n\nx a Q‚ÇÄ x ‚óª\n\nQuesta non √® una parola qualsiasi, ma rappresenta una configurazione del nastro della macchina di Turing simulata dalla grammatica.\nVediamo cosa significano i singoli simboli:\n\nIl primo x (composto da simboli 0 e 1) √® l‚Äôinput da confrontare: √® una copia della stringa originale.\nIl simbolo a √® un separatore usato solo per distinguere le due met√† della configurazione.\nQ‚ÇÄ √® un non terminale che rappresenta lo stato iniziale della macchina di Turing: si trova nella posizione della testina, sopra il primo simbolo della seconda x.\nLa seconda x √® una copia dell‚Äôinput, ed √® la parte che la testina della macchina inizier√† a leggere.\nIl simbolo ‚óª (blank) indica la fine del nastro e serve alla grammatica per sapere dove finisce la computazione.\nLa parte a destra del simbolo a, cio√®:\n\nQ‚ÇÄ x ‚óª\n\nrappresenta lo stato globale della computazione della macchina di Turing su input x, ovvero:\n\n\nil contenuto del nastro (la seconda x),\n\n\nla posizione della testina (indicata dal punto in cui compare Q‚ÇÄ),\n\n\nlo stato corrente della macchina (anch‚Äôesso rappresentato da Q‚ÇÄ).\n\n\n‚úÖ Quando una parola √® davvero generata?\nDurante la simulazione della macchina di Turing, se la grammatica riesce ad arrivare a una configurazione in cui il non terminale q_A (lo stato di accettazione) si trova nella parola, allora la computazione √® terminata con successo.\nIn altre parole:\n\nSe, a un certo punto, la parola generata diventa x a q_A,\nsignifica che la macchina di Turing su input x termina nello stato di accettazione q_A,\nquindi la grammatica accetta x, ovvero x ‚àà L(G).\n\n\n\nSe la computazione T(x) non termina nello stato di accettazione q‚Çê,  allora qualsiasi parola generata durante la fase 2 contiene un non terminale  appartenente all‚Äôinsieme {q·µ¢ : i = 0, ..., k} ‚à™ {q·µ£}.\nIn pratica, se non termino in q‚Çê avr√≤ sempre un carattere non terminale che pu√≤ essere\n\nuno stato attuale q·µ¢ : i = 0, ..., k\nlo stato di rigetto q·µ£\n\n\n\nAndiamo ad avere una sorta di ‚Äúprotezione‚Äù avere ogni volta il blank Impedisce che vengano generate parole terminali se la simulazione non √® andata a buon fine. Qualunque parola generata durante la fase 2 ha come ultimo carattere il blank ‚ñØ\nQuesto perch√© ogni volta che la testina si sposta a destra, la grammatica aggiunge un nuovo ‚ñØ alla fine.\n‚úÖ Perch√© √® utile?\n\nServe per delimitare la fine del nastro simulato\nPermette alle produzioni della grammatica di sapere dove si trova il bordo destro, utile nelle riscritture\nAiuta a identificare che la simulazione √® ancora in corso o pronta a terminare\n\n\n\nFase 3 approfondita\navevamo detto che una volta finita la computazione dovevamo lasciare solo x e pulire tutto il resto\n\nSE E SOLO SE T(x) ha terminato in q‚Çê (e quindi se leggiamo q‚Çê nella parola costruita nella FASE 1 e modificata nella FASE 2)\n\npossiamo eliminare tutti i caratteri dopo a\nlasciare solo l‚Äôinput x\n\n\n\nquindi ad esempio prima di cancellare abbiamo\n01 a q_A 01 ‚óª\ndopo avremmo solo\n01\nProduzioni che ci consentono di pulire tutto\n\n\nPer ogni b ‚àà {0,1}:\nq‚Çê b ‚Üí b q‚Çê\nfa slittare q‚Çê a destra dei vari simboli (vogliamo portarla a sinistra del blank)\na destra di q_a bisogna immaginare che ci siano i blank\n\n\nPoi:\nq‚Çê ‚ñØ ‚Üí C\ntrasformo la coppia q‚Çê ‚ñØ in un carattere speciale C\n\n\nPoi:\nb C ‚Üí C     (per ogni b ‚àà {0,1})\nC avr√† prima di s√© tanti caratteri (‚àà {0,1}) che verranno mano mano ‚Äúeliminati‚Äù\n\n\nInfine:\na C ‚Üí Œµ\nDopo aver eliminato tutti i caratteri rimane solo a con C, che trasformo in una parola vuota (Œµ) e quindi le cancello definitivamente\n\n\nESEMPIO GRAFICO\n\nAltre osservazioni\n\n\nLe produzioni della fase 3 possono essere applicate solo se nella parola c‚Äô√® q‚Çê.\nanche perch√© se noti le prime due produzioni posso eseguirle SOLO SE ho q‚Çê\n\n\nSe applichi le produzioni della fase 3 a una parola che contiene solo q‚Çê come non terminale e termina con ‚ñØ,  allora ottieni una parola composta solo dai simboli a sinistra di a, cio√® proprio l‚Äôinput x.\n\n\nMega conclusione (e sintesi)\n\n"},"UNI/ANNO-2/FONDAMENTI/FONDAMENTI-LEZ.15":{"slug":"UNI/ANNO-2/FONDAMENTI/FONDAMENTI-LEZ.15","filePath":"UNI/ANNO 2/FONDAMENTI/FONDAMENTI LEZ.15.md","title":"FONDAMENTI LEZ.15","links":["UNI/ANNO-2/FONDAMENTI/FONDAMENTI-LEZ.14","UNI/ANNO-2/FONDAMENTI/FONDAMENTI-LEZ.5"],"tags":[],"content":"Questa lezione continua la precedente FONDAMENTI LEZ.14\nVogliamo dimostrare che se un linguaggio L √® generato da una grammatica(di tipo 0)\nallora esiste una macchina di Turing che accetta L ovvero:\nL_{0} \\subseteq A\nVogliamo quindi dimostrare che l‚Äôinsieme dei Linguaggi accettabili coincide con quelli dell‚Äôinsieme dei linguaggi generabili da grammatiche di tipo 0\nTeorema G.5\nPer ogni grammatica G esiste una macchina di Turing che accetta L(G).\nOssia:\n\\forall grammatica G\n\\exists \\ T : L(G) √® il linguaggio accettato da T\nAvendo G = &lt;V_{N}, V_{T}, P_{G}, S&gt;\n\\forall \\ x \\ \\exists \\ V_{T}^{*} \\ [o_{T}(x) = q_{A} \\iff L(G)]\nAndiamo a definire una dimostrazione ma che √® sbagliata\nSia G la grammatica definita come G = &lt;V_{N}, V_{T}, P_{G}, S&gt;\nProgettiamo una macchina di Turing NON DETERMINISTICA a 2 nastri\n\nsu N1 scriviamo l‚Äôinput x \\in V_{T}^{*}\nsu N2 √® il nastro di lavoro (su cui scriviamo le parole generate da G)\nScegliamo una macchina non deterministica perch√© cos√¨ posso simulare TUTTE le computazioni ‚Äúinsieme‚Äù.\n\nCosa facciamo?\n\nscriviamo sul secondo nastro S e iniziamo a scrivere tutte le produzioni\n\nSe ad un certo punto la parola scritta sul nastro 2 √® uguale all‚Äôinput (nastro 1), accetta\nse abbiamo uno di questi due casi\n\nla parola sul nastro due contiene tutti terminali MA √® diversa dall‚Äôinput\nla parola sul secondo nastro ha qualche carattere NON terminale MA non possiamo pi√π applicare produzioni\nallora rigetta\nLa dimostrazione √® sbagliata perch√©, pur cercando di riconoscere x, non garantisce che in caso positivo (x ‚àà L(G)) venga mai accettato in tempo finito.\nUna macchina riconoscitrice deve:\n\n\n\n\naccettare in tempo finito se x ‚àà L(G)\npu√≤ non terminare mai se x ‚àâ L(G)\n(non √® obbligata a rigettare esplicitamente)\n\nPer capire ancora meglio andiamo a fare un esempio\n\n\nGrammatica: G = &lt;V_{N}, V_{T}, P_{G}, S&gt;\n\nV_{N} = \\{S\\}\nV_{T} = \\{a,b\\}\nProduzioni\n\nS -&gt; aSa |  bSb | a | b | Œµ\n\n\n\n\n\nInput: ababa\n\n\nüìåQuindi l‚Äôobiettivo √® prendere l‚Äôinput ababa e vedere se la grammatica produce la stessa parola e quindi accetta il linguaggio\nallora avremmo una macchina non deterministica NT(x) con la seguente computazione:\n\ni nodi sono le produzioni su N2 mentre gli archi indicano che la produzione √® stata applicata\nin questo caso accetta e quindi funziona\n\n\n                  \n                  Perch√© funziona? \n                  \n                \n\nPerch√© dopo ogni produzione avr√≤ sempre MASSIMO una S, quindi ogni volta la macchina dovr√† eseguire un numero di produzioni COSTANTE (visto che tutte le produzioni partono da S, e sono 5, allora per ogni parola (nodo) verranno applicate 5 produzioni).\n\n\n\n\n                  \n                  Ma funziona sempre? \n                  \n                \n\nNO e riprendiamo ci√≤ che abbiamo detto prima.\nImmagina di avere queste produzioni\n\nS -&gt; ABS | Œµ\nB -&gt; Cb\nAC -&gt; cA\nBC -&gt; Cc\nC -&gt; Œµ\n\nSe x √® tanto grande, verr√† generata una parola molto grande che sar√† del tipo S \\ \\rightarrow \\ ABS \\ \\Rightarrow_{G} \\ ABABS \\ \\Rightarrow_{G} \\ ABABABS  \\ \\Rightarrow_{G}^{*} \\ (AB)^{n}Se poi dovr√≤ applicare la produzione B -&gt; Cb.\nFin qui tutto tranquillo.\nPer√≤ ora chiediti, quante volte devo applicare la produzione? DIPENDE DALLA LUNGHEZZA DELLA PAROLA.\nQUINDI NON √à COSTANTE COME NEL CASO DI PRIMA.\n\n\n\nPer risolvere questi problemi dobbiamo modificare la macchina.\nDIMOSTRAZIONE CORRETTA PERFETTA ASSURDA!\nProgettiamo una macchina di Turing NON DETERMINISTICA  NT_{G} a 3 nastri\n\nsu N1 scriviamo l‚Äôinput x \\in V_{T}^{*}\nsu N2 √® il nastro di lavoro (su cui scriviamo le parole generate da G)\nsu N3 scrivo un intero (inizializzato a 1)\n\n\n\n                  \n                  a che ci serve il nastro N3? \n                  \n                \n\nil nastro N3  ci serve per rappresentare la posizione della parola su cui applicare una produzione, ad esempio:\n\nparte da un nodo\nguarda i\napplica la produzione in posizione i generando una nuova parola (nodo nel livello successivo)\nora inizio a applicare le produzioni in posizione i sulla nuova parola\ne continua finch√© non si ferma\n\nper q_{A}\nper q_{R}\nperch√© ha finito le quintuple(raggiunge la fine di i)\n\n\n\nSE ARRIVA IN q_{A}\n\nvuol dire che ha confrontato la parola generata con l‚Äôinput e sono uguali.\n\nSE NON ARRIVA IN q_{A} (le parole sono diverse)\n\nincrementa i\nrimane nella parola corrente (quindi nello stesso nodo dell‚Äôalbero)\ne prova ad applicare le produzioni da una posizione successiva\n\n[!danger] QUANDO CAMBIO RAMO, i viene riportato a 1.\nin sostanza faccio le produzioni perch√© voglio ricondurmi alla parola giusto, quindi vado in posizione 1 della parola iniziale, mi accorgo che non posso fare produzioni quindi vado in posizione 2 e cos√¨ via finch√© non arrivo alla i finale e posso determinare se ho raggiunto una parola accettabile o no\nesempio grafico:\n\n\n\nIl grado di non determinismo √® costante e la computazione non prova le produzioni a casaccio ma con una logica ben definita(si basa sulle i posizioni)\nil grado di non determinismo della macchina rimane costante\nApprofondimento sui rami\nQuanti rami ho?\nIl numero di produzioni + la produzione in cui non esegue nulla ma incrementa, quindi |P_{G}| + 1\nQuindi il valore √® costante e NON DIPENDE DALL‚ÄôINPUT.\nLa macchina funziona correttamente\ninfatti NT_{G} accetta una parola x \\iff esiste una sequenza di produzioni che, partendo da S, genera x.\nCio√®, la macchina simula correttamente ogni sequenza di produzioni come: S \\ \\Rightarrow_{G} \\ x_{1} \\ \\Rightarrow_{G} \\ x_{2} \\ ... \\Rightarrow_{G} \\ x\nQuindi: NTG(x)¬†\\ accetta¬†‚ÄÖ\\iff ‚ÄÖ‚Ääx \\in L(G)\nE da qui concludi che: L(NTG‚Äã)=L(G)\nPer quanto riguarda il caso in cui x ‚àâ L(G)\nla macchina entra in un loop infinito e quindi eseguire computazioni non terminali\nci√≤ va comunque bene perch√© a noi ci basta che essa accetti se x ‚àà L(G) in un tempo finito\nNT_G tenta tutte le possibili sequenze di produzioni, nella speranza di trovare una derivazione che generi x.\nMa se x non appartiene a L(G), nessuna derivazione porter√† mai a x, e quindi:\nx \\notin L(G) \\quad \\Rightarrow \\quad NT_G(x) non rigetta (potrebbe non terminare)\nprecisazione su una possibile scorciatoia\n\n‚úîÔ∏è stiamo lavorando con grammatiche di tipo 0\nüö´ non possiamo usare euristiche (tipo la lunghezza della parola) per decidere se un ramo porter√† a q_A oppure no\nüòµ Quindi il problema del q_R (cio√® sapere se dobbiamo rigettare) √® davvero complicato con grammatiche di tipo 0\nüö´non possiamo dire tipo ‚Äústiamo incappando in una situazione dove abbiamo una parola lunga 2000 mentre x era 5‚Äù perch√© potrebbe esserci una produzione che la accorcia a 5\n\nConclusione\n\nESERCIZIO DA FARE\n"},"UNI/ANNO-2/FONDAMENTI/FONDAMENTI-LEZ.16":{"slug":"UNI/ANNO-2/FONDAMENTI/FONDAMENTI-LEZ.16","filePath":"UNI/ANNO 2/FONDAMENTI/FONDAMENTI LEZ.16.md","title":"FONDAMENTI LEZ.16","links":[],"tags":[],"content":"Osservazione\nSe L(G) contiene un numero infinito di parole, allora la macchina che abbiamo creato nel teorema G.5 chiamata NT_G che non rigettava le parole contenenti qualche non terminale di G, allora significa che qualche computazione(ramo) di NT_G non termina(entra in loop)\n\npraticamente questa macchina applica produzioni e poi verifica se la parola ottenuta coincide con quella ricevuta in input\ne continua a farlo fino a quando non porta al risultato sperato\ne quindi se x ‚àâ L(G), per poter rigettare NTG(x) deve continuare ad ‚Äò‚Äòapplicare produzioni‚Äô‚Äô fino a quando non ha confrontato x con tutte le parole in L(G)\nma abbiamo detto che L(G) ha infinite parole\nquindi va a infinito\nQuindi quando x ‚àâ L(G) NTG(x) non rigetta\n\n\n\n                  \n                  il problema √® che siamo in una grammatica di tipo 0 \n                  \n                \n\n\nci√≤ ci obbliga a dover provare tutte le produzioni finch√© non raggiungiamo caratteri terminali\nanche se abbiamo una parola pi√π grande dell‚Äôinput possiamo comunque poi ricondurci attraverso delle produzioni alla parola che cercavamo\nda ‚Äúaaaaaasdadsdas possiamo produrre una parola piccola anche come solo a asdadasdas ‚Üí aa‚Äù\n\n\n\n\n\n                  \n                  se invece ci riduciamo a usare una grammatica di tipo 1 \n                  \n                \n\n\npossiamo utilizzare la regola del:\n\na sx devo avere una parola pi√π piccola di quella a dx\nquindi se raggiungo una parola pi√π grande dell‚Äôinput sto sforando e posso terminare quella computazione\nProduzioni che diminuiscano la lunghezza della parola generata sono proibite nelle grammatiche di tipo 1\n\n\n\n\n\n\n\n                  \n                  rivedendo la regola solita della grammatica di tipo 1 abbiamo che: \n                  \n                \n\nquesto significa che, se G =&lt;V_T,V_N,P,S&gt; √® una grammatica di tipo 1 e y √® una parola in (V_T \\cup V_N)^* tale che S ‚üπ_G y, da y non √® possibile derivare in G alcuna parola x la cui lunghezza √® inferiore a quella di x\n\n(ossia, |x| &lt; |y|)\nricordiamo che S ‚üπ_G y questo significa che una serie di produzioni della grammtica portano risultato y\n\n\n\nCon la grammatica di tipo 0 abbiamo definito una macchina di Turing che accetta\ninvece ora con quella di tipo 1 proveremo a definirne una che decide\nAndiamo ora a modificare la macchina NT_G in modo tale che ciascuna computazione deterministica in NTG(x) rigetti non appena viene generata una parola che contiene pi√π caratteri di x\nProcediamo con la creazione di questa macchina\n\npraticamente queste produzioni ci portano a raggiungere un loop e che non aumenta la dimensione fino a superare x, quindi finiamo in un loop anche se siamo nel tipo 1 quindi nella macchina NT&#039;_G(x)\n\nAnche in questo caso siamo in un loop\nConseguentemente, poich√© x ‚àâ L(G) e dunque nessuna computazione deterministica di NT‚ÄôG(x) accetta, la computazione NT‚ÄôG(x) non termina\n\nquindi  NT‚ÄôG(x) non rigetta\nquindi non decide ma accetta il linguaggio\ndobbiamo fare in modo che si accorga che sta per entrare in un loop\nCome facciamo a capire se siamo in un loop?\ndovrei definire un numero per cui quella parola poi per forza √® in loop\nla risposta √® facile |V_T \\cup V_N|^{|x|}\nattraverso questa formula riusciamo a definire quali sono tutte le possibili combinazioni delle parole di una data lunghezza dell‚Äôinput x\ne dell‚Äôunione delle parole terminali e non\n\n\n\n                  \n                  una volta superato questo numero siamo in un loop \n                  \n                \n\nin questo caso facciamo (3+2)^{4+1} dove abbiamo\n\n3 caratteri terminali\n2 non terminali\ninput x con cardinalit√† 4\nsommiamo 1 perch√© indica che abbiamo sforato di 1\n\nDefiniamo una macchina NT^1 che lavora su grammatica di tipo 1\ne che oltretutto aggiunge questo riconoscimento del loop!!\n\nusiamo un nastro N4 per calcolare il valore della formuletta fatta prima |V_T \\cup V_N|^{|x|}\n\nin unario, far√† il calcolo\nPrendiamo per assodato che esiste una macchina di Turing che calcola la formuletta in unario\n\nprendendolo per assodato basta che sul nastro N4 effettuiamo una simulazione\n\n\n\n\nusiamo un nastro N5 per contare quante volte troviamo le parole di una determinata lunghezza in modo sequenziale e consecutivo\nesso sar√† inizializzato a 1 e, con una parola y scritta sul primo nastro, ogni volta che viene generata (non deterministicamente) una parola z:\n\nviene incrementato di 1 (eseguendo una somma in binario) se |z|=|y|,\nmentre viene resettato a 1 se |z|&gt;|y|\ntipo becco 3 volte di fila una parola lunga 5 allora segno 3\n\n\n\nCome opera la macchina  NT^1 nello specifico\n\nha input x scritto sul primo nastro\nsi svolgono 2 fasi\n\nFase di inizializzazione\n\nNT^1 scrive S sul secondo nastro e 1 sul terzo nastro\n\ncome faceva gi√† quella del teorema G.5\n\n\npoi calcola la formuletta |V_T \\cup V_N|^{|x|} in unario sul nastro 4\nscrive 1 sul quinto nastro perch√© ha scritto 1 volta una parola di quella lunghezza\nsposta le testine sui simboli non blank pi√π a sx di ogni nastro\n\nritorna all‚Äôinizio\n\n\n\nFase di iterazione\nquesta fase si divide in 2 sotto casi\n1. Generazione\nNT^1 simula non deterministicamente l‚Äôapplicazione di tutte le produzioni possibili alla parola scritta sul secondo nastro a partire dalla posizione indicata sul terzo nastro\n\nmodifica attraverso una produzione la parola sul secondo nastro\n\nse la produzione non aumenta la cardinalit√† della parola\n\nallora siamo nel caso |z|=|y|\ne incrementiamo di 1 il contatore sul nastro 5\n\n\naltrimenti ri-inizializza il nastro 5 a 1\n\n\nse una produzione porta a un blank sul secondo nastro\n\nallora nessuna produzione √® stata applicata\nquindi le ho finite e posso passare al carattere successivo\n\nincremento di 1 il terzo nastro\n\n\n\n\n\n2. Verifica\nQuando una parola sul secondo nastro viene modificata\n\nse coincide con l‚Äôinput sul primo nastro allora  NT^1 accetta\naltrimenti se la parola cos√¨ ottenuta\n\nnon contiene alcun non terminale (contiene solo terminali)\nse ad essa non pu√≤ essere applicata alcuna produzione\noppure se √® pi√π lunga della parola x\noppure se il valore scritto sul quinto nastro √® maggiore di quello scritto sul quarto nastro\nallora NT^1 rigetta,\n\n\nse non succede nulla di tutto ci√≤\n\nri-inizializzando a 1 il contenuto del terzo nastro e riposizionando a sinistra la testina sul quarto nastro\n\n\n\nPoich√©  NT^1 accetta una parola x se e soltanto se G genera x\n\nallora possiamo concludere che  NT^1 accetta L(G)\n\nOra vogliamo dimostrare come ultima cosa che invece lo decide\n\nsostanzialmente andiamo a dimostrare che per ogni parola \\notin  L(G)  NT^1 rigetta\nPoniamo quindi di avere una parola x che non appartiene a L(G) e che siamo nel corso di una computazione con una parola y che \\in (V_T \\cup V_N)^*\nabbiamo 3 casistiche\nse y contiene solo caratteri terminali per costruzione di  NT^1 , S ‚üπ_G y  allora\n\ny ‚ààL(G) e dunque,\n\npoich√© x ‚àâ L(G), y √®  ‚â†  da x\ne la computazione deterministica della macchina rigetta\n\n\n\n\nse y contiene almeno un carattere non terminale ma |y|&gt;|x| allora\n\nla computazione della macchina rigetta\n\n\nse y contiene almeno un carattere non terminale e la cardinalit√† √® nei limiti quindi abbiamo che\n\n|y|\\leq|x|\nallora la macchina trover√† una parola z da sostituire a y tale che |z| \\geq |y|\n\nquesto perch√© siamo nella grammatica di tipo 1 quindi le parole possono solo crescere o rimanere uguali\n\n\nfino a quando poi non ricaschiamo nei casi 1 o 2 oppure abbiamo sforato le parole con cardinalit√† uguale possibili\n\ndefinite dalla formuletta |V_T \\cup V_N|^{|x|}\nquindi rigettano\ne quindi possiamo dire che questa macchina  NT^1\n\n\n\n\nDECIDE L(G)\n\nCOROLLARIO per finire\nL‚Äôinsieme dei linguaggi di tipo 1 √® un sottoinsieme dei linguaggi decidibili o ricorsivi\n\ndecidibili e ricorsivi so la stessa coda\n\nOSSERVAZIONE\nMentre i teoremi G.4 e G.5 implicano che un linguaggio √® accettabile se e solo se esso √® generato da una grammatica (ossia, gli insiemi dei linguaggi decidibili e l‚Äôinsieme dei linguaggi generati da grammatiche coincidono), il teorema G.6 dimostra soltanto che tutti i linguaggi generati da grammatiche di tipo 1 sono decidibili, ma non il viceversa!\nVisione sull‚Äôinsieme delle varie grammatiche + Linguaggi accettabili o decidibili\n\nGrammatiche context free di tipo 2\ntutte le grammatiche di tipo 2 si dicono context free\nper contesto si intende quale istanza mi fa avvenire quella determinata produzione\nse ho solo produzioni che hanno una lettera a sx indipendentemente da dove mi trovo posso applicarle quindi sono senza contesto\nRicordando che le Grammatiche di tipo-2\n\npossiedono solo produzioni nella forma\n\nA ‚Üí\\alpha  con A ‚àà V_N e \\alpha \\in (V_T \\cup V_N)^*\n\n\n\nESEMPIO\n\nin questo caso a=b perch√© ogni volta che faccio una produzione che sostituisce a avr√≤ anche una b e viceversa invece c no\nEsercizi da fare in casa da benedetta\n"},"UNI/ANNO-2/FONDAMENTI/FONDAMENTI-LEZ.17":{"slug":"UNI/ANNO-2/FONDAMENTI/FONDAMENTI-LEZ.17","filePath":"UNI/ANNO 2/FONDAMENTI/FONDAMENTI LEZ.17.md","title":"FONDAMENTI LEZ.17","links":[],"tags":[],"content":"G2 \\ e \\ G1 sono con una inclusione propria o impropria?\nper rispondere a questa domanda intanto precisiamo cosa significa inclusione propria o impropria, giusto per ripassare\n\nimpropria \\subseteq\n\nho due insiemi che sono uno contenuto nell‚Äôaltro ma possono essere anche uguali\nA=\\{1,2\\} e B=\\{1,2\\} allora A‚äÜB\n\n\npropria \\subset\n\nsemplicemente sono uno contenuto nell‚Äôaltra ma non sono uguali\nA=\\{1\\} e B=\\{1,2\\}  A\\subset B\n\n\n\nQuindi ora continuiamo con la domanda\nG2 \\subseteq G1?\noppure\nG2\\subset G1?\nSicuramente sappiamo che\nG_{2} \\subset G_{1}\nora bisogna solo capire se √® propria o meno\nPer risolverlo ci aiuta il Pumping lemma\n\n\n                  \n                  Pumping Lemma \n                  \n                \n\nPer ogni linguaggio L \\in G_{2} esiste una costante (che dipende esclusivamente dal linguaggio L), definita come p_{L} &gt; 0 (di tipo intero) tale che per ogni parola z \\in L se |z| \\ge p_{L} allora esistono 5 parole\n\nu\nv\nw\nx\ny\ntali che\n\n\nz = u v w x y (ossia z puoi scriverlo come concatenazione delle cinque parole)\n|v w x| \\le p_{L}\n|v x| \\ge 1 (v e x NON POSSONO ESSERE ENTRAMBE VUOTE)\nu \\ v^{h} \\ w \\ x^{h} \\ y √® in L per ogni h ‚â• 0.\n\nvariano v e x perch√© le altre sono prese come parti fisse della parola\n\n\n\n\n                  \n                  Perch√© P_L esiste?\n                  \n                \n\n\n\n\nDa qui viene usato il teorema di Bar-Hillel\nDefinisce che i 4 punti visti prima sono sufficienti per formare un linguaggio context-free\n\nma non lo rendono obbligatorio\npossono esistere linguaggi con quei 4 punti ma non essere comunque context-free\nperci√≤ lo sfrutteremo al contrario per dimostrare quando un linguaggio non √® context-free\n\nApplicazioni del lemma\nL= \\{a^{n} b^{n} c^{n} : n &gt; 0\\} \\in G_{1}\nDimostriamo che NON APPARTIENE A G2\nSe  L \\in G_{2} allora esiste un P_{L} &gt; 0 per cui valgono le condizioni del lemma.\nPosso ora scrivere z = a^{P_{L}} \\ b^{P_{L}} \\ c^{P_{L}} \\in Lche va bene, perch√© ha lo stesso esatto numero di a, b, c.\nProviamo ad applicare il teorema\nSappiamo che la lunghezza della sottostringa |v w x| deve essere lunga AL MASSIMO p_{L}\nQuindi non pu√≤ attraversare tutte e tre le zone (a, b e c)\nQuesto vuol dire che la sottostringa v w x pu√≤ rispettare SOLO UNA di queste condizioni\n\nsta tutta dentro a\nsta tutta dentro b\nsta tutta dentro c\nha ALMENO un carattere di a (e di conseguenza nessuna c)\nha ALMENO un carattere di c (e di conseguenza nessuna a)\n\nQuesto quindi vuol dire che se applico il lemma non potr√≤ mai rispettare la condizione iniziale posta dal linguaggio e quindi L NON √à CONTEXT-FREE\nnon √® context-free proprio perch√© serve tenere traccia contemporaneamente di tre blocchi legati tra loro:\n\nquanti a\nquanti b\nquanti c\ne tutti e tre devono essere uguali.\n\n\n\n                  \n                  CONCLUSIONE FINALE \n                  \n                \n\nE quindi G_{2} \\subset G_{1} (non uguale)\n\n\n\n\n                  \n                  perch√© le grammatiche context-free possono gestire una sola dipendenza per volta? \n                  \n                \n\n\n\n\n\nUnione e Intersezione di due linguaggi context-free\nSiano L^{1}, L^{2} \\in G_{2}\nUNIONE\n\n\n                  \n                  Possiamo dire che \n                  \n                \n\nL^{1} \\cup L^{2} \\in G_{2}\n\n\n\n\n                  \n                  Risposta: SI \n                  \n                \n\n\nsemplicemente genera una grammatica con l‚Äôunione dei vari stati non terminali e terminali e le varie produzioni ecc‚Ä¶\n\n\nINTERSEZIONE\n\n\n                  \n                  Possiamo dire che \n                  \n                \n\nL^{1} \\cap L^{2} \\in G_{2}\n\n\n\n\n                  \n                  Risposta: NON √à DETTO \n                  \n                \n\n\n\n\npropriet√† che si ritrovano sui 3 teoremi\nQueste due propriet√† sono riassunte nei seguenti teoremi\n\n\n                  \n                  TEOREMA G.7 \n                  \n                \n\nL‚Äôinsieme dei linguaggi context-free √® chiusa rispetto all‚Äôunione.\nNel senso che, se sono nell‚Äôinsieme dei linguaggi context-free e eseguo l‚Äôunione, rimango in questo insieme.\n\n\n\n\n                  \n                  TEOREMA G.8 \n                  \n                \n\nL‚Äôinsieme dei linguaggi context-free non √® chiusa rispetto all‚Äôintersezione\n\n\n\n\n                  \n                  TEOREMA G.9 \n                  \n                \n\nL‚Äôinsieme dei linguaggi context-free non √® chiusa rispetto al complemento\n\n\nPDA\nvisto che G_2 \\subset G_1 e che G_1 \\subset Decidibili allora anche G_2 lo √®\nPossiamo ora mostrare che, i linguaggi context-free sono decisi da un modello di calcolo STRETTAMENTE MENO POTENTE della MACCHINA DI Turing: L‚Äôautoma a pila (PDA, PushDown Automata)\nstrettamente meno potente: ossia, ogni PDA pu√≤ essere simulato da una macchina di Turing, ma non viceversa\nCome √© strutturata?\nInformalmente, un PDA consiste di\n\n\nun testone che decide\n\n\ndue nastri SEMI INFINITI\n\n\nN_{1} = input (che utilizza l‚ÄôALFABETO \\Sigma)\nquesto √® un nastro di sola lettura e la testina ad esso associata pu√≤ muoversi A DESTRA o RESTARE FERMA (mai a sinistra) - in particolare, quando si arriva al \\square tutto a dx la testina rimane ferma\n\n\nN_{2} (che utilizza l‚ÄôALFABETO \\Gamma(si legge gamma))\nquesto nastro √® chiamato PILA perch√© funziona letteralmente come le pile (LIFO).\nAd inizio computazione verr√† scritto sul nastro un carattere speciale di \\Gamma, ossia Z_{0}\n\n\nI nastri, in qualsiasi momento, possono contenere sia una stringa vuota che non.\n\n\nDEFINIZIONE\nLa PDA √® una settupla cos√¨ composta&lt;\\Sigma, \\ \\Gamma, \\ Q, \\ q_{0}, \\ Q_{F}, \\ Z_{0}, \\ \\delta&gt;Quindi\n\ndue alfabeti (\\Sigma e \\Gamma)\nSono insiemi DIFFERENTI e quindi deve valere la regola \\Sigma \\ \\cap \\ \\Gamma = \\varnothing\nun insieme degli stati (Q)\nuno stato iniziale (q_{0})\nun insieme di stati finali (Q_{F})\nun simbolo iniziale che va scritto SOLO sul secondo nastro (Z_{0})\ndelle funzioni di transizione \\delta (che hanno lo stesso ruolo delle quintuple in una Macchina di Turing), definite come \\delta: Q \\times (\\Sigma \\ \\cup \\ \\{\\epsilon\\}) \\times \\Gamma \\ \\rightarrow P{(Q \\ \\times \\ (\\Gamma^{+} \\ \\cup \\{\\epsilon\\}))}\nquindi prima della freccia abbiamo un input definito da:\ncio√® la funzione prende in input:\n\n\n\nuno stato attuale q‚ààQ\n\n\nun simbolo dell‚Äôinput a‚ààŒ£, oppure Œµ se vogliamo muoverci senza leggere input\n\n\nun simbolo dalla pila X‚ààŒì\nin output:\nun insieme di possibili coppie (q‚Ä≤,Œ≥)\n\n\n\n\nq‚Ä≤‚ààQ nuovo stato\n\n\nŒ≥‚ààŒì^‚àó\\cup \\{Œµ\\} nuovo contenuto da mettere sulla pila, che pu√≤ anche essere vuoto\ndove P √® l‚Äôinsieme delle parti e vuol dire 2^{QUALCOSA}\nsi intende l‚Äôinsieme di tutti i sottoinsiemi di qualcosa con quel 2^x\n\n\nOsserviamo che, poich√© l‚Äôazione da compiere deve essere scelta in un insieme, quel che stiamo definendo √® un PDA non deterministico\nSTATO (globale, ma non si dice) DI UN PDA\nlo stato √® la ‚Äúfotografia‚Äù di un modello di calcolo che ci permette di capire tutto di quella determinata situazione\n√à una tripla&lt;q, \\ x, \\ \\gamma&gt;dove\n\nq \\in Q e quindi specifica lo stato interno in cui si trova PDA\nx \\in \\Sigma^{*} e quindi indica il contenuto del primo nastro\n\\gamma \\in \\Gamma^{*} e quindi indica il contenuto del secondo nastro\n\nNota come non √® necessario specificare la posizione delle testine perch√©\n\nla testina sul primo nastro √® sempre posizionata sul carattere pi√π a sinistra\nla testina sul secondo nastro √® sempre posizionata sul carattere pi√π a destra (√® una pila, quindi LIFO)\n\nEsempio di transizione\nSiano\n\na ‚àà Œ£,\nZ ‚àà Œì\nùõæ ‚àà Œì^{*}\nq_{1}, q_{2} ‚àà Q\n\nSupponiamo che lo stato attuale del PDA sia questo (ax, \\ \\beta Z, \\ q_{1})\n\nax = input: il carattere su cui √® posizionata la testina √® a e il resto della parola √® x\nŒ≤Z = pila: in cima alla pila c‚Äô√® Z, sotto i restanti simboli sono Œ≤\nq‚ÇÅ = stato attuale\n\nOra, il PDA sceglie una transizione del tipo (q_{2}, \\ \\gamma) \\in \\delta(q_{1}, \\ a, \\ Z)ossia: ‚Äúse sono nello stato q‚ÇÅ e leggo a (su N1) e Z (su N2), allora vado nello stato q‚ÇÇ e sostituisco Z con Œ≥ (che pu√≤ anche essere vuoto).‚Äù\nNel pratico, succede questo\n\nla testina sul primo nastro viene spostata di una posizione a destra dopo aver cancellato il carattere letto\nil carattere Z sulla pila viene cancellato e, se ùõæ ‚â† ùúÄ sulla pila viene scritta (un carattere per cella) la parola ùõæ e la testina si posiziona sul carattere pi√π a destra sul nastro pila\nPDA entra nello stato q‚ÇÇ\n\nüí° Risultato finale:\nDopo la transizione, lo stato del PDA diventa: (x, \\ \\beta \\ \\gamma, \\ q_2)\ncio√®:\n\nrimane da leggere x nell‚Äôinput\nLa pila ora √® Œ≤Œ≥\nSei nello stato q‚ÇÇ\n\n\n\n                  \n                  La scelta per√≤ poteva anche essere questa \n                  \n                \n\n(q_{2}, \\ \\gamma) \\in \\delta(q_{1}, \\ \\epsilon, \\ Z)\nQuesto perch√© magari l‚Äôinput era una parola vuota.\nQui semplicemente, da prima, cambia che\n\nla testina sul primo nastro rimane ferma\nil nuovo stato dell‚Äôautoma √® (a \\ x, \\ ùõΩ \\ ùõæ, \\ q_{2})\n\n\n\n\nDa un determinato input (configurazione), possiamo avere diversi output (transizioni possibili)\nESEMPIO CON FOTO\n\nqui in questa foto mi sa che c‚Äô√® un errore perch√© anche nella scritta blu dovrebbe esserci solo B\n\n\n                  \n                  OSSERVAZIONI \n                  \n                \n\nLa parola vuota ùúÄ ha un diverso significato a seconda se sia usata come ARGOMENTO DELLA FUNZIONE DI TRANSIZIONE oppure come RISULTATO DELLA SUA APPLICAZIONE.\n\n\nQuando ùúÄ compare come RISULTATO DELL‚ÄôAPPLICAZIONE DI ùõø, tipo (q_{2} ,ùú∫) ‚àà ùõø(q_{1}, a, Z)vuol dire che il simbolo in cima alla pila viene letteralmente cancellato (e la testina si sposta a sx).\n\n\nQuando ùúÄ compare come ARGOMENTO DI ùõø, ad esempio ùúπ(q_{1}, ùú∫, Z) = \\{ ... \\} implica che qualunque transizione all‚Äôinterno dell‚Äôinsieme pu√≤ essere eseguita ogni volta che il carattere Z si trova in cima alla pila, INDIPENDENTEMENTE DA COSA VIENE LETTO SU N1 (e la testina su N1 rimane ferma).\nLe transizioni di tipo ùúπ(q_{1}, ùú∫, Z) = \\{ ... \\} sono dette \\epsilon-regole\n\n\nATTENZIONE: NON ESISTONO TRANSIZIONI DELLA FORMA ùõø(q_{1},\\ \\square, \\ Z) = \\{ ... \\}ossia quando leggo blank su N1.\nE quindi, se ùõø non contiene \\epsilon-regole ‚Üí  la computazione termina una volta finito l‚Äôinput\nSe ci sono, pu√≤ andare avanti in modo indefinito.\n\n\nData l‚Äôultima osservazione si dice che un linguaggio √® ACCETTATO da un automa a pila, non √® mai deciso.\nDue tipologie di accettazione\n1. Accettazione per stato finale\nUna parola x √® accettata se esiste una sequenza di transizioni che porta: \\langle q_0, x, Z_0 \\rangle \\rightarrow^* \\langle q_F, \\varepsilon, \\gamma \\rangle\ndove:\n\nq_{F} \\in Q_{F}‚Äã: uno stato finale\n\\varepsilon: l‚Äôinput √® stato consumato\n\\gamma \\in \\Gamma^*: non importa cosa resta sulla pila\n\n‚úÖ Basta arrivare in uno stato finale, dopo aver letto tutta la parola, indipendentemente dal contenuto della pila.\nüìò Il linguaggio accettato in questa modalit√† si indica con:L(\\mathcal{M})\n2. Accettazione per pila vuota\nUna parola x √® accettata se esiste una sequenza di transizioni che porta: \\langle q_0, x, Z_0 \\rangle \\rightarrow^* \\langle q_F, \\varepsilon, \\varepsilon \\rangledove:\n\nq \\in Q: qualsiasi stato, non necessariamente finale\nLa pila √® completamente vuota\n\n‚úÖ Qui l‚Äôimportante √® svuotare completamente la pila, dopo aver letto tutta la parola, indipendentemente dallo stato finale.\nüìï Quando un linguaggio √® accettato da un PDA per pila vuota, si indica con:N(\\mathcal{M})\nQueste due modalit√† son equivalenti e infatti vale il teorema\n\n\n                  \n                  TEOREMA G.10 \n                  \n                \n\nPer ogni linguaggio L, esiste un PDA M che accetta L per pila vuota se e soltanto se esiste un PDA M‚Äô che accetta L per stato finale\n\n\nCome conseguenza del precedente teorema, possiamo parlare di insieme dei linguaggi accettati da automi a pila indipendentemente dalla modalit√† di accettazione.\nInfine, il prossimo teorema mostra che tale insieme coincide con l‚Äôinsieme dei  linguaggi context-free\n\n\n                  \n                  TEOREMA G.11 \n                  \n                \n\nUun linguaggio L √® context-free  se e soltanto se esiste un PDA M che accetta L.\n\n"},"UNI/ANNO-2/FONDAMENTI/FONDAMENTI-LEZ.18":{"slug":"UNI/ANNO-2/FONDAMENTI/FONDAMENTI-LEZ.18","filePath":"UNI/ANNO 2/FONDAMENTI/FONDAMENTI LEZ.18.md","title":"FONDAMENTI LEZ.18","links":["UNI/ANNO-2/FONDAMENTI/FONDAMENTI-LEZ.17"],"tags":[],"content":"Questa lezione riprende due teoremi principali e i conseguenti concetti\n\nOra procediamo a vedere due esempi di PDA per i due tipi di accettazione\nESEMPIO 1: PDA che accetta per pila vuota\nCostruiamo un PDA „Äà \\{a,b\\}, \\ \\{Z_{0}, A, B\\}, \\ Z_{0} , \\ \\{q_{0} , q_{1} \\} , \\ \\varnothing, \\ q_{0} , \\ Œ¥ „Äâ\n\n\n                  \n                  non so perch√© ma la prof ha invertito l&#039;insieme degli stati(quelli in pos 4) con Z_0, essi andrebbero scambiati per definizione vista in PDA\n                  \n                \n\nQuesta PDA riconosce per pila vuota perch√© come stato finale ha un insieme vuoto\n\n\npu√≤ terminare solo con pila vuota\n\n\nriconosce le parole di L_{PPAL}\nqueste sono le varie transizioni della funzione:\n\n\n\nriempie la pila finch√©:\n\nnon raggiungiamo met√† della parola da leggere\n\n\n\nIn questa fase, per ogni simbolo letto dall‚Äôinput, controlla se corrisponde al simbolo in cima alla pila:\n\nSe corrisponde, lo rimuove dalla pila\nAltrimenti, la computazione fallisce\n\n\n\nSe al termine dell‚Äôinput la pila risulta completamente vuota, allora la parola √® palindroma e di lunghezza pari, e quindi accettata.\n\n\n\n\n                  \n                  come faccio a dirgli di comportarsi diversamente dopo la met√†? \n                  \n                \n\nIl cambio di comportamento (da ‚Äúaccumulo‚Äù a ‚Äúcontrollo‚Äù) non √® scritto\nesplicitamente nel testo o nella struttura del PDA, ma √® gestito dal non\ndeterminismo grazie alle transizioni:\n\n√à il PDA che decide ‚Äúquando basta‚Äù e passa a controllare.\nNon c‚Äô√® un contatore della lunghezza, non ne ha bisogno.\n\n\n\npraticamente una volta raggiunta la met√† inizia a svuotare la pila ma continua a leggere a destra ci√≤ che avviene nella stringa di input\n\nse i caratteri corrispondono allora significa che si pu√≤ eliminare il tutto\n\n\n\n\n\n\n                  \n                  quindi una PDA pu√≤ essere non deterministico \n                  \n                \n\n\nquando non sa che fare crea due rami della stessa istanza per fare due scelte diverse\n\n\n\nESEMPIO 2: PDA che accetta per stato finale\nOra, costruiamo un PDA „Äà \\{a,b\\}, \\ \\{Z_{0}, A, B\\}, \\ Z_{0} , \\ \\{q_{0} , q_{1}, q_{2} \\} , \\ \\{q_{2}\\}, \\ q_{0} , \\ Œ¥ „Äâche riconosce PER STATO FINALE (q_{2}) il linguaggio L_{PPAL} delle parole palindrome pari sull‚Äôalfabeto \\{a,b\\}\nqueste sono le varie transizioni della funzione:\n\nQuindi\n\nfinch√© si trova PRIMA della met√† aggiunge parole alla pila (NON CANCELLANDO Z_{0})\nquando arriva alla met√†, se pu√≤, cancella\nse cancella tutto e arriva a leggere, di nuovo, Z_{0}, entra in q_{2} e accetta\nanche qui si applica il non determinismo perch√© ‚Äúa una certa‚Äù deve cambiare modo di fare\n\n\nVogliamo simulare un PDA con una Macchina di Turing\nVisto che si assomigliano, hanno nastri ecc‚Ä¶\nsi possono fare simulazioni di questo genere\n√® a titolo di esempio quindi penso sia un po‚Äô inutile\n\n\n\n                  \n                  spiegazione chiara di tutto ci√≤ che sta sopra: \n                  \n                \n\nüéØ Obiettivo\nDimostrare che una Macchina di Turing (TM) pu√≤ simulare un PDA, cio√® che ogni linguaggio accettato da un PDA per pila vuota pu√≤ essere accettato da una TM deterministica.\nQuesto dimostra che PDA ‚äÜ TM, ovvero che i linguaggi context-free sono riconoscibili anche da una macchina di Turing.\nüß© Componenti in gioco\nIl PDA √® definito come:\nA = ‚ü® Œ£, Œì, Q, Z‚ÇÄ, Q‚Çê, ‚àÖ, Œ¥ ‚ü©\n\n\nŒ£: alfabeto di input\nŒì: alfabeto della pila\nQ: stati del PDA\nZ‚ÇÄ: simbolo iniziale della pila\nQ‚Çê: stati accettanti della TM (non del PDA)\nŒ¥: funzione di transizione del PDA\n\n‚ö†Ô∏è Il PDA accetta per pila vuota, quindi non ha stati finali propri (‚àÖ in sesta posizione).\n\nüî® Costruzione della TM che simula il PDA\nCostruiamo una TM T come:\nT = ‚ü® Œ£ ‚à™ Œì, Q_T, q‚ÇÄ, {q‚Çê}, P ‚ü©\n\n\nŒ£ ‚à™ Œì: l‚Äôalfabeto comprende sia input che pila (la TM li tratta come simboli sul nastro)\nQ_T = Q ‚à™ {q‚Çê}: stati del PDA pi√π un nuovo stato finale q‚Çê\nq‚ÇÄ: stato iniziale della TM\nq‚Çê: stato accettante della TM\nP: insieme delle transizioni (quintupla) della TM\n\n\nüîÅ Simulazione delle transizioni del PDA nella TM\n‚úÖ Caso 1: Transizione semplice con Œµ\nSe:\n(q‚ÇÇ, Œ≥) ‚àà Œ¥(q‚ÇÅ, a, Z)\n\nAllora in P si inserisce:\n‚ü®q‚ÇÅ, (a, Z), (a, 1), q‚ÇÇ, D‚ü©\n\n\nLeggi a e Z\nScrivi a (o lo lasci uguale), scrivi 1 al posto di Z\nVai a q‚ÇÇ, muovi a destra\n\n\n‚úÖ Caso 2: Transizione che spinge pi√π simboli\nSe:\n(q‚ÇÇ, Z‚ÇÅZ‚ÇÇ...Z‚Çñ) ‚àà Œ¥(q‚ÇÅ, a, Z)\n\n\nSi creano stati temporanei in Q_T per gestire ciascun push\nSi scrivono i simboli sulla ‚Äúpila‚Äù della TM da destra a sinistra:\nZ‚Çñ, Z‚Çñ‚Çã‚ÇÅ, ..., Z‚ÇÅ\n\n\n\n\n‚úÖ Caso 3: Transizione con Œµ sull‚Äôinput\nSe:\n(q‚ÇÇ, Œ≥) ‚àà Œ¥(q‚ÇÅ, Œµ, Z)\n\nPer ogni a ‚àà Œ£, si inserisce:\n‚ü®q‚ÇÅ, (a, Z), (a, 1), q‚ÇÇ, D‚ü©\n\nServe per simulare le transizioni del PDA che agiscono solo sulla pila.\n\n‚úÖ Caso finale: accettazione per pila vuota\nAlla fine, per ogni q ‚àà Q, se la pila √® vuota, si inserisce:\n‚ü®q, (‚ä•, ‚ä•), (‚ä•, ‚ä•), q‚Çê, (F, F)‚ü©\n\n(‚ä• = simbolo di margine o vuoto)\n\n‚úÖ Conclusione\nLa TM costruita simula fedelmente le transizioni del PDA, accettando se e solo se il PDA avrebbe svuotato la pila.\nQuindi:\nL(N(M)) ‚äÜ L(TM)\n\n\n\n\n\n                  \n                  ESERCIZIO da fare: dimostrare l&#039;equivalenza di A e T \n                  \n                \n\nFino ad ora\nfino ad ora abbiamo creato delle funzioni che si limitano a\n\nconsumare un elemento a\nnon consumare un elemento a\nquindi sostanzialmente abbiamo l‚Äôunione di queste due funzioni\n ùúπ(q_{1} , a, Z) ‚à™ ùúπ(q_{1}, ùú∫, Z)\ncon un PDA non deterministico e che in questo caso si riferisce solo a q1\n\nInvece un PDA deterministico?\nsemplicemente per renderlo deterministico per:\n\nogni stato interno ùúπ\nogni simbolo sul nastro\nogni azione da scegliere\nsia solo e soltanto una\n\n\n\n                  \n                  DEFINIZIONE \n                  \n                \n\nUn PDA ‚Ñ≥=„Äà Œ£, \\ Œì , \\ Z_{0} , \\ Q , \\ Q_{F} , \\ q_{0} , \\ Œ¥ „Äâ √® deterministico se ogni q ‚àà Q, per ogni a ‚àà Œ£, e per ogni Z ‚àà Œì accade che |\\delta(q_{1}, a, Z)| \\ + \\ |\\delta(q_{1}, \\varepsilon, Z)| \\ = \\ 1 \n\n\nin poche parole la somma delle azioni per un dato simbolo e stato interno deve essere 1, quindi una delle due \\nexists\nUna piccola differenza\nSappiamo che dal punto di vista della calcolabilit√†, una Macchina di Turing NON DETERMINISTICA √® equivalente a una Macchina di Turing DETERMINISTICA\nossia, tutto ci√≤ che possiamo fare con la NON DETERMINISTICA lo possiamo possiamo fare anche con la DETERMINISTICA\n\n\n                  \n                  Vale lo stesso per i PDA? \n                  \n                \n\nNo, perch√© esistono dei linguaggi context-free che non sono accettati da automi a pila non deterministici\n\n\nda qui viene un teorema:\n\n\n                  \n                  TEOREMA G.12 \n                  \n                \n\nL‚Äôinsieme dei linguaggi accettati da automi a pila deterministici √® un sottoinsieme proprio (\\subset) dei linguaggi context-free\nIn altri termini, gli automi a pila deterministici sono ‚Äò‚Äôstrettamente meno potenti‚Äô‚Äô di quelli non deterministici.\n\n\nConclusione Macchina di Turing VS PDA\n\n\n                  \n                  üîç La domanda che la prof si pone √®: \n                  \n                \n\nSe possiamo trasformare (lez. iniziali) un PDA non deterministico (NPDA) in una macchina di Turing non deterministica (NTM), e poi una NTM in una deterministica (DTM)‚Ä¶\nallora perch√© non possiamo ‚Äúrientrare‚Äù e costruire un DPDA equivalente?\n\n\n\n\n                  \n                  üö® Risposta: \n                  \n                \n\nPerch√© non sappiamo trasformare una DTM in un PDA deterministico!\n\n\nCio√®:\n\nPossiamo partire da NPDA ‚Üí NTM ‚Üí DTM, e accettare i linguaggi.\nMa non possiamo tornare indietro da DTM ‚Üí DPDA, perch√©:\n\nI PDA hanno meno memoria (solo una pila).\nE non possono simulare ogni DTM.\n\n\n\n\n\n                  \n                  ‚úÖ Quindi: \n                  \n                \n\n\nOgni linguaggio context-free √® accettato da una macchina di Turing (deterministica).\nMa non tutti i linguaggi context-free sono accettabili da un DPDA.\n\n\n\nAlberi sintattici üå≥\n√à un classico albero informatico con\n\nnodi\nrami\nfoglie\nche rappresenta il processo di derivazione di una parola secondo le regole della grammatica viste nelle lezioni scorse\n\nCome √® strutturato per essere applicato alle grammatiche\nüîç Struttura dell‚Äôalbero sintattico:\n\n\nRadice = S\nParte sempre dal simbolo iniziale della grammatica (cio√® il punto di partenza della derivazione).\n\n\nNodi interni = simboli non terminali (cio√® ‚àà VN)\nQuesti sono i simboli che vengono espansi secondo le regole di produzione.\n\n\nFoglie = simboli terminali (cio√® ‚àà VT)\nSono i caratteri finali della parola generata (quelli che vedi nell‚Äôoutput).\n\n\nEspansione dei nodi Rami:\nSe in una regola hai per esempio A ‚Üí x‚ÇÅ x‚ÇÇ ... x‚Çô,\nallora nel tuo albero:\n\nA sar√† un nodo interno\nx‚ÇÅ, x‚ÇÇ, ..., x‚Çô saranno i suoi figli, nell‚Äôordine indicato dalla produzione.\n\n\n\n\n\n                  \n                  gli alberi sintattici servono per fornire una desrizione sintetica di come √® strutturata sintatticamente una parola \n                  \n                \n\n\nti mostra quali produzioni l‚Äôhanno generata\n\n\n\nESEMPIO PRATICO\n\n\n\n                  \n                  L&#039;osservazione √® molto importante perch√© dice uno stesso albero sintattico corrisponde a pi√π di una derivazione. \n                  \n                \n\nSignifica che una stessa parola pu√≤ essere generata in modi diversi, cio√® seguendo derivazioni diverse, ma che alla fine portano allo stesso albero sintattico.\nQuindi da un albero sintattico possono corrispondere pi√π derivazioni\n\n\n                  \n                  per√≤ c&#039;√® un problema ovvero che una singola parola pu√≤ corrispondere pi√π di un albero sintattico \n                  \n                \n\n\necco un esempio\nquesto pu√≤ causare ambiguit√† di lettura della parola\n\n\n\n\n√® un problema perch√© gli alberi sintattici sono usati anche per capire il significato delle parole al livello anche semantico, questi due alberi danno un significato differente\nPrendiamo l‚Äôesempio nella foto, e ipotizziamo che l‚Äôalbero sia impostato per interpretare la parola generata PARTENDO DAL BASSO\n\nALBERO IN ROSSO: 3 + (3 * 3) = 12\nALBERO IN BLU: (3 + 3) * 3 = 18\n\nSarebbe veramente bello poter capire in anticipo se una grammatica sia ambigua o no MA OVVIAMENTE NON SI PU√í FARE.\nDa qui viene fuori il teorema che d√† dei dettagli sulle ambiguit√†\n\n\n                  \n                  Teorema G.13 \n                  \n                \n\nsia L_{A} l‚Äôinsieme delle grammatiche di tipo 2 ambigue ‚Üí il linguaggio L_{A} √® non decidibile.\nCi√≤ significa che non esiste un algoritmo che, data una grammatica G di tipo 2 decide se G √® ambigua\n\n\n\n\n                  \n                  Chiacchiere finali della prof \n                  \n                \n\n\nüìå I linguaggi di programmazione ‚Äúgrosso modo‚Äù sono di tipo 2 (context-free):\n\n\nOvvero: la struttura sintattica di base di un linguaggio di programmazione pu√≤ essere espressa con una grammatica context-free.\n\n\nTuttavia, alcune regole, come per esempio l‚Äôunicit√† della dichiarazione di una variabile, richiedono controlli pi√π potenti ‚Üí cio√® di tipo 1 (context-sensitive).\n\n\n\nüí° Si possono separare gli aspetti:\n\nDi tipo 2: la struttura del programma.\nDi tipo 1: le regole contestuali, come i nomi unici, i tipi delle variabili ecc.\n\n\nüîç L‚Äôanalisi sintattica (parsing):\n\nViene divisa in due fasi: una per controllare la struttura generale (tipo 2), l‚Äôaltra per gli aspetti contestuali (tipo 1).\n\n\n‚öôÔ∏è Il parsing √® la fase di verifica della correttezza del programma:\n\nServe prima della traduzione in codice eseguibile.\nIn questa fase si costruisce l‚Äôalbero sintattico della frase/programmazione.\nDa questo albero poi si genera il codice oggetto (eseguibile).\n\n\nüìö Le grammatiche formali sono nate per descrivere le frasi nei linguaggi naturali, ma‚Ä¶\n\n‚Ä¶sono risultate inadatte a quello scopo.\nTuttavia, si sono rivelate perfette per analizzare i linguaggi di programmazione.\n\n\nüí° A cosa servono nei linguaggi di programmazione?\n\nPer studiare la sintassi.\nPer descrivere formalmente se un programma √® corretto dal punto di vista sintattico.\n\n\nüß† Ogni linguaggio di programmazione pu√≤ essere associato a una grammatica G_{P}‚Äã:\n\nUn programma √® sintatticamente corretto se √® una parola del linguaggio generato da G_{P}‚Äã.\n\n\n\n\n"},"UNI/ANNO-2/FONDAMENTI/FONDAMENTI-LEZ.19":{"slug":"UNI/ANNO-2/FONDAMENTI/FONDAMENTI-LEZ.19","filePath":"UNI/ANNO 2/FONDAMENTI/FONDAMENTI LEZ.19.md","title":"FONDAMENTI LEZ.19","links":["UNI/ANNO-2/FONDAMENTI/FONDAMENTI-LEZ.13"],"tags":[],"content":"Ruolo delle grammatiche di tipo 2 e 3 nella programmazione\n\nTipo 2 (context-free) ‚Üí usato per la sintassi del linguaggio.\n\nvengono usate per definire se una sintassi di un codice √® corretta\n\ntipo graffe { } che devono essere aperte e poi chiuse\n\n\n\n\nTipo 3 (regolare) ‚Üí usato per componenti lessicali (parole chiave, nomi di variabili)\n\nGrammatiche di tipo 3\nIn questa lezione parleremo principalmente di grammatiche di tipo 3, se vuoi ripassarle ecco una rapida spiegazione:\n\n\n\n                  \n                  Tutti i linguaggi di tipo 3 sono REGOLARI \n                  \n                \n\necco un esempio:\n\nLa domanda √® sempre quella:\n\n\n                  \n                  G3 \\subsetG2 oppure √® \\subseteq\n                  \n                \n\nFacciamo anche qui un pumping lemma(leggermente differente dal precedente)\n\n\n                  \n                  Pumping lemma: \n                  \n                \n\nPer ogni linguaggio regolare L esiste un intero ( p_L &gt; 0 ) (dipendente esclusivamente da L) tale che per ogni parola ( z \\in L ) con ( |z| \\geq p_L ) esistono tre parole u, v, w tali che:\n\n( z = u\\ v\\ w )(cio√® z si pu√≤ esprimere come concatenazione di u, v, w)\n( |uv| \\leq p_L )\n( |v| \\geq 1 ) (v non pu√≤ essere la parola vuota)\n( uv^h w \\in L ) per ogni ( h \\geq 0 )\n\n\n\n\n\n                  \n                  perch√© v non deve essere una parola vuota e deve &quot;pompare&quot;? \n                  \n                \n\nüîÅ Idea fondamentale del Pumping Lemma\nSe un linguaggio √® regolare, allora ogni parola abbastanza lunga pu√≤ essere divisa in tre parti u, v, w, tali che:\n\nuv^n w \\in L \\quad \\forall n \\geq 0\n\n‚ö†Ô∏è Perch√© |v| \\geq 1?\nSe v = \\varepsilon, allora:\n\nuv^n w = uw per ogni n, quindi tutte le parole sono uguali\nüëâ Non possiamo testare se la ripetizione di v fa uscire la parola dal linguaggio.\n\nüí° Se invece |v| \\geq 1‚Ä¶\n\nRipetere v modifica la parola.\nSe uv^n w \\notin L per qualche n, abbiamo dimostrato che il linguaggio non √® regolare.\nin poche parole l‚Äôobiettivo √® quello di pompare v finch√© non scoppia e la parola non √® nel linguaggio\n\n\n\n\n\n                  \n                  questa del pumping lemma √® una condizione necessaria come quella delle grammatiche di tipo 2 \n                  \n                \n\n\nsono necessari perch√© comunque esistono linguaggi che soddisfano il pumping lemma ma non sono comunque regolari‚ùå\nse fosse stato sufficiente avremmo avuto la certezza che era regolare e di tipo 2\n\n\n\n\n\n                  \n                  per questa ragione, di nuovo, il pumping lemma si utilizza ‚Äò‚Äôal negativo‚Äô‚Äô ¬¥ ossia, per dimostrare che un linguaggio non √® regolare \n                  \n                \n\n\nper farlo si cerca di mandare ‚Äúfuori strada‚Äù le parole di quel linguaggio\n\nsi cerca di non far soddisfare il pumping lemma per dire che:\n\nquel linguaggio non √® regolare\n\n\n\n\n\n\n\nEsempio di uso del pumping lemma per far scoppiare tutta la parola\n\n\n\n                  \n                  questo esempio in poche parole \n                  \n                \n\nabbiamo una parola formata da due caratteri a e b ripetuti n-volte prima uno poi l‚Äôaltro\n\nse prendiamo la parola e la suddividiamo in uvw possiamo dire con certezza che uv sicuramente contengono solo caratteri a\n\ninvece w pu√≤ avere sia a che b\n\n\nnella dimostrazione diciamo che |uv|\\leq P_L solo perch√© lo diciamo noi\n\nfa parte della dimostrazione\n\n\ndetto questo quello che succede √® che se proviamo a ‚Äúpompare‚Äù la lettera v ci accorgiamo che il numero di caratteri a √® diverso dalle b e quindi il linguaggio non √® regolare\nfine!\n\n\n\n\nn.b u,v,w \\in \\Sigma^*\n\nSostanzialmente anche per dimostrare che G3 \\subset proprio di G2 fa una sorta di pumping lemma\nAutomi a stati finiti(decidibili)\ni linguaggi regolari sono \\subset dei linguaggi di tipo 2\n\nquindi anche loro possono essere decidibili\n\nse sono decidibili allora possono anche essere accettabili\nPossiamo quindi creare un modello di calcolo (le ASFD)\nche riconosce un linguaggio regolare\n\n\nper riconosce si intende se √® accettabile, decidibile ecc‚Ä¶\n\nCome sono definiti(informale):\n\nUn automa a stati finiti pu√≤ essere visto come una Macchina di Turing molto limitata, dove:\n\nc‚Äô√® un solo nastro, e non si pu√≤ scrivere su di esso\nla testina √® di sola lettura\nla computazione si ferma quando finisce l‚Äôinput(si raggiunge il \\square)\n\n\nLa funzione di transizione (\\delta) determina il passaggio da uno stato all‚Äôaltro in base al simbolo letto.\nLa computazione di un ASFD √® deterministica, finita e diretta: parte da uno stato iniziale, legge ogni simbolo uno dopo l‚Äôaltro, e accetta o rifiuta in base allo stato in cui si trova alla fine dell‚Äôinput.\nle ASFD a differenza della Minchie di Turing\n\nhanno stati che possono essere sia finali che non\nmentre invece le MT hanno degli stati definiti solo come terminali\n\ntu da q_a non puoi muoverti\n\n\n\n\nquesto creer√† dei piccoli problemi quando andremo a fare la solita cosa\n\nda macchina ASFD a MT\n\n\n\nCome sono definiti formalmente):\nUn automa a stati finiti deterministico (ASFD) √® una quintupla:\n\n\\langle \\Sigma, Q, q_0, Q_F, \\delta \\rangle\n\ndove:\n\n\\Sigma √® l‚Äôalfabeto\nQ √® l‚Äôinsieme degli stati\nq_0 \\in Q √® lo stato iniziale\nQ_F \\subseteq Q √® l‚Äôinsieme degli stati finali\n\\delta : Q \\times \\Sigma \\rightarrow Q √® la funzione totale di transizione, che associa a ogni coppia (stato, simbolo letto) un nuovo stato\n\nüîÅ Funzione di transizione in tabella\nLa funzione di transizione pu√≤ essere rappresentata tramite tabella:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\deltaabq_0q_0q_1q_1q_2q_0q_2q_2q_2\n\n\n                  \n                  La tabella deve essere tutta piena \n                  \n                \n\nnon possiamo avere caratteri con ‚Äúazioni‚Äù non definite\n\n\nLa notazione \\delta(q, a) = q&#039; √® equivalente alla quintupla della Macchina di Turing:\n\n\\langle q, a, a, q&#039;, D \\rangle\n\n(dove si legge un simbolo e ci si sposta a destra senza modificarlo)\nüìà Rappresentazione grafica\n√à possibile rappresentare l‚Äôautoma anche con un diagramma degli stati:\n\nLo stato iniziale ha una freccia entrante con etichetta ‚Äústart‚Äù\nGli stati finali sono indicati con un doppio cerchio\nEsempio:\n\n\n\nGli archi sono etichettati con i simboli letti (es. a, b, a,b), e i cerchi doppi rappresentano gli stati finali.\n\nConcetti delle MT trasposti sulle ASFD\nPoich√© un automa a stati finiti √® una particolare macchina di Turing, possiamo estendere agli automi a stati finiti le definizioni di:\n\nstato globale\ntransizione\ncomputazione\nesito di una computazione\n\ntali definizioni risultano semplificate per gli automi a stati finiti perch√© hanno funzionalit√† pi√π limitate\nEsempio di stato globale per le ASFD\n\nEsempio di transizione per le ASFD\n\n\n\n                  \n                  la prof ha detto che se non ti ricordi di scrivere |- va bene uguale perch√© tanto la \\rightarrow √® praticamente la stessa cosa\n                  \n                \n\nDefinizione formale di computazione e transizioni\nora procediamo a spiegare come funzionano le computazioni per un modello di calcolo di questo tipo\nSupponiamo di avere una parola: x=x_{0}‚Äã \\ x_{1} \\ ‚Äã‚Ä¶ \\ x_{n}‚Äã ‚àà Œ£^{‚àó}\nLa computazione parte da una configurazione iniziale (q_{0}, \\ x)\n\nCio√® siamo nello stato iniziale q_0‚Äã e dobbiamo leggere la parola x.\n\nOra, la sequenza di transizioni √® descritta cos√¨ (q_0, x_0x_1\\ldots x_n) \\vdash (q_1, x_1\\ldots x_n) \\vdash (q_2, x_2\\ldots x_n) \\vdash \\ldots \\vdash (q_n, x_n) \\vdash (q, \\square)Spiegazione:\n\nad ogni passo leggiamo un simbolo x_{i}\n\nsi pu√≤ anche dire che esso viene ‚Äúconsumato‚Äù\n\n\nlo stato cambia da q_{i} a q_{i+1} in base alla funzione di transizione \\delta(q_{i}, \\ x_{i})\nalla fine abbiamo letto tutto, e ci troviamo nello stato q e con input vuoto (\\square), ossia siamo a fine parola\n\nFunzione di transizione estesa \\delta^{*} (delta star)\nUna definizione ricorsiva di quello che abbiamo detto prima.\nViene definita funzione di transizione estesa  \\delta^*(q, x), e dice:\n\n\\delta^*(q, \\square) = q  (se l‚Äôinput √® vuoto, restiamo nello stato corrente)\n\\delta^*(q, a_1 a_2 \\ldots a_n) = \\delta(\\delta^*(q, a_1 \\ldots a_{n-1}), a_n)\n\n\nIn parole semplici:\n√® come dire: ‚Äúfaccio una serie di \\delta, e ogni volta prendo lo stato che ho ottenuto prima, e lo uso come input per la prossima transizione‚Äù.\n\nüß† Conclusione\nLa computazione dell‚Äôautoma a partire dalla configurazione iniziale (q_0, x) √®:\n\\delta^*(q_0, x)\nE questo stato finale ci dice l‚Äôesito dell‚Äôelaborazione.\nSe questo stato √® uno degli stati finali, allora la parola √® accettata.\n\n\n                  \n                  Osservazione: La funzione di transizione NON √à DEFINITA quando sul nastro viene letto blank ( \\square).\n                  \n                \n\nNel senso che, come abbiamo detto prima, quando arrivi al blank devi fermarti E QUINDI per farlo non abbiamo nessuna transizione dal blank in poi.\n\n\nConseguentemente all‚Äôosservazione, possiamo dire che tutte le computazioni di un ASFD terminano e che\n\n\nse lo stato in cui si trova \\in Q_{F}, la parola √® ACCETTATA\n\ndetto in termini ricorsivi ‚Äúse q = ùúπ^{*}(q_{0}, x) √® uno stato finale‚Äù\n\n\n\nse lo stato in cui si trova \\notin Q_{F}, la parola viene RIGETTATA\n\ndetto in termini ricorsivi ‚Äúquando q = ùúπ^{*}(q_{0}, x) non √® uno stato finale‚Äù\n\n\n\n\n\n                  \n                  Il linguaggio accettato da un ASFD A = \\langle \\Sigma, Q, q_0, Q_F, \\delta \\rangle √® l&#039;insieme delle parole accettate da A, ossia L(A) = \\{x \\in \\Sigma^{*} : (q_{0}, \\ x) \\vdash^{*} (q, \\ \\square) \\ \\ \\ \\text{con q} \\in Q_{F}\\}o equivalentemente L(A) = \\{x \\in \\Sigma^{*} : \\delta^{*}(q_{0}, \\ x) \\in Q_{F}\\}\n                  \n                \n\nin poche parole una serie di transizioni se portano a uno stato Q_f con il rispettivo \\square allora il linguaggio √® accettato da quel modello A\nA legge l‚Äôintera parola x, e:\n\nse termina in uno stato finale ‚Üí accetta x\nse termina in uno stato non finale ‚Üí rifiuta x\n\n\n\nSottolineiamo che, poich√© tutte le computazioni di un ASFD terminano sempre allora\n\n\n                  \n                  L(A) √à IL LINGUAGGIO DECISO DA A \n                  \n                \n\nDifferenza tra accettato e deciso:\nUn linguaggio √® accettato se l‚Äôautoma riconosce tutte le parole del linguaggio (ma potrebbe non terminare su quelle fuori dal linguaggio).\nUn linguaggio √® deciso se l‚Äôautoma termina sempre e dice s√¨ o no per ogni parola.\nPoich√© un ASFD termina sempre, ogni linguaggio accettato da un ASFD √® anche deciso da esso.\n\n\nEsempio\n\nMacchina di Turing vs Automa a stati finiti\nAbbiamo detto prima che un ASFD √® una MT con dei deficit.\nTuttavia, le descrizioni dei due modelli differiscono in due aspetti\n\nUn ASFD √® descritto mediante una funzione di transizione \\delta; mentre una MdT √® descritta mediante un insieme di quintuple\n\nSOLUZIONE: l‚Äôabbiamo gi√† vista prima, fai in modo che la quintupla riscriva letteralmente il carattere letto e si sposti a destra\n\n\n\nIn un ASFD ci possono essere transizioni che partono da uno stato finale, in una MT questa cosa non √® possibile\n\nSOLUZIONE\n\nfai in modo che gli unici stati finali della MT rimangano q_{A} e q_{R}\naggiungi a P, per ogni stato finale q dell‚Äôautoma, le quintuple „Äàq,\\square ,\\square ,q_A, F„Äâ\naggiungi a P, per ogni stato NON finale q dell‚Äôautoma, le quintuple \\langle q, \\square, \\square, q_{R}, F \\rangle\nIN PRATICA\nTutti gli stati finali q del ASFD diventano stati normalissimi per la MT, per√≤ quando li usi dici ‚Äúah aspetta, questo √® uno stato finale, allora PREMATURAMENTE aggiungo la quintupla \\langle q, \\square, \\square,q_A,F \\rangle nel caso in cui subito dopo volesse terminare‚Äù (nota come, nel caso in cui non terminasse, non andrei nella quintupla \\langle q, \\square, \\square, q_{A}, F \\rangle ma ne sceglierei un‚Äôaltra)\nStessa cosa vale per i gli stati NON FINALI.\n\n\n\n\n\nin definitiva possiamo dire che:\n\nCosa resta da dimostrare\n\nIn questa lezione vedremo solo il PASSO 1)\n\n\n                  \n                  TEOREMA G.14 \n                  \n                \n\nPer ogni ASFD A = \\langle Œ£, Q, q_0 , Q_F, ùõø \\ \\rangle esiste una grammatica G_A= \\langle ùëâ_T, ùëâ_N , P, S \\rangle  tale che L(A) = L(GA)\n\n‚úèÔ∏è Cosa significa?\n\nOgni automa a stati finiti pu√≤ essere tradotto in una grammatica regolare equivalente.\n\n\nN.B.: Dal punto due abbiamo che ogni stato ho un simbolo non terminale corrispondente A\n\n\n\n                  \n                  spiegazione degli ultimi 3 punti \n                  \n                \n\n\n\n\nIniziamo la dimostrazione vera e propria\nx \\in L(A) \\Leftarrow\\Rightarrow x \\in L(G_A)\nche dividiamo in 2 parti\nla prima:\nx \\in L(A) \\Rightarrow x \\in L(G_A)\ne poi la seconda:\nx \\in L(G_{A}) \\Rightarrow x \\in L(A)\nPARTE 1\nStiamo dimostrando che:\nx \\in L(A) \\Rightarrow x \\in L(G_A)cio√®:\n\nse una parola √® accettata dall‚Äôautoma, allora pu√≤ essere derivata dalla grammatica regolare costruita.\n\n‚úèÔ∏è Passaggi\n\n\nSia x = x_{0} \\ x_{1} \\ ... \\ x_{n} una qualunque parola che appartiene al linguaggio accettato da A\n\n\nSe x \\in L(A), allora possiamo scrivere che \\delta^{*}(q_{0}, \\ x) = q_{j} \\in Qossia che se l‚Äôautoma parte da q_{0} e legge tutta la parola, arriver√† in uno stato finale q_j\n\n\nAllora esiste una sequenza di stati q_{i_{1}}, \\ q_{i_{2}}, \\ ..., \\ q_{i_{n}} \\in Qtale che\n\n\\delta(q_{0}, \\ x_{0}) = q_{i_{1}}\n\\delta(q_{i_{1}}, \\ x_{1}) = q_{i_{2}}\n‚Ä¶\n\\delta(q_{i_{n-1}}, \\ x_{n-1}) = q_{i_{n}}\n\\delta(q_{i_{n}}, \\ x_{n}) = q_{j} \\in Q\n\nQuesta √® la sequenza di stati visitati dall‚Äôautoma mentre legge la parola, quindi ogni transizione √® collegata e arriviamo al nostro q_{j}\n\n\nüî∏Ora, colleghiamoci alla grammatica\nRicordiamo che nella grammatica avevamo costruito le produzioni cos√¨: A_i \\rightarrow a A_h \\quad \\text{se } \\delta(q_i, a) = q_hoppure A_i \\rightarrow a \\quad \\text{se } \\delta(q_i, a) = q_h \\in Q_F\nin poche parole se siamo alla fine non mettiamo pi√π parole che appartengono ai V_N\nQuesto vuol dire che possiamo riscrivere la sequenza di transizioni in questo modo\n\nA_0 \\rightarrow x_0 A_{i_1}\nA_{i_1} \\rightarrow x_1 A_{i_2}\n\\ldots\nA_{i_{n-1}} \\rightarrow x_{n-1} A_{i_n}\nA_{i_{n}}\\rightarrow x_{n}\n\nüß† Conclusione:\nLa grammatica ha quindi generato, tramite derivazione, la parola: A_0 \\Rightarrow x_0 A_{i_1} \\Rightarrow x_0 x_1 A_{i_2} \\Rightarrow \\ldots \\Rightarrow x_0 x_1 \\ldots x_{n-1} A_{i_n} \\Rightarrow x_0 x_1 \\ldots x_nCHE √à ESATTAMENTE LA PAROLA CHE APPARTIENE A L(A).\n\n\n                  \n                  Quindi x\\in L(G_{A})\n                  \n                \n\nPARTE 2\nOra stiamo dimostrando x \\in L(G_{A}) \\Rightarrow x \\in L(A)cio√®:\n\nSe una parola pu√≤ essere generata dalla grammatica regolare G_A‚Äã, allora √® anche accettata dall‚Äôautoma A.\n\n‚úèÔ∏è Passaggi della dimostrazione:\n\n\nSupponiamo che x = x_0 x_1 \\ldots x_n \\in L(G_A),\ncio√®: la grammatica ha derivato x, partendo da A_0: A_0 \\Rightarrow^* x\n\n\nAllora esistono non terminali A_{i_1}, A_{i_2}, \\ldots, A_{i_n} \\in V_N tali che:\n\nA_0 \\rightarrow x_0 A_{i_1}\nA_{i_1} \\rightarrow x_1 A_{i_2}\n\\ldots\nA_{i_{n-1}} \\rightarrow x_{n-1} A_{i_n}\nA_{i_n} \\rightarrow x_n\n\nüëâ Quindi la grammatica ha fatto esattamente la derivazione: A_0 \\Rightarrow x_0 A_{i_1} \\Rightarrow x_0 x_1 A_{i_2} \\Rightarrow \\ldots \\Rightarrow x_0 x_1 \\ldots x_n\n\n\nMa per come √® costruita G_A, ogni produzione corrisponde a una transizione dell‚Äôautoma:\n\n\\delta(q_0, x_0) = q_{i_1}\n\\delta(q_{i_1}, x_1) = q_{i_2}\n\\ldots\n\\delta(q_{i_{n-1}}, x_{n-1}) = q_{i_n}\n\\delta(q_{i_n}, x_n) = q_f \\in Q_F\n\nüìå Quindi: partendo da q_0, l‚Äôautoma legge tutta la parola e arriva in uno stato finale q_f, E QUINDI ACCETTA\n\n\n\n\n                  \n                  Quindi x \\in L(A)\n                  \n                \n\n‚úÖ Teorema completato:\nAbbiamo dimostrato entrambe le direzioni:\n\nx \\in L(A) \\Rightarrow x \\in L(G_A)\nx \\in L(G_A) \\Rightarrow x \\in L(A)\n\nquindi:\n\n\n                  \n                   L(A) = L(G_{A})\n                  \n                \n"},"UNI/ANNO-2/FONDAMENTI/FONDAMENTI-LEZ.2":{"slug":"UNI/ANNO-2/FONDAMENTI/FONDAMENTI-LEZ.2","filePath":"UNI/ANNO 2/FONDAMENTI/FONDAMENTI LEZ.2.md","title":"FONDAMENTI LEZ.2","links":[],"tags":[],"content":"Di cosa ha bisogno la nostra macchina\n\nI caratteri da scrivere sui nastri √® dato da \\Sigma che rappresenta un insieme di caratteri\nNecessita gli stati interni definiti da un insieme Q\ngli stati iniziali e finiti con q_0 e q_f\nq_0 \\in Q e Q_f  un insieme di stati finali che √® \\subseteq Q\nl‚Äôinsieme delle quintuple P (le istruzioni) P \\subseteq  Q x \\Sigma \\cup {\\square} x \\Sigma \\cup \\square x Q x \\{S,F,D\\}\n\\Sigma P e Q sono insiemi con cardinalit√† costante\n\n√à una macchina di Turing se\n\\forall q \\in Q a \\in \\Sigma [\\forall b,c \\in \\Sigma \\ \\forall q‚Äô, q‚Äô‚Äô \\in Q: b \\ne c \\ v \\ q‚Äô \\ne q‚Äô‚Äô [&lt;q,a,b,q‚Äô,m‚Äô&gt; \\notin P \\ v \\ &lt;q, a, c, q‚Äô‚Äô, m‚Äô‚Äô&gt; \\notin P]\nuna macchina di Turing √® definita da\n‚ü®Œ£,Q,q_0‚Äã,Q_F‚Äã,P‚ü©  che sono tutti gli insiemi citati prima\nFacciamo un esempio per definire una possibile incorrettezza\nsia Q=\\{q_0,q_1,q_2\\} e \\Sigma={0,1}\nse abbiamo &lt;q_0,0,0,q_1,D&gt; &lt;q_0,0,1,q_1,D&gt;\nle due quintuple sono distinte quindi non possono \\subseteq in P\nperch√© hanno stessa condizione ma azione diversa\nQuindi √® sufficiente scrivere tale che non esistono due coppie che hanno stessa condizione e diversa azione\nDefinizione di funzione di Transizione\nla definizione che indica come una funzione deve essere definita\n\\sigma : Q x \\Sigma‚Üí\\Sigma x Q x \\{S,F,D\\}\nci√≤ indica che abbiamo\n\nuno stato iniziale insieme di Q\nun dato di ricevuta iniziale insieme di \\Sigma\nche ci porta ad avere una azione con\nun dato in scrittura insieme di \\Sigma\nuno stato aggiornato che verr√† eseguito al prossimo step\nuno spostamento della testina da qualche parte o un fermo\n\nquando pu√≤ terminare?\nLa macchina pu√≤ terminare se non ha quintuple da eseguire oppure se deve terminare a prescindere\nESEMPIO\nData una parola binaria con una sola x progettare una macchina a un solo nastro che analizza e cancella via via i valori sul nastro\n\ntermina nello stato q_p se x contiene un numero pari di 1\ntermina in q_d se x contiene un numero dispari di 1\n\n\n\nESERCIZIO\nProgettare una macchina di Turing a due nastri che, avendo sul primo nastro due numeri interi della stessa lunghezza, calcola il valore della loro somma scrivendo il risultato sul secondo nastro ‚Äì ossia, si richiede di progettare una macchina di Turing che esegua la somma ‚Äúin riga‚Äù di due numeri\n\nUna serie di definizioni\n\\Sigma ^* sono tutte le parole dell‚Äôalfabeto, tutte le sequenze di caratteri combinate tra loro\nStato globale\n√à una ‚Äúfotografia‚Äù della macchina a un certo istante\nlo stato globale rappresenta lo stato interno della macchina:\n\nil contenuto del nastro\n\ntutti i vari caratteri non blank \\square\n\n\nla posizione della testina\n\nEcco come si scrive lo stato globale ad esempio di questo:\n√® sostanzialmente una parola dove rappresenta lo stato attuale di una macchina con il testo del nastro\necco due esempi:\n\nlo Stato √® iniziale quando siamo su q0 a b c d\nsi dice finale quando abbiamo qf\n\ntransizione\navviene tra due stati globali\nSG1‚ÜíSG2\nSG1 non deve essere stato uno globale finale\n√à il passaggio tra uno stato globale a un altro tramite l‚Äôesecuzione di una quintupla\n\ncomputazione\nEsecuzione della macchina di Turing applicata a un input\nSG0 ‚ÜíSg1‚ÜíSG2‚Üí(SG_f oppure errore e termina in uno stato non definito)\nanche un loop infinito dato da &lt;q,a,a,q,f&gt; ad esempio\nsono una serie di transizioni\npossiamo dire quindi che formalmente una computazione √® una sequenza di transizioni di vari stati Globali partendo da un SG0 con stato interno q_0\nse esiste una h tale che un SGh non ha transizioni allora significa che √® uno stato di terminazione\nmentre invece tutti gli altri che hanno transizioni sono definite tra 0 e h-1\n\n2 tipi di macchine di Turing\nTrasduttori\nCalcolano il valore di una funzione e la scrivono su nastro\n\ndispongono di un nastro di output(serve solo per il risultato)\nhanno un solo stato finale Q_f\n\nRiconoscitori\n\ncalcolano solo funzioni booleane(0,1) (V,F) (S,N)‚Ä¶\nnon hanno un nastro di output, il risultato lo danno nello Q_f stato finale\n\nvero falso ecc‚Ä¶\nun esempio e la macchina T_{parit√†}\nGli stati riconoscitori\nQ_a e Q_r\n\n\naccettazione\nrigetto\n"},"UNI/ANNO-2/FONDAMENTI/FONDAMENTI-LEZ.20":{"slug":"UNI/ANNO-2/FONDAMENTI/FONDAMENTI-LEZ.20","filePath":"UNI/ANNO 2/FONDAMENTI/FONDAMENTI LEZ.20.md","title":"FONDAMENTI LEZ.20","links":[],"tags":[],"content":"Dobbiamo continuare il discorso dell‚Äôultima volta\n\nPASSO 2 (inverso)\nper inverso si intende che per una grammatica ci sar√† un automi a stati finiti non deterministico che la riconosce\nAutoma a stati finiti NON DETERMINISTICO\nUn automa a stati finiti non deterministico (ASFND) √® una quintupla \\langle \\Sigma, Q, q_{0}, Q_{F}, \\delta \\rangledove:\n\n\\Sigma √® l‚Äôalfabeto\nQ √® l‚Äôinsieme degli stati\nq_0 √® lo stato iniziale\nQ_F √® l‚Äôinsieme degli stati finali\n\\delta √® la funzione di transizione non deterministica\n\n\nLa differenza sostanziale con un ASFD sta nella funzione di transizione \\delta:\ninvece di associare un solo stato come nei deterministici, qui associa un insieme di stati\n\nFormalmente: \\delta: Q \\times \\Sigma \\rightarrow P(Q)cio√®: per ogni coppia (stato, simbolo), ti restituisce un insieme di stati possibili.\nQuesta √® una funzione TOTALE.\n\nuna funzione totale √® una funzione che √® definita per ogni possibile input nel dominio.\n\nüîÅ Le definizioni (configurazione, transizione, funzione estesa) sono simili.\n‚úÖ Quando un ASFND accetta una parola?\n\nSe esiste almeno una sequenza di scelte che ti porta in uno stato finale.\n\nFormalmente:\n\nSia x = x_1 x_2 \\ldots x_n\nL‚ÄôASFND accetta x se esistono stati q_1, \\ldots, q_n tali che:\n\nq_1 \\in \\delta^*(q_0, x_1)\nq_2 \\in \\delta^*(q_1, x_2)\n‚Ä¶\nq_n \\in \\delta^*(q_{n-1}, x_n)\nq_n \\in Q_F\n\n\n\nüìå Cio√®: almeno un percorso porta in uno stato finale.\n\n\n                  \n                  Significato effettivo di \\delta^{*}\n                  \n                \n\nüìå Cosa significa &quot;q_1 \\in \\delta^*(q_0, x_1)&quot;?\n\n\n\\delta(q_0, x_1) = insieme degli stati raggiungibili leggendo un singolo simbolo\n\n\n\\delta^*(q_0, x_1) = insieme degli stati raggiungibili leggendo una stringa (in questo caso di lunghezza 1)\n\n\n\n\nüëâ Quindi in questo caso specifico, \\delta^*(q_0, x_1) coincide con \\delta(q_0, x_1),\nma la notazione con l‚Äôasterisco viene usata per uniformit√†, perch√© pu√≤ generalizzare a stringhe pi√π lunghe.\n‚ú≥Ô∏è Conclusione\nIl linguaggio accettato da un ASFND √® l‚Äôinsieme delle parole per cui esiste almeno un cammino che termina in uno stato finale.\nAltro modo (pi√π compatto) per dire quello che abbiamo detto ora\n\n‚ÄúUn ASFND A accetta una parola x se \\delta^*(q_0, x) \\cap Q_F \\neq \\emptyset‚Äù\n\nTradotto\nL‚Äôautoma accetta la parola x se, leggendo x dallo stato iniziale q_{0}, esiste almeno un cammino che porta in uno stato finale.\nIn simboli: L(A) = \\{ x \\in \\Sigma^* : \\delta^*(q_0, x) \\cap Q_F \\neq \\emptyset \\}\nPasso 3\n\n\n                  \n                  Teorema G.15 \n                  \n                \n\nPer ogni grammatica regolare G = \\langle V_N, V_T, P, S \\rangle\nesiste un ASFND A_G = \\langle \\Sigma, Q, q_0, Q_F, \\delta \\rangle tale che L(G) = L(A_{G})\n\n\nIn parole semplici\nIl teorema dice che ogni grammatica regolare pu√≤ essere simulata da un automa a stati finiti non deterministico, cio√® che i linguaggi generati da grammatiche regolari possono anche essere riconosciuti da questi automi non deterministici.\nüîç Come funziona la dimostrazione\n\nCostruzione dell‚Äôautoma a partire dalla grammatica\n\nSupponiamo di avere le produzioni nella forma B_{i} \\rightarrow aB_{j} \\ | a\nL‚Äôautoma A_{G} verr√† costruito in questo modo\n\nL‚Äôalfabeto dell‚Äôautoma √® \\Sigma = V_T\nGli stati Q corrispondono ai simboli non terminali della grammatica, pi√π uno stato q_{F}\nLo stato iniziale q_{0} corrisponde a S\nLe transizioni sono definite\n\n\\text{se } B_i \\rightarrow a B_j \\text{ √® una produzione, allora } q_j \\in \\delta(q_i, a)\n\\text{se } B_i \\rightarrow a \\text{ √® una produzione, allora } q_F \\in \\delta(q_i, a)\n\\text{se } \\varepsilon \\in L(G), \\text{ allora } q_F \\in \\delta(q_0, \\varepsilon)\n\n\n\n\n\n\n\nüìçDimostrazione\n‚úçÔ∏è Passaggi chiave:\nSupponiamo che:\n\nLa grammatica G abbia produzioni nella forma: $$\nB_0 \\rightarrow x_1 B_1, \\quad\nB_1 \\rightarrow x_2 B_2, \\quad\n\\dots, \\quad\nB_{n-2} \\rightarrow x_{n-1} B_{n-1}, \\quad\nB_{n-1} \\rightarrow x_n\n\n- Allora la parola $x = x_1 x_2 \\dots x_n$ √® derivabile da G, cio√® $x  \\in L(G)$\n\n###### üîÅ Traduzione in termini di automa:\n\n- Ai simboli $B_0, B_1, ..., B_{n-1}$‚Äã della grammatica corrispondono stati $q_0, q_1, ..., q_{n-1}$‚Äã nell‚Äôautoma.\n    \n- Se la grammatica ha le produzioni viste sopra, allora l‚Äôautoma ha le transizioni: $$\nq_1 \\in \\delta(q_0, x_1), \\quad\nq_2 \\in \\delta(q_1, x_2), \\quad\n\\dots, \\quad\nq_{n-1} \\in \\delta(q_{n-2}, x_{n-1}), \\quad\nq_F \\in \\delta(q_{n-1}, x_n)\n‚úÖ Conclusione:\nLa sequenza di produzioni nella grammatica corrisponde a una sequenza di transizioni dell‚Äôautoma che porta dallo stato iniziale q_0‚Äã allo stato finale q_F‚Äã, leggendo esattamente i simboli della parola x.\nQuindi:\n\nx \\in L(G) \\iff x \\in L(A_G)\n\nPasso 4\n\n\n                  \n                  Teorema G.16 \n                  \n                \n\nPer ogni ASFND N A = \\langle \\Sigma, Q, q_{0}, Q_{F}, \\delta \\rangle esiste un ASFD A = \\langle \\Sigma, Q_{D}, q_{0D}, Q_{FD}, \\delta_{D} \\rangle\ntale che L(NA) = L(A)\n\n\nIn parole semplici\nIl teorema dice che qualsiasi automa a stati finiti non deterministico (ASFND) pu√≤ essere trasformato in un automa deterministico (ASFD) che riconosce esattamente lo stesso linguaggio.\n‚öôÔ∏è Costruzione dell‚Äôautoma deterministico A\nDati\n\nsia dato NA = \\langle \\Sigma, Q, q_0, Q_F, \\delta \\rangle\ncostruiamo A = \\langle \\Sigma, Q_{D}, q_{0D}, Q_{FD}, \\delta_{D} \\rangle\nNota come A opera sullo stesso alfabeto di NA\n\nStruttura\n\n\nGli stati del nuovo automa deterministico Q_D‚Äã sono tutti i sottoinsiemi degli stati di NA\nOssia, se indichiamo Q_{D} = \\langle \\omega_{1,} \\dots, \\omega_{H} \\rangle, ciascun \\omega_{i} √® un sottoinsieme di Q dell‚Äôautoma NA\n\n\nponiamo q_{0D} = q_{0}\n\n\nponiamo \\{ \\omega_{i} \\subseteq Q : \\omega_{i} \\cap Q_F \\neq \\emptyset \\}\nOssia gli stati finali di A sono tutti quei sottoinsiemi di Q che contengono almeno uno stato finale di NA\n\n\nper ogni a \\in \\Sigma e \\omega \\in Q_{D}, poniamo \\delta_D(\\omega, a) = \\omega&#039; tale che \\omega&#039; = \\bigcup_{q \\in \\omega} \\delta(q, a)\nLa frase significa:\n‚ÄúPer calcolare la transizione dell‚Äôautoma deterministico da un insieme di stati \\omega, leggendo il simbolo a, guarda dove pu√≤ andare ciascuno dei singoli stati in \\omega nell‚Äôautoma originale non deterministico, e poi metti insieme tutti i risultati: quello sar√† il nuovo stato.‚Äù\n\n\nla U indica l‚Äôunione di tutti gli insiemi delle transizioni delta\n\n\nla macchina non deterministica ha una w che √® un insieme di stati perch√© deve simulare la macchina non deterministica che ovviamente ne ha pi√π di uno\n\n√® una sorta di stratagemma per avere pi√π stati in una macchina deterministica\n\n\n\n\nOra che abbiamo definito A, dobbiamo dimostrare che x \\in L(NA) \\iff x \\in L(A)ossia che la parola x √® accettata dall‚Äôautoma non deterministico se e solo se √® accettata da quello deterministico che abbiamo costruito.\nLo vediamo informalmente\n\nCome vedi\n\na sinistra abbiamo la computazione dell‚Äôautoma NON DETERMINISTICO, il quale pu√≤ avere pi√π scelte\na destra abbiamo la computazione dell‚Äôautoma DETERMINISTICO\n\nPossiamo quindi concludere che\n\n\n                  \n                  Teorema G.17 \n                  \n                \n\nLa classe dei linguaggi regolari coincide con la classe dei linguaggi decisi da automi a stati finiti deterministici.\n\n\nChiusura: Unione, Intersezione e Complemento\nCi occupiamo ora di studiare se la propriet√† di essere regolari si trasporta all‚Äôunione, all‚Äôintersezione e al complemento.\nUnione\n\n\n                  \n                  Se due linguaggi L_1‚Äã e L_2‚Äã sono regolari, allora anche L = L_1 \\cup L_2‚Äã √® regolare.\n                  \n                \n\nüß† Come lo si dimostra?\nL‚Äôidea √® usare un automa non deterministico (ASFND) per costruire un automa che riconosce L_1 \\cup L_2, dato che conosciamo automi deterministici per L_1 e L_2.\n‚öôÔ∏è Costruzione tecnica\nSupponiamo di avere\n\n\nA_1 = \\langle \\Sigma, Q_1, q_{01}, Q_{F1}, \\delta_1 \\rangle: l‚Äôautoma che decide L_1\n\n\nA_2 = \\langle \\Sigma, Q_2, q_{02}, Q_{F2}, \\delta_2 \\rangle: l‚Äôautoma che decide L_2\n\n\nCostruiamo un ASFND (automa non deterministico)\nNA = \\langle \\Sigma, Q, q_0, Q_F, \\delta \\rangletale che riconosce L_1 \\cup L_2.\nDettagli della costruzione\nüß© Stati\nL‚Äôinsieme degli stati √®: Q = Q_1 \\cup Q_2 \\cup {q_0}\nAggiungiamo un nuovo stato iniziale q_0, che non c‚Äôera n√© in A_1 n√© in A_2.\n‚úÖ Stati finali\nL‚Äôinsieme degli stati finali √®: Q_F = Q_{F1} \\cup Q_{F2}\nCio√®: sono finali tutti gli stati finali di A_1 e A_2.\nüîÅ Funzione di transizione\nDefinita cos√¨:\n\n\nDal nuovo stato iniziale q_0, per ogni simbolo a \\in \\Sigma:\n\\delta(q_0, a) = \\delta_1(q_{01}, a) \\cup \\delta_2(q_{02}, a)\nüëâ Cio√®: da q_0, l‚Äôautoma pu√≤ non deterministicamente iniziare a comportarsi come A_1 o come A_2.\n\n\nPer tutti gli altri stati:\n\nSe q \\in Q_1, allora: \\delta(q, a) = \\delta_1(q, a)\nSe q \\in Q_2, allora: \\delta(q, a) = \\delta_2(q, a)\n\n\n\nüéØ Risultato\nQuesto automa NA pu√≤ decidere L_1 \\cup L_2 perch√©:\n\nDallo stato iniziale q_0, pu√≤ simulare sia A_1 che A_2.\nSe la stringa appartiene a L_1 o a L_2, esiste una computazione che porter√† a uno stato finale.\nE quindi NA accetter√† la parola.\n\nComplemento\n\n\n                  \n                  Se L √® un linguaggio regolare, allora anche L^C (il suo complemento) √® regolare.\n                  \n                \n\nüß† Come si dimostra?\nL‚Äôidea √®\n\npartire da un automa A che accetta L, linguaggio regolare\ncostruire un automa A^{C}, complementare ad A, che accetta L^{C}\ndimostrare che questo nuovo automa √® deterministico (ASFD) ‚Üí L^{C} √® regolare\n\nInfatti, si vuole sfruttare il fatto che i linguaggi regolari sono riconoscibili da automi deterministici (ASFD).\n‚öôÔ∏è Costruzione dell‚Äôautoma per il complemento\nSupponiamo di avere un ASFD che riconosce L:\nA = \\langle \\Sigma, Q, q_0, Q_F, \\delta \\rangle\n‚Üí questo √® l‚Äôautoma che accetta solo le parole di L.\n‚ú® Come si costruisce A^C?\nSi mantengono tutti gli elementi invariati, tranne gli stati finali.\nI nuovi stati finali saranno:  Q - Q_F\n‚Üí cio√® tutti e soli gli stati dell‚Äôautoma che non erano finali in A.\n\nquindi praticamente gli stati finali di A^C sono gli stati non finali di A\n\nFormalmente:  A^C = \\langle \\Sigma, Q, q_0, Q - Q_F, \\delta \\rangle\n‚úÖ Conclusione\n\nL‚Äôautoma A^C accetta tutte le stringhe che non vengono accettate da A.\nQuindi A^C accetta L^C, il complemento di L.\nEssendo A^C un ASFD, allora anche L^C √® regolare.\n\nIntersezione\n\n\n                  \n                  Se L_1 e L_2 sono due linguaggi regolari, allora L = L_1 \\cap L_2 √® regolare.\n                  \n                \n\nüß† Strategia (usando complementi e unione)\nLa dimostrazione sfrutta le due propriet√† di chiusura gi√† dimostrate\n\nla classe dei linguaggi regolari √® chiusa rispetto al complemento *\nla classe dei linguaggi regolari √® chiusa rispetto all‚Äôunione *\n\nE usa una legge di De Morgan dell‚Äôalgebra degli insiemi L_1 \\cap L_2 = (L_1^C \\cup L_2^C)^C\n‚ú® Passaggi della dimostrazione\n\n\nSe L_{1} e L_{2} sono regolai, allora anche i loro complementi L_{1}^{C} e L_{2}^{C} sono regolari *\n\n\nDato che i linguaggi regolari √® chiusa rispetto all‚Äôunione *, allora anche L_{1}^{C} \\cup L_{2}^{C} √® regolare\n\n\nOra che abbiamo formato un linguaggio unico (regolare), per la propriet√† * sappiamo che il complemento di quel linguaggio √® regolare (L_1^C \\cup L_2^C)^C\n\n\nMa questo √® proprio l‚Äôintersezione L_1 \\cap L_2 = (L_1^C \\cup L_2^C)^C\n\n\n‚úÖ Conclusione:\nüëâ Quindi anche l‚Äôintersezione L_1 \\cap L_2 √® regolare.\n\nEspressioni regolari\nLe espressioni regolari sono uno strumento che permette di descrivere una particolare classe di linguaggi\nDefinizione\nDati\n\nun insieme di caratteri \\Sigma\nuna parola r sull‚Äôalfabeto \\Sigma \\cup \\{+, *, (, ), \\cdot, \\emptyset\\}\ndove\n\n+ ‚Üí unione (scelta di accettazione tra due alternative)\n\nAlternativa: a + b accetta ‚Äúa‚Äù o ‚Äúb‚Äù\n\n\n\\cdot ‚Üí concatenazione\n\nSequenza: a ¬∑ b accetta ‚Äúab‚Äù\n\n\n* ‚Üí chiusura di Kleene (ripetizione 0 o pi√π volte)\n\nRipetizione: a* accetta &quot;&quot;, ‚Äúa‚Äù, ‚Äúaa‚Äù, ‚Äúaaa‚Äù, ‚Ä¶\n\n\n(,) ‚Üí per raggruppare\n\nCome nelle operazioni matematiche: (a + b)*\n\n\n\\emptyset ‚Üí il linguaggio vuoto\n\nNon accetta nessuna parola\n\n\n\n\n\nAbbiamo un‚Äôespressione regolare se\n\nr = \\emptyset, oppure\nr \\in \\Sigma, oppure\ndato due espressioni regolari s e t, abbiamo che\n\nr = (s + t), oppure\nr = (s \\cdot t), oppure\nr = s^{*}\n\n\n\n\n\n\n                  \n                  Secondo esempio \n                  \n                \n\nAndiamo per parti\n\nTutte le a e le b sono espressioni regolari (\\in \\Sigma)\n(a \\cdot b) ‚Üí concatenazione di due espressioni regolari ‚Üí regolare\n(a \\cdot b)^{*} ‚Üí chiusura di Kleene ‚Üí regolare\nb \\cdot (a \\cdot b)^{*} ‚Üí concatenazione di due espressioni regolari ‚Üí  regolare\n(b \\cdot (a \\cdot b)^{*}) ‚Üí chiusura di Kleene ‚Üí regolare\na + (b \\cdot (a \\cdot b)^{*}) ‚Üí unione di due espressioni regolari ‚Üí  regolare\n(a + (b \\cdot (a \\cdot b)^{*})) ‚Üí raggruppamento ‚Üí regolare\n\n\n\nInterpretazione e significato\nSe interpretiamo i simboli speciali (+, *, ¬∑, ‚àÖ) come operazioni su insiemi di parole, e se consideriamo ogni carattere dell‚Äôalfabeto come un ‚Äúsingleton‚Äù\n‚Üí allora possiamo usare le espressioni regolari per definire linguaggi (insiemi di stringhe).\n\n\n                  \n                   Cosa significa &quot;singleton&quot; in questo contesto?\n                  \n                \n\nUn singleton √® un insieme che contiene un solo elemento.\nNel contesto delle espressioni regolari:\n\nOgni carattere dell‚Äôalfabeto (ad esempio a, b, 0, 1, ecc.) viene interpretato come un insieme contenente solo quella parola.\nPer esempio:\n\nIl simbolo a rappresenta il linguaggio {a} ‚Üí un singleton\nIl simbolo b rappresenta {b} ‚Üí un singleton\nIl simbolo 0 rappresenta {0} ‚Üí un singleton\n\n\n\n\n\nüî£ Interpretazione degli elementi di base\n\n\nSimbolo \\emptyset\nL‚Äôespressione regolare \\emptyset definisce il linguaggio vuoto: \nL = \\emptyset‚Üí cio√® nessuna stringa √® accettata.\n\n\nSimbolo a \\in \\Sigma\nL‚Äôespressione regolare a definisce il linguaggio L = \\{a\\}‚Üí cio√® un singleton che contiene solo la parola formata da a\n\n\nüîÅ Operatori composti\nDate due espressioni regolari s e t, che definiscono i linguaggi L(s) e L(t), allora:\n\n\nUnione +\n\n(s + t) definisce: L = L(s) \\cup L(t)‚Üí ossia l‚Äôunione tra due parole\n\n\n\nConcatenazione ¬∑\n\n(s \\cdot t) definisce: L = \\{ xy : x \\in L(s),\\ y \\in L(t) \\}‚Üí ossia tutte le parole ottenuta concatenando una parola di L(s) con una parola di L(t)\nüí¨ Ad esempio, se L(s) = \\{a\\} e L(t) = \\{b\\}, allora L = \\{ab\\}\n\n\n\nChiusura di Kleene *\n\ns^{*} definisce: $$\nL = \\text{tutte le concatenazioni di } 0 \\text{ o pi√π parole in } L(s)\n\n\n\n\t- include\n\t\t- $\\varepsilon$ (stringa vuota ‚Üí 0 ripetizioni)\n\t\t- tutte le stringhe ottenute concatenando **1, 2, 3, ...** elementi di $L(s)$\n\t\t\tcos√¨ come, ad esempio, $Œ£*$ √® l‚Äôinsieme delle parole che sono concatenazione di  (0 o pi√π) caratteri di $Œ£$\n\n![[Pasted image 20250423181308.png]]\n\n\n&gt;[!question] Ma possiamo definire un qualunque linguaggio mediante una espressione regolare?\n&gt; \n&gt; **NO**, per il seguente teorema.\n\n&gt;[!lemma] Teorema G.18\n&gt; \n&gt;Un linguaggio √® generato da una grammatica di tipo 3 $\\iff$ **esso √® definito da una espressione regolare**.\n\nRiprendendo, e collegando a G.18, il teorema G.17, che dice \n\t**grammatica regolare ‚Üî automa a stati finiti**\n\nPossiamo affermare che\n##### Un linguaggio regolare √®:\n- ‚úÖ un linguaggio **generato da una grammatica di tipo 3**\n- ‚úÖ un linguaggio **deciso da un automa a stati finiti (deterministico o non)**\n- ‚úÖ un linguaggio **definito da un‚Äôespressione regolare**\n\n##### üß† In pratica:\nSe riesci a scrivere un‚Äôespressione regolare, allora esiste **un automa finito che la riconosce**, e **una grammatica regolare che la genera**, e viceversa.\nHai quindi **tre modi equivalenti** per descrivere un linguaggio regolare!\n\n\n---\n\n#### Introduzione alla complessit√† e Torre di Hanoi\n\n&gt;[!tip] Riassunto di tutto ci√≤\n&gt; \n&gt;Ci sono problemi che sappiamo risolvere ma non lo facciamo perch√© ci vuole talmente tanto tempo che sarebbe¬†infattibile.\n&gt;\n&gt;Un esempio √® quello della torre di Hanoi a 64 dischi, che dopo il relativo calcolo di complessit√† temporale $(2^n)$ si scopre ci vorrebbe talmente tanto tempo per risolverla che non basterebbe la vita umana sulla terra fino allo spegnimento¬†del¬†sole."},"UNI/ANNO-2/FONDAMENTI/FONDAMENTI-LEZ.21":{"slug":"UNI/ANNO-2/FONDAMENTI/FONDAMENTI-LEZ.21","filePath":"UNI/ANNO 2/FONDAMENTI/FONDAMENTI LEZ.21.md","title":"FONDAMENTI LEZ.21","links":[],"tags":[],"content":"Misura di complessit√†\nUna misura di complessit√† √® una funzione c che associa un valore numerico ad una macchina di Turing T e ad un suo input.\n\n\n                  \n                   c(T,x) rappresenta il &quot;costo&quot; della computazione T(x)\n                  \n                \n\nDue propriet√† fondamentali da dover rispettare (Assiomi di Blum)\n\nc √® definita per TUTTE E SOLE le computazioni che terminano\n\nanche perch√©, se una computazione non termina non ha senso considerare un costo ‚Äúfinito‚Äù\n\n\nc deve essere calcolabile\n\ndeve esistere una macchina di Turing M che, ricevendo come input una macchina di Turing T e un suo input x, calcola c(T,x) ogniqualvolta c(T,x) √® definita (ossia quando T(x) termina\n\n\n\n\nMisure deterministiche\nQueste sono misure di complessit√† che si riferiscono a computazioni deterministiche.\nQuindi\n\nper ogni macchina di Turing deterministica T (riconoscitore o trasduttore) definita su un alfabeto \\Sigma\ne per ogni x \\in \\Sigma^{*}\ndefiniamo le due funzioni associate alla computazione T(x)\n\n\n\n\n                  \n                  OSSERVAZIONE \n                  \n                \n\nLe due funzioni sono PARZIALI: non sono definite quando T(x) non termina\n\n\nDimostriamo ora che dtime e dspace rispettano i due assiomi di Blum\n\n\n==c √® definita per TUTTE E SOLE le computazioni che terminano==\nLO ABBIAMO GI√Ä DIMOSTRATO IN ‚ÄúOSSERVAZIONE‚Äù\n\nPer ogni macchina di Turing deterministica T e per ogni x ‚àà Œ£^{*}, dtime(T,x) e dspace(T,x) sono definite se e solo se T(x) termina.\n\n\n\n==c deve essere calcolabile==\nPartiamo da dtime\nper verificare se rispetta i due assiomi di Blum andiamo a vedere U‚Äô\nuna classica macchina Universale U ma con un nastro in pi√π che conta 1 ogni volta che facciamo una quintupla\n\n\n\novviamente la simulazione avviene a scatola aperta\n\nOGNI quintupla deve essere modificata per mettere 1 e poi andare a destra\ndovremmo prendere tutte le quintuple di U e farlo\n\n\n\n\n\n\n                  \n                  Dimostriamo che dspace √® calcolabile\n                  \n                \n\nüîß Idea\n\n\nCostruiamo una modifica U_{dspace} della macchina di Turing universale U.\n\nüîπ Modifiche rispetto a U\n\nAggiungiamo a U un nuovo nastro N‚ÇÖ che funger√† da contatore del numero di celle diverse utilizzate nella computazione di T(x)\nU_dspace(T, x) si comporta come U(T, x), con la differenza che:\nTiene traccia dell‚Äôinsieme delle celle di lavoro visitate almeno una volta\nOgni volta che visita una nuova cella non ancora raggiunta, scrive un 1 sul nastro N‚ÇÖ e la registra\nAlla fine della computazione, il nastro N‚ÇÖ contiene in unario il numero di celle di memoria usate da T(x)\n\nüîö Risultato\n\nSe T(x) termina, allora U_dspace(T,x) termina e sul nastro N‚ÇÖ c‚Äô√® il valore dspace(T,x)\nQuindi dspace(T, x) √® una funzione calcolabile\nSe T(x) non termina, anche dspace(T,x) non √® definita (√® una funzione parziale)\n\n‚úÖ Conclusione\n\nLa funzione dspace soddisfa i due assiomi di Blum e √® calcolabile.\n\nMisure non deterministiche\nora lavoriamo su macchine non deterministiche\nQueste sono misure di complessit√† che si riferiscono a computazioni NON deterministiche.\nQuindi\n\nper ogni macchina di Turing deterministica T (riconoscitore pefforza!!) definita su un albero \\Sigma\ne per ogni x \\in \\Sigma^{*}\n\ntali che NT(x) ACCETTA\ndefiniamo le due funzioni seguenti\n\n\n\n\n\n\n                  \n                  perch√© prendiamo il minimo? \n                  \n                \n\npossono esserci diverse computazioni che accettano con tempi diversi\n\nil genio √® burlone pasticcione ma anche pigro quindi prende le minime\n\n\n\n\n\n                  \n                  OSSERVAZIONE \n                  \n                \n\nQueste due funzioni sono MOLTO PARZIALI\nquesto perch√© sono accettanti, ovvero non decidono un linguaggio ma lo accettano\n\nquesto significa che ci sono ancora pi√π spazi non definiti\n\nspazi dove termina ma non accetta\n\n\n\n\n\n\n\n                  \n                  perch√© diciamo solo che accettano e non che decidono pure? \n                  \n                \n\nperch√© in realt√† le macchine di Turing non deterministiche non decide un linguaggio nel senso classico, questo √® dovuto a una asimmetria tra la accettazione e il rigetto, infatti diciamo per semplificare le cose che:\n\nuna macchina non deterministica\n\naccetta se in una qualche computazione accetta\nrigetta se per qualsiasi computazione termina(non va in loop) e non accetta\nquesto per√≤ non significa che decide il linguaggio per√≤ almeno termina e da qualcosa in output\n\n\nricorda bene che se va in loop allora rientriamo nel caso loop, perch√© non sapremo mai l‚Äôesito finale di quel ramo\n\nüìå In sintesi: una NTM accetta, ma non sempre decide, perch√© l‚Äôeventuale presenza di loop rende impossibile determinare l‚Äôesito complessivo in certi casi.\n\n\nCambio delle definizioni nspace e ntime\noltre a ci√≤ che √® stato detto prima aggiungiamo anche i casi di rigetto:\n\n\n\n                  \n                  possiamo notare che precedentemente le definizioni di entrambi non rispettavano gli assiomi di Blum visto che prendevamo in considerazione solo i casi di accettazione, non era definita per i casi di rigetto, ricordando ci√≤ che diceva il primo assioma \n                  \n                \n\n==c √® definita per TUTTE E SOLE le computazioni che terminano==\n\npossiamo quindi dire che in questo caso non era definita per i rigetti\n\n\n\n\nProcediamo a dimostrare se queste due funzioni rispettano gli assiomi\nscherzetto! non lo chiede all‚Äôesame pappapero pappapa!\nil primo assioma gi√† abbiamo visto perch√© ha senso\nper definire se rispetta il secondo assioma, ovvero se √® calcolabile si fa una sorta di macchina universale come dtime di prima\n\nma tanto non lo chiede\nnspace(NT,x)\nuguale a ntime\n\nRelazione tra queste 4 funzioni temporali e spaziali\nricapitolando abbiamo:\ndtime, dspace, ntime, nspace\nquali di questi possiamo mettere in relazione?\nuna macchina non deterministica pu√≤ anche essere deterministica\n\nquindi dtime(T,x)=ntime(T,x)\npoi con il teorema 6.1 mettiamo in relazione tutto il resto\n\n\n\n                  \n                  Teorema 6.1 \n                  \n                \n\nSia T una macchina di Turing deterministica, definita su un alfabeto Œ£ (non contenente il simbolo \\square  ) e un insieme degli stati Q, e sia x ‚àà Œ£^‚àó tale che T(x) termina. Allora\ndspace(T,x)\\leq dtime(T,x)\\leq {dspace(T,x)} *|Q| *(|\\Sigma| +1)^{dspace(T,x)}\n\n\nora risolviamo piano piano tutto il teorema\nRisoluzione teorema 6.1(in parti)\nParte 1\ndspace(T,x) ‚â§ dtime(T,x)\n\nquesto perch√© per fare una scrittura comunque devi usare almeno il tempo della macchina\n\nla prof la scrittura la chiama anche sporcatura del nastro\n\nperch√© √® come se stai scrivendo qualcosa su una tela vuota, la sporchi\nquindi: se T(x) utilizza dspace(T,x) celle di memoria, quelle celle deve almeno leggerl\n\n\n\n\nquesta definizione non prende i casi anomali che distruggono questo \\leq\n\nParte 2\ndtime(T,x)\\leq {dspace(T,x)} *|Q| *(|\\Sigma| +1)^{dspace(T,x)}\nper facilit√† di lettura andiamo a definire che dspace(T,x)=H\ncosa indica quella cosa a destra del \\leq ?\nH *|Q| *(|\\Sigma| +1)^H\n√® il numero di stati globali possibili di T nel caso in cui non pi√π di dspace(T,x) celle del nastro vengano utilizzate dalla computazione T(x)\nscomponiamo le lettere\npossiamo dire sicuramente che H √® il numero di elementi nel nastro\n\nquindi avremo come numero di parole nelle H celle come \\leq (|\\Sigma|+1)^H\n\ntutti i caratteri + il blank\nelevato alla H ovvero il numero di celle\nse non capisci rivediti l‚Äôargomento di probabilit√† tipo sul calcolo combinatorio\n\n\ncome numero di stati globali in H avremo (|\\Sigma |+1)^H\nH*|Q|\n- |Q| perch√© possiamo essere in qualsiasi stato\n- combinato anche al fatto che pu√≤ essere in una delle qualsiasi celle H\nquindi alla fine avremo H *|Q| *(|\\Sigma| +1)^H\nponiamo H *|Q| *(|\\Sigma| +1)^H = k(T,x)\nquindi ora sappiamo che k(T,x) √® il numero di stati globali possibili in T\nora, ricordiamo che una computazione (deterministica) √® una successione di stati globali tali che si passa da uno stato globale al successivo eseguendo una quintupla\nse in una sequenza di stati globali DISTINTI raggiungiamo K+1 significa che siamo in un loop!\nSG_0 \\rightarrow SG_1 \\ ... SG_K \\rightarrow SG_{K+1}\nK doveva essere l‚Äôultimo stato\nma visto che siamo in K+1 siamo in un loop e allora non termina\n\nMa noi sappiamo che T(x) termina (√® una computazione valida e finita),\nquindi non pu√≤ entrare in loop,\nquindi non pu√≤ durare pi√π di k(T,x)) passi.\n‚û°Ô∏è Questo limita il tempo in funzione dello spazio.\nüß† Quindi dtime conta solo le computazioni che terminano\n\nora facciamo il caso non deterministico del teorema 6.1\nper le non deterministiche √® uguale ma scambi d con n\nRelazione tra queste 4 funzioni\ndtime, dspace, ntime, nspace\nquali di questi possiamo mettere in relazione?\ndati T e x dtime(T,x)\nuna macchina non deterministica pu√≤ anche essere deterministica\nquindi dtime(T,x)=ntime(T,x)\npossiamo dire che dspace(T,x)\\leq dtime(T,x)\n\nquesto perch√® per fare una scrittura comunque devi usare almeno il tempo della macchina\n\nse definiamo che dspace(T,x)=H\npossiamo dire sicuramente che H √® il numero di elementi nel nastro\n\nquindi avremo come numero di parole nelle H celle come \\leq (|\\Sigma|+1)^H\ncome numero di stati globali in H avremo \\leq H * |Q| *(|\\Sigma |+1)^H mettiamo che questo sia uguale  a K\nse in una sequenza di stati globali DISTINTI raggiungiamo K+1 significa che siamo in un loop!\nSG_0 \\rightarrow SG_1 \\ ... SG_K \\rightarrow SG_{K+1} visto che siamo in K+1 siamo in un loop e allora non termina\nquindi tutto questo per definire che\ndspace(T,x)\\leq dtime(T,x)\\leq H *|Q| *(|\\Sigma| +1)^H\nper√≤ abbiamo detto che dspace(T,x)=H\nquindi‚Ä¶\ndspace(T,x)\\leq dtime(T,x)\\leq H *|Q| *(|\\Sigma| +1)^{dspace(T,x)}\n\nper le non deterministiche √® uguale ma scambi d con n\n\nla dimostrazione non √® da fare\nDefinizione dei tempi\nSia f : ‚Ñï ‚Üí ‚Ñï una funzione totale calcolabile.\nServe a esprimere limiti di tempo o spazio in funzione della lunghezza dell‚Äôinput ‚à£x‚à£|x|‚à£x‚à£\nSia Œ£ un alfabeto finito e sia x ‚àà Œ£^‚àó\n\nindichiamo con |x| il numero di caratteri di x\n\nL \\subseteq \\Sigma^* √® deciso in un tempo deterministico f(n) se:\nesiste una macchina di Turing deterministica T che decide L e tale che\n\nper ogni x ‚àà Œ£^‚àó, dtime(T,x) ‚â§ f(|x|)\n\ne abbiamo che invece ( dspace(T,x) = f(|x|) ).\n\n\n\nPer le non deterministiche √® un po‚Äô pi√π difficile perch√© c‚Äô√® quella roba dei due stati di accetto e rigetto\nUn linguaggio L ‚äÜ Œ£^‚àó √® accettato in tempo (spazio) non deterministico f(n) se:\nesiste una macchina di Turing non deterministica NT che accetta L e tale che\n\nper ogni x ‚àà L, ntime(NT,x) ‚â§ f(|x|)\n\ndove per lo spazio √® uguale ( nspace(NT,x) ‚â§ f(|x|) )\nqui √® accettato se la macchina NT non termina sempre ma accetta quindi basta che sia un riconoscitore\n\n\n\ninvece √® deciso:\nUn linguaggio L ‚äÜ Œ£^‚àó √® deciso in tempo (spazio) non deterministico f(n) se:\nesiste una macchina di Turing non deterministica NT che accetta L e tale che\n\nper ogni x ‚àà \\Sigma^*, ntime(NT,x) ‚â§ f(|x|)\n\ndove per lo spazio √® uguale( nspace(NT,x) ‚â§ f(|x|) )\nqui la macchina deve essere di tipo trasduttore quindi termina sempre e quindi decide\n\n\n\npiccole precisazioni su quanto detto prima\nüìå 1. Deterministico ‚áí nessun problema\nNel caso deterministico, tutto √® semplice:\n\nSe una macchina accetta sempre decidendo correttamente (termina su ogni input), allora accettare = decidere\nNon c‚Äô√® distinzione tra ‚Äúaccettato‚Äù e ‚Äúdeciso‚Äù in un tempo/spazio f(n)\n\n‚ö†Ô∏è 2. Non deterministico ‚áí distinzione tra accettare e decidere\n\nSi distingue tra:\n\nLinguaggi accettati: basta che esista un cammino accettante\nLinguaggi decisi: tutte le computazioni terminano, e rigettano correttamente se \\  x‚àâL\n\n\nQuesto porta a pensare che:\n\nci siano linguaggi accettabili in tempo/spazio non deterministico, ma non decidibili nello stesso tempo/spazio\n\n\n\nLa distinzione tra accettare e decidere non ha pi√π rilevanza pratica quando si impone un limite di risorse, ad esempio un numero massimo di passi f(‚à£x‚à£)\nIn questo caso, anche se una macchina non deterministica accetta un linguaggio, tutte le sue computazioni devono comunque terminare entro f(‚à£x‚à£)\nDi conseguenza, non ci sono loop infiniti, e quindi la macchina si comporta come un decisore.\n‚û§ In altre parole, accettare in tempo/spazio limitato equivale a decidere in tempo/spazio limitato.\nOssia, la teoria della complessit√† computazionale si occupa solo di linguaggi decidibili\nTeorema 6.2\nQuindi risolviamo il Teorema 6.2\n\n\n                  \n                  Teorema 6.2 (intanto espresso nel tempo): \n                  \n                \n\nSia f : ‚Ñï ‚Üí ‚Ñï una funzione totale calcolabile. Se L ‚äÜ Œ£^‚àó √® accettato da una macchina di Turing non deterministica NT tale che,\n\nper ogni x ‚àà L, ntime(NT,x) ‚â§ f (|x|)\n\nallora L √® decidibile.\n\n\n\n\n\nRisoluzione teorema 6.2(nel tempo)\nüß† Intuizione:\nAbbiamo una macchina non deterministica che accetta le stringhe in L entro tempo f(|x|),\nma non dice nulla su cosa succede per x \\notin L (potrebbe anche non fermarsi mai!).\nIl nostro obiettivo √® costruire una nuova macchina NT‚Ä≤ che decide L: cio√® che termina sempre e accetta se e solo se x \\in L.\nüõ†Ô∏è Strategia della dimostrazione\n\n\nCostruiamo una macchina T_f‚Äã che calcola f(n) in unario (cio√® una stringa di 1 ripetuti)\n\nEsempio: se f(5)=4, allora T_f‚Äã scrive 1111\n\n\n\nCostruiamo una nuova macchina NT‚Ä≤, a 3 nastri, che decide L:\n\nNastro 1: contiene l‚Äôinput x\nNastro 2: usato per calcolare |x|\nNastro 3: conterr√† f(|x|) in unario (numero di passi massimi concessi)\n\n\n\nüß© PASSAGGI DELLA COSTRUZIONE\nüîß FASE 1: Calcoliamo f(|x|)\n\nNT&#039; prende in input x.\nScrive |x| (la lunghezza di x) su un nastro.\nChiede a una macchina calcolatrice T_f‚Äã di calcolare f(|x|) e scriverlo in unario su un altro nastro (questo qui sar√† il tempo massimo utilizzabile)\n\nüîß FASE 2: Simuliamo NT(x)\n\nNT^{‚Ä≤} simula NT su input x.\nOgni volta che fa una mossa della simulazione, cancella un 1 dal nastro dove c‚Äô√® f(|x|).\nSe:\n\nNT(x) accetta ‚Üí anche NT^{‚Ä≤}(x) accetta.\nNT(x) rigetta ‚Üí anche NT^{‚Ä≤}(x) rigetta.\nFinisce il tempo (il nastro √® vuoto, ma NT non ha ancora terminato) ‚Üí NT^{‚Ä≤} rigetta.\n\n\n\n\nQuindi NT^{‚Ä≤} simula il comportamento di NT, ma si ferma dopo f(|x|) passi.\n\nquindi\n\n‚úÖNT accetta nei tempi prestabiliti, e visto che NT‚Äô la simula accetta\n‚ùåNT non accetta in tempo, NT‚Äô rigetta perch√© √® scaduto il tempo\n\noppure rigetta a prescindere NT quindi anche NT‚Äô rigetta\n\n\n\n‚ùì Ma‚Ä¶ c‚Äô√® un problema?\n\nQuanto tempo impiega NT&#039; per calcolare f(|x|)?\n\n\nNon lo sappiamo!\nSappiamo solo che termina, perch√© f √® totale calcolabile\nMa non possiamo sapere quanto tempo impiega\n\n‚úÖ Conclusione\n\nLa macchina NT&#039; decide il linguaggio L (cio√® termina sempre e d√† una risposta corretta)\n‚ùå Non possiamo dire che lo decide in tempo f(n), perch√© non sappiamo quanto tempo ci vuole per calcolare f(n)\n\nüîö Quindi:\nüî¥ L √® decidibile\nüü° Ma non necessariamente in tempo f(n)\nRisoluzione teorema 6.2(nello spazio)\nuguale a ntime, non serve studiarla\nCorrelazione polinomiale\nQui si dimostra che che tutti i modelli di calcolo deterministici sono fra loro polinomialmente correlati\n\nMacchine di Turing ad un nastro\nMacchine di Turing a quanti nastri ci pare\nMacchine di Turing su alfabeto binario\nMacchine di Turing su alfabeti grandi quanto ci pare\n\n\n\n                  \n                  cosa significa che sono polinomialmente correlati? \n                  \n                \n\nche per ogni macchina di Turing T di uno di questi tipi esistono una macchina di Turing T‚Äô di uno qualunque degli altri tipi ed un polinomio p tali che\n\nT‚Äô risolve lo stesso problema risolto da T e, per ogni x,\n\ndtime(T‚Äô,x) ‚â§ p( dtime(T,x) ) e\ndspace(T‚Äô,x) ‚â§ p( dspace(T,x) )\n\n\n\nin poche parole puoi fare le stesse computazioni di una qualsiasi macchina di quelle sopra con un‚Äôaltra di quelle l√† in un tempo \\leq\n\n\nE possiamo anche dire che il modello Macchina di Turing √® polinomialmente correlato con il PascalMinimo\n\n\n                  \n                  a cosa serve sapere questo? \n                  \n                \n\nChe possiamo risolvere un problema utilizzando il modello che pi√π ci aggrada\n\ncon costi uguali o addirittura inferiori!\nquindi possiamo creare un algoritmo in pascal minimo e sapere che poi funzioni anche in una Macchina di Turing ad un nastro\n\nbasta che lo risolva in f(|x|) istruzioni almeno in una istanza\n\n\n\n\n\n|x| √® la lunghezza dell‚Äôinput quindi il numero di celle dell‚Äôinput del rispettivo modello di calcolo\n\nad esempio i bit di una RAM\n"},"UNI/ANNO-2/FONDAMENTI/FONDAMENTI-LEZ.22":{"slug":"UNI/ANNO-2/FONDAMENTI/FONDAMENTI-LEZ.22","filePath":"UNI/ANNO 2/FONDAMENTI/FONDAMENTI LEZ.22.md","title":"FONDAMENTI LEZ.22","links":["UNI/ANNO-2/FONDAMENTI/FONDAMENTI-LEZ.21","UNI/ANNO-2/FONDAMENTI/FONDAMENTI-LEZ.22"],"tags":[],"content":"Questa lezione parte da un problema\nArriver√† sempre qualcuno che dimostrer√† che un linguaggio √® decidibile in un tempo o spazio inferiore a quello che abbiamo deciso f(n), magari in f(n/3) o f(n/k)\nper definire ci√≤ andiamo ad applicare dei teoremi\nTeorema di accelerazione lineare\n\n\n                  \n                  Teorema 6.7 \n                  \n                \n\n\nQuesto teorema ci dice che, dato un qualunque algoritmo, esiste sempre un algoritmo pi√π veloce del primo di un fattore costante!\n\n\n\n\n                  \n                  a cosa servono quei due addendi \n                  \n                \n\nO(|x|^2) e O(|x|)?\n\nservono perch√© le macchine per essere pi√π veloci devono codificare tutto il nastro di input\n\nse abbiamo un solo nastro impiegheremo tempi di cancellazione e riscrittura\nse abbiamo pi√π di un nastro basta riscrivere sotto e basta\n\n\n\ndi questo teorema non c‚Äô√® da studiare la dimostrazione!\n\n\nTeorema di compressione lineare\n\n\n                  \n                  Teorema 6.6 \n                  \n                \n\nmedesimo Teorema del precedente ma con dspace\n\nQuesto teorema ci dice che, dato un qualunque algoritmo, esiste sempre un algoritmo che usa una frazione costante della memoria del primo!\n\nin questo caso anche se con solo un nastro\n\noccupiamo O(|x|)\nquesto perch√© non teniamo conto delle riscritture sullo stesso spazio di memoria\n\n\n\n\n\n\n\n                  \n                   Lo spazio usato da una macchina di Turing √® la quantit√† massima di celle diverse scritte o lette durante l‚Äôesecuzione, non quanto spesso ci si muove tra esse.\n                  \n                \n\n\navremo quindi un T_1 che comprime il nastro di input di T\nin poche parole T_1 avr√† un linguaggio che sar√† \\Sigma \\cup (\\Sigma \\cup \\{\\square \\})^K\nunire Sigma all‚Äôinsieme quello elevato a K serve per definire anche l‚Äôalfabeto originale che effettivamente √® ancora incluso\npraticamente se abbiamo K=2 lui compatter√† l‚Äôinput in 2 a 2 ovvero:\nse (x1),(x2) occupava due celle ora (x1,x2) sul nastro occupa 1 sola cella\nSe l‚Äôinput originario occupava ‚à£x‚à£ celle, ora viene codificato in circa \\frac{|x|}{K}‚Äãcelle.\n\nLa computazione poi avviene su questo nastro compresso, quindi usa meno spazio complessivo.\n\n\n\nClassi di complessit√† (deterministiche)\nSiamo pronti a raggruppare i linguaggi in base all‚Äôefficienza delle macchine che li decidono.\n\n\n                  \n                  Cosa vuol dire che una macchina che decide un linguaggio ha una certa efficienza? \n                  \n                \n\nSignifica che la macchina che decide un linguaggio L \\subseteq \\Sigma^{*} si comporti ‚Äúbene‚Äù su ogni parola x \\in \\Sigma^{*}\n\n\nPer√≤ ovviamente non possiamo trovare la macchina ‚Äúmigliore‚Äù, perch√© tanto sappiamo che se ne prendo una ne esisteranno altre pi√π potenti (teoremi di prima).\nPer risolvere questa questione utilizziamo la notazione O e diciamo che\n==Un linguaggio L appartiene all‚Äôinsieme caratterizzato dalla ‚Äúefficienza temporale‚Äù individuata dalla funzione totale e calcolabile f, se esiste una macchina T che decide (o accetta) L e che, per ogni x sull‚Äôalfabeto di L, termina in O(f(|x|)) istruzioni.==\nE discorso analogo per ‚Äúefficienza spaziale‚Äù.\nEffettive classi di complessit√† deterministiche\nEfficienza temporale - DTIME\nLe classi che misurano ‚Äúefficienza temporale‚Äù nel caso deterministico si chiamano DTIME: data una funzione totale e calcolabile f\n\nATTENZIONE:\n\ndtime (minuscolo) √® la misura di complessit√†, ossia, una funzione\nDTIME (MAIUSCOLO) √® una classe di complessit√†, ossia, una sorta di insieme\n\nEfficienza spaziale - DSPACE\nLe classi che misurano ‚Äúefficienza spaziale‚Äù nel caso deterministico si chiamano DSPACE: data una funzione totale e calcolabile f\n\n\nClassi di complessit√† (non deterministiche)\nFacciamo le stesse considerazioni delle deterministiche.\nEfficienza temporale - NTIME\nLe classi che misurano ‚Äúefficienza temporale‚Äù nel caso non deterministico si chiamano NTIME: data una funzione totale e calcolabile f\n\nQui si parla di ACCETTAZIONE perch√© sappiamo che se un linguaggio √® accettato entro un certo numero di istruzioni, sappiamo che √® decidibile; MA NON SAPPIAMO QUANTO CI METTE A RIGETTARE.\nE, per di pi√π, a noi interessa solo accettare le parole del linguaggio.\nEfficienza spaziale - NSPACE\nLe classi che misurano ‚Äúefficienza spaziale‚Äù nel caso non deterministico si chiamano NSPACE: data una funzione totale e calcolabile f\n\n\nClassi di complemento\n\n\nUn paio di questioni\n\nQui stiamo considerando linguaggi sull‚Äôalfabeto \\{0,1\\} per comodit√† ma possiamo considerare anche altri alfabeti (e lo faremo)\nAlla funzione f che definisce una classe di complessit√† (ad esempio DTIME[fn]) diamo il nome di funzione limite\n\nche ovviamente deve essere totale e calcolabile senn√≤, per definizione, avremo una funzione che ci dice quante istruzioni esegue una computazione MA di cui non sappiamo il reale valore (inutile se ci pensi!)\n\n\n\n\nRelazioni fra classi di complessit√†\n\n\n                  \n                  Teorema 6.8 \n                  \n                \n\n\n\n\nLa dimostrazione √® facile.\nUna macchina deterministica √® una particolare macchina non deterministica con il grado di non determinismo pari a 1 e, inoltre\n\nuna parola decisa in un certo numero di passi √® anche accettata in quel certo numero di passi\nuna parola decisa utilizzando un certo numero di celle √® anche accettata in quel certo numero di celle\n\n\n\n                  \n                  Teorema 6.9 \n                  \n                \n\n\n\n\nQuesta dimostrazione segue direttamente dal teorema 6.1\nSia L \\subseteq \\{0,1\\}^{*} tale che L \\in DTIME[f(n)].\nSappiamo, per il Teorema 6.1, che \\text{spazio} \\le \\text{tempo} per ogni macchina di Turing:\nse una macchina fa al massimo t passi, non pu√≤ usare pi√π di t caselle\nPerci√≤ \\text{dspace(T,x)} \\le \\text{dtime(T,x)}e dato che \\text{dtime} \\in O(f(|x|)) (per definizione DTIME)\nAllora possiamo scrivere \\text{dspace(T,x)} \\le \\text{dtime(T,x)}  \\in O(f(|x|))e quindi anche \\text{dspace(T,x)} \\in O(f(|x|))\n‚úÖ Conclusione\n\nSe L \\in \\text{DTIME}[f(n)], allora L \\in \\text{DSPACE}[f(n)]\n\nCio√®: \\text{DTIME}[f(n)] \\subseteq \\text{DSPACE}[f(n)]\n‚úÖ Vale anche nel caso non deterministico: \\text{NTIME}[f(n)] \\subseteq \\text{NSPACE}[f(n)]\n\n\n                  \n                  Teorema 6.10 \n                  \n                \n\n\n\n\nüìò Teorema 6.10 (detto in parole semplici)\n\nSe usi al massimo f(n) celle di memoria per decidere un problema, allora esiste un modo per risolverlo che richiede tempo al massimo 2^O(f(n)) (cio√® tempo esponenziale rispetto allo spazio).\n\nFormalmente:\nDSPACE[f(n)] ‚äÜ DTIME[2^O(f(n))]\nNSPACE[f(n)] ‚äÜ NTIME[2^O(f(n))]\n\nüß† Ok, ma perch√©?\nImmagina che la macchina di Turing T usi al massimo f(n) celle del nastro per un input lungo n.\n\nüîç Ogni ‚Äúconfigurazione‚Äù della macchina √®:\nstato + contenuto del nastro + posizione della testina\n\nQuante possibili configurazioni diverse pu√≤ assumere T?\nLe combinazioni sono tante, ma finite! E in particolare:\n\nGli stati sono un numero fisso, diciamo |Q|\nLe celle usate sono al massimo f(n)\nOgni cella pu√≤ contenere uno dei simboli dell‚Äôalfabeto |Œ£| (pi√π il blank)\nLa testina pu√≤ stare in una delle f(n) celle\n\nAllora il numero totale di configurazioni √® al massimo:\n|Q| √ó |Œ£ + 1|^f(n) √ó f(n)\n\nüìå Questo √® un numero esponenziale rispetto a f(n)\n‚áí diciamo che √® al massimo 2^O(f(n)) configurazioni\nüîÅ E come ci serve questo?\nSe conosci tutte le configurazioni possibili, puoi:\n\nsimulare la macchina T ‚Äúdall‚Äôesterno‚Äù\nesplorare tutte le possibili sequenze di configurazioni (tipo albero di esecuzione)\ncontrollare se si arriva a uno stato di accettazione\n\nQuesto √® un algoritmo che decide il linguaggio, anche se √® pi√π lento, perch√© deve controllare tutte le configurazioni.\nMa √® comunque un algoritmo deterministico che termina!\n‚úÖ Conclusione:\n\nSe un problema si pu√≤ decidere usando al massimo f(n) celle di memoria,\nallora esiste un algoritmo deterministico che risolve lo stesso problema in tempo 2^O(f(n))\n\nE lo stesso vale anche nel caso non deterministico.\nin calcoli\n\nTeorema 6.11\n\n\n                  \n                  Teorema 6.11 \n                  \n                \n\n\n\n\nüß† Cosa significa?\nSignifica che ogni linguaggio decidibile in tempo deterministico f(n)f(n)f(n) ha complemento decidibile nello stesso tempo deterministico f(n)f(n)f(n). Lo stesso vale per lo spazio.\n\n‚ú≥Ô∏è In altre parole: le classi deterministiche sono chiuse per complemento.\n\n\nüõ†Ô∏è Dimostrazione semplificata\nPartiamo dal caso temporale, cio√® DTIME[f(n)]=coDTIME[f(n)]\nTanto quello spaziale √® analogo\n‚ú≥Ô∏è 1. Sia L‚ààDTIME[f(n)]\n\nEsiste una macchina di Turing deterministica T che decide L e impiega al massimo O(f(‚à£x‚à£)) passi su ogni input x‚àà{0,1}^‚àó.\n\n\n‚ú≥Ô∏è 2. Costruisci una nuova macchina T‚Ä≤\n\n\n√à identica a T, tranne per una cosa:\n\n\nInverte lo stato di accettazione e rifiuto:\n\nse T(x)=q_A‚Äã (accetta), allora T‚Ä≤(x)=q_R(rigetta)\ne viceversa\n\n\n\n\n\nüëâ Quindi T‚Ä≤ **decide il complemento di L, cio√® L^C\n\n‚ú≥Ô∏è 3. Quanto tempo impiega T‚Ä≤?\n\n\nFa esattamente gli stessi passi di T, quindi:\ndtime(T‚Ä≤,x)‚ààO(f(‚à£x‚à£))\n\n\n\n‚úÖ Conclusione:\n\n\nL^C \\in \\text{DTIME[f(n)]}\n\n\nQuesto implica che ogni linguaggio L‚ààDTIME[f(n)]‚áíL^C‚ààDTIME[f(n)]quindi:\nDTIME[f(n)]=coDTIME[f(n)]\nüîÅ Per lo spazio?\nStesso ragionamento:\n\n\nE per le non deterministiche?\n\n\n                  \n                  non possiamo definirle a partire da una macchina!(quello fatto prima non vale per quelle non deterministiche) \n                  \n                \n\n‚ö†Ô∏è Uso della notazione O nella teoria della complessit√†\n1. Il problema dell‚Äôuso di O nelle classi di complessit√†\nL‚Äôuso della notazione O-grande (ad esempio DTIME[f(n)]) implica che:\n\nLe classi non caratterizzano esattamente i linguaggi, ma solo asintoticamente.\nInfatti, se un linguaggio L appartiene a \\text{DTIME}[f(n)], allora:\n\n\nEsiste una macchina di Turing che lo decide in tempo al pi√π c \\cdot f(n), per qualche costante c e per n sufficientemente grande.\nQuesto significa che L √® contenuto in una serie infinita di classi DTIME pi√π grandi, perch√©:\n\nf(n) \\in O(g(n)) \\Rightarrow \\text{DTIME}[f(n)] \\subseteq \\text{DTIME}[g(n)]\n\n2. Definizione formale di f(n) \\in O(g(n))\nDate due funzioni totali calcolabili f, g : \\mathbb{N} \\to \\mathbb{N}, si dice che:\nf(n) \\in O(g(n)) \\quad \\text{se} \\quad \\exists n_0 \\in \\mathbb{N}, \\exists c \\in \\mathbb{N} \\text{ tali che } \\forall n \\geq n_0, \\; f(n) \\leq c \\cdot g(n)\nIn parole semplici:\n\nf cresce al massimo quanto g, a partire da un certo punto e fino a costanti moltiplicative.\n\n\n\n\n                  \n                  Teorema 6.12 \n                  \n                \n\n\n\nOk, allora il Teorema 6.12 ci dice che, se collochiamo un linguaggio L, ad esempio, in DTIME[f(n)], allora L appartiene anche a tutte le classi DTIME[g(n)] tali che, definitivamente, f(n) ‚â§ g(n)\n\n\n\nTeorema 6.12 ‚Äî Conseguenze pratiche\nIl Teorema 6.12 ci dice che:\n\nSe collochiamo un linguaggio L, ad esempio, in \\text{DTIME}[f(n)],\nallora L appartiene anche a tutte le classi \\text{DTIME}[g(n)]\ntali che, definitivamente, f(n) \\leq g(n).\n\nü§î Ma attenzione!\n\nSe diciamo che L \\in \\text{DTIME}[f(n)], questo NON implica che L\nnon possa appartenere anche a una classe \\text{DTIME}[r(n)]\ntale che, definitivamente, r(n) \\leq f(n)!\n\nIn parole semplici:\n\nPotrebbe esistere un algoritmo pi√π efficiente per decidere lo stesso linguaggio!\n\nüß† Conclusione operativa\nDire che L \\in \\text{DTIME}[f(n)] √® solo met√† del lavoro.\n\nL‚Äôaltra met√† sarebbe dimostrare che non esiste alcuna funzione r(n) tale che:\nr(n) \\leq f(n) \\quad \\text{definitivamente}, \\quad \\text{e} \\quad L \\in \\text{DTIME}[r(n)]\n\n\n\nMa questo √® molto difficile da provare, perch√© significherebbe escludere tutti gli algoritmi possibili pi√π efficienti.\n\n‚úÖ Facciamo il punto\n\nGerarchia tra classi di complessit√†\n\nAbbiamo gi√† visto che, se collochiamo un linguaggio L in \\text{DTIME}[f(n)],\nallora L appartiene anche a tutte le classi \\text{DTIME}[f(n)^k] per ogni k \\in \\mathbb{N}\n\nperch√©, definitivamente: f(n) \\leq f(n)^k\n\n\nEsiste quindi una gerarchia infinita di classi\n\n\\text{DTIME}[f(n)] \\subseteq \\text{DTIME}[f(n)^2] \\subseteq \\text{DTIME}[f(n)^3] \\subseteq \\cdots \\subseteq \\text{DTIME}[f(n)^k] \\subseteq \\mathcal{D}\n(dove \\mathcal{D} rappresenta l‚Äôinsieme delle classi decidibili)\n3. Teorema generale di inclusione\nData una funzione totale e calcolabile f, vale:\n\\text{DTIME}[f(n)] \\subseteq \\text{DTIME}[g(n)]\nper ogni altra funzione totale e calcolabile g tale che,\ndefinitivamente: f(n) \\leq g(n)\n\nMa per rendere significativa la teoria della complessit√†‚Ä¶\n\n\nSarebbe auspicabile che \\text{DTIME}[f(n)] \\not\\subseteq \\text{DTIME}[g(n)]\nquando f(n) √® molto pi√π grande di g(n), ad esempio:\n\nf(n) = 2^{g(n)}\nüéØ Perch√©?\nPerch√©, in definitiva, ci√≤ che ci interessa √® poter distinguere i problemi in base alla loro difficolt√†:\n\n‚ÄúQuesto problema √® pi√π difficile di quest‚Äôaltro‚Äù.\n\nDa questo problema ci viene incontro il GAP THEOREM\n\n\n                  \n                  GAP THEOREM \n                  \n                \n\n\n\n\nSignifica che anche se la funzione 2^{f(n)} √® molto pi√π grande di f(n) non ci sono nuovi problemi che si possono risolvere in 2^{f(n)} che non erano gi√† risolvibili in f(n)\nIn altre parole: quella differenza di tempo non ha effetto sulla potenza computazionale\nAndiamo a definire due insiemi di definizioni\n\n\n                  \n                  Definizione 6.1 \n                  \n                \n\n\n\n\n\n\n                  \n                  Definizione 6.2 \n                  \n                \n\n\n\n\nPer intendere n 1 scriveremo 1^n\n\n1^5 = 11111\nvisto che deve essere espresso in notazione unaria:\nla lunghezza dell‚Äôinput √® uguale al valore dell‚Äôinput: |n| = n\n\nUna funzione time-constructible √® molto pi√π che una funzione totale e calcolabile\n\n√® una funzione che pu√≤ essere calcolata in tempo proporzionale al suo valore\n\nin soldoni, scrivere un ‚Äò1‚Äô sul nastro di output richiede alla macchina che la calcola di eseguire un numero costante di istruzioni (in media)\n\n\n\ntutte le funzioni ‚Äúregolari‚Äù che usiamo normalmente lo sono:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTipoEsempioPolinomif(n)=nkf(n) = n^kf(n)=nk, con kkk costanteEsponenzialif(n)=2nf(n) = 2^nf(n)=2n, f(n)=nnf(n) = n^nf(n)=nnAltreLogaritmi, funzioni razionali, iterazioni di log, etc.\nüìå In pratica: se puoi scriverla con una formula familiare, probabilmente √® constructible.\nüí£ Il problema del Gap Theorem\nIl Gap Theorem ci dice che:\n\nEsiste una funzione calcolabile f(n) non time-constructible\ntale che:\n\\text{DTIME}[2^{f(n)}] \\subseteq \\text{DTIME}[f(n)]\n\nüò± Questo √® controintuitivo!\nAumentare le risorse non sempre significa poter risolvere pi√π problemi.\n‚úÖ La salvezza: funzioni ‚Äúben comportate‚Äù\nSe per√≤ restringiamo l‚Äôattenzione a funzioni:\n\ntime-constructible per il tempo\nspace-constructible per lo spazio\n‚Ä¶allora vale davvero l‚Äôintuizione che:\n\n\nPi√π risorse ‚áí pi√π potere computazionale\n\n\nTeorema 6.14\n\n\n                  \n                  Teorema 6.14 \n                  \n                \n\n\n\n\nüîÅ Esistono problemi risolvibili in f(n) spazio ma non in g(n).\n\nTeorema 6.15\n\n\n                  \n                  Teorema 6.5 \n                  \n                \n\n\nüîÅ Esistono problemi risolvibili in tempo f(n) ma non in g(n).\nüîç Significato dei limiti\nQuando:\n\n\\displaystyle \\lim_{n \\to \\infty} \\frac{g(n)}{f(n)} = 0\noppure \\displaystyle \\lim_{n \\to \\infty} \\frac{g(n) \\log g(n)}{f(n)} = 0\n\n‚Ä¶allora f(n) cresce molto pi√π velocemente di g(n):\nla distanza asintotica tra le due funzioni diventa enorme.\n‚ú® Conclusione\nIl Gap Theorem mostra che esistono collassi tra classi di complessit√†,\nma solo se usiamo funzioni non-constructible\nInvece, i teoremi di gerarchia ci dicono:\n\nSe usiamo funzioni constructible e crescenti in modo regolare,\naumentare le risorse permette davvero di risolvere problemi pi√π complessi.\n\n‚úÖ Quindi:\n\nQuando f(n) √® time-constructible:\nf(n) \\gg g(n) \\Rightarrow \\text{DTIME}[f(n)] \\not\\subseteq \\text{DTIME}[g(n)]\n\nQuando f(n) √® space-constructible:\nf(n) \\gg g(n) \\Rightarrow \\text{DSPACE}[f(n)] \\not\\subseteq \\text{DSPACE}[g(n)]\n\n"},"UNI/ANNO-2/FONDAMENTI/FONDAMENTI-LEZ.23":{"slug":"UNI/ANNO-2/FONDAMENTI/FONDAMENTI-LEZ.23","filePath":"UNI/ANNO 2/FONDAMENTI/FONDAMENTI LEZ.23.md","title":"FONDAMENTI LEZ.23","links":["UNI/ANNO-2/FONDAMENTI/FONDAMENTI-LEZ.21"],"tags":[],"content":"Delle lezioni precedenti mancano ancora delle cose da precisare\n\ndelle classi di complessit√† non deterministiche\n\nnon sappiamo quanto tempo o spazio serve per rigettare le parole che non appartengono al linguaggio\nsappiamo per√≤ che se fissiamo una quantit√† massima allora possiamo dire che il linguaggio √® sia accettabile che decidibile\n\n\npoi abbiamo detto che se viene deciso da una macchina non deterministica\n\nallora √® deciso anche da una macchina deterministica\nma non sappiamo a quale classe di complessit√† collocare un linguaggio che appartiene a un certo NTIME[f(n)]\ne oltretutto non sappiamo dire se dato un certo NTIME[f(n)] allora esso sar√† uguale a quel determinato DTIME[qualche altra funzione]\n\n\n\nLa prima questione aperta\nüß† Contesto\n\nHai un linguaggio L \\in \\text{NTIME}\n\nQuesto significa: esiste una macchina non deterministica che, se una parola x \\in L, la accetta in tempo O(f(|x|))\n‚úîÔ∏è Per le parole nel linguaggio, sappiamo che esiste un ramo accettante veloce.\n\n\n\n‚ùó Il problema\n\nPer le parole x \\notin L:\n\nNon c‚Äô√® nessun ramo che accetta,\nMa non sappiamo quanto tempo serve per rigettare, perch√© bisogna esplorare tutti i rami (o, almeno, assicurarsi che nessuno accetti).\n\n\n\n\nIn altre parole: sappiamo che la macchina rigetta, ma non sappiamo quanto tempo ci mette per concludere che ‚Äúnessun ramo accetta‚Äù.\n\nTeorema 6.16 per risolvere\n\n\n                  \n                  Teorema 6.16 \n                  \n                \n\n\n\n\n\ncome sempre andiamo a dimostrare solo nel tempo perch√© lo spazio √® analogo\n\nsolo che avr√† al posto delle istruzioni le celle e tutte le cose con space\n\n\n\nQuesto teorema dice\n\nse f √® time-constructible e L √® in NTIME[f(n)], allora una modifica della macchina NT che accetta le parole x di L eseguendo O(f(|x|)) istruzioni √® anche capace di rigettare le parole non in L eseguendo O(f(|x|)) istruzioni;\nPer dimostrarlo, ci avvaliamo del teorema 6.2 molto simile\n\n\nLa dimostrazione √® divisa in 2 parti\nParte 1\nil problema di questo teorema √® che abbiamo quella O che rende il tutto molto ‚Äúgrigio‚Äù\nma sostanzialmente essa ci serve per dire che\n\nil linguaggio viene accettato in tempo f(n) per una costante\n\nSia NT la macchina che accetta L, tale che ntime(NT, x) \\le c \\cdot f(|x|)e, poich√© f √® time-constructible, allora anche c \\cdot f √® time-constructible: allora esiste una macchina T_{f} di tipo trasduttore che, per ogni n \\in ‚Ñï ,\n\nT_{f}(1^{n}) termina\n\ncon il valore c \\cdot f(n) scritto sul nastro di output\ndopo aver eseguito O(c \\cdot f(n)) istruzioni\n\n\n\nora abbiamo definito che anche con O rimane time-constructible\nParte 2\nCostruiamo una nuova macchina non deterministica \\text{NT}&#039;, a tre nastri, che decide L.\nPer ogni x \\in \\Sigma^{*}\n\nScrive |x| in unario su un secondo nastro e invoca la macchina T_f‚Äã che calcola c \\cdot f(|x|), e lo scrive in unario su un terzo nastro.\nPoi invoca \\text{NT}(x) per simulare tutte le computazioni non deterministiche.\nOgni volta che un ramo di NT(x) esegue un passo, \\text{NT}&#039; controlla che il contatore (terzo nastro) non sia esaurito.\n\nSe c‚Äô√® ancora un ‚Äò1‚Äô, lo toglie e continua.\nSe termina il tempo, rigetta.\n\n\nAlla fine accetta se NT(x) accetta entro il limite, altrimenti rigetta.\n\nüìå Perch√© funziona?\n\n\nPer x \\in L, esiste un ramo accettante in \\leq c \\cdot f(|x|) passi ‚Üí \\text{NT}&#039; lo trover√† e accetter√†.\n\n\nPer x \\notin L,\n\nogni ramo rifiuta entro il tempo limite ‚Üí\\text{NT}&#039; li esaminer√† e rigetter√†\noppure finir√† il tempo senza trovare un‚Äôaccettazione ‚Üí rigetta.\n\n\n\nQuindi le computazioni su \\text{NT}&#039; TERMINANO SEMPRE e, per questi ultimi due punti, possiamo affermare che \\text{NT}&#039; DECIDE L.\n‚è±Ô∏è Quanto tempo usa NT‚Äô?\n\nPer calcolare f(‚à£x‚à£) (in unario): serve O(f(‚à£x‚à£)) tempo, perch√© f √® time-constructible.\nPer simulare tutte le computazioni entro c \\cdot f(|x|) passi: O(f(‚à£x‚à£))\n‚úÖ Totale: O(f(‚à£x‚à£))\n\n\n\n                  \n                  Per questo possiamo concludere che L √® decidibile, in tempo non deterministico O(f(n))\n                  \n                \n\nSeconda questione aperta\nüîç Punto di partenza\nLe uniche relazioni sicure che conosciamo finora tra classi deterministiche e non deterministiche sono le seguenti:\nDTIME[f(n)] ‚äÜ NTIME[f(n)]\nDSPACE[f(n)] ‚äÜ NSPACE[f(n)]\n\nQueste derivano da un fatto banale:\n\nogni macchina deterministica √® un caso particolare di macchina non deterministica (cio√® con un solo ramo).\n\n‚úÖ E sappiamo anche che:\n\nTutto ci√≤ che √® decidibile da una macchina non deterministica √® anche decidibile da una deterministica (concettualmente parlando).\n\n‚ùóMA‚Ä¶il vero problema\nSupponiamo di avere un linguaggio L \\in NTIME[f(n)]cio√®: esiste una macchina NON deterministica che lo decide in tempo f(n)\n\n\n                  \n                  In questo caso non sappiamo dire \n                  \n                \n\n\nin quale classe deterministica si trova L\nse c‚Äô√® una funzione g(n) tale che L ‚àà DTIME[g(n)]\ne non sappiamo quanto pi√π grande debba essere g(n) rispetto a f(n)\n\n\n\nüéØ In parole semplici:\n\nSappiamo che una macchina deterministica pu√≤ risolvere tutto ci√≤ che una non deterministica pu√≤,\nma non sappiamo quanto tempo le serve per farlo.\na meno che la funzione limite f della classe non sia una funzione time-constructible‚Ä¶\n\nTeorema 6.17\n\n\n                  \n                  Teorema 2 \n                  \n                \n\n\n\n\nCio√®:\n\nSe un linguaggio √® decidibile in tempo non deterministico f(n), allora √® anche decidibile deterministicamente in tempo esponenziale in f(n).\n\nüß† Cosa significa e perch√© √® importante\n\nQuesto teorema ti risponde: al massimo tempo 2^{O(f(n))}.\n(Non sappiamo se basta meno, ma almeno abbiamo un limite superiore!)\n\n\nPrecisazioni sulla foto sopra:\n\ncreiamo una macchina che accetta L\nusiamo una costante h per porre un limite entro in quale un ramo di una macchina non deterministica termini per forza\ncon k indichiamo il grado di non determinismo, ma cosa √®?\n\n√à il numero massimo di rami che si possono aprire da ogni configurazione della macchina.\n\n\nda non determinismo passiamo a determinismo con la macchina T\nse f √® time-constructible allora anche con una costante h lo √® quindi hf() √® t-c\n\nLa dimostrazione anche qui √® divisa in 2 parti\nParte 1\nSimula la computazione T_{f}(| x |)\n\n\nScrive 1^{|x|} sul secondo nastro\n\nPrende in input la stringa x\nConta i caratteri: |x|\nScrive |x| simboli 1 sul secondo nastro ‚Üí 1^{|x|}\n\nQuesto √® l‚Äôinput per calcolare f(|x|) nella fase successiva.\n\n\nCalcola f(|x|) e scrive 1^{f(|x|)} sul terzo nastro\n\nUsa una macchina trasduttore T_f che:\n\nPrende 1^{|x|} come input\nScrive 1^{f(|x|)} sul terzo nastro\n\n\nQuesta computazione richiede O(f(|x|)) passi perch√© f √® time-constructible\n\n\n\nConcatena h volte il contenuto del terzo nastro\n\nDal terzo nastro legge 1^{f(|x|)}\nLo ripete h volte ottenendo: 1^{h ¬∑ f(|x|)}\nQuesto rappresenta il limite massimo di passi ammessi per ogni computazione di NT(x)\n\n\n\nParte 2\nSimulazione delle vere e proprie computazioni deterministiche\nüéØ Obiettivo\nSimulare tutte le possibili computazioni deterministiche della macchina non deterministica NT(x) entro un numero massimo di passi pari a h(f(|x|)).\n\nüîπSimula tutte le computazioni deterministiche di NT(x) una per una:\n\nOgni computazione ha al massimo h(f(|x|)) passi.\nSi usa un contatore sul terzo nastro con 1^{h(f(|x|))} in notazione unaria.\nLe computazioni vengono simulate:\n\nda sinistra verso destra nell‚Äôalbero delle scelte,\n- una alla volta,\n\n\n\n\n\n\ne ciascuna viene interrotta se supera il limite di passi.\n\nCorrettezza\n‚û§ Se x \\in L:\n\nAlmeno una computazione accetta entro h(f(|x|)) passi.\nQuindi T prima o poi simula quella computazione e accetta.\n\n‚û§altrimenti no\n\nx \\notin L\n\nT √® corretta e decide L.\nVari costi computazionali di questa macchina T\nLa fase 1:\nRichiede O(h(f(|x|))) passi, perch√© f √® time-constructible.\nLa fase 2:\n\nSia k il grado di non determinismo di NT (costante).\nIl numero totale di computazioni deterministiche di lunghezza h(f(|x|)) √® k^{h(f(|x|))} = 2^{O(f(|x|))}.\nOgni computazione richiede al pi√π h(f(|x|)) passi.\n\nQuindi:\n\\text{dtime}(T,x) \\in O(h(f(|x|)) \\cdot k^{h(f(|x|))}) = O(h(f(|x|)) \\cdot 2^{O(f(|x|))}) \\subseteq O(2^{O(f(|x|))})\nDal Teorema 6.3 (che consente di simulare una macchina a pi√π nastri con una a un nastro), possiamo dire che:\nL \\in \\text{DTIME}[2^{O(f(|x|))}]\n\n\n                  \n                  Questi due teoremi potrebbero apparire all&#039;esame \n                  \n                \n\nOra entriamo nel vivo della complessit√† computazionale\nStiamo per introdurre alcune fra le pi√π rilevanti classi di complessit√†, definite sulla base di funzioni time- e space-constructible\nüìå Classi polinomiali\nüî¥ P = ‚ãÉ‚Çñ‚àà‚Ñï DTIME[n·µè]\n\nContiene tutti i linguaggi decidibili in tempo deterministico polinomiale\nUna macchina deterministica risponde sempre s√¨ o no entro tempo ( n^k )\n\nüî¥ NP = ‚ãÉ‚Çñ‚àà‚Ñï NTIME[n·µè]\n\nLinguaggi accettabili in tempo non deterministico polinomiale\nEsiste un ramo della computazione che accetta entro n^k se la parola √® nel linguaggio\nMa anche decidibili grazie alla simulazione entro tempo O(f(n)\n\nüü£ Classi di spazio\nüü£ PSPACE = ‚ãÉ‚Çñ‚àà‚Ñï DSPACE[n·µè]\n\nLinguaggi decidibili in spazio deterministico polinomiale\n\nüü£NPSPACE = ‚ãÉ‚Çñ‚àà‚Ñï NSPACE[n·µè]\n\nLinguaggi accettabili (e decidibili) in spazio non deterministico polinomiale\n\n‚úÖ Teorema di Savitch:\n\nci afferma che:\n\n\\text{PSPACE} = \\text{NPSPACE}\n\n\n\nüìå Classi esponenziali\nüî¥ EXPTIME = ‚ãÉ‚Çñ‚àà‚Ñï DTIME2^{p(n,k)}\n\nLinguaggi decidibili in tempo deterministico esponenziale\nL‚Äôesponente ( p(n, k) ) √® un polinomio\n\nüî¥ NEXPTIME = ‚ãÉ‚Çñ‚àà‚Ñï NTIME2^{p(n,k)}\n\nLinguaggi accettabili in tempo non deterministico esponenziale\nMa anche decidibili, con le stesse tecniche di simulazione\n\nüü¢ FP ‚Äì Funzioni polinomiali\nFP = ‚ãÉ‚Çñ‚àà‚Ñï { f : Œ£‚ÇÅ* ‚Üí Œ£‚ÇÇ* }\n\nClasse delle funzioni totali calcolabili in tempo deterministico polinomiale\nUna macchina di Turing **trasduttore calcola f(x) in tempo O(|x|^k)\n\nRelazioni tra tutte queste classi Corollario 6.2\nüî¥ P \\subseteq NP, PSPACE \\subseteq NPSPACE, EXPTIME \\subseteq NEXPTIME\n\nüß† Conseguenza del Teorema 6.8:\nOgni macchina deterministica √® un caso particolare di una macchina non deterministica (con grado di non determinismo pari a 1).\nüëâ Ogni linguaggio decidibile in tempo o spazio deterministico √® anche decidibile in quello non deterministico.\n\nüî¥ P \\subseteq PSPACE, NP \\subseteq NPSPACE\n\nüß† Conseguenza del Teorema 6.9:\nPer ogni funzione totale e calcolabile f(n):\n\nDTIME[f(n)] \\subseteq DSPACE[f(n)]\nNTIME[f(n)] \\subseteq NSPACE[f(n)]\n\n\n\n‚û°Ô∏è Ogni linguaggio decidibile in tempo f(n) √® anche decidibile in spazio f(n), ma non viceversa.\nPerch√©? Il tempo impone un limite superiore anche allo spazio usato.\nüî¥ PSPACE \\subseteq EXPTIME, NPSPACE \\subseteq NEXPTIME\n\nüß† Conseguenza del Teorema 6.10:\nPer ogni funzione calcolabile f(n):\n\nDSPACE[f(n)] \\subseteq DTIME[2^{O(f(n))}]\nNSPACE[f(n)] \\subseteq NTIME[2^{O(f(n))}]\n\n\n\n‚û°Ô∏è Una macchina che usa poco spazio pu√≤ essere simulata deterministicamente in tempo esponenziale, perch√© lo spazio limita il numero di configurazioni possibili (che si possono esplorare in tempo).\nüî¥ NP \\subseteq EXPTIME\n\nüß† Conseguenza del Teorema 6.17:\nSe f(n) √® time-constructible, allora:\n\nNTIME[f(n)] \\subseteq DTIME[2^{O(f(n))}]\n\n\n\n‚û°Ô∏è Tutto ci√≤ che √® accettabile in tempo non deterministico √® anche decidibile in tempo deterministico esponenziale.\nüìå E siccome i polinomi sono time-constructible, allora in particolare:\n\nNP \\subseteq EXPTIME\n\n\n\n                  \n                  SONO TUTTE INCLUSIONI DEBOLI (oppure improprie) \n                  \n                \n\nSappiamo che una classe √® contenuta nell‚Äôaltra, ma non sappiamo se le due classi coincidano oppure no.\nAd esempio:\n\nSappiamo che \\text{P} \\subseteq \\text{NP},\nma non sappiamo se \\text{P} = \\text{NP} oppure \\text{P} \\subset NP\n\n\n\nsolo 2 uguaglianze sono state trovate\nGrazie al teorema di Gerarchia temporale\n\n\n                  \n                  Teorema 6.15 \n                  \n                \n\n\n\n\n‚úÖ Significato:\n\nEsiste un linguaggio L che √® decidibile in tempo f(n) ma non in g(n).\nQuesto perch√© g(n) √® troppo pi√π piccolo (e meno potente) di f(n)\nQuindi \\text{DTIME}[f(n)] √® strettamente pi√π potente di \\text{DTIME}[g(n)].\n\nDi conseguenza quindi abbiamo che:\n\nP \\subset EXPTIME (Teorema 6.18)\n\nsenza uguaglianza\nabbiamo una inclusione propria\n\n\nPSPACE = NPSPACE (Teorema 6.19)\n\nqui sono uguali\nsenza dimostrazione da studiare\nsi scrive un programma in Pascal minimo\n\n\n\nLeggi con voce della Di Ianni\n\n\n                  \n                  la lezione di oggi sarebbe finita \n                  \n                \n\nma visto che abbiamo tempo facciamo 3 esercizietti!\nva bene a TUTTI!!!???\n\n\nEsercizi vari:\nQUESTI ESERCIZI POSSONO CAPITARE ALL‚ÄôESAME IN TUTTE LE SALSE\nNota: se ho L1 accettabile non posso dire che L1^c non possiamo dire nulla\n\nse ho L1 accettabile e precisato non decidibile allora il complemento √® non decidibile\n"},"UNI/ANNO-2/FONDAMENTI/FONDAMENTI-LEZ.24":{"slug":"UNI/ANNO-2/FONDAMENTI/FONDAMENTI-LEZ.24","filePath":"UNI/ANNO 2/FONDAMENTI/FONDAMENTI LEZ.24.md","title":"FONDAMENTI LEZ.24","links":[],"tags":[],"content":"Fino ad ora abbiamo visto quasi tutte relazioni tra classi di complessit√† improprie\n\novvero senza sapere se hanno una inclusione propria oppure se hanno una coincidenza\nle uniche certezze che abbiamo sono su\nP \\subset EXPTIME\nPSPACE=NPSPACE\n\nsappiamo che\n\ntutti i linguaggi in PSPACE sono anche in EXPTIME\n\nPSPACE \\subseteq EXPTIME\n\n\ntutti i linguaggi che sono in P sono anche in NP\n\nP \\subseteq NP\nMa sorgono altre domande come\n\n\n\n\n\n                  \n                  Question\n                  \n                \n\n\nPSPACE=EXPTIME?\n\ntutti i linguaggi di PSPACE sono in EXPTIME\n\n\nP \\subset NP?\nP=NP?\n\n\n\n\n\n                  \n                  Le relazioni che conosciamo sono, in massima parte, relazioni deboli \n                  \n                \n\nLa domanda della prof che poi ci porta a creare delle cose concrete nella lezione √®:\n\n\n                  \n                  Siano C1 e C2 classi di complessit√† e sia dato un linguaggio L‚ààC2, come facciamo a sapere se √® anche incluso in C1‚Äã, oppure se √® davvero un linguaggio separatore (cio√® in C2‚àñC1‚Äã)? \n                  \n                \n\nquesto ci serve per capire se abbiamo C1\\subset C2 oppure continuiamo ad avere C1 \\subseteq C2\n\n\n\n\n                  \n                   \n                  \n                \n\nPotremmo forse realizzare questo sogno con le riduzioni?\nLe riduzioni sono un argomento vecchio ma che ci pu√≤ tornare utile\nRicapitolando cosa erano:\nDati due linguaggi L_1 \\subseteq \\Sigma_1^* e L_2 \\subseteq \\Sigma_2^*, diciamo che\nL_1 √® riducibile a L_2, e scriviamo: L1 ‚âº L2\nse esiste una funzione f : \\Sigma_1^* \\to \\Sigma_2^* tale che:  \n\n\nf √® totale e calcolabile\n\nf(x) √® definita per ogni x \\in \\Sigma_1^*.\nEsiste una macchina di Turing T_f tale che, per ogni x, T_f termina con f(x) scritto sul nastro di output.\n\n\n\nf preserva l‚Äôappartenenza al linguaggio\n\n\n\nPer ogni x \\in \\Sigma_1^*:\nx‚ààL1‚ÄÖ‚Ää‚ü∫‚ÄÖ‚Ääf(x)‚ààL2\n\nQuindi decidere se x \\in L_1 equivale a decidere se f(x) \\in L_2.\n\nin poche parole se un linguaggio ha l‚Äôinput l‚Äôaltro deve avere il suo rispettivo output\n\nA queste riduzioni per il nostro scopo si aggiunge una piccola cosa\nRivisitazione delle riduzioni\naggiungiamo il concetto del \\pi\n\n√® un predicato ovvero una propriet√† che serve per definire le funzioni totali e calcolabili prese in causa\nad esempio \\pi mette come propriet√† che:\n\\forall x \\in \\Sigma_1^*, \\ |f(x)| = |x| (la lunghezza dell‚Äôoutput √® uguale a quella dell‚Äôinput).\ninoltre come condizione di \\pi viene anche detto che\nf √® calcolabile in tempo polinomiale in funzione di |x| ovvero che:\n\nf(x) termina in al pi√π p(|x|) passi, dove |x| √® la lunghezza della stringa x.\n\n\n\nQuindi definite queste due condizioni possiamo ad esempio avere che:\nDati due linguaggi L_1 \\subseteq \\Sigma_1^* e L_2 \\subseteq \\Sigma_2^*, diciamo che:\nL1 ‚âº_\\pi L2\nse esiste una funzione f : \\Sigma_1^* \\to \\Sigma_2^* tale che:\n\nLe cose sopra delle riduzioni\nf soddisfa anche \\pi\nQuindi queste riduzioni+aggiunta ci possono permettere di individuare i linguaggi separatori tra due classi di complessit√†\nusando concetti legati alle \\pi- riduzioni :\n\nchiusura di una classe rispetto a una \\pi- riduzione\ncompletezza di un linguaggio per una classe rispetto a una \\pi- riduzione\nquesti due concetti li spiegheremo adesso con due teoremi\n\n\n\nDefinizione 6.4\n\n\n                  \n                  Definizione 6.4 \n                  \n                \n\nUna classe di complessit√† \\mathcal{C} √® chiusa rispetto a una \\pi-riduzione se:\nPer ogni coppia di linguaggi L_1, L_2 tali che:\nL_1 ‚âº_\\pi L_2 \\quad \\text{e} \\quad L_2 \\in \\mathcal{C}‚Äã\nallora:\nL_1 \\in \\mathcal{C}\n\n\nIN POCHE PAROLE\nSe posso ridurre un linguaggio L_1 a un linguaggio L_2 ‚Üê che so gi√† appartenere alla classe \\mathcal{C} e \\mathcal{C} √® chiusa rispetto a quel tipo di riduzione, allora anche L_1 appartiene a \\mathcal{C}\nDefinizione 6.3\n\n\n                  \n                  Definizione 6.3 \n                  \n                \n\nSia \\mathcal{C} una classe di complessit√† di linguaggi, e sia ‚âº_\\pi una \\pi-riduzione.\nUn linguaggio L \\subseteq \\Sigma^* √® \\mathcal{C}-completo rispetto alla \\pi-riducibilit√† se:\na) L \\in \\mathcal{C}\nIl linguaggio fa parte della classe.\nb) \\forall L_0 \\in \\mathcal{C} \\quad L_0 ‚âº_\\pi L\nOgni altro linguaggio nella classe \\mathcal{C} si riduce a L tramite \\pi.\n\n\nLa completezza e la chiusura sono strumenti centrali per:\n\nStudiare la struttura interna delle classi di complessit√†\nIdentificare i problemi pi√π rappresentativi e difficili\nRagionare su separazioni tra classi (come P \\neq NP)\n\nStrategia per dire che due classi sono uguali\n‚úÖ Ipotesi iniziali:\n\nHai due classi di complessit√†:\nC1‚äÜC2\nC1 √® contenuto in C2\nSai che \\mathcal{C}_1 √® chiusa rispetto a una \\pi-riduzione\n(cio√®: se L_2 \\in \\mathcal{C}_1 e L_1 ‚âº_\\pi L_2, allora anche L_1 \\in \\mathcal{C}_1)\n\nüéØ Strategia:\n\nTrova un linguaggio L che sia \\mathcal{C}_2-completo rispetto a \\pi:\n\ncio√®:\nL \\in \\mathcal{C}_2 \\quad \\text{e} \\quad \\forall L_0 \\in \\mathcal{C}_2, \\quad L_0 ‚âº_\\pi L\nTutti i problemi in C2 si possono trasformare in un linguaggio L\n\nogni problema L0 √® in C2 e posso trasformare ogni problema L0 in L\n\n\n\n\n\n\nSe C1 √® chiusa rispetto a questa riduzione (cio√®: se L √® in C1, anche L0 ci entra)\n\nAllora anche L0 √® in C1\n\n\n\n\nDimostra che L \\in \\mathcal{C}_1\n\nüìå Conclusione:\nPoich√©:\n\nL_0 ‚âº_\\pi L per ogni L_0 \\in \\mathcal{C}_2\nL \\in \\mathcal{C}_1\nE \\mathcal{C}_1 √® chiusa rispetto a \\pi\nAllora: \\forall L_0 \\in \\mathcal{C}_2, \\quad L_0 \\in \\mathcal{C}_1 \\quad \\Rightarrow \\quad \\mathcal{C}_2 \\subseteq \\mathcal{C}_1\n\nTutti i problemi in C2 sono anche in C1\nMa gi√† sapevamo che:\n\\mathcal{C}_1 \\subseteq \\mathcal{C}_2 Quindi: \\mathcal{C}_1 = \\mathcal{C}_2\nTrovare un problema completo (come L) √® utile perch√©:\n\nSe appartiene a C1, allora tutta C2 √® in C1 ‚áí C1 = C2\nSe non appartiene a C1, allora C1 ‚â† C2\n\n\n\n                  \n                  precisazioni su problemi completi, ovvero i pi√π difficili \n                  \n                \n\n\n\n\nTeorema 6.20\nHai due classi di problemi:\n\nC1 √® contenuta in C2\nC1 √® chiusa rispetto a una certa riduzione \\pi\nSe per caso trovassimo un linguaggio L C2‚Äìcompleto rispetto a una qualche riduzione\\pi e\nse qualcuno riuscisse a dimostrare che C1 ‚â† C2 allora sapremmo automaticamente che L ‚àâ C2\n\n\n\n                  \n                  Teorema 6.20 \n                  \n                \n\nDate:\n\nDue classi di complessit√†: C‚ÇÄ e C\nSappiamo che C‚ÇÄ √® contenuta in C (cio√® tutti i problemi di C‚ÇÄ sono anche in C)\nSappiamo anche che C‚ÇÄ √® chiusa rispetto a una riduzione œÄ\n\nIl teorema dice:\nSe prendi un linguaggio L che √® C-completo (cio√® il pi√π difficile in C),\nallora:\nL √® in C‚ÇÄ se e solo se C = C‚ÇÄ\n\n\n\nuna particolare \\pi-riduzione la riduzione polinomiale\nuna \\pi greco riduzione in un esempio fatto prima prevedeva una funzione che doveva essere calcolata in |x|\n\nora facciamo un esempio di \\pi -riduzione che lo fa in tempo polinomiale\n\nDati due linguaggi L‚ÇÅ e L‚ÇÇ‚Äã, diciamo che:\n\n‚ÄúL‚ÇÅ √® polinomialmente riducibile a L‚ÇÇ‚Äù\n\nEsiste una funzionef: \\Sigma_1^* \\to \\Sigma_2^* tale che:\n\nf √® totale e calcolabile in tempo polinomiale\n\nf √® definita per ogni input x \\in \\Sigma_1^*\nesiste una macchina di Turing T_f che calcola f(x)\nil tempo di calcolo dtime(T_f, x) √® al massimo un polinomio nella lunghezza di x inteso come:  O(|x|^c)\n\n\n\n\nIn altre parole: si pu√≤ calcolare f(x) in ‚Äútempo ragionevole‚Äù (cio√® non esplosivo)\n\n\nf conserva la verit√† del problema\nPer ogni parola x \\in \\Sigma_1^*‚Äã:\n\n\nx \\in L‚ÇÅ \\iff f(x) \\in L‚ÇÇ\n\nCio√®: posso decidere se x sta in L‚ÇÅ controllando se f(x) sta in L‚ÇÇ\nin poche parole se esiste una funzione f che trasforma ogni istanza di L‚ÇÅ‚Äã in un‚Äôistanza di L‚ÇÇ‚Äã, e questa trasformazione:\n\n√® corretta\n√® calcolabile in tempo polinomiale\n\n\n\n                  \n                  d&#039;ora in poi scriveremo ‚âº per intendere per√≤: ‚âº_p ovvero una riduzione polinomiale\n                  \n                \n\ncome usare una riduzione polinomiale per costruire una macchina che decide un linguaggio, sfruttando un altro linguaggio che sappiamo gi√† decidere.\nüéØ Obiettivo\nHai due linguaggi, L1 e L2, e vuoi decidere se una parola x sta in L1.\nIl nuovo strumento\n\n\nAbbiamo due linguaggi, L_1 \\subseteq \\Sigma_1^* e L_2 \\subseteq \\Sigma_2^*\n\nSono due insiemi di stringhe su alfabeti diversi. L_1 √® quello che vogliamo decidere.\n\n\n\nRiusciamo a dimostrare che L_1 \\preceq L_2 (cio√®: L_1 √® riducibile a L_2 in tempo polinomiale)\n\nPossiamo trasformare ogni input x per L_1 in un input f(x) per L_2, in modo ‚Äúveloce‚Äù (tempo polinomiale)\n\n\n\nEsistono un trasduttore T_f e una costante c tali che:\n\nper ogni x \\in \\Sigma_1^*:\nx \\in L_1 \\iff f(x) \\in L_2,\ne inoltre \\text{dtime}(T_f, x) \\in O(|x|^c)\n\n\nIl trasduttore calcola f(x) in tempo polinomiale e conserva la verit√† tra L_1 e L_2\n\n\n\nSupponiamo di sapere che L_2 \\in \\text{DTIME}[f(n)]\n\nSignifica che esiste un algoritmo deterministico (una macchina T_2) che decide L_2 entro tempo f(n)\n\n\n\nQuindi: esiste un riconoscitore T_2 tale che, per ogni y \\in \\Sigma_2^*:\n\nT_2(y) accetta se e solo se y \\in L_2\n\\text{dtime}(T_2, y) \\in O(f(|y|))\n\n\nT_2 √® una macchina affidabile che decide L_2 in tempo noto\n\n\n\nAllora possiamo costruire una macchina T_1 che decide L_1:\nT_1 lavora in due fasi e usa due nastri:\nFASE 1\n\nT_1 simula T_f(x) e scrive l‚Äôoutput y = f(x) sul secondo nastro\n\nSta traducendo il problema da L_1 in un‚Äôistanza equivalente di L_2 che aveva f(x)\nFASE 2\n\n\nT_1 simula T_2(y) sul secondo nastro\n\nSe T_2 accetta, allora T_1 accetta\nSe T_2 rifiuta, anche T_1 rifiuta\n\n\nUsa T_2 per decidere se x \\in L_1, passando per f(x)\nConclusione:\n\n\nT_1 decide L_1, perch√©:\n\nT_2(y) accetta \\iff y \\in L_2\ny = f(x) e x \\in L_1 \\iff f(x) \\in L_2\n\n\nSe funziona per L_2, allora funziona anche per L_1\n\n\n\nQuanto tempo impiega T_1 a decidere L_1?\n\n(Serve per sapere in che classe di complessit√† finisce L_1)\n\n\nAbbiamo due linguaggi, L_1 \\subseteq \\Sigma_1^* e L_2 \\subseteq \\Sigma_2^*\nAbbiamo dimostrato che L_1 \\preceq L_2\nE sappiamo che L_2 \\in \\text{DTIME}[f(n)]\n\nQuindi possiamo usare una macchina T_2 per decidere L_2 in tempo deterministico f(n)\n\n\n\nper quanto riguarda invece il tempo che impiega T_1 a decidere L_1\nCon input x:\n\nFASE 1 (calcolo della riduzione):\n\\text{dtime}(T_f, x) \\in O(|x|^c)\n\nServe per trasformare x in y = f(x)\n\n\nFASE 2 (verifica con T_2):\n\\text{dtime}(T_2, y) \\in O(f(|y|))\n\nServe per verificare se f(x) \\in L_2\n\n\n\nil risultato sar√† la somma delle due fasi!\nnella fase 2 abbiamo detto che impiega f(|y|)\n\nPoich√© T_f(x) impiega O(|x|^c) per calcolare y\ne scrivere la simulazione sul secondo nastro di T_1 richiede almeno tanti passi quanto al lunghezza di y\nQuindi la lunghezza |y| √® al massimo O(|x|^c)\n\nSi fa la somma dei due e quindi\nil tempo che impiega T_1 a decidere L_1 √®\nO(‚à£x‚à£^c+f(‚à£x‚à£^c))\ne si scrive anche come:\nL1‚Äã‚ààDTIME[n^c+f(n^c)]\nConclusione su questa parte\nRICAPITOLIAMO: abbiamo due linguaggi, L_{1} ‚äÜ Œ£_{1}^{*} e L{2} ‚äÜ Œ£{2}^{*}, e sappiamo che L_{1} ‚âº L_{2}\nConclusione su questa parte\nRICAPITOLIAMO: abbiamo due linguaggi, L_{1} ‚äÜ Œ£_{1}^{*}  e L_{2} ‚äÜ Œ£_{2}^{*},  e sappiamo che L_{1} ‚âº L_{2}\n\n\n                  \n                  Grazie a quello che abbiamo visto prima, siamo riusciti a dimostrare che se L_{2} \\in P allora L_{1}\\in P\n                  \n                \n\nInfatti, in questo caso esiste una costante k tale che L_{2} \\in \\text{DTIME}[n^{k}]\n‚Üí allora da quanto visto nella dimostrazione precedente L_{1} \\in \\text{DTIME}[n^{c} + (n^{c})^{k}] \\subseteq P\n\n\nOssia abbiamo dimostrato il seguente teorema\nTeorema 6.21\n\n\n                  \n                  TEOREMA 6.21 \n                  \n                \n\nSe\n\nL_{1} ‚âº L_{2}\ne  L_{2} \\in P\n\\ \\Rightarrow \\ L_{1} \\in P\n\nOssia, il teorema dice che la classe P √® chiusa rispetto alla riducibilit√† polinomiale.\n\n\nSe hai:\n\nDue linguaggi L_1 e L_2\nE L_1 \\preceq L_2 (cio√® L_1 si riduce a L_2 in tempo polinomiale)\nE L_2 si risolve in tempo polinomiale\nAllora anche L_1 si risolve in tempo polinomiale, quindi:\n\n\nL_1 \\in P\n\nIn sintesi:\n\nSe trasformi un problema in un altro in tempo polinomiale, e l‚Äôaltro √® in P, allora anche il primo √® in P..\n\nAnche per altre classi non deterministiche\n\nI linguaggi NP-completi_\n\n\nA questo punto, abbandoniamo le generiche \\pi-riduzioni\ne torniamo definitivamente alle nostre riduzioni polinomiali\n\nDa ora in poi, si usa il simbolo \\preceq per indicarle\n\n\n\nUn linguaggio L \\subseteq \\Sigma^* √® NP-completo (rispetto alla riducibilit√† polinomiale) se:\na)¬†L‚ààNP\nb) ‚àÄL0‚Äã‚ààNP, \\  L0‚Äã‚™ØL\n\n\nI linguaggi NP-completi sono importanti per il loro ruolo di linguaggi separatori tra le classi P e NP\n\n\n\nüß© Corollario 6.4:\n\nSe P \\ne NP, allora per ogni linguaggio NP-completo L, si ha L \\notin P\n\n\n\nSupponiamo invece che L sia NP-completo e anche L \\in P\n\n\nPoich√© L √® NP-completo, allora:\n\\forall L_0 \\in \\text{NP}, \\quad L_0 \\preceq L\n\n\nMa P √® chiusa rispetto a \\preceq ‚áí quindi anche:\n\\forall L_0 \\in \\text{NP}, \\quad L_0 \\in P\n\n\nDunque: \\text{NP} \\subseteq \\text{P} ‚áí \\text{P} = \\text{NP}, contraddicendo l‚Äôipotesi\n\n\nüìò I problemi NP-completi\n\nMa qual √® il senso del Corollario 6.4?\n\n\n√à molto improbabile che un linguaggio NP-completo appartenga a P\n\n\n\nPerch√©? Perch√© si sospetta che P \\ne NP, ma nessuno √® mai riuscito a dimostrarlo\n‚Üí √à la congettura fondamentale della complessit√† computazionale\n\n\n√à cos√¨ importante che c‚Äô√® una taglia da 1 milione di dollari per chi risolve la congettura (o la sua negazione)\n\n\n‚ùó Quindi:\nSe vogliamo dimostrare (probabilmente) che non esiste un algoritmo deterministico polinomiale per un certo problema in NP‚Ä¶\n\n‚Ä¶ dobbiamo dimostrare che quel problema √® NP-completo\n\n\nüí∞ E se invece troviamo un algoritmo polinomiale per un NP-completo?\n\nAbbiamo vinto un milione di dollari\n‚Ä¶ oppure, ehm, abbiamo sbagliato qualcosa üòÖ\n\n\nüìò Uso delle riduzioni\n\n\nLe riduzioni sono uno strumento fondamentale anche nella calcolabilit√†:\n\n\nSe dimostro che:\nL_1 \\preceq L_2 \\quad \\text{e} \\quad L_2 \\text{ √® decidibile}\nallora anche L_1 √® decidibile\n\n\nSe invece:\nL_0 \\preceq L_1 \\quad \\text{e} \\quad L_0 \\text{ non √® decidibile}\nallora anche L_1 non √® decidibile\n\n\n\n\n\n\n\nAllo stesso modo, le riduzioni polinomiali sono utili per la complessit√†:\n\nSe dimostro che:\nL_1 \\preceq L_2 \\quad \\text{e} \\quad L_2 \\in P\nallora:\nL_1 \\in P\nSe invece:\nL_0 \\preceq L_1 \\quad \\text{e} \\quad L_0 \\notin P \\text{ (probabilmente)}\nallora:\nL_1 \\notin P \\text{ (probabilmente)}\n\n\n\n\nPerch√© un linguaggio non pu√≤ essere pi√π facile di uno a cui tutti si riducono\n\n\n\nMa di questo parleremo (e abbondantemente!) nella dispensa 9\n"},"UNI/ANNO-2/FONDAMENTI/FONDAMENTI-LEZ.25":{"slug":"UNI/ANNO-2/FONDAMENTI/FONDAMENTI-LEZ.25","filePath":"UNI/ANNO 2/FONDAMENTI/FONDAMENTI LEZ.25.md","title":"FONDAMENTI LEZ.25","links":[],"tags":[],"content":"Classi complemento\nOltre ad aver definito le classi computazionali classiche ci sono anche quelle complemento:\n\nNon cambia nulla se stiamo parlando di linguaggi L o L^c perch√© il teorema 6.11 ci dice che sostanzialmente i costi sono gli stessi\n\n\n                  \n                  Teorema 6.11 recap \n                  \n                \n\n\nche viene dimostrato:\n\nSi prende una macchina T che decide L tale che, per ogni x, dtime(T,x) ‚àà O(f(|x|))\n\nquesta cosa vale anche per dspace\nsostanzialmente una macchina che decide una x nel linguaggio L in tempo al pi√π la lunghezza dell‚Äôinput\n\n\n\nsuccessivamente si crea una macchina T‚Äô che complementa gli stati finali della macchina e ci si rende conto che lo fanno nello stesso tempo o spazio\n\n\n\nDal teorema 6.11 possiamo derivare delle definizioni\nCorollario 6.3\n\n\n                  \n                  Corollario 6.3 \n                  \n                \n\n\nP = coP\ncoPSPACE = PSPACE\n\n\n\nQuesto √® definito per le classi deterministiche\n\n\n                  \n                  possiamo dire lo stesso per le non? \n                  \n                \n\n\npossiamo utilizzare la stessa tecnica utilizzata nella dimostrazione del Teorema 6.11 nel caso non deterministico?\nPossiamo complementare gli stati di accettazione e di rigetto di una macchina NT che accetta un linguaggio L al fine di accettare il complemento di L?\n\n\n\nRicordiamo che:\n\nle classi non deterministiche sono definite come classi di linguaggi accettati da macchine non deterministiche entro quantit√† limitate di istruzioni o celle di nastro\nabbiamo inoltre detto che:\nmalgrado abbiamo macchine di Turing non deterministiche che decidono un linguaggio in un certo tempo\n\npresentano comunque una asimmetria\nQuesto perch√© nelle macchine deterministiche a differenza di quelle non hanno accettazione e rigetto simmetrici: basta invertire lo stato finale.\n\n\nquesto ci ha permesso di dimostrare il 6.11\nla prof ci fa vedere comunque che succede se lo facciamo con quelle non deterministiche\ne ci accorgiamo che la dimostrazione non pu√≤ funzionare allo stesso modo, proprio a causa dell‚Äôasimmetria(spoilerz)\n\napplichiamo la stessa tecnica\n\ncostruiamo una nuova macchina NT‚Äô invertendo gli stati di accettazione e di rigetto di NT\ne vediamo se NT‚Äô accetta (oppure no) il complemento del linguaggio accettato da NT\nCominciamo scegliendo un linguaggio L ‚äÜ {0,1}* accettato da una macchina di Turing non deterministica NT\nricordiamo che il linguaggio complementato L^c si crea facendo\nL^c = \\{0,1\\}^*- L ossia, per ogni x ‚àà {0,1}*\n\nse x ‚àà L allora x ‚àâ L^c\nse x ‚àâ L allora x ‚àà L^c\nin poche parole il contrario\n\n\n\nCome si comporta una macchina NT^C?\n\nquindi nel concreto possiamo avere macchine non deterministiche complementari\nOra proviamo ad applicare la vera e propria dimostrazione del teorema 6.11 per le non deterministiche\n\nScegliamo un linguaggio L‚äÜ{0,1}^‚àóche √® accettato da una macchina di Turing non deterministica, chiamiamola NT.\npoi ‚Üí\nProviamo a fare come nel Teorema 6.11:\n\nCostruire una nuova macchina NT‚Ä≤ invertendo gli stati di accettazione e rigetto della NT\n(cio√®, provare a costruire una macchina che accetta il complemento di L)\n\n\n\nper sgamare eventuali errori sul seguente teorema, creiamo una macchina NT_1 che\n\nin poche parole questa macchina per ogni possibile input avr√† comunque uno stato di rigetto\nIn pratica: abbiamo ‚Äúiniettato‚Äù una computazione finta che fallisce sempre,\nanche se NT accettava x tramite un‚Äôaltra computazione.\nnella foto sotto vediamo che ora NT rigetta sempre con le nuove quintuple\n\nPossiamo inoltre notare anche che\n\nNT‚ÇÅ accetta tutto ci√≤ che accettava NT (cio√® il linguaggio L)\nMa in pi√π ha una computazione che porta a rigetto\n\noltre a non accettare rigetta anche\nse tutte le computazioni di NT rigettano\nanche le computazioni di NT_1 rigettano+ quella speciale che rigetta sempre\nquesto avviene quando x ‚àâ L\n\n\nAdesso che abbiamo definito NT_1 correttamente possiamo applicare le stesse cose del teorema 6.11\n\nproviamo a creare la macchina non deterministica complementare\n\nNT_1^C\ninvertendo gli stati di accettazione e di rigetto di NT1\n\n\n\nOra andremo a verificare se NT‚ÇÅ·∂ú accetta il complemento di L, cio√® se davvero:\n\naccetta gli input x ‚àà L·∂ú\ne non accetta quelli in L\n\nDividiamo in 2 casi:\nSe x \\in L^C\n\nma che succede invece se\nSe x \\notin L^C ?\nNT_1^C non dovrebbe accettare\n\nRicapitolando\nvisto che con le macchine non deterministiche abbiamo una asimmetria non possiamo dire che\n\ncongetture di classi\n\nabbiamo detto che la maggior parte delle inclusioni tra classi di complessit√† sono deboli\n\nnon si dimostra che sono diverse\nma nemmeno uguali\nil caso famoso riguarda soprattutto P e NP\n\n\n\n\nDa qui nasce un teorema che definisce una relazione tra queste due congetture definite sopra\nTeorema 6.23\n\n\n                  \n                  Teorema 6.23 \n                  \n                \n\n\n\n\n\nTeorema 6.24\n\n\n                  \n                  Teorema 6.24 \n                  \n                \n\n\nCio√®: se prendi un problema in coNP e lo riduci polinomialmente a un altro problema, il problema risultante resta in coNP.\n\n\nCome per tutte le classi di complessit√†, anche per la classe coNP possiamo definire linguaggi completi rispetto alla riducibilit√† polinomiale\n\nCosa abbiamo imparato dalla classe NP:\n\nQuando supponiamo che P ‚â† NP, allora i linguaggi NP-completi non possono appartenere a P.\nQuesti linguaggi sono quindi i ‚Äúpi√π difficili‚Äù della classe NP.\nInoltre, proprio per questa loro difficolt√†, possono agire da linguaggi separatori tra P e NP (cio√®: se uno di essi stesse in P, P = NP, altrimenti no).\n\nCosa vogliamo fare con coNP:\n\nStessa logica, ma tra NP e coNP.\nVogliamo mostrare che i linguaggi coNP-completi sono i candidati a essere linguaggi separatori tra NP e coNP.\nCio√®, se supponiamo che coNP ‚â† NP, allora:\n\nUn linguaggio coNP-completo non pu√≤ stare in NP\nAnche qui, questi linguaggi sono i ‚Äúpi√π difficili‚Äù all‚Äôinterno di coNP.\n\n\n\nTeorema 6.25\n\n\n                  \n                  Teorema 6.25 \n                  \n                \n\nUn linguaggio L √® NP-completo se e soltanto se il suo complemento L^c √® coNP-completo\nper dimostrarlo facciamo una doppia ‚áê ‚áí\n\nOra dimostriamo l‚Äôaltra parte\n\n\n\nTeorema 6.26\n\n\n                  \n                  Teorema 6.26 \n                  \n                \n\n\n\n\n\n"},"UNI/ANNO-2/FONDAMENTI/FONDAMENTI-LEZ.26":{"slug":"UNI/ANNO-2/FONDAMENTI/FONDAMENTI-LEZ.26","filePath":"UNI/ANNO 2/FONDAMENTI/FONDAMENTI LEZ.26.md","title":"FONDAMENTI LEZ.26","links":[],"tags":[],"content":"Come √® strutturato un problema\nDato un quesito abbiamo inoltre\n\nun insieme di oggetti conosciuti\ndefinito insieme delle istanze\nall‚Äôinterno di un secondo insieme di oggetti\ndefinito insieme delle soluzioni possibili\ndobbiamo cercare gli oggetti che soddisfano certi dati vincoli\ne, sulla base degli oggetti trovati, dobbiamo rispondere al quesito posto\n\nEsempio 1\n\n\n                  \n                  PROBLEMA: dato un numero intero n, trovare tutti i divisori di n\n                  \n                \n\n\n\nL‚Äôinsieme delle istanze del problema le definiamo con la lettera ùï¥\nun elemento di ùï¥ corrisponde ad una istanza del problema.\nNel nostro esempio abbiamo che ùï¥ = \\mathbb{N}ossia tutti i numeri naturali\n\n\nAbbiamo poi l‚Äôinsieme delle soluzioni possibili, che definiamo come S(n)\nS(n) descrive tutti gli oggetti che dobbiamo testare per verificare se soddisfano i vincoli del problema\nNel nostro esempio abbiamo che S(x) = \\{y \\in \\mathbb{N} : y \\le n\\}ossia tutti i numeri che vanno da 1 a n sono candidati da controllare per trovare i divisori di x\n\n\nAll‚Äôinterno dell‚Äôinsieme delle soluzioni possibili dobbiamo andare a trovare le soluzioni effettive ossia quelle soluzioni che soddisfano effettivamente i vincoli del problema.\nAndiamo a definire questo insieme \\eta (S(n)).\nNel nostro caso abbiamo che \\eta(S(n)) = \\{y \\in S(n) : \\exists \\ h \\in N \\ [n = y \\cdot h]\\}Ossia\n\npresa una y dall‚Äôinsieme delle soluzioni possibili\nse esiste una h che, moltiplicata a y, mi restituisce n\nallora y √® un divisore di n\n\n\n\nDobbiamo descrivere ora la risposta del problema\nPer farlo, definiamo una funziona \\rho che associa, all‚Äôinsieme delle soluzioni effettive per l‚Äôistanza n, una risposta scelta nell‚Äôinsieme R delle risposte\nNel nostro caso abbiamo che R = 2^\\mathbb{N} ossia la risposta ad un‚Äôistanza del problema √® un sottoinsieme di \\mathbb{N}\nE, per ogni istanza del problema, la funzione √® definita come \\rho(\\eta(S(n))) = \\eta(S(n))Ossia, in questo caso specifico, l‚Äôinsieme delle soluzioni effettive coincide con la risposta del quesito.\n\n\nEsempio 2\n\n\n                  \n                  PROBLEMA: dato un numero intero n, verificare se n √® primo\n                  \n                \n\nQui i punti 1, 2 e 3 sono IDENTICI, a quelli di prima, perch√©\n\n\nLavoriamo ancora sui naturali, quindi ùï¥ = \\mathbb{N}\n\n\nDobbiamo comunque cercare se esistono dei divisori per n, quindi intanto prendiamo un insieme con TUTTI i numeri da 1 a n S(x) = \\{y \\in \\mathbb{N} : y \\le n\\}\n\n\nPer capire se un numero √® primo, prendiamo il numero e cerchiamo i divisori di n \\eta(S(n)) = \\{y \\in S(n) : \\exists \\ h \\in N \\ [n = y \\cdot h]\\}\nOra, l‚Äôunico punto che cambia, giustamente, √® il 4 (perch√© si richiede una risposta diversa da prima)\n\n\nQuello che andiamo a fare ora √® utilizzare \\rho come ‚Äúfiltro‚Äù per \\eta(S(n))\nDato che noi cerchiamo un numero primo, sappiamo che tutti i possibili divisori di n sono solo\n\n1\nn\n\nQuindi andiamo a specificare questa cosa nella funzione \\rho(\\eta(S(n))) = [\\eta(S(n)) = \\{1, n\\}]\nE, in questo caso, la nostra R sar√† R = \\{\\text{vero, falso}\\}perch√© dobbiamo solo dire\n\nS√¨, √® primo\nNo, non √® primo (down)\n\n\n\nEsempio 3\n\n\n                  \n                  PROBLEMA: dato un numero intero n, calcolare UN divisore d non banale di n\n                  \n                \n\nPer DIVISORI NON BANALI si intende tutti tranne 1 e n\nAnche in questo caso 1, 2 e 3 sono IDENTICI a prima\nOra, il 4.\n4) Abbiamo che R = \\mathbb{N} perch√© dobbiamo scegliere UN SOLO NUMERO\nE, la nostra funzione sar√† \\rho(\\eta(S(n))) = \\eta(S(n)) \\ \\ \\backslash \\ \\  \\{1, n\\}da cui poi dobbiamo estrarre l‚Äôelemento d\n\n\n                  \n                  ATTENZIONE: d potrebbe anche non esistere!\n                  \n                \n\nEsempio 4\n\n\n                  \n                  PROBLEMA: dato un numero intero n, calcolare IL PI√ô GRANDE divisore d non banale di n\n                  \n                \n\n√à identico a quello sopra, cambia solo che alla fine tiro fuori il pi√π grande da \\rho\n\nTipi di problemi\nProblemi di ottimizzazione\nL‚Äôesempio 4\n\n\n                  \n                  PROBLEMA: dato un numero intero n, calcolare IL PI√ô GRANDE divisore d non banale di n\n                  \n                \n\n√à un problema di ottimizzazione in quanto alle soluzioni effettive √® associata una misura e viene richiesto di trovare la soluzione effettiva di misura massima (come in questo caso), oppure minima.\nProblemi di ricerca\nL‚Äôesempio 3\n\n\n                  \n                  PROBLEMA: dato un numero intero n, calcolare UN divisore d non banale di n\n                  \n                \n\n√à un problema di ricerca in quanto viene richiesto di trovare (e mostrare) una qualunque soluzione effettiva\n\nsono i problemi con i quali abbiamo maggiore confidenza\n\nProblemi di enumerazione\nL‚Äôesempio 1\n\n\n                  \n                  PROBLEMA: dato un numero intero n, trovare tutti i divisori di n\n                  \n                \n\n√à un problema di enumerazione, in quanto ci viene richiesto di elencare tutte le soluzioni effettive.\nProblemi di decisione\nL‚Äôesempio 2\n\n\n                  \n                  PROBLEMA: dato un numero intero n, verificare se n √® primo\n                  \n                \n\n√à un problema di decisione (o decisionale), in quanto ci viene richiesto di decidere se l‚Äôistanza possiede una certa propriet√†\nProblemi e macchine\nI due diversi tipi di macchine di Turing risolvono questi problemi.\nIn particolare utilizziamo\n\nTrasduttori per i problemi di ricerca, di enumerazione, e di ottimizzazione\nRiconoscitori per i problemi di decisione\n\nNOI CI OCCUPEREMO SOLO DI PROBLEMI DECISIONALI.\nProblemi decisionali\n\n\n                  \n                  Definizione formale (e generale) di PROBLEMA \n                  \n                \n\nDa quello che abbiamo visto prima possiamo dire che un problema, in generale, pu√≤ essere descritto da una quintupla \\langle \\ ‚Ñë, \\ S, \\ \\eta, \\ \\rho, \\ R \\ \\rangledove\n\n\\eta √® il sottoinsieme di S che specifica quali, fra le soluzioni possibili, sono le soluzioni effettive per una data istanza x ‚àà ‚Ñë\n\\rho √® la funzione che associa all‚Äôinsieme delle soluzioni effettive ùúÇ(S(x)) una risposta (elemento di R) all‚Äôistanza x del problema\n\n\n\nNel caso dei problemi decisionali, abbiamo che R = \\{\\text{vero, falso}\\}Questo significa che \\rho √® un predicato\n\nossia una funzione booleana\n\no, per dirla meglio una proposizione logica il cui valore di verit√† dipende da qualche incognita\n\n\n\nAllora possiamo riassumere \\eta, \\ \\rho, \\ R in un unico predicato \\pi \\pi(x, S(x)) = \\text{vero} \\iff \\text{ l‚Äôinsieme delle soluzioni possibili per x soddisfa i vincoli del problema}\nE quindi, un problema decisionale √® descritto da una tripla \\langle \\ ùï¥, \\ S, \\ \\pi \\ \\rangle\n\n\n                  \n                  COSA FACILE CHE CHIEDE SEMPRE ALL&#039;ESAME \n                  \n                \n\nDato un problema, formalizzarlo con la terna \\langle \\ ùï¥, \\ S, \\ \\pi \\ \\rangle\n\n\nProblemi decisionali: esempi\nEsempio 1\n\nDescrizione\n1. Insieme delle istanze ùï¥\nùíÆ = { ‚ü®G, s, t, k‚ü© : G √® un grafo non orientato ‚àß s,t ‚àà G ‚àß k ‚àà ‚Ñï }\n\nüìå Qui stiamo dicendo che:\n\nUn‚Äôistanza del problema √® una quatupla \\langle \\ G, \\ s, \\ t, \\ k \\ \\rangle, dove:\n\nG √® un grafo valido (non orientato),\ns e t sono due nodi del grafo,\nk √® un numero naturale (lunghezza cercata del percorso).\n\n\n\n2. Insieme delle soluzioni possibili ùíÆ(G, s, t, k)\nùíÆ(G, s, t, k) = { ‚ü®u‚ÇÄ, u‚ÇÅ, ..., u‚Çñ‚ü© : ogni u·µ¢ √® un nodo del grafo G }\n\nüìå Qui stiamo elencando tutte le sequenze di nodi lunghe k+1, potenziali percorsi da s a t:\n\nOgni sequenza rappresenta un cammino che potrebbe essere lungo k archi.\nNon sappiamo ancora se √® valido, solo che ha la forma giusta.\n\n3. Predicato di verifica œÄ(G, s, t, k, ùíÆ(G, s, t, k))\nœÄ(G, s, t, k, ùíÆ(G, s, t, k)) =\n    ‚àÉ ‚ü®u‚ÇÄ, ..., u‚Çñ‚ü© ‚àà ùíÆ(G, s, t, k) :\n      u‚ÇÄ = s ‚àß u‚Çñ = t ‚àß ‚àÄi ‚àà [0, k‚àí1], (u·µ¢, u·µ¢‚Çä‚ÇÅ) ‚àà E\n\nüìå Questo controlla che:\n\nLa sequenza parte da s e arriva a t\nOgni coppia consecutiva di nodi sia connessa da un arco (cio√® esista nel grafo),\nQuindi: verifica che sia un vero cammino da s a t di lunghezza k.\n\nESEMPIO 2\n\nQui detta molto in breve\n\nho un insieme di variabili booleane x_{0}, x_{1}, ... , x_{n}\nho poi un predicato f costituito da\n\nqueste variabili\ne operatori ‚àß, ‚à® e ¬¨\n\n\ndevo trovare un‚Äôassegnazione a che mi renda f vera\n\n\n\n                  \n                  NOTA BENE: ciascun problema decisionale pu√≤ essere descritto da diverse triple \\langle \\ ùï¥, \\ S, \\ ùùÖ \\ \\rangle!\n                  \n                \n\n\nDa problema a linguaggio\n\nCodifica\nRiprendendo l‚Äôesempio 2 che abbiamo visto poco fa\n\nQuesto esempio, che √® generale, viene definito SAT\nPrendiamo in considerazione un suo caso particolare: 3SAT\n\nIn pratica, abbiamo un SAT ma\n\nogni clausola (ossia le parentesi, che noi chiamiamo c_{j}) √® l‚Äôor (‚à®) di tre letterali (variabili / variabili negate).\n\n\n\n                  \n                  Come codifichiamo gli elementi di ùï¥?\n                  \n                \n\nAbbiamo due possibilit√†\n\ncodifichiamo la STRUTTURA di  f\ncodifichiamo ‚Äúil SIGNIFICATO‚Äù di f\n\n\n\nCodifica \\chi_{1}: codifichiamo la STRUTTURA di f\nüß† L‚Äôidea di fondo\nHai:\n\nUn insieme di variabili: X = {x‚ÇÅ, x‚ÇÇ, ..., x‚Çô}\nUna formula f = c‚ÇÅ ‚àß c‚ÇÇ ‚àß ... ‚àß c‚Çò, dove ogni clausola c·µ¢ √® tipo x‚ÇÅ ‚à® ¬¨x‚ÇÇ ‚à® x‚ÇÉ\n\nVogliamo codificare questa formula usando bit.\n‚úèÔ∏è Come funziona la codifica?\n1. Codifichiamo le variabili\nLe variabili vengono rappresentate in binario, una alla volta. Esempio:\n\nSe X = {x‚ÇÅ, x‚ÇÇ, x‚ÇÉ}, allora:\n\nx‚ÇÅ √® 100\nx‚ÇÇ √® 010\nx‚ÇÉ √® 001\n\n\n\n2. Letterali nelle clausole\nPer ogni letterale (cio√® variabile o negazione):\n\nSe NON negato, si mette 0 davanti alla variabile.\nSe negato, si mette 1 davanti.\nEsempio:\n\nx‚ÇÅ ‚Üí 0 100\n¬¨x‚ÇÇ ‚Üí 1 010\n\n\n\n3. OR (‚à®) √® rappresentato con il simbolo &#039;2&#039;\n4. AND (‚àß) √® rappresentato con il simbolo &#039;3&#039;\n5. Si mette all‚Äôinizio un &#039;4&#039; per ogni variabile di X (serve per dire quante ce ne sono)\nüß™ Esempio\nX = {x‚ÇÅ, x‚ÇÇ, x‚ÇÉ}\nf = c‚ÇÅ ‚àß c‚ÇÇ \ncon:\nc‚ÇÅ = x‚ÇÅ ‚à® x‚ÇÇ ‚à® x‚ÇÉ\nc‚ÇÇ = x‚ÇÅ ‚à® ¬¨x‚ÇÇ ‚à® x‚ÇÉ\n\nCodifica:\n444       ‚Üê tre 4 perch√© ci sono 3 variabili\n0 100     ‚Üê x‚ÇÅ\n2         ‚Üê OR\n0 010     ‚Üê x‚ÇÇ\n2\n0 001     ‚Üê x‚ÇÉ\n3         ‚Üê AND\n0 100     ‚Üê x‚ÇÅ\n2\n1 010     ‚Üê ¬¨x‚ÇÇ\n2\n0 001     ‚Üê x‚ÇÉ\n\n‚úÖ Risultato finale\n\nCodifica \\chi_{2}: codifichiamo il SIGNIFICATO di f\nSappiamo che possiamo rappresentare completamente f dicendo che valore restituisce in ogni possibile combinazione di input ‚Üí questa √® la tavola di verit√†.\nDato che la f della nostra istanza \\langle \\ X, \\ f \\ \\rangle di 3SAT √® definita su \\text{\\{vero, falso\\}}^{|X|}e poich√© X √® un insieme finito ‚Üí allora possiamo codificare f in forma esplicita e la sua tabella di verit√† sar√† finita.\nPer esempio: \nCodificando\n\nvero con ‚Äò1‚Äô\nfalso con ‚Äò0‚Äô\ne scrivendo le righe della tavola una di seguito all‚Äôaltra, separate da ‚Äò2‚Äô\nOtteniamo:\n\n\nPerfetto, ora ci manca solo fornire una risposta al problema\nData \\langle \\ X, \\ f \\ \\rangle istanza di 3SAT, per decidere se f √® soddisfacibile.\n\nossia esiste una assegnazione a di valori in \\text{\\{vero, falso\\}} alle variabili in X tali che f(a(X))= \\text{vero}\nconsideriamo il seguente algoritmo:\n\n\ncalcola n = |X|;\nper ogni assegnazione di verit√† a all‚Äôinsieme delle n variabili in X : verifica se f(a(X))= \\text{vero} e, in tal caso termina nello stato di accettazione q_{A};\nse non ha mai terminato in q_{A} al passo 2, termina nello stato di rigettoq_{R}.\n\n\n\n                  \n                  Quindi \n                  \n                \n\nDobbiamo sfruttare questo algoritmo che\n\nprende in pasto una istanza codificata o secondo \\chi_{1} o secondo \\chi_{2}\ne restituisce un risultato.\n\nIn particolare, abbiamo\n\nun solo algoritmo\na questo algoritmo passiamo, una alla volta, entrambe le codifiche\ndobbiamo verificare quale codifica ‚Äúcosta‚Äù meno.\n\n\n\nUtilizzando \\chi_{1}\nFASE 1\n\n\nFASE 2\n\nQuindi in pratica,\n\nlegge tutte le assegnazioni (ogni singolo blocco prima di un 5)\napplica ciascuna assegnazione dentro f\nse almeno una restituisce 1 ‚Üí accetta\nse NESSUNA restituisce 1 ‚Üí rigetta\n\nQuanto √® dtime(T_{1}, \\ \\chi_{1}(X, f))?\n\nSono solo calcoli, per√≤ l‚Äôimportante √® capire che con questa codifica, dtime √® POLINOMIALE in n\nUtilizzando \\chi_{2}\n\nQuando √® dtime(T_{2}, \\ \\chi_{2}(X, f))?\n\nQuindi in questo caso dtime √® LINEARE in n!\nOra, ricordando che un linguaggio √® nella classe P se esiste una macchina di Turing deterministica che lo decide in tempo polinomiale, possiamo concludere che il linguaggio associato a 3SAT appartiene a P?\n\nOsserva che T1 e T2 implementano lo stesso algoritmo\nma operano su due codifiche differenti!\n\n\n\n                  \n                  Ma quindi scusa, la caratteristica essere un algoritmo polinomiale dipende dal modo in cui √® codificato l‚Äôinput?\n                  \n                \n\nSi e no.\n\n\nSe io prendo \\chi_{1} so che l‚Äôalgoritmo, data una istanza x, impiega tempo POLINOMIALE.\nOra, se io prendo la stessa istanza ma la allungo IRRAGIONEVOLMENTE di lunghezza polinomiale e do tutto questo in pasto all‚Äôalgoritmo, mi sembrer√† di aver utilizzato tempo LINEARE!\nMa in realt√† non √® cos√¨, perch√© ho incrementato in maniera insensata l‚Äôinput\nSe invece prendo \\chi_{2}, l‚Äôalgoritmo, data una istanza x, impiega tempo LINEARE.\nPer√≤ l‚Äôistanza cos‚Äô√®? Letteralmente la codifica della tabella di verit√†.\nE quando ci vuole per costruire una tabella di verit√†? 2^{n} passi.\nQuanto √® lungo l‚Äôinput? 2^{n}, quindi \\chi_{2} √® esponenzialmente pi√π lunga di \\chi_{1}\nQuindi, da qualche parte, anche in questo caso, impiego tempo POLINOMIALE.\n\nPossiamo nascondere una complessit√†, ma non possiamo eliminarla davvero\n\n\nCodifiche (ir)ragionevoli\nPrendiamo in considerazione le due codifiche di prima\n\nœá‚ÇÅ: codifica strutturale della formula.\n√à compatta: dice solo quali sono le clausole, i letterali, ecc.\nœá‚ÇÇ: codifica esplicita della formula.\nDice gi√† per ogni assegnazione se la formula √® vera o falsa ‚Üí √® la tabella di verit√†.\n\n‚õî 3. Perch√© œá‚ÇÇ √® ‚Äúingannevole‚Äù?\nPerch√© sembra che con œá‚ÇÇ tu abbia un algoritmo che funziona in tempo lineare:\n\nLeggi la tabella ‚Üí rispondi subito: ‚Äúf √® soddisfacibile? S√¨/No‚Äù\n\n‚ö†Ô∏è Ma attenzione:\nQuanto tempo hai impiegato per costruire œá‚ÇÇ?\n\nHai dovuto calcolare 2‚Åø righe di tabella, per ogni combinazione delle variabili.\nQuindi hai impiegato tempo esponenziale prima, e solo poi hai un input lungo.\n\nü§Ø 4. Cosa vuol dire che √® irragionevole?\nUna codifica œá √® irragionevole se:\n\nEsiste un‚Äôaltra codifica œá‚Ä≤ che rappresenta le stesse istanze,\nma œá(x) √® molto pi√π lunga di œá‚Ä≤(x), diciamo che √® pi√π che polinomialmente (tipo n^{n}).\n\nIn altre parole:  |\\chi(x)| \\geq F(|\\chi&#039;(x)|) con F pi√π che polinomiale (es. esponenziale).\nüí° 5. Perch√© √® un problema?\nPerch√© la complessit√† di un algoritmo si misura in base alla lunghezza dell‚Äôinput.\nQuindi:\n\nSe codifichi in modo lunghissimo, anche un algoritmo lento sembra veloce.\nMa stai barando: stai nascondendo il lavoro dentro all‚Äôinput.\n\n‚úÖ Conclusione:\n\nœá‚ÇÅ √® una codifica ragionevole: √® compatta, riflette il vero lavoro da fare.\nœá‚ÇÇ √® una codifica irragionevole: √® lunga, nasconde il lavoro fatto prima.\n\nCodifiche ragionevoli\n\nQui in poche parole ti dice\n\ndate due codifiche \\chi e \\chi^{&#039;}\n\\chi pu√≤ anche essere pi√π grande di \\chi^{&#039;}\nper√≤ esiste un polinomio p che, qualunque sia l‚Äôistanza che prendi, far√† si che la lunghezza di \\chi non sia MAI PI√ô GRANDE della lunghezza di \\chi^{&#039;} data in pasto al polinomio\n\n\n\n                  \n                   \\Gamma lo ha usato la prof nella slide precedente a questa foto per indicare un generale problema.\n                  \n                \n\nQuindi, in breve\n\nSe \\chi √® esponenzialmente pi√π lunga di \\chi^{&#039;} ‚Üí \\chi √® irragionevole\nSe \\chi √® al pi√π polinomialmente pi√π lunga di \\chi^{&#039;} ‚Üí \\chi √® ragionevole\n\n"},"UNI/ANNO-2/FONDAMENTI/FONDAMENTI-LEZ.27":{"slug":"UNI/ANNO-2/FONDAMENTI/FONDAMENTI-LEZ.27","filePath":"UNI/ANNO 2/FONDAMENTI/FONDAMENTI LEZ.27.md","title":"FONDAMENTI LEZ.27","links":[],"tags":[],"content":"da recuperare"},"UNI/ANNO-2/FONDAMENTI/FONDAMENTI-LEZ.28":{"slug":"UNI/ANNO-2/FONDAMENTI/FONDAMENTI-LEZ.28","filePath":"UNI/ANNO 2/FONDAMENTI/FONDAMENTI LEZ.28.md","title":"FONDAMENTI LEZ.28","links":[],"tags":[],"content":"DIRE CHE UN PROBLEMA √à NP NON SIGNIFICA PER√í CHE SIA HARD PU√í ANCHE ESSERE IN P\nNP √© la classe dei linguaggi che sono accettati da una macchina non deterministica non polinomiale\nperch√© cazzo e che continuiamo a dire per√≤ che essi devono essere accettati anche se abbiamo definito che sono anche decisi?\nDefiniamo una macchina non det che accetta un linguaggio L in un certo tempo poly\nCodifichiamo questa macchina\nin poche parole del genio di merda non ci fidiamo quindi potrebbe portarci in una computazione di rigetto, quindi continuiamo a dire che solo viene accettato"},"UNI/ANNO-2/FONDAMENTI/FONDAMENTI-LEZ.29":{"slug":"UNI/ANNO-2/FONDAMENTI/FONDAMENTI-LEZ.29","filePath":"UNI/ANNO 2/FONDAMENTI/FONDAMENTI LEZ.29.md","title":"FONDAMENTI LEZ.29","links":[],"tags":[],"content":""},"UNI/ANNO-2/FONDAMENTI/FONDAMENTI-LEZ.3":{"slug":"UNI/ANNO-2/FONDAMENTI/FONDAMENTI-LEZ.3","filePath":"UNI/ANNO 2/FONDAMENTI/FONDAMENTI LEZ.3.md","title":"FONDAMENTI LEZ.3","links":[],"tags":[],"content":"Esercizio 1\nProgettare un riconoscitore che prende in input una parola dall‚Äôalfabeto a,b\n\ntermina in q_p se la parola √® palindroma\nq_{np} se non √® palindroma\nDividiamo l‚Äôesercizio in 3 parti\n\n\nrisolviamo quando x ha anche lunghezza pari\nquando x √® palindroma ma lunghezza dispari\nx palindroma e basta\n\nUso delle simulazioni\nSi riutilizzano macchine di Turing per farne una nuova\nEsercizio 2\nRiprendiamo la macchina delle addizioni\nora la facciamo con piu somme con un numero arbitrario di +\nUsiamo la simulazione"},"UNI/ANNO-2/FONDAMENTI/FONDAMENTI-LEZ.4":{"slug":"UNI/ANNO-2/FONDAMENTI/FONDAMENTI-LEZ.4","filePath":"UNI/ANNO 2/FONDAMENTI/FONDAMENTI LEZ.4.md","title":"FONDAMENTI LEZ.4","links":[],"tags":[],"content":"Diversi tipi di macchine\n\nMacchine con testine indipendenti e tanti nastri\nMacchine con tanti nastri e testine solidali\nMacchine con un solo nastro\nMacchine con alfabeto con tanti simboli\nMacchine con alfabeto binario\ne si dimostra che ‚Äútutto quello che riusciamo a fare con una macchina di uno qualsiasi di questi modelli, riusciamo a farlo anche con una macchina di uno qualsiasi degli altri modelli‚Äù\n\nTeorema 1\n\nDimostrazione testine solidali=indipendenti\n√à ovvio definire che una macchina con testine indipendenti pu√≤ lavorare come una macchina con testine solidali ma dimostriamo l‚Äôopposto con una macchina con 2 nastri con testine solidali\nSia T una macchina a 2 nastri con testine indipendenti una sua quintupla √®\n&lt; q1 , (a,b), (c,d), q2 , (m1,m2) &gt;dove m1 √® il movimento della testina sul primo nastro e m2 √® il movimento della testina sul secondo nastro\nTrasformiamo questa quintupla in una serie di quintuple che possono funzionare su pi√π nastri con una macchina con testine solide\nla serie di quintuple ci riporta a voler shiftare prima un nastro poi l‚Äôaltro della direzione desiderata per poi rimettere le testine in modo correndo usando un terzo nastro per il pinning\n\nIn questo caso stiamo parlando di una simulazione a scatola aperta\n\nper quella chiusa si intendeva quando fai una simulazione ma non sai precisamente come sono fatte le macchine che utilizzerai ma sai solo le specifiche\nin questo caso fai una simulazione cercando di emulare un‚Äôaltra macchina che funziona in modo diverso\nSu questa tecnica √® basata la dimostrazione di un sacco di teoremi che vedremo in questo corso\nfra i quali gli altri due che seguono\n\n\n\n                  \n                  un po di esempi dei passaggi per le quintuple di T&#039; \n                  \n                \n\n\n\n\nTeorema 2\n\nDimostrazione di una macchina T_3 che funziona su T&#039;\nScriviamo un indirizzo(colonna) di T_3  per lungo\nT_3 ha come procedura definita questa quintupla\n\\langle \\mathbf{q}_1, (\\mathbf{x}_{11}, \\mathbf{x}_{12}, \\mathbf{x}_{13}), (\\mathbf{y}_{11}, \\mathbf{y}_{12}, \\mathbf{y}_{13}), \\mathbf{q}_2, m \\rangle\n\nquello che faccio con la mia macchina T&#039; √® andare a salvarmi tutti i singoli stati che si conseguono per fare una sorta di lettura continua\nappena verifico che ho letto x11 x12 e x13 allora significa che posso procedere con la scrittura delle varie y definendo quanto tornare indietro\n\nPassaggio per poi andare a fare la write e i vari spostamenti a sinistra\n\nScrittura con i vari spostamenti a destra\n\n\n\n                  \n                  esempi quintuple che farebbe T&#039; \n                  \n                \n\n\n\nil nastro inizialmente aveva a1 b1 c1 ma poi viene modificato con le varie lettere greche\nscrive gli stati con la potenza e non come 5 elemento\n\n\n\nTeorema 3\n\nMi raccomando usare la parola CODIFICA\nUsiamo anche qui una macchina che simula la macchina con pi√π lettere\n\nCominciamo con lo scrivere sui k nastri di T_{01} la codifica binaria dell‚Äôinput scritto sull‚Äôunico nastro di T\n\novviamente sar√† log_2 8=3\n\nQuesto √® il risultato della macchina dove\nb1(a) significa la prima cifra di a ovvero 0 e cos√¨ via per ogni nastro su cui siamo posizionati\nQuando una macchina fa le stesse cose di una macchina si esprime con\n\n\n                  \n                  l‚Äôesito della computazione di una macchina su un input coincide con l‚Äôesito della computazione dell‚Äôaltra macchina sullo stesso input (eventualmente codificato) \n                  \n                \n"},"UNI/ANNO-2/FONDAMENTI/FONDAMENTI-LEZ.5":{"slug":"UNI/ANNO-2/FONDAMENTI/FONDAMENTI-LEZ.5","filePath":"UNI/ANNO 2/FONDAMENTI/FONDAMENTI LEZ.5.md","title":"FONDAMENTI LEZ.5","links":[],"tags":[],"content":"Quando si inizializza una macchina di Turing\nsi definisce una quintupla con\n\nDagli ultimi 3 possiamo definire subito una macchina di turing\nDefiniremo esattamente P con una funzione di transizione\n\nSe di questo insieme \\delta  non abbiamo delle azioni definite ad esempio \\delta(q,s)=insieme vuoto\nallora significa che la macchina star√† ferma\nCon i TRASDUTTORI\novvero quelli che lavorano con un alfabeto ampio e output\nQuando non abbiamo una istruzione possono crearsi dei problemi e non basta fermare la macchina quindi possiamo\n\ncreare una Funzione totale con tutte le istruzioni possibili\nsono cavoli di chi usa l‚Äôinput che non deve mettere roba sbagliata\n\nCon i RICONOSCITORI\nCon i riconoscitori abbiamo lo stesso problema ma dobbiamo definire bene gli stati perch√® lo stato di rigetto non pu√≤ essere usato come stato di errore di computazione quindi in questo caso dobbiamo definire un errore in scrittura come E oppure rendiamo la procedura in modo che dia un unico output corretto e tutti gli altri sono l‚Äôopposto\nAnzich√® scrivere pari o dispari qa qr scrivo pari oppure tutto il resto\nE se P non corrisponde a una sola funzione?\nmettiamo caso di avere P che corrisponde a pi√π funzioni avremo quindi definito una funzione di transizione di tipo multiplo\n\na delle condizioni corrispondono pi√π funzioni quando tu hai un insieme A e fai 2^A ottieni tutti i sottoinsiemi con A\nnon possiamo avere due quintuple perch√® la Macchina di Turing non saprebbe cosa scegliere\n\\langle q, a, b_1, q_1, m_1 \\rangle, \\langle q, a, b_2, q_2, m_2 \\rangle, \\dots, \\langle q, a, b_k, q_k, m_k \\rangle\nchiamiamo cos√¨ questa struttura multi-quintupla\nle multi quintuple vengono gestite da macchine non deterministiche\nil grado di non determinismo di una singola funzione transitoria √® dato da\n\ninvece il grado di non determinismo di tutte le funzioni transitorie di una macchina sono date da\n\nIl comportamento di T di una macchina non deterministica  pu√≤ fare in due modi (equivalenti) quando ci si presenta una multi quintupla.\nLe macchine non deterministiche sono definite con NT\nTUTTE QUESTE DUE MACCHINE SI BASANO SU RICONOSCITORI\n1. Macchina super iper ultra parallela o la coda di rondine con ripetizioni\nEsegue tutte le k quintuple in modo parallelo si moltiplica tutto per ogni stato globale che si va a creare, se poi da una quintupla si creano altri sotto stati globali con altre quintuple si crea una sorta di albero dove ciasciun ramo(percorso) √® una computazione deterministica\n\nora per√≤ date tutte queste istanze, come faccio a definire quale di questi esiti considerare?\nteniamo in considerazione lo stato globale in cui arriviamo a un qa\nl‚Äôimportante √® che ce ne sia almeno 1 senn√≤ significa rigetto\n\n2. Intervento del genio burlone e pasticcione\nIn questo caso colui che sceglie il singolo percorso di stati globali √® un genio\nsceglie quali quintuple eseguire\nQuando questa non rigetta?\nla situazione √® analoga alla macchina super iper ultra parallela\nsolo che adesso ci saranno pi√π geni a scegliere\nDa macchina non deterministica a deterministica\nposso dire che abbiamo una macchina T che simula la macchina NT nelle istanze in cui rigetta oppure accetta, se NT alla fine accetta allora anche T accetta se NT rigetta allora T rigetta\n\nPrima le prova fino al livello 1 se non trova qa oppure tutte che rigettano scende al livello 2\n\nPerch√® lavorare con 1‚Ä¶i livelli di volta in volta?\nperch√© possiamo avere un path che non termina mai e rimanere in un loop senza svolgere quello che termina se lavoriamo su livelli vediamo un po di tutti i percorsi\n"},"UNI/ANNO-2/FONDAMENTI/FONDAMENTI-LEZ.6":{"slug":"UNI/ANNO-2/FONDAMENTI/FONDAMENTI-LEZ.6","filePath":"UNI/ANNO 2/FONDAMENTI/FONDAMENTI LEZ.6.md","title":"FONDAMENTI LEZ.6","links":[],"tags":[],"content":"Cosa √® una macchina di Turing\nT=&lt;\\Sigma,Q,q0,Qf,P&gt;\ncaratterizzata principalmente dagli ultimi 3\nAl livello pi√π teorico possiamo dire che √® la descrizione di un procedimento per risolvere un problema descritto con le quintuple\nDefiniamo una macchina T\nche ha come parola ovvero l‚Äôinput dato i vari stati separati da un - e tutte le varie quintuple una di seguito all‚Äôaltra\nquesta parola in input definisce completamente una macchina T\n\ncon i vari stati e parole\n\nL‚Äôinsieme delle quintuple non √® una funzione totale poich√© manca il caso in cui la lunghezza √® dispari e la parola √® palindroma\nsi possono aggiungere queste quintuple\n„Äàqa1 , ‚óª, ‚óª, qR , F„Äâ,„Äà qb1 , ‚óª, ‚óª, qR , F„Äâ\nma comunque manca il caso in cui una parola √® dispari ma palindroma\nCi torneremo poi\n\n\nMacchina di Turing presa come parola\nquindi possiamo definire una vera e propria macchina di Turing come se fosse una parola completa costituita da\nQ \\cup \\Sigma \\cup \\{-\\} \\cup \\{ \\langle \\} \\cup \\{ \\rangle \\} \\cup \\{ \\square \\}\nfacendo ci√≤ possiamo ottenere una macchina che simula un‚Äôaltra macchina che lavora data la macchina dall‚Äôinput delle parole\nCosa succede se progettassimo una macchina Universale\nU(T,x)\npossiamo fare in modo che o_u(T,x)=o_t(x)\nU cosa deve fare per simulare ci√≤ che fa T?\n\nAl primo nastro metto tutti gli stati e le quintuple di T\nAl secondo l‚Äôinput effettivo\nSul terzo nastro U copia lo stato iniziale di T (primo simbolo di p_t)\nSul quarto nastro U copia lo stato di accettazione di T dopo il primo simbolo dopo il -\n\nN_3 non cambier√† mai\nN_4 contiene lo stato attuale della macchina di T (non U)\n\nU ripeter√† i seguenti passaggi\n\nFase 1) Cerca la quintupla da eseguire\nFase 2) Se abbiamo trovato la quintupla la eseguiamo e torniamo a Fase 1\nFase 3) Se non troviamo la quintupla(lo capiamo se abbiamo\n( \\rangle \\ poi \\square) confronta cos√¨ il terzo nastro con il 4 se sono uguali accetta altrimenti rigetta\n\nPrime due fasi nel dettaglio\nFASE 1\n\nFASE 2\n\nDefinire correttamente l‚Äôalfabeto\n\n\n                  \n                  Problema: \n                  \n                \n\nl‚Äôalfabeto deve essere finito e quindi lo codifichiamo in binario per renderlo finito\n\n\n\n\nOvviamente ci√≤ cambia un po di cose ma solo in termini di lettura tutto qui\novvero verranno lette sequenze di bit e non pi√π lettere dell‚Äôalfabeto\n\n\n                  \n                  e se, putacaso, la parola scritta sul primo nastro di U non corrisponde alla descrizione di una macchina di Turing? \n                  \n                \n\nAbbiamo due possibilit√†:\n\nprima di computare e scrivere il tutto la macchina U controlla se sono state rispettate le specifiche descritte che definiscono una macchina di Turing\nsono cavoli di chi sbaglia\n\n\n\nLa prof alla fine\nalla fine del pdf la prof descrive un metodo con accesso diretto per i nastri con le varie posizioni\nEsercizio lezione di ieri"},"UNI/ANNO-2/FONDAMENTI/FONDAMENTI-LEZ.7":{"slug":"UNI/ANNO-2/FONDAMENTI/FONDAMENTI-LEZ.7","filePath":"UNI/ANNO 2/FONDAMENTI/FONDAMENTI LEZ.7.md","title":"FONDAMENTI LEZ.7","links":[],"tags":[],"content":"Concetto di Linguaggio\nUn linguaggio L √® un insieme di parole x \\in \\Sigma  come {0,1} che hanno una certa propriet√† con i infatti si pu√≤ definire che L ‚äÜ Œ£^*\nPossiamo dire che un linguaggio L √® deciso da una macchina di Turing T se\n\nper ogni x ‚àà L, la computazione T(x) termina in q_A\nper ogni x ‚àâ L, la computazione T(x) termina in q_R\n\nEsempio Linguaggio di una macchina T_{RPPAL}\n\nEbbene, TRPPAL decide il linguaggio LPPAL (Pari e PALindrome) seguente: L_{PPAL} = { x_1x_2‚Ä¶ x_{2n} ‚àà\\{a,b\\}^*: n ‚àà ‚Ñï ‚àß ‚àÄ i ‚àà {1, 2, ... , n} [ x_i = x_{2n-i+1} ] }\nx_{2n} con 2 perch√© indica che l‚Äôultima parola deve essere pari\nIl problema qui √® che con certezza possiamo dire che se x appartiene a L allora termina e termina in q_A\nma, se x non appartiene ad L, non √® detto che T(x) termini in q_R potrebbe anche non terminare\n\nquindi non posso dire con certezza che nella computazione di quella parola essa non appartenga a L\n\nQui vediamo  T_{pal} che nel caso in cui  la parola sia palindroma ma dispari e al centro abbia ‚Äòa‚Äô la macchina non termina e va in loop(vedi la quintupla azzurra)\n\nPossiamo dire che T_{pal1} accetta il linguaggio L_{ppal}\ndove semplicemente se il linguaggio viene riconosciuto esso viene accettato ma se non viene riconosciuto potrebbe andare in rigetto\n\ngrazie alla modifica qui abbiamo un loop che lo rende accettabile e non decidibile\n\nDef 1 Decidibile\n\nDef 2 Accettabili\n\nLa differenza tra le due\nnella prima def abbiamo dato un rigetto se non √® nel linguaggio invece nella def 2 sicuramente non accetta ma non √® certo che rigetti\nse L √® decidibile allora √® anche accettabile ma non il contrario\nLinguaggio complemento L^C\nIl linguaggio complemento ci viene in aiuto quando stiamo lavorando su una macchina che lavora su un insieme \\Sigma definito e che non sa come comportarsi se ci troviamo al di fuori di esso ad esempio una parola in \\Sigma^*-L\ndefiniamo perci√≤\n\nDef 3.1\n\n\n                  \n                   L \\subseteq \\Sigma^* √® decidibile \\iff L √® accettabile \\land L^{C} √® accettabile.\n                  \n                \n\n(\\Rightarrow) Se L √® decidibile allora\n\n\\exists \\ T che decide L\n\\Rightarrow T accetta L ( abbiamo visto che DECIDIBILI \\subseteq ACCETTABILI)\nDobbiamo costruire una T^{C} che accetta L^{C}, e lo facciamo prendendo T e INVERTENDO i suoi stati di accettazione e rigetto\n\nT^{C} = &lt;\\Sigma, \\Omega, \\omega_{0}, {\\omega_{A}, \\omega_{R}}, P^C&gt;_\n\n_\\Omega = {\\omega_{0}, \\omega_{A}, \\omega_{R}, q_{A}, q_{R}}\nFASE 1) dallo stato \\omega_0 simula T(x) (e quindi pu√≤ finire o in q_{A} o in q_{R})\nFASE 2) se o_{T}(x) = q_{A} \\Rightarrow o_{T^{C}}(x) = \\omega_{R} se o_{T}(x) = q_{R} \\Rightarrow o_{T^{C}}(x) = \\omega_{A}\n\n\n\n\n\n(\\Leftarrow) Se L √® accettabile e L^C √® accettabile allora\n\n\nPrendiamo le macchine T che accetta L e T^{C} che accetta L^C.\n\n\nDobbiamo costruire una macchina \\overline{T} che DECIDE L, e per farlo la dotiamo di due nastri e\n\nN1 ‚Üí simula T\nN2 ‚Üí simula T^{C}\nINPUT scritto inizialmente su N1\n\n\n\nINIZIALIZZAZIONE) T copia x su N2\nFASE 1) T simula un‚Äôistruzione (un passo) di T(x) su N1 SE porta in q_{A} \\Rightarrow accetta ALTRIMENTI _fase 2)*\nFASE 2) T simula un‚Äôistruzione di T^{C} su N2 SE porta in q_{R} \\Rightarrow rigetta ALTRIMENTI fase 1)\nVisto che stiamo coprendo entrambi i casi, x \\in L e x \\notin L, allora prima o poi T_{1} o T_{2} accettano e quindi T DECIDE L.\n\n\n                  \n                  Possiamo simulare PRIMA TUTTO UN NASTRO? \n                  \n                \n\nNo, perch√© se un‚Äôistruzione va in loop allora non avremo mai un output.\nRicorda che passiamo da FASE 1 a FASE 2 (e viceversa) SOLO se non otteniamo q_{A} (il loop credo sia consentito se lavoriamo passo-passo).\n\n\nse chiamiamo con D l‚Äôinsieme dei linguaggi decidibile possiamo dire che D sottoinsieme A(linguaggi accettabili)\nESERCIZI\n\nTrasduttori\nI trasduttori ricordiamo che sono quelle macchine di Turing che hanno un solo nastro di output e che terminano in uno stato Q_f vengono usati per svolgere funzioni\nil problema √® quando una funzione non ha soluzioni tipo\nf(n)=\\frac{1}{n-4}\nPer calcolo di funzione intanto definiamo cos√¨ la cosa\nconsiderando funzioni ‚Äùdiscrete‚Äù ‚Äì ossia, dati due alfabeti finiti Œ£1 e Œ£2, noi consideriamo funzioni:\nf : Œ£1* ‚Üí Œ£2^*\n\nossia, funzioni che trasformano parole in altre parole\nvisto che questa funzione con n=4 non si pu√≤ svolgere noi dividiamo le funzioni calcolabili in 2 tipi\n\n\nfunzione classica dove calcoliamo nei punti definiti\nfunzione TOTALE che sono definite per ogni x ‚àà Œ£1*\n\npiccola definizione\n\nT(X)=f(X) si pu√≤ scrivere anche come oT(x)=f(x)\nQui definiamo il caso in cui x √® definita ma come per quanto riguarda i casi in cui non √® accettabile non abbiamo definito il caso in cui bisogna calcolare una x non definita\nfunzione caratteristica\n\ndove quella x in realt√† si chiama \\chi chi\nTeorema 3.2\nbho sta sulle dispense dice che una macchina \\chi_L deve per forza avere un linguaggio L decidibile\nDue alfabeti che mi portano a una incognita risultato\n\nTeorema 3.3\n\nTeorema 3.4\nUna funzione calcolabile √® una funzione che pu√≤ essere calcolata da una macchina di Turing con output (cio√® una macchina che scrive un risultato su un nastro e termina la computazione).\nIn pratica, immaginiamo che la funzione trasformi parole in altre parole. Per esempio:\n\nSe la funzione √®: f(n) = n¬≤, e inseriamo n = 5, il risultato sar√† 25.\nMa se la funzione non √® definita per certi valori (come ‚àön se n √® negativo), allora non possiamo calcolare quel valore.\n\n‚û°Ô∏è Diciamo quindi che una funzione √® calcolabile se esiste una macchina di Turing che, ogni volta che la funzione √® definita, riesce a scrivere il risultato corretto e fermarsi.\nOgni linguaggio (cio√® insieme di parole) pu√≤ essere collegato a una funzione chiamata funzione caratteristica:\n\nQuesta funzione vale 1 se la parola appartiene al linguaggio.\nVale 0 se la parola non appartiene.\n\nüí° Ecco il punto importante:\n\nUna funzione caratteristica √® calcolabile se e solo se il linguaggio √® decidibile.\n\nCosa vuol dire?\nChe possiamo costruire una macchina di Turing capace di dirci sempre s√¨ o no per ogni parola, se questa appartiene al linguaggio.\nAnche per una funzione f(x) possiamo costruire un linguaggio associato che contiene tutte le coppie (x, y) tali che y = f(x).\nQuesto linguaggio √® come il grafico della funzione.\nüìå Se f √® calcolabile e totale (cio√® definita ovunque), allora questo linguaggio √® decidibile.\nCio√® possiamo costruire una macchina che, data una coppia (x, y), sa sempre dirci se y √® il risultato di f(x) oppure no."},"UNI/ANNO-2/FONDAMENTI/FONDAMENTI-LEZ.8":{"slug":"UNI/ANNO-2/FONDAMENTI/FONDAMENTI-LEZ.8","filePath":"UNI/ANNO 2/FONDAMENTI/FONDAMENTI LEZ.8.md","title":"FONDAMENTI LEZ.8","links":[],"tags":[],"content":"Concetto di Biezione\nDati due insiemi A e B, questi hanno |A| = |B| se \\exists \\ biezione \\ \\beta: A \\rightarrow Bossia \\forall a \\in A, \\ \\exists! \\ b \\in B: b= \\beta(a)$$$$\\forall b \\in B, \\ \\exists! \\ a \\in A: a = \\beta(b)\nInfiniti\nCantor ha dimostrato che esistono infiniti pi√π piccoli e infiniti pi√π grandi.\nPer esempio ha dimostrato che |\\mathbb{R}| &gt; |\\mathbb{N}|.\n\nCantor ha dimostrato che non esiste una corrispondenza biunivoca di questo tipo nell‚Äôinsieme {0, 1}.\n\n\n\n                  \n                  I numeri NATURALI sono numerabili; i numeri REALI non sono numerabili.\n                  \n                \n\nProblemi irrisolvibili\nTuring ha dimostrato l‚Äôesistenza di un problema irrisolvibile, usando questo schema:\n\nsi dimostra che le macchine di Turing sono tante quante i numeri naturali\ne, utilizzando questo conteggio, si dimostra che esiste almeno un linguaggio che NON √® deciso da alcuna macchina e quindi esiste almeno un problema che NON pu√≤ essere risolto con una macchina di Turing\n\nquindi esistono pi√π problemi dei numeri reali\n\n\n\nRiprendiamo il concetto di parola codificata\n\n\nVogliamo trasformare tutto questo in un numero, dobbiamo quindi cambiare TUTTI i caratteri non codificati\n\nAbbiamo quindi associato ad una macchina di Turing un numero naturale, e quindi ora ogni macchina di Turing sar√† identificata con un numero differente dalle altre.\nQuindi possiamo chiamare una macchina generica T_{h}e possiamo scrivere T_{h} &lt; T_{k} \\ \\ se \\ \\ h&lt;kIn questo modo avremo una ‚Äúprima‚Äù macchina, una ‚Äúseconda‚Äù macchina e cos√¨ via.\nAllora\n\n\nL‚Äôoutput sono le singole celle con 1 e 0.\nM rappresenta TUTTI i linguaggi ACCETTATI dalle Macchine di Turing\nperch√© tutte le macchine di Turing sono rappresentate in M!\nAd esempio, gli 1 sulla riga uno rappresentano il linguaggio L_{1} accettato da T_{h_{1}}, ossia L_{1} = \\{x_{1}, x_{4}, ...\\}\nPrendiamo ora la diagonale (quella evidenziata in giallo).\nDi per s√® quella √® un linguaggio L.\nOra scriviamo \\overline{L}, ossia il complementare di L e formalmente L = \\{k : T_{h_{k}}(k) \\ non \\ accetta\\}Questo vuol dire che il linguaggio \\overline{L} non √® accettato da NESSUNA macchina di Turing che compare nella matrice e quindi non esiste nessuna T che accetta \\overline{L}.\nQui l‚Äôidea √® quella di prendere la diagonale, e scrivere in \\overline{L} tutte le celle hanno output 0 (quindi nella foto \\overline{L} = \\{x_{2,}...\\}).\nOra, do questo linguaggio a TUTTE le macchine (quindi tento di sovrascrivere \\overline{L} al posto delle singole righe).\nEsiste una riga che √® ESATTAMENTE IDENTICA a \\overline{L}? NO, perch√© almeno un output (quello corrispondente alla diagonale in questo caso) sar√† l‚Äôopposto rispetto alla matrice originale.\nEs. nella matrice originale T_{h_2}(2) NON ACCETTA ma in \\overline{L} T_{h_2}(2) √® accettato: QUESTA COSA √à IMPOSSIBILE.\nQUINDI, \\overline{L} √® un linguaggio NON accettabile.\n\n\n                  \n                   |L| &gt; |T| mentre |L_{a}| = |T|\n                  \n                \n\nQuesto perch√© se esiste un linguaggio accettabile, devo avere per forza una T che lo accetta.\n\n\nE quindi abbiamo dimostrato che esiste un problema che non pu√≤ essere risolto con una macchina di Turing.\nHalting Problem\nTuring consider√≤ il seguente linguaggio:\n\nchiamato Halting Problem.\nTuring dimostr√≤ che L_{h} √® accettabile MA non decidibile.\nil che vuol dire che L_{h}^{c} NON √à ACCETTABILE.\n\n\n                  \n                  TEOREMA: L_{h} √® accettabile\n                  \n                \n\nCostruisco una macchina U&#039; con input (i,x) prendendo la macchina universale U e facendo delle piccole modifiche.\nFASE 1) verifica se i √® la codifica di una macchina di Turing T\nse NO, rigetta\naltrimenti FASE 2\nFASE 2) simula U(i,x)\nse o_{u}(i,x) \\in \\{q_{a}, q_{r}\\} \\Rightarrow ACCETTA\naltrimenti NON LO POSSIAMO SAPERE.\nQuindi U&#039;(i,x) accetta TUTTE E SOLE le coppie (i,x) che appartengono a L_{h} - ossia L_{h} \\ √® \\ accettabile"},"UNI/ANNO-2/FONDAMENTI/FONDAMENTI-LEZ.9":{"slug":"UNI/ANNO-2/FONDAMENTI/FONDAMENTI-LEZ.9","filePath":"UNI/ANNO 2/FONDAMENTI/FONDAMENTI LEZ.9.md","title":"FONDAMENTI LEZ.9","links":[],"tags":[],"content":"Descrizione dell‚Äôhalting problem\n\nDimostrazione per assurdo TEOREMA 5.5\nmettiamo per assurdo che L_H √® decidibile ricordiamo che per essere decidibile esiste una macchina T per cui per ogni (i,x) la macchina:\n\nT(i,x) accetta se (i,x) ‚àà LH\nT(i,x) rigetta se (i,x) ‚àâ LH\n\nCreazione di una macchina T&#039; che sarebbe il complementare\n\nT‚Äô(i,x) accetta se (i,x) ‚àâ LH\nT‚Äô(i,x) rigetta se (i,x) ‚àà LH\nT&#039; viene creata a scatola chiusa perch√© semplicemente prende l‚Äôoutput di T e lo cambia\n\nCreazione macchina T&#039;&#039;\n\nCreiamo una macchina che sostanzialmente accetta il linguaggio ma non lo decide\nIn teoria dovrebbe funzionare anche con la diagonale\n\nCreazione macchina T^*\nCreiamo una macchina T*(i) che lavora con un solo input in modo che il risultato sia uguale a T&#039;&#039;(i,i)\nOssia, se i √® la codifica di una macchina di Turing, allora\n\nT*( i ) accetta se ( i, i ) ‚àâ LH , ossia se Ti ( i ) non termina\nT*( i ) non termina se ( i, i ) ‚àà LH , ossia se Ti ( i ) termina\ntanto con solo i era la stessa cosa\n\nCreiamo T_k che √® uguale a T* ma\n√® la macchina con una codifica k della macchina T^* (trasformiamo tutti gli stati e le quintuple in interi)\nabbiamo quindi che T_k=T^*\nNocciolo della questione\nVisto che T_k √® una macchina vera e propria possiamo dargli un input k e quindi avremo T_k(k)\nFacciamo chiarezza passo per passo.\n\n1. Cos‚Äô√® T?*\nT* √® una macchina di Turing costruita nel corso della dimostrazione, tale che:\n\n\nprende un intero i come input,\n\n\ne fa la stessa computazione che farebbe T&#039;&#039;(i, i) (cio√® una macchina che si comporta diversamente se (i, i) ‚àà LH o no).\n\n\nIn simboli:\n\nT(i)* = risultato della computazione di T‚Äù(i, i)\n\n\n2. Cos‚Äô√® k?\nk √® il codice (cio√® l‚Äôindice numerico) della macchina T*.\nVisto che ogni macchina di Turing pu√≤ essere codificata con un numero, allora anche T* pu√≤ ‚Äî e il numero che la rappresenta √® k.\nQuindi:\n\nT* = T‚Çñ\n(cio√® la macchina con codice k √® proprio la macchina T*)\n\n\n3. T(k) = T‚Çñ(k)*\nQui si arriva al paradosso!\nPoich√© T* = T‚Çñ, allora fare la computazione T(k)* (cio√® dare k come input alla macchina T*)\n√® la stessa cosa che fare la computazione T‚Çñ(k)\n(la macchina numero k, che si chiama T*, riceve il suo stesso codice k come input).\n\nüìâ E cosa succede quando fai T‚Çñ(k)?\nLa macchina si interroga su se stessa.\nProprio come una persona che si chiede: ‚ÄúNon mi fido di me stesso‚Ä¶ ma posso fidarmi di questa affermazione?‚Äù üòµ‚Äçüí´\nE questo porta al paradosso:\n\n\nSe T‚Çñ(k) accetta, allora significa che non dovrebbe accettare (perch√© dovrebbe accettare solo se non termina),\n\n\nSe T‚Çñ(k) non termina, allora significa che dovrebbe terminare (perch√© dovrebbe non terminare solo se termina).\n\n\nE quindi‚Ä¶ ‚ùå Contraddizione!\nCos√¨ facendo abbiamo visto che esiste un caso in cui non √® decidibile e quindi L_H non √® decidibile\nSIMULARE A SCATOLA CHIUSA\nSostanzialmente posso sempre modificare l‚Äôinput per facilitare le cose senza fare scatola aperta\nse ho una macchina che vuole vedere Palindromia per 1 e 2 posso sfruttare quella di ab semplicemente mettendo che una volta ricevuto l‚Äôinput ab esso viene modificato in 12 direttamente sul nastro\n\nRIDUZIONI MANY-to-ONE\nAbbiamo progettato una funzione f : \\{1,2\\}^* ‚Üí \\{a,b\\}^* tale che\n1) f √® totale e calcolabile ‚Äì ossia:\n‚ñ™ √® definita per ogni parola x ‚àà {1,2}* e, inoltre,\n‚ñ™ esiste una macchina di Turing di tipo trasduttore T_f tale che, per ogni parola x ‚àà {1,2}*,\nla computazione T_f(x) termina con la parola f(x) ‚àà {a,b} scritta sul nastro di output.\n\n2) Per ogni x ‚àà {1,2}* vale che:\nx ‚àà L_P12 se e solo se f(x) ‚àà L_PPAL\n‚ñ™ che in matematichese si scrive:\n‚àÄ x ‚àà {1,2}* [ x ‚àà L_{P12} ‚ü∑ f(x) ‚àà L_{PPAL} ]\n\nüî∏ La funzione f si chiama riduzione da L_{P12} a L_{PPAL}.\nüî∏ E si dice che L_{P12} √® riducibile a L_{PPAL} e si scrive:  L_{P12} ‚âº L_{PPAL}\nGeneralizzazione della riducibilit√†\n\nCome possiamo sfruttarla\npossiamo sfruttare la cosa della riduzione per dire che un linguaggio √® decidibile o accettabile basta solo dimostrare la riducibilit√† tra due linguaggi\npoi dice che due linguaggi hanno praticamente stesso input e stesso output solo con indici diversi\n\n\n\n"},"UNI/ANNO-2/LINGUAGGI/ESERCITAZIONE-1":{"slug":"UNI/ANNO-2/LINGUAGGI/ESERCITAZIONE-1","filePath":"UNI/ANNO 2/LINGUAGGI/ESERCITAZIONE 1.md","title":"ESERCITAZIONE 1","links":[],"tags":[],"content":"La seguente esercitazione √® suddivisa in diverse sezioni in package\nTUTTO FUORI DAL PACKAGE IL MAIN\n//TIP To &lt;b&gt;Run&lt;/b&gt; code, press &lt;shortcut actionId=&quot;Run&quot;/&gt; or\n// click the &lt;icon src=&quot;AllIcons.Actions.Execute&quot;/&gt; icon in the gutter.\npublic class Main {\n    public static void main(String[] args) {\n        //TIP Press &lt;shortcut actionId=&quot;ShowIntentionActions&quot;/&gt; with your caret at the highlighted text\n        // to see how IntelliJ IDEA suggests fixing it.\n        System.out.printf(&quot;Hello and welcome!&quot;);\n \n        for (int i = 1; i &lt;= 5; i++) {\n            //TIP Press &lt;shortcut actionId=&quot;Debug&quot;/&gt; to start debugging your code. We have set one &lt;icon src=&quot;AllIcons.Debugger.Db_set_breakpoint&quot;/&gt; breakpoint\n            // for you, but you can always add more by pressing &lt;shortcut actionId=&quot;ToggleLineBreakpoint&quot;/&gt;.\n            System.out.println(&quot;i = &quot; + i);\n        }\n    }\n}\nPACKAGE: it.uniroma2.lmp.lmp0\nabbiamo test.java\npackage it.uniroma2.lmp.lmp0;\n \nimport it.uniroma2.lmp.lmp0.model.*;\n \npublic class Test {\n \n    public static void main(String[] args) {\n \n        Persona franco = new PersonaImpl(&quot;Franco&quot;, &quot;Bellucci&quot;, &quot;xyz02&quot;);\n \n        System.out.println(&quot;Abbiamo appena creato: &quot; + franco);\n \n        franco.saluta();\n \n \n        Professore professore = new ProfessoreImpl(&quot;Armando&quot;, &quot;Stellato&quot;, &quot;1234&quot;, &quot;Knowledge Engineering&quot;);\n \n        Universita torVergata = new Universita();\n \n \n        Studente stud1 = null;\n        Studente stud2 = null;\n        Studente stud3 = null;\n        try {\n            stud1 = torVergata.iscriviStudente(&quot;Mario&quot; , &quot;Rossi&quot;, &quot;mrrs&quot;, CorsoDiStudi.INFORMATICA, 3);\n            stud2 = torVergata.iscriviStudente(&quot;Luigi&quot; , &quot;Bianchi&quot;, &quot;mr8e&quot;, CorsoDiStudi.INFORMATICA, 1);\n            stud3 = torVergata.iscriviStudente(&quot;Marco&quot; , &quot;Neri&quot;, &quot;rts&quot;, CorsoDiStudi.PSICOLOGIA, 7);\n        } catch (Exception e) {\n            System.err.println(&quot;C&#039;√® stato un problema di iscrizione: &quot; + e.getMessage());\n        }\n        System.out.println(stud1 + &quot;\\n&quot; + stud2 + &quot;\\n&quot; + stud3);\n        Professore x = null;\n        stud1.saluta(x);\n    }\n \n}\nit.uniroma2.lmpl.mp0.model\nABBIAMO 11 FILE\nAnnoCorsoException\npackage it.uniroma2.lmp.lmp0.model;\n \npublic class AnnoCorsoException extends Exception {\n    public AnnoCorsoException(int annoCorso) {\n        super(&quot;L&#039;anno &quot; + annoCorso + &quot; √® fuori dai limiti ammessi da questa universit√†&quot;);\n    }\n}\n \nCorsoDiStudi\npackage it.uniroma2.lmp.lmp0.model;\n \npublic enum CorsoDiStudi {\n    INFORMATICA, PSICOLOGIA, LETTERE;\n}\n \nPersona\npackage it.uniroma2.lmp.lmp0.model;\n \npublic interface Persona {\n    //Normalm. si pensa prima all&#039;interf. e poi alla classe\n \n    //In questo caso e&#039; piu&#039; utile un getter invece del setter\n    String getNome();\n \n    String getCognome();\n \n    String getCodiceFiscale();\n \n    void saluta();\n \n}\n \nPersonaImpl\npackage it.uniroma2.lmp.lmp0.model;\n \n//Tra classi e interfacce si usa &quot;implements&quot;, mentre tra classi/classi o\n//interfacce/interfacce si usa &quot;extends&quot;\n \npublic class PersonaImpl implements Persona {\n    String nome;\n    String cognome;\n    String codiceFiscale;\n    /** &lt;-- commento per doc (es. javadoc)\n     * @param nome nome &lt;em&gt;persona&lt;/em&gt;\n     * @param cognome &lt;-- i param sono dei tag\n     * @param codiceFiscale\n     */\n    public PersonaImpl(String nome, String cognome, String codiceFiscale) {\n        this.nome = nome;\n        this.cognome = cognome;\n        this.codiceFiscale = codiceFiscale;\n    }\n \n    //In questo caso e&#039; piu&#039; utile un getter invece del setter\n    @Override\n    public String getNome() {\n        return nome;\n    }\n    @Override\n    public String getCognome() {\n        return cognome;\n    }\n    @Override\n    public String getCodiceFiscale() {\n        return codiceFiscale;\n    }\n \n \n    public void saluta() {\n        System.out.println(&quot;Salve a tutti!&quot;);\n    }\n \n    @Override\n    public String toString() {\n        return nome + &quot; &quot; + cognome + &quot;: &quot; + codiceFiscale;\n    }\n}\n \nProfessore\n/**\n *\n */\npackage it.uniroma2.lmp.lmp0.model;\n \n/**\n *\n */\npublic interface Professore extends Persona {\n \n    //per scontato anche i metodi son tutti public\n    String getCattedra();\n \n    void setCattedra(String cattedra);\n}\n \nProfessoreImpl\n/**\n *\n */\npackage it.uniroma2.lmp.lmp0.model;\n \n/**\n *\n */\npublic class ProfessoreImpl extends PersonaImpl implements Professore {\n \n    String cattedra;\n \n    /**\n     * @param nome\n     * @param cognome\n     * @param codiceFiscale\n     * @param cattedra\n     */\n \n    public ProfessoreImpl(String nome, String cognome, String codiceFiscale, String cattedra) {\n        super(nome, cognome, codiceFiscale);\n        this.cattedra = cattedra; //e&#039; cio&#039; che fa setCattedra\n    }\n \n    @Override\n    public String getCattedra() {\n        return this.cattedra; //e&#039; meglio this.cattedra\n    }\n \n    @Override\n    public void setCattedra(String cattedra) {\n        this.cattedra = cattedra;\n    }\n \n}\n \nProfessoreNonPresenteException\npackage it.uniroma2.lmp.lmp0.model;\n \npublic class ProfessoreNonPresenteException extends RuntimeException {\n    public ProfessoreNonPresenteException() {\n        super(&quot;Il professore √® assente (null) e non pu√≤ essere salutato&quot;);\n    }\n}\n \nStudente\n/**\n *\n */\npackage it.uniroma2.lmp.lmp0.model;\n \n/**\n *\n */\npublic interface Studente extends Persona {\n \n    String getMatricola();\n \n    void saluta(Professore professore);\n \n}\n \nStudenteCDS\npackage it.uniroma2.lmp.lmp0.model;\n \npublic class StudenteCDS extends StudenteImpl implements Studente {\n \n    CorsoDiStudi CDS;\n    int annoCorso;\n \n    StudenteCDS(String nome, String cognome, String codiceFiscale, CorsoDiStudi CDS, int annoCorso) {\n        super(nome, cognome, codiceFiscale, CDS.toString() + numStudenti);\n        this.CDS = CDS;\n        this.annoCorso = annoCorso;\n \n    }\n \n    StudenteCDS(Persona persona, CorsoDiStudi CDS, int annoCorso) {\n \n        this(persona.getNome(), persona.getCognome(), persona.getCodiceFiscale(), CDS, annoCorso);\n        //invoco il costruttore &quot;principale&quot;\n    }\n \n \n}\n \nStudenteImpl\npackage it.uniroma2.lmp.lmp0.model;\n \npublic class StudenteImpl extends PersonaImpl implements Studente {\n    static int numStudenti;\n    String matricola;\n \n    protected StudenteImpl(String nome, String cognome, String codiceFiscale, String matricola) {\n        super(nome, cognome, codiceFiscale);\n        numStudenti++;\n        this.matricola = matricola;\n \n    }\n \n    protected StudenteImpl(Persona persona, String matricola) {\n        this(persona.getNome(), persona.getCognome(), persona.getCodiceFiscale(), matricola);\n        //invoco il costruttore &quot;principale&quot;\n    }\n \n    @Override\n    public String getMatricola() {\n        return this.matricola;\n    }\n \n \n    @Override\n    public void saluta(Professore professore) {\n        if( professore == null) throw new ProfessoreNonPresenteException();\n        System.out.println(&quot;Salve prof. &quot; + professore.getCognome());\n \n    }\n \n    @Override\n    public String toString() {\n        return super.toString() + &quot; &quot; + matricola;\n    }\n}\n \nUniversita\npackage it.uniroma2.lmp.lmp0.model;\n \npublic class Universita {\n \n    public Studente iscriviStudente(String nome, String cognome, String codiceFiscale, CorsoDiStudi CDS, int annoCorso) throws AnnoCorsoException{\n        if (annoCorso &gt; 5){\n            throw new AnnoCorsoException(annoCorso);\n        }\n        return new StudenteCDS(nome, cognome, codiceFiscale, CDS, annoCorso);\n    }\n}\n "},"UNI/ANNO-2/LINGUAGGI/ESERCIZI-DI-GPT":{"slug":"UNI/ANNO-2/LINGUAGGI/ESERCIZI-DI-GPT","filePath":"UNI/ANNO 2/LINGUAGGI/ESERCIZI DI GPT.md","title":"ESERCIZI DI GPT","links":[],"tags":[],"content":"ES 1\nConsegna:\n\n\nCreare un‚Äôinterfaccia chiamata StudenteI:\n\n\nDeve estendere un‚Äôaltra interfaccia esistente chiamata PersonaI.\n\n\nDichiarare un metodo aggiuntivo:\npublic String getCorsoDiStudi();\n\n\n\n\nCreare una classe concreta chiamata Studente:\n\nLa classe deve implementare l‚Äôinterfaccia StudenteI.\nDeve avere i seguenti campi:\n\nString nome: il nome dello studente.\nString cognome: il cognome dello studente.\nString codicefiscale: il codice fiscale dello studente.\nint piedi: un campo qualsiasi per simulare l‚Äôesempio (es. altezza in piedi).\nString corsoDiStudi: il corso di studi dello studente.\n\n\nImplementare un costruttore che accetta tutti i campi come parametri.\nImplementare i metodi richiesti dalle interfacce (PersonaI e StudenteI).\nSovrascrivere il metodo toString() per restituire una descrizione leggibile dello studente.\nImplementare il metodo saluta(), che stampa un messaggio personalizzato, ad esempio: ‚ÄúCiao a tutti, sono uno studente di [corso di studi]!‚Äù.\n\n\n\nScrivere un programma di test:\n\nCreare un file di test chiamato Test.\nNel metodo main, creare un oggetto di tipo Studente e inizializzarlo con valori significativi.\nStampare l‚Äôoggetto utilizzando il metodo toString() e verificare il suo contenuto.\nChiamare il metodo saluta() dell‚Äôoggetto.\n\n\n\nCosa consegnare:\n\nIl codice sorgente dell‚Äôinterfaccia StudenteI.\nIl codice sorgente della classe Studente.\nIl file di test con il main.\n"},"UNI/ANNO-2/LINGUAGGI/LINGUAGGI-INDICE":{"slug":"UNI/ANNO-2/LINGUAGGI/LINGUAGGI-INDICE","filePath":"UNI/ANNO 2/LINGUAGGI/LINGUAGGI INDICE.md","title":"LINGUAGGI INDICE","links":["UNI/ANNO-2/LINGUAGGI/LINGUAGGI-LEZ.1+2","UNI/ANNO-2/LINGUAGGI/LINGUAGGI-LEZ.3","UNI/ANNO-2/LINGUAGGI/LINGUAGGI-LEZ.4","UNI/ANNO-2/LINGUAGGI/LINGUAGGI-LEZ.5","UNI/ANNO-2/LINGUAGGI/LINGUAGGI-LEZ.6+7","UNI/ANNO-2/LINGUAGGI/LINGUAGGI-LEZ.8","UNI/ANNO-2/LINGUAGGI/LINGUAGGI-LEZ.9","UNI/ANNO-2/LINGUAGGI/LINGUAGGI-LEZ.10","UNI/ANNO-2/LINGUAGGI/LINGUAGGI-LEZ.11","UNI/ANNO-2/LINGUAGGI/LINGUAGGI-LEZ.12","UNI/ANNO-2/LINGUAGGI/LINGUAGGI-LEZ.13","UNI/ANNO-2/LINGUAGGI/LINGUAGGI-LEZ.14","UNI/ANNO-2/LINGUAGGI/PROLOG/PROLOG-LEZ.1","UNI/ANNO-2/LINGUAGGI/PROLOG/PROLOG-LEZ.2","UNI/ANNO-2/LINGUAGGI/PROLOG/PROLOG-LEZ.3"],"tags":[],"content":"sito prof\nLEZIONI JAVA\nLINGUAGGI LEZ.1+2\nLINGUAGGI LEZ.3\nLINGUAGGI LEZ.4\nLINGUAGGI LEZ.5\nLINGUAGGI LEZ.6+7\nLINGUAGGI LEZ.8\nLINGUAGGI LEZ.9\nLINGUAGGI LEZ.10\nLINGUAGGI LEZ.11\nLINGUAGGI LEZ.12\nLINGUAGGI LEZ.13\nLINGUAGGI LEZ.14\nLEZIONI PROLOG\nPROLOG LEZ.1\nPROLOG LEZ.2\nPROLOG LEZ.3"},"UNI/ANNO-2/LINGUAGGI/LINGUAGGI-LEZ.1+2":{"slug":"UNI/ANNO-2/LINGUAGGI/LINGUAGGI-LEZ.1+2","filePath":"UNI/ANNO 2/LINGUAGGI/LINGUAGGI LEZ.1+2.md","title":"LINGUAGGI LEZ.1+2","links":[],"tags":[],"content":"TIPI DI PROGRAMMAZIONE\nNEGLI ANNI 60\n\nastrazione di memoria per variabili ecc‚Ä¶\npresenza di operazioni con flusso\n\nsalto incondizionato GOTO per definire le decisioni di algoritmo\n\n\nfine anni 60 revisione con programmazione strutturata e Jacopini B√∂hm\n\nProgrammazione procedurale\nUtilizzo di blocchi di codice identificati con nomi come:\n\nsubroutine: programmi per intero che possiamo eseguire pi√π volte\nprocedure: blocchi di istruzioni con parametri senza ritorno modificando variabili ‚Äúglobali‚Äù\nfunzioni: procedure ma meglio con ritorno di variabili\nmetodi: fanno parte della object oriented\n\nPROGRAMMAZIONE A OGGETTI\nCon la programmazione a oggetti ci si avvicina al pensiero umano rendendo il codice pi√π intuitivo.\n\nCi consente di separare il codice in oggetti ovvero creare elementi del nostro software che hanno il loro ciclo di vita e che possono essere creati e distrutti, un oggetto pu√≤ essere di una singola tipologia\nUna famiglia di oggetti si chiama classe e indica un nuovo tipo di dato\nPermette di suddividere i lavori tra vari programmatori\n\nPRINCIPI FONDAMENTALI\n\nINCAPSULAMENTO\n\nincapsulare il codice dividendo i problemi in pi√π parti. Facendo cos√¨ alcuni aspetti implementativi non sono visibili da alcuni utilizzatori del codice\n(non significa che il codice sia pi√π sicuro semplicemente √® pi√π  leggibile per chi non deve modificare determinate parti)\naccessors: metodi che ti permettono di leggere delle informazioni private di una classe(get)\nmutators: metodi che ti permettono di modificare una parte della classe(set)\n\n\nASTRAZIONE\n\nprogrammi sfruttando gli oggetti e le classi senza interagire con cosa sono veramente quindi in modo astratto semplificando il codice\n\n\nEREDITARIET√Ä\n\nL‚Äôereditariet√† consente di ridurre le ridondanze con sotto-gruppi che ereditano le caratteristiche del gruppo principale\n\n\nPOLIMORFISMO\n\n\nIl polimorfismo √® la capacit√† di un linguaggio di programmazione di gestire in modo uniforme oggetti o funzioni che in realt√† possono avere comportamenti diversi. In altre parole, uno stesso ‚Äúnome‚Äù (un metodo o una funzione) pu√≤ assumere forme differenti a seconda del contesto.\n\nLinguaggi tipizzati\n\n\nUn linguaggio pu√≤ essere debolmente tipizzato (o ‚Äúipizzato‚Äù come avevi scritto, nel senso di pi√π generico), cio√® i tipi sono usati in modo meno rigoroso e possono anche essere convertiti implicitamente.\n\n\nUn linguaggio fortemente tipizzato invece ha un sistema di type checking: ogni variabile o funzione appartiene a un tipo preciso e ci sono regole rigide per l‚Äôuso e la compatibilit√† dei tipi.\n\n\nNei linguaggi orientati agli oggetti (come Java, C++, C#, ecc.), quasi sempre si usa un controllo dei tipi statico (in compilazione), che permette anche di gestire il polimorfismo in modo sicuro.\n\n\nPolimorfismo nelle classi\n\n\nImmagina una classe base (ad esempio Animale) e pi√π classi derivate (Cane, Gatto).\n\n\nTutte queste classi possono avere un metodo con lo stesso nome, ad esempio verso(), ma ciascuna implementa il metodo in modo diverso.\n\n\nSe io scrivo animale.verso(), il risultato dipender√† dal tipo effettivo dell‚Äôoggetto (se √® un cane abbaier√†, se √® un gatto miagoler√†).\n\n\nQuesto √® il cuore del polimorfismo ad oggetti.\n\n"},"UNI/ANNO-2/LINGUAGGI/LINGUAGGI-LEZ.10":{"slug":"UNI/ANNO-2/LINGUAGGI/LINGUAGGI-LEZ.10","filePath":"UNI/ANNO 2/LINGUAGGI/LINGUAGGI LEZ.10.md","title":"LINGUAGGI LEZ.10","links":["UNI/ANNO-2/LINGUAGGI/LINGUAGGI-LEZ.6+7"],"tags":[],"content":"\n\n                  \n                  factory \n                  \n                \n\nindica una classe che avr√† un oggetto, questo oggetto ha il compito di creare altri oggetti attraverso i suoi metodi\nesempio di codice:\n// Interfacce per i prodotti\ninterface Button {\n    void paint();\n}\n \ninterface Checkbox {\n    void paint();\n}\n \n// Implementazioni concrete dei prodotti\nclass WindowsButton implements Button {\n    public void paint() {\n        System.out.println(&quot;Rendering a Windows Button&quot;);\n    }\n}\n \nclass WindowsCheckbox implements Checkbox {\n    public void paint() {\n        System.out.println(&quot;Rendering a Windows Checkbox&quot;);\n    }\n}\n \n \n// Abstract Factory\ninterface GUIFactory {\n    Button createButton();\n    Checkbox createCheckbox();\n}\n \n// Concrete Factory\nclass WindowsFactory implements GUIFactory {\n    public Button createButton() {\n        return new WindowsButton();\n    }\n \n    public Checkbox createCheckbox() {\n        return new WindowsCheckbox();\n    }\n}\n \n// Uso dell&#039;Abstract Factory\npublic class Main {\n    public static void main(String[] args) {\n        GUIFactory factory = new WindowsFactory();\n \n        Button button = factory.createButton();\n        Checkbox checkbox = factory.createCheckbox();\n \n        button.paint();\n        checkbox.paint();\n    }\n}\n\n\nLe annotazioni\n\n\n                  \n                  definizione \n                  \n                \n\nSono dei tag che ci consentono di ‚Äúmetaprogrammare‚Äù collegabili a qualsiasi cosa all‚Äôinterno del nostro codice, semplicemente devi mettere @annotazione sopra una classe, un metodo o quello che vuoi\n\n\n\nservono al compilatore tipo override che gli indica di sovrascrivere un metodo\nservono per ‚Äúchi viene dopo‚Äù e capire eventuali informazioni extra\n\n\n\n                  \n                  cosa si intende per metaprogrammazione \n                  \n                \n\nla programmazione che include metadati, ovvero informazioni aggiuntive ai dati stessi\n\n\nCARATTERISTICHE DELLE ANNOTAZIONI\nposso aggiungere dei campi a una annotazione\n\nposso fare annotazioni multiple\n\nposso ripetere le stesse annotazioni(da mettere in un contenitore repeatable)\n\nCome creare una annotazione\n\ncreo il tipo di annotazione e ci√≤ che devo contenere poi la applico ad una classe\n\nANNOTAZIONI PREDEFINITE IN JAVA\n1.@DEPRECATED\nSe lo mettiamo su un metodo indica che quest‚Äôultimo √® in disuso e quando verr√† eseguito il codice verr√† mandato un warning dal compilatore\nesempio di cobolzongz\n\n2.@OVERRIDE\nviene usato per indicare che un metodo interno a una classe sovrascrive un altro metodo\n\n3.@SUPPRESSWARNINGS\nServe per sopprimere eventuali warning da parte del compilatore, bisogna specificare la categoria del warning es:\n\ndeprecated: indica warning di tipo deprecated\nunchecked: warning generici\n\n\nESEMPIO FATTO BENE\n\n\n4.@SAFEVARARGS\nse non ti ricordi varargs\nQuando viene utilizzato questo tipo di annotazione, gli avvisi non controllati relativi all‚Äôutilizzo¬†varargs¬†vengono soppressi.\nANNOTAZIONI CHE SI APPLICANO AD ALTRE ANNOTAZIONI\nda cui nasce il termine meta annotazioni\n\nsono definite nel pacchetto¬†java.lang.annotation\n\nESEMPI:\n1.@RETENTION\nSpecifica come una determinata annotazione viene salvata in memoria:\nquesti sono i 3 casi:\n\n2.@DOCUMENTED\nindica che la tua annotazione deve essere documentata con lo strumento JavaDoc\n3.@TARGET\nspecifica la tua annotazione dove pu√≤ essere messa es: solo sui metodi, solo sui package‚Ä¶\n\n4.@INHERITED\nIndica che un‚Äôannotazione applicata a una classe √® ereditata dalle sottoclassi,¬†funziona solo per annotazioni applicate alle classi\n5.@REPEATABLE\nServe per creare il contenitore delle varie annotazioni ripetute\nLe type annotations\nle type annotations servono per annotare determinate cose sui dati per migliorare la programmazione in java.\nSe ad esempio voglio che una variabile String non assuma mai null creo un plug-in che mi controlla il NullPointerException, ovvero il gestore di quando ho un null\ne faccio in modo di attaccare questo plug-in con una annotazione alla variabile\n\nAnnotazioni Ripetibili\n\nsono real-time\nservono per fare azioni ripetibili\ntipo :\n\n1.@SCHEDULE\nServe per eseguire un metodo in momenti diversi\n\n2.@Alert\nUsato ad esempio per definire ruoli\n\nCOME SI IMPLEMENTANO QUESTI REPEATABLE?\nUtilizzo il @Repeatable cos√¨ da specificare che la struttura che sto creando per le annotazioni pu√≤ essere ripetuta.\nmi creo il contenitore per inserire l‚Äôoggetto schedule\n\n\nReflection API\nreflection gestisce le ripetizioni prendendo i contenitore e lo gestisce"},"UNI/ANNO-2/LINGUAGGI/LINGUAGGI-LEZ.11":{"slug":"UNI/ANNO-2/LINGUAGGI/LINGUAGGI-LEZ.11","filePath":"UNI/ANNO 2/LINGUAGGI/LINGUAGGI LEZ.11.md","title":"LINGUAGGI LEZ.11","links":[],"tags":[],"content":"Dettagli ulteriori sulle interfacce\nnell‚Äôinterfaccia vanno pure le costanti\nnon serve specificare public static final perch√© √® scontato che si stia parlando di costanti\npublic interface DoIt {\n   String const=&quot;ciao&quot;;\n   void doSomething(int i, double x);\n   int doSomethingElse(String s);\n}\nSignificato di Signature\nper signature si intende la firma di un metodo che si trova in una classe o interfaccia\ne indica:\n\nil nome del metodo\nl‚Äôordine e il tipo dei parametri del metodo\nviene usato tipo per l‚Äôoverloading per differenziare i metodi\n\n\n\n                  \n                  le interfacce servono per fornire un vocabolario unificante o un contratto che le classi devono rispettare. Fornendo delle sorta di api che qualcuno potr√† utilizzare senza andare a leggere i dettagli implementativi \n                  \n                \n\nrelatable\n√à un concetto che indica la possibilit√† di comparare due oggetti tra loro secondo delle caratteristiche\nconcetto di dato derivato\nQuando tu fai un metodo lo ritorni facendo una formula di altri dati effettivi\n public int getArea() {\n        return width * height;\n    }\nProblema delle interfacce\n\n\n                  \n                  se ho una interfaccia implementata da 1000 classi e la aggiorno, il problema √® che poi devo implementare quel metodo in ogni classe: \n                  \n                \n\n\nsoluzione 1, estendo l‚Äôinterfaccia cosi non rompo il cazzo agli altri\nsoluzione 2 ma di merda, creo un metodo di default che vale per tutte le classi che implementano l‚Äôinterfaccia ma che non sono costretti ad utilizzare\n\n \npublic interface DoIt {\n \n   void doSomething(int i, double x);\n   int doSomethingElse(String s);\n   default boolean didItWork(int i, double x, String s) {\n       // il corpo del metodo\n   }\n   \n}\n\n\n                  \n                  perch√© fa cagare? \n                  \n                \n\nperch√© toglie tutto il concetto di generalizzazione delle interfacce e dovresti fare un override del metodo, √® una non soluzione\n\n\n\n\n                  \n                  una serie di metodi della classe Object √® che sono ereditati da tutti \n                  \n                \n"},"UNI/ANNO-2/LINGUAGGI/LINGUAGGI-LEZ.12":{"slug":"UNI/ANNO-2/LINGUAGGI/LINGUAGGI-LEZ.12","filePath":"UNI/ANNO 2/LINGUAGGI/LINGUAGGI LEZ.12.md","title":"LINGUAGGI LEZ.12","links":[],"tags":[],"content":"DEFINIRE CLASSI ASTRATTE DI METODI ASTRATTI\n\n\n                  \n                  perch√© fare abstract class e non normali? \n                  \n                \n\nun metodo abstract indica un metodo incompleto che ipoteticamente √® previsto nell‚Äôinterfaccia\n\n\nse fai un metodo abstract dichiari la classe abstract\n\nSottoclasse concreta: √à obbligata a implementare tutti i metodi astratti definiti sia nella classe base sia di una ipotetica sottoclasse astratta.\nTutte le cose statiche su una classe abstract funzionano come in una normale classe\n\npublic abstract class GraphicObject {\n   // declare fields\n   // declare nonabstract methods\n   abstract void draw();\n}\npublic class Circle extends GraphicObject { \n\t@Override void draw() \n\t\t{ \n\t\tSystem.out.println(&quot;Drawing a circle&quot;); \n\t\t} \n}\nLe eccezioni\n\n\n                  \n                  in c non esiste un metodo per gestire gli errori bensi verranno ritornati valori negativi che appartengono a qualcosa, quindi -1 leggi sul manuale -3 leggi ecc... \n                  \n                \n\nLe chiamiamo eccezioni perch√© indicano un evento che avviene al di fuori del solito flusso di istruzioni del programma\n\n\nquando chiamiamo un metodo avviamo un call stack\n\nrappresenta le varie chiamate scendendo sempre pi√π a basso livello\nquindi effettuo delle chiamate cos√¨ main‚Üím1‚Üím2‚Üím3\npoi per le restituzioni di controllo a chi mi ha chiamate m3‚Üím2‚Üím1‚Üímain\n\n\nimmaginiamo che durante una chiamata succede qualcosaü§öüõë\ntipo m3 ha un errore, potrebbe risolverlo oppure potrebbe farla risalire al chiamante\ncome se fosse una bolla, quello che vedremo e impacchettare la bolla e portarla su\n\npublic class ExceptionExample {\n    public static void main(String[] args) {\n        method1(); // Chiamata al metodo 1\n    }\n \n    static void method1() {\n        try {\n            method2(); // Chiamata al metodo 2\n        } catch (ArithmeticException e) {\n            System.out.println(&quot;Gestito in method1: &quot; + e.getMessage());\n        }\n    }\n \n    static void method2() {\n        method3(); // Chiamata al metodo 3\n    }\n \n    static void method3() {\n        int result = 10 / 0; // Questo genera un&#039;eccezione\n    }\n}\n\n\n                  \n                  Quando avviene una exception \n                  \n                \n\nil sistema runtime cerca un metodo all‚Äôinterno del call stack per gestire questa eccezione\n\nquesto metodo viene detto gestore delle eccezioni\nviene prima ricercato nel metodo che la causa e poi a ritroso sale ai vari chiamanti\nquando viene trovato questo gestore viene passato l‚Äôoggetto eccezione e verr√† gestito\nle eccezioni SONO OGGETTI!!!!\nse non viene trovato un gestore viene terminato il programma\n\n\n\nGercarchia delle eccezioni\nAd esempio ho le I/O exception che gestiscono gli errori di input e output ma in modo generico\npotrebbe esserci invece una sotto classe FileNotFoundException che √® un sotto errore della I/O,\n\nposso quindi scegliere se gestire eccezioni generiche oppure cose meno generiche\n\nTRE TIPI DI EXCEPTION\n\nchecked exception, Vengono controllate in compile time, e queste eccezioni possono essere gestite proprio nel codice con\n\nblocchi try catch\nthrow\n\n\nunchecked exception si dividono in:\n\nruntime exception tipo: nullpointer exception oppure segmentation fault\n\nper gestirle non serve usare try catch o throw\nvengono lanciate direttamente da metodi appartenenti alle classi predefinite.\n\n\nerror non sono eccezioni bens√¨ sono errori di basso livello terribile e rarissimo\n\ntipo errori hardware tipo dove ti finisce la memoria\n\n\n\n\n\nVediamo ora i metodi per gestire le eccezioni\nTry-Catch\nCon Checked Exception (IOException)\nProviamo a gestire un file che non pu√≤ essere aperto.\nimport java.io.*;\n \npublic class CheckedExceptionExample {\n    public static void main(String[] args) {\n        try {\n            // Prova ad aprire un file\n            FileReader file = new FileReader(&quot;nonexistent.txt&quot;);\n        } catch (IOException e) {\n            // Gestione dell&#039;eccezione\n            System.out.println(&quot;Errore: Il file non esiste.&quot;);\n        }\n    }\n}\n \n// OUTPUT\n// Errore: Il file non esiste.\nIo qui provo a eseguire il codice con il try, qualora non dovesse andare a buon fine utilizzo il catch per gestire quell‚Äôeccezione.\nCon Runtime Exception (IndexOutOfBoundsException).\nProviamo ad accedere ad un indice che non esiste in una lista.\nimport java.util.ArrayList;\nimport java.util.List;\n \npublic class RuntimeExceptionExample {\n    public static void main(String[] args) {\n        List&lt;Integer&gt; numbers = new ArrayList&lt;&gt;();\n        numbers.add(1); // Lista con un solo elemento\n\t\t\n        try {\n            // Prova ad accedere a un indice non valido (es. indice 5)\n            System.out.println(numbers.get(5));\n        } catch (IndexOutOfBoundsException e) {\n            System.out.println(&quot;Errore: Indice fuori dai limiti.&quot;);\n        }\n    }\n}\n \n// OUTPUT\n// Errore: Indice fuori dai limiti.\nFinally\nIl blocco finally viene eseguito indipendentemente dal verificarsi di un‚Äôeccezione\n\nil finally serve per rilasciare le risorse e chiudere tutto(lo vedremo dopo)\n\npublic class FinallyExample {\n    public static void main(String[] args) {\n        try {\n            int result = 10 / 0; // Questo genera un&#039;eccezione\n        } catch (ArithmeticException e) {\n            System.out.println(&quot;Errore: Divisione per zero.&quot;);\n        } finally {\n            System.out.println(&quot;Blocco finally eseguito sempre.&quot;);\n        }\n    }\n}\n \n// OUTPUT\n/* Errore: Divisione per zero.\n   Blocco finally eseguito sempre.\n*/\nTry-with-resources\nIl try-with-resources √® una variante del blocco try che garantisce automaticamente la chiusura delle risorse dopo che sono state usate, senza bisogno di farlo manualmente nel blocco finally.\nGeneralmente dopo aver aperto una risorsa, nel finally scrivo\nfinally {\n\tRISORSA.close();\n}\ncos√¨ lo chiudo.\nCon il try-with-resources posso chiuderla automaticamente.\npublic void writeList() throws IOException {\n    try (FileWriter f = new FileWriter(&quot;OutFile.txt&quot;);\n         PrintWriter out = new PrintWriter(f)) {\n        for (int i = 0; i &lt; SIZE; i++) {\n            out.println(&quot;Value at: &quot; + i + &quot; = &quot; + list.get(i));\n        }\n    }\n}\n\n\n                  \n                  Boh non lo so prendilo molto alla larga \n                  \n                \n\nThrows\nQuando si verifica un‚Äôeccezione √® sempre meglio non gestirla direttamente nel metodo (con il try-catch) ma lasciare che sia il metodo chiamante a gestirla (letteralmente quello che abbiamo visto prima nel call stack).\nPer farlo utilizziamo la clausola throws nel metodo ‚Äúchiamato‚Äù, andando a specificare il tipo (uno o pi√π) di eccezioni che potrebbero verificarsi.\nEsempio\nMETODO CHIAMATO\npublic void writeFile() throws IOException {\n    PrintWriter out = new PrintWriter(new FileWriter(&quot;output.txt&quot;));\n    out.println(&quot;Ciao!&quot;);\n    out.close();\n}\nIl metodo dice al chiamante ‚Äúsenti a me mi importa ‚Äòna ricca sega, io faccio il mio lavoro e se genero un‚Äôeccezione gestiscitela tu (down)‚Äù.\nLetteralmente il metodo chiamato LANCIA  la sua eccezione(vedremo meglio come).\nMETODO CHIAMANTE\npublic static void main(String[] args) {\n    try {\n        new MyClass().writeFile();\n    } catch (IOException e) {\n        System.out.println(&quot;Errore gestito in main.&quot;);\n    }\n}\nQui il metodo prova a eseguire writeFile, quando questo avr√† finito, il chiamante controlla se ha lanciato un‚Äôeccezione e nel caso la gestisce personalmente.\n\n\n                  \n                  Esempio con pi√π eccezioni \n                  \n                \n\nMettiamo caso che il chiamato possa generare pi√π tipologie di eccezioni\npublic void piuEccezioni() throws IOException, IndexOutOfBoundsException {\n   // Potenziale IOException\n   PrintWriter out = new PrintWriter(new FileWriter(&quot;output.txt&quot;));\n \n   // Potenziale IndexOutOfBoundsException\n   int[] numbers = {1, 2, 3};\n   System.out.println(numbers[5]); // Accesso non valido\n \n   out.close();\n\n\n}\n\n\nDi conseguenza il chiamante deve essere in grado di &quot;catturarle&quot; tutte\n```java\npublic static void main(String[] args) {\n   try {\n       new MyClass().piuEccezioni();\n   } catch (IOException e) {\n       System.out.println(&quot;Errore di I/O gestito.&quot;);\n   } catch (IndexOutOfBoundsException e) {\n       System.out.println(&quot;Errore di accesso alla lista gestito.&quot;);\n   }\n\n\n}\n\n\n\nTutto bello, ma se ci sono eccezioni che vengono generate in Runtime da Java come faccio? Utilizzo il throw\nIn pratica io uso throw per creare la mia eccezione e con il throws specifico quale eccezione sto per lanciare.\nSINTASSI\nthrow new NomeEccezione(&quot;Messaggio di errore&quot;);\n\nNomeEccezione: Deve essere una classe che eredita da Throwable.\n\nse io genero un‚Äôeccezione che non √® standard, posso creare una sottoclasse di exception e inserisco tutte le mie ‚Äúnuove‚Äù eccezioni\n\n\nMessaggio di errore: Una stringa opzionale che descrive l‚Äôerrore\n\nESEMPIO\nUTILIZZO THROW MA NON THROWS quando mi aspetto un‚Äôunchecked excpetion\npublic double calcolaRadiceQuadrata(double numero) {\n    if (numero &lt; 0) {\n        throw new IllegalArgumentException(&quot;√à un numero negativo!!&quot;);\n    }\n    return Math.sqrt(numero);\n}\nIllegalArgumentException √® una Unchecked exception e quindi posso non scrivere throws.\nUTILIZZO THROW E THROWS quando mi aspetto una checked exception\npublic void scriviSuFile(String testo) throws IOException {\n        // Lancia un&#039;eccezione checked\n        throw new IOException(&quot;Errore di scrittura su file&quot;);\n    }\nUTILIZZO THROW E THROWS quando mi aspetto un‚Äôeccezione ‚Äúpersonalizzata‚Äù, ossia inserita da me in una sottoclasse di exception, INDIPENDENTEMENTE SE SIA CHECKED O UNCHECKED.\npublic void calcolaRadice(double numero) throws NumeroNegativoException {\n    if (numero &lt; 0) {\n        throw new NumeroNegativoException(&quot;Numero negativo: &quot; + numero);\n    }\n    return Math.sqrt(numero);\n}\nQui NumeroNegativoException √® una mia eccezione personalizzata (non scrivo il codice della sottoclasse ma fai finta)."},"UNI/ANNO-2/LINGUAGGI/LINGUAGGI-LEZ.13":{"slug":"UNI/ANNO-2/LINGUAGGI/LINGUAGGI-LEZ.13","filePath":"UNI/ANNO 2/LINGUAGGI/LINGUAGGI LEZ.13.md","title":"LINGUAGGI LEZ.13","links":[],"tags":[],"content":"Prima di iniziare con i Generics si pu√≤ precisare che √® possibile sfruttare oggetti ovunque vogliamo\n\nin classi\nmetodi\ninterfacce\necc‚Ä¶\nTutte le classi comprese quelle che si creano sono figlie di Object\n\npublic class Box {\n    private Object object;\n \n    public void set(Object object) { \n\t    this.object = object; \n    }\n    public Object get() { \n\t    return object; \n    }\n}\nVisto che usiamo un Object la dentro possiamo metterci quello che ci pare\nGenerics\n//Se noi facciamo una arraylist, che oggetti mettiamo dentro? che cazzo ne so?\nio voglio vincolarla ad avere determinati valori//\n\n\n                  \n                  se uso Object potrei incorrere in problemi di correlazione tra oggetti, cio√® magari per sbaglio, uso Stringhe e poi subito dopo altri tipi di oggetti \n                  \n                \n\n \npublic class Box {\n    private Object object;\n \n    public void set(Object object) { \n\t    this.object = object; \n    }\n    public Object get() { \n\t    return object; \n    }\n}\n \nBox box = new Box();\nbox.setContent(&quot;Hello&quot;);\nString value = (String) box.get(); // Serve per forza il cast\nSystem.out.println(value);\nServe per forza il cast perch√© una Stringa non pu√≤ accogliere un oggetto qualsiasi\n\n\n                  \n                  uso Generics per risolvere il problema lasciando spazio all&#039;utilizzatore della classe nel definire una volta per tutte quella classe cosa prevede \n                  \n                \n\nT √® un placeholder viene deciso quando istanzi la classe\npublic class Box&lt;T&gt; {\n    private T content;\n \n    public void setContent(T content) {\n        this.content = content;\n    }\n \n    public T getContent() {\n        return content;\n    }\n}\n \nBox&lt;String&gt; box = new Box&lt;&gt;();\nbox.setContent(&quot;Hello&quot;);\nString value = box.getContent(); // Nessun cast necessario\nSystem.out.println(value);\n \n\n\n                  \n                  In C++ \n                  \n                \n\nList&lt;E&gt; List&lt;Person&gt; indica che al posto della cosa con E lui deve sostituire tutte le volte con\nPerson\n\n\nUSO DI GENERICS MULTIPLE E IN INTERFACCE\ncome si pu√≤ vedere dal codice qua sotto ho usato molteplici generics in interfacce, vanno in base all‚Äôordine\npublic interface Pair&lt;K, V&gt; {\n    public K getKey();\n    public V getValue();\n}\n \npublic class OrderedPair&lt;K, V&gt; implements Pair&lt;K, V&gt; {\n \n    private K key;\n    private V value;\n \n    public OrderedPair(K key, V value) {\n\tthis.key = key;\n\tthis.value = value;\n    }\n \n    public K getKey()\t{ return key; }\n    public V getValue() { return value; }\n}\n \nnel main avremo:\n \nPair&lt;String, Integer&gt; p1 = new OrderedPair&lt;String, Integer&gt;(&quot;Even&quot;, 8);\nPair&lt;String, String&gt;  p2 = new OrderedPair&lt;String, String&gt;(&quot;hello&quot;, &quot;world&quot;);\nUSO DEI RAW(Sconsigliato e deprecated)\n\nQui si parla di codice Legacy ovvero vecchio prima di un aggiornamento\nprima di Java 5 non esistevano le generics, quindi dovevo fare in una ipotetica classe che implementa le generics la cosa del casting\nAnche se una nuova classe implementa i generics\n\npublic class Box &lt;T&gt; {\n    private T content;\n \n    public void setContent(T content) {\n        this.content = content;\n    }\n \n    public T getContent() {\n        return content;\n    }\n}\n \nmagari ho un vecchio main o da qualche altra parte che non lo fa\nfunziona lo stesso senza usare il diamond in box ma devo mettere poi il casting\nBox box = new Box(); // Uso senza specificare il tipo\nbox.setContent(&quot;Hello&quot;);\nString value = (String) box.getContent(); // Serve il cast\nSystem.out.println(value);\n \nSi possono dichiarare anche solo i metodi in modo generic senza tutta la classe, si usano soprattutto con i metodi statici\npublic class Util {\n    **public static &lt;K, V&gt; boolean compare(Pair&lt;K, V&gt; p1, Pair&lt;K, V&gt; p2)** {\n        return p1.getKey().equals(p2.getKey()) &amp;&amp;\n               p1.getValue().equals(p2.getValue());\n    }\n}\nPosso usare generics in questo modo &lt;U extends Number&gt;\nper fare in modo che sicuramente estendono la classe number in questo esempio cos√¨ sono sicuro che uso un numero\nExtends con la &amp;\nFacciamo finta che mi creo una classe A una interfaccia B e un‚Äôaltra C\nclass D &lt;T extends A &amp; B &amp; C&gt;\n{ /* ‚Ä¶ */ }\n\ndevono rispettare una gerarchia e la classe pu√≤ essere solo una se viene messa\n\ndeve oltretutto essere messa per prima rispetto alle interfacce\n\n\nextends indica sia implement che extend in questo caso\n\nskip fino a wildcards\npublic void printBoxContent(Box&lt;?&gt; box) {\n    Object content = box.getContent(); // Tipo sconosciuto\n    System.out.println(content);\n}\nSi usa il ? per indicare una cosa ancora piu generica, quando invece con il placeholder T una volta che scrivevo String per quell‚Äôoggetto vale come String ogni volta, ora posso cambiare le cose a mio piacimento anche dopo aver creato l‚Äôoggetto e averlo basato su una String\nCon le wildcard potrei ad esempio anche creare delle extends ma che ogni volta variano\nType Erasure\nRiprende i concetti di java 5 e codice Legacy\n√à il meccanismo che rimuove le informazioni sui tipi generici a runtime per garantire la compatibilit√† con il codice legacy e ridurre la complessit√† del bytecode"},"UNI/ANNO-2/LINGUAGGI/LINGUAGGI-LEZ.14":{"slug":"UNI/ANNO-2/LINGUAGGI/LINGUAGGI-LEZ.14","filePath":"UNI/ANNO 2/LINGUAGGI/LINGUAGGI LEZ.14.md","title":"LINGUAGGI LEZ.14","links":[],"tags":[],"content":"Le Collections sono un framework che racchiudono diverse strutture dati\n\n\n                  \n                  Per framework si intende un insieme di strumenti, codici librerie e funzionalit√† gi√† preparate \n                  \n                \n\napportano a dei miglioramenti\n\naumentano l‚Äôefficienza e la qualit√† del codice e delle sue implementazioni\nriduce la fatica nel creare nuove API\nLe collections sono un framework che hanno una struttura interna con delle interfacce come la collection\n\nLa gerarchia delle interfacce di collection\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTipoCosa faEsempioListUna lista ordinata di elementi. Pu√≤ avere duplicati.ArrayList, LinkedListSetUn insieme di elementi unici, senza duplicati.HashSet, TreeSetQueueUna coda FIFO (First In, First Out).LinkedList, PriorityQueueDequeUna coda dove puoi aggiungere/rimuovere elementi sia dalla testa che dalla coda.ArrayDequeMapUna struttura chiave-valore, dove ogni chiave √® unica e associata a un valore. (dizionari)HashMap, TreeMap\nun esempio di ArrayList e Supporta i Generics\nList&lt;String&gt; list = new ArrayList&lt;&gt;();\nChe operazioni posso fare su una lista?\n\nadd facendo list.add(&quot;Apple&quot;);\nremove list.remove(&quot;Banana&quot;);\n\nper eliminare a un indice list.remove(1);\nlist.remove(Integer.valueOf(1)); // Rimuove il numero 1\n\n\nposso usare strumenti di iterazione(lo vedremo tra poco)\n\nDiverse Operazioni che iterano sulle Collection\n1. Le aggregate operations\nSostanzialmente uso uno stream che mi scorre la sequenza della collection e poi ci applico dei\n\nfilter\nmap\nforeach\nper effettuare delle funzionalit√† specifiche di ricerca\n\nEsempio\nmyShapesCollection.Stream()\n    .filter(e -&gt; e.getColor() == Color.RED)  //uso una lambda expression\n    .forEach(e -&gt; System.out.println(e.getName()));\nLambda expression\nuso e come variabile temporale che assume prima il primo elemento poi il secondo ecc‚Ä¶\npongo una condizione sull‚Äôelemento\nforEach poi esegue un‚Äôazione su ogni elemento filtrato\n-&gt; serve per indicare che prima della freccia ho gli attributi e dopo la condizione\n\n\n                  \n                  gli aggregator non ti consentono di modificare la collezione ma solo di giocarci su \n                  \n                \n\n2. for -each\nfor (Object o : collection)\n    System.out.println(o);\n\n\n                  \n                  pure con il foreach stessa cosa \n                  \n                \n\n3. iterators\nMetodi principali dell‚ÄôIterator\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMetodoDescrizionehasNext()Restituisce true se c‚Äô√® un altro elemento nella collezione da scorrere.next()Restituisce l‚Äôelemento successivo nella collezione.remove()Rimuove l‚Äôelemento corrente dalla collezione in modo sicuro (opzionale).\nList&lt;String&gt; list = new ArrayList&lt;&gt;(List.of(&quot;Apple&quot;, &quot;Banana&quot;, &quot;Cherry&quot;));\n \nIterator&lt;String&gt; iterator = list.iterator();\n \nwhile (iterator.hasNext()) {\n    String fruit = iterator.next();\n    if (fruit.equals(&quot;Banana&quot;)) {\n        iterator.remove(); // Rimuove &quot;Banana&quot; dalla collezione\n    }\n}\n \nSystem.out.println(list); // Output: [Apple, Cherry]\n \nBulk operations\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMetodoCosa facontainsAllRitorna true se tutti gli elementi della collezione specificata sono presenti nella collezione presa in considerazione.addAllAggiunge tutti gli elementi di un‚Äôaltra collezione alla collezione target.removeAllRimuove dalla collezione target tutti gli elementi presenti in un‚Äôaltra collezione.retainAllMantiene solo gli elementi comuni tra la collezione target e quella specificata.clearRimuove tutti gli elementi dalla collezione target.\n\n\n                  \n                  versioni con e senza eccezioni \n                  \n                \n\nPer ogni struttura abbiamo versioni con e senza eccezioni perch√© ci sta chi dice che se tanto la\nstruttura la implementi bene nel codice a nessuno importa\n\nle eccezioni ci sono comunque ma una in runtime\n\n\n\nDifferenza tra Integer e int\nInt essendo un dato primitivo non √® un oggetto, per usarlo come oggetto si sono inventati integer\n\ninteger √® un wrap dell‚Äô int ed √® sottoclasse di number\n\nOperatore ternario\ncondizione ? valore1 : valore2\n(x &gt; 5) ? &quot;Maggiore di 5&quot; : &quot;Minore o uguale a 5&quot;;\nse √® True butta fuori la cosa a sx se √© False la cosa a dx\nDeque\n\nfirst indica il primo inserito\nlast indica l‚Äôultimo inserito\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTipo di OperazioneElemento Iniziale (Inizio del Deque)Elemento Finale (Fine del Deque)InserimentoaddFirst(e)addLast(e)RimozioneremoveFirst()removeLast()EsaminazionegetFirst()getLast()\nLe map(sono tipo i dizionari)\nLe varie implementazioni\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImplementazioneCaratteristiche principaliQuando usarlaHashMap- Usa una tabella hash.Quando serve alta velocit√† per inserimento, ricerca e rimozione.- Non garantisce ordine.LinkedHashMap- Estende HashMap.Quando serve mantenere l‚Äôordine di inserimento delle coppie chiave-valore.- Mantiene l‚Äôordine di inserimento.TreeMap- Implementa una mappa ordinata (usando un albero rosso-nero).Quando serve un ordine naturale delle chiavi o un ordine personalizzato.- Le chiavi sono ordinate in modo naturale o tramite un Comparator personalizzato.Hashtable- Simile a HashMap ma sincronizzata (thread-safe).Quando serve una mappa sincronizzata (ma √® meno usata nelle applicazioni moderne).\nMap&lt;String, Integer&gt; map = new HashMap&lt;&gt;();\nmap.put(&quot;Apple&quot;, 1);\nmap.put(&quot;Banana&quot;, 2);\nSystem.out.println(map.get(&quot;Apple&quot;)); // Output: 1\nSystem.out.println(map.keySet());     // Output: [Apple, Banana]\nMetodi delle map\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMetodoDescrizioneput(K key, V value)Inserisce o aggiorna un valore associato alla chiave specificata.get(K key)Restituisce il valore associato alla chiave specificata, o null se non esiste.remove(K key)Rimuove la chiave e il valore associato.containsKey(K key)Restituisce true se la chiave esiste nella mappa.containsValue(V value)Restituisce true se il valore esiste nella mappa.keySet()Restituisce un Set di tutte le chiavi presenti nella mappa.values()Restituisce una Collection di tutti i valori presenti nella mappa.entrySet()Restituisce un Set di tutte le coppie chiave-valore come oggetti Map.Entry.size()Restituisce il numero di coppie chiave-valore nella mappa.isEmpty()Restituisce true se la mappa √® vuota.clear()Rimuove tutte le coppie chiave-valore dalla mappa."},"UNI/ANNO-2/LINGUAGGI/LINGUAGGI-LEZ.3":{"slug":"UNI/ANNO-2/LINGUAGGI/LINGUAGGI-LEZ.3","filePath":"UNI/ANNO 2/LINGUAGGI/LINGUAGGI LEZ.3.md","title":"LINGUAGGI LEZ.3","links":[],"tags":[],"content":"STORIA SU JAVA\nNecessit√† di astrarre la programmazione\nTutti gli oggetti sono passati per riferimento quindi prevedono puntatori ma non visibili perfettamente\nJava √® una implementazione completa della programmazione a oggetti ad alto livello\nJava e la sua portabilit√†\nIn C il codice andava compilato e il compilatore differiva in base all‚Äôhardware e al s.o.\nJava ha una virtual machine che converte il linguaggio scritto in java nel linguaggio della macchina che usiamo, ci√≤ consente di non dover riscrivere i codici per macchine diverse\n\n\n                  \n                  write once, run everywhere \n                  \n                \n\n√à portabile\nJava si dice un linguaggio High performance per l‚Äôuomo, C viene eseguito pi√π velocemente ma √® pi√π complesso\nLa sicurezza di Java pi√π o meno dipende dalla macchina virtuale e basta\nJava si utilizza anche per sviluppare app web con applet\n\n\n                  \n                  Cosa √® un applet? \n                  \n                \n\nPiccolo programma che viene eseguito su un browser web per fornire interazioni, sostituito poi da JavaScript e altre cose\n\n\nJava oggigiorno viene principalmente utilizzato in ambienti back-end e non front-end\nCome funziona la Java Virtual Machine\nCi sono due cose principali\n\nil codice sorgente(il codice in Java) e il file sar√† contraddistinto in .Java\nil bytecode √® il risultato dell‚Äôoperazione di compilazione fatta da Javac il file sar√† in .class\nLa jvm traduce in real-time il bytecode(.class) in linguaggio macchina\n\n\n\nAPI(Application Programming Interface) IN JAVA\n√à un insieme di regole e meccanismi come classi, oggetti e metodi che danno funzionalit√† aggiuntive al programma in Java\nCome ad esempio java.net che aggiunge funzioni per la gestione delle reti\n\nCose importanti nelle tecnologie  Java\n\navere strumenti  di sviluppo come l‚Äôeseguibile Java e Javac ovvero il compilatore di bytecode e anche javaDOC(prende I commenti che fai in Java e genera del codice in HTML per visualizzare ci√≤ che commenti)\nTool per le interfacce come JavaFX e Swing\n\nCOSE TANGIBILI\nesempio hello world\nclass Helloworld{\n\tpublic static void main(String[] args){\n\t\tSystem.out.println(&quot;Hello World&quot;);\n\t}\n}\n\nDichiarazione della Classe che avr√† il compito di svolgere il main e deve avere lo stesso nome del file\nha un metodo pubblico, statico e di tipo void e si deve chiamare main\nin questo main √® previsto un passaggio di parametri\nstiamo passando string[] args  ovvero un array di stringhe che prende le info dalla linea di comando\n\nSe esegui questo programma con:\njava MyProgram uno due tre\n\n\ngli args saranno rispettivamente\nArgomento 0: uno\nArgomento 1: due\nArgomento 2: tre\n\n"},"UNI/ANNO-2/LINGUAGGI/LINGUAGGI-LEZ.4":{"slug":"UNI/ANNO-2/LINGUAGGI/LINGUAGGI-LEZ.4","filePath":"UNI/ANNO 2/LINGUAGGI/LINGUAGGI LEZ.4.md","title":"LINGUAGGI LEZ.4","links":[],"tags":[],"content":"Carrellata di caratteristiche di Java\n\n\n                  \n                  Funzione vs Metodo \n                  \n                \n\nLa funzione √® indipendente invece i metodi sono dipendenti dall‚Äôoggetto che usiamo\n\n\n\nStringa fa parte di default del linguaggio Java\nLa maggior parte delle volte non importiamo nessun pacchetto di classi perch√© sono gi√† intrinsecamente nelle classi di base di Java\nil print si scrive cosi strano perch√© stiamo invocando un metodo di un oggetto statico chiamato System.out\n\n\n\n                  \n                  esempio di compilazione e esecuzione di un file \n                  \n                \n\nJavac file.java‚Üí compilo (faccio riferimento a un file)\nJava file‚Üí eseguo (non serve che faccia riferimento a un file in una dir) dico Java file senza estensione perch√© la classe √® gi√† disponibile nel classPath(con tutti i bytecode, posso fare -cp per modificare il classPath) nella macchina virtuale di Java\nIl classPath √® presente nella cartella dove invochiamo Java(working directory)\n\n\nELEMENTI FONDAMENTALI DELLA PROGRAMMAZIONE A OGGETTI\nL‚Äôoggetto ha uno stato che pu√≤ variare nel tempo dell‚Äôesecuzione del codice\npu√≤ variare a seconda dei metodi dell‚Äôoggetto e degli attributi dell‚Äôoggetto\nCodice con bicicletta\nclass Bicycle {\n \n    int cadence = 0;\n    int speed = 0;\n    int gear = 1;\n \n    void changeCadence(int newValue) {\n         cadence = newValue;\n    }\n \n    void changeGear(int newValue) {\n         gear = newValue;\n    }\n \n    void speedUp(int increment) {\n         speed = speed + increment;   \n    }\n \n    void applyBrakes(int decrement) {\n         speed = speed - decrement;\n    }\n \n    void printStates() {\n         System.out.println(&quot;cadence:&quot; +\n             cadence + &quot; speed:&quot; + \n             speed + &quot; gear:&quot; + gear);\n    }\n}\n \n  \nclass BicycleDemo {\n    public static void main(String[] args) {\n \n        // Create two different \n        // Bicycle objects\n        Bicycle bike1 = new Bicycle();\n        Bicycle bike2 = new Bicycle();\n \n        // Invoke methods on \n        // those objects\n        bike1.changeCadence(50);\n        bike1.speedUp(10);\n        bike1.changeGear(2);\n        bike1.printStates();\n \n        bike2.changeCadence(50);\n        bike2.speedUp(10);\n        bike2.changeGear(2);\n        bike2.changeCadence(40);\n        bike2.speedUp(10);\n        bike2.changeGear(3);\n        bike2.printStates();\n    }\n}\n\n\n                  \n                  Con la classe abbiamo creato lo stampino di una bicicletta quindi potrei crearne n oggetti \n                  \n                \n\n\n\n                  \n                  Creazione di un oggetto in java \n                  \n                \n\nCreiamo uno spazio in memoria dinamico(hip) e salviamo il suo riferimento con un ‚Äúpuntatore‚Äù, questo puntatore sar√† ad esempio nomeclasse nomeoggetto e il suo riferimento = a\nnew nomeclasse()\n\n\n\n\n                  \n                  Se faccio una uguaglianza tra due puntatori ad oggetti? nomeoggetto1=nomeoggetto2\n                  \n                \n\navr√≤ lo stesso puntamento a memoria quindi entrambe puntano allo stesso oggetto\n\n\n\n\n                  \n                  che succede all&#039;oggetto a cui puntavo prima?? \n                  \n                \n\nSu c++ avevo costruttori e distruttori ma in Java non ce ne frega nulla perch√® √® magico‚ú®\n\n\n                  \n                  a cosa serve @override?\n                  \n                \n\n@override serve a sovrascrivere un metodo che gi√† abbiamo nominato in precedenza con un altro metodo specifico per la singola classe\n\n\nConcetto di ereditariet√†\nPosso creare delle sotto classi che riprendono TUTTE le caratteristiche della classe madre(o superclasse) ma aggiungono dei dettagli\n\n\n\n                  \n                  Una classe non pu√≤ ereditare da pi√π classi come in c++ \n                  \n                \n\n\n\n                  \n                  In Java le variabili bisogna sempre dichiararle prima con lettere e poi numeri \n                  \n                \n\n\n\n                  \n                  esempio di codice con sottoclassi \n                  \n                \n\n \nclass Schedavideo{\n \n¬† ¬† int ventole=0;\n \n¬† ¬† int vram=0;\n \n¬† ¬† int sborra;\n \n¬† ¬† String colore=&quot;bianco&quot;;\n \n¬† ¬† void stampadati (){\n \n¬† ¬† ¬† ¬† System.out.println(ventole+&quot; &quot;+vram+&quot; &quot;+sborra+&quot; &quot;+colore+&quot; &quot;); ¬† \n \n¬† ¬† }\n \n}\n \n  \n  \n \nclass NVIDIA extends Schedavideo{\n \n¬† ¬† double DLSS=1.0;\n \n¬† ¬† @Override\n \n¬† ¬† void stampadati (){\n \n¬† ¬† ¬† ¬† System.out.println(DLSS);\n \n}\n \n}\n \n  \n \nclass AMD extends Schedavideo{\n \n¬† ¬† double FSR=1.5;\n \n¬† ¬† @Override\n \n¬† ¬† void stampadati (){\n \n¬† ¬† ¬† ¬† System.out.println(FSR);\n \n}\n \n}\n \n  \n \nclass test2{\n \n¬† ¬† public static void main(String[] args){\n \n¬† ¬† ¬† ¬† Schedavideo RTX3060= new Schedavideo(); ¬†\n \n¬† ¬† ¬† ¬† RTX3060.ventole=5;\n \n¬† ¬† ¬† ¬† RTX3060.vram=7;\n \n¬† ¬† ¬† ¬† RTX3060.sborra=0;\n \n¬† ¬† ¬† ¬† RTX3060.colore=&quot;rosso&quot;;\n \n¬† ¬† ¬† ¬† NVIDIA TI3070=new NVIDIA();\n \n¬† ¬† ¬† ¬† TI3070.DLSS=1.6;\n \n \n¬† ¬† ¬† ¬† AMD XT6700=new AMD();\n \n¬† ¬† ¬† ¬† XT6700.FSR=2.1;\n¬† ¬† ¬† ¬† XT6700.ventole=3;\n \n \n¬† ¬† ¬† ¬† RTX3060.stampadati();\n \n¬† ¬† ¬† ¬† TI3070.stampadati();\n \n¬† ¬† ¬† ¬† XT6700.stampadati();\n \n¬† ¬† }\n \n}\n\n\n\n\n                  \n                  piccola spiegazione sugli override \n                  \n                \n\nquando vogliamo sovrascrivere un metodo di una superclasse usiamo override sopra al metodo\ndella sottoclasse\n¬† @Override\n \n¬† void stampadati (){\n \n¬† ¬† ¬† ¬† System.out.println(DLSS);\n \n}\n\n\nCosa √® una interfaccia\n\n\n                  \n                  Definizione \n                  \n                \n\nLe interfacce in Java servono principalmente per definire un insieme di metodi generici che devono essere implementati da varie classi.\nLe interfacce si possono definire come dei contratti che vanno rispettati dalle varie classi che lo firmano e che devono OBBLIGATORIAMENTE applicare quei metodi  definiti\ninterface Animale {\n    void verso();\n}\n \nclass Cane implements Animale {\n    @Override\n    public void verso() {\n        System.out.println(&quot;Bau bau&quot;);\n    }\n}\n \nclass Gatto implements Animale {\n    @Override\n    public void verso() {\n        System.out.println(&quot;Miao miao&quot;);\n    }\n}\n \n\n\n‚úñÔ∏è In java non esiste l‚Äôereditariet√† multipla, una classe figlia non pu√≤ avere due genitori\n\n\n                  \n                  utilizzo di interfaccia per creare una sorta di ereditariet√† multipla dei metodi \n                  \n                \n\nInfatti in java posso far accettare pi√π contratti ad una classe\ninterface TERRA\n{ \nvoid GUIDA(); \n} \ninterface ACQUA{ \nvoid NAVIGA();\n} \nclass AUTOMOBILE implements TERRA{  \nint velocit√†= 5; @Override  \npublic void GUIDA()\n{ System.out.println(velocit√†); \n}  \n} \nclass BARCA implements ACQUA{ int velocit√†= 60; @Override  \npublic void NAVIGA(){ System.out.println(velocit√†); }  \n} class HOVERCRAFT implements TERRA,ACQUA{ int velocit√†=100; @Override  \npublic void GUIDA(){ System.out.println(velocit√†); } @Override  \npublic void NAVIGA(){ System.out.println(velocit√†); } } class interfacce{ public static void main(String[] args) { AUTOMOBILE lamborghini=new AUTOMOBILE(); lamborghini.velocit√†=400; BARCA yatch=new BARCA(); yatch.velocit√†=50; HOVERCRAFT aereo= new HOVERCRAFT(); aereo.velocit√†=700;  \nlamborghini.GUIDA(); yatch.NAVIGA(); aereo.NAVIGA(); aereo.GUIDA(); } }\n\n\n\n\n\n                  \n                  perch√® non creo dei metodi e li uso e basta senza fare le interfacce? \n                  \n                \n\n√à una domanda molto comune! Le interfacce in Java possono sembrare ridondanti all‚Äôinizio,\nspecialmente se pensi: ‚ÄúPerch√© non posso semplicemente definire dei metodi in una classe e\nchiamarli quando ne ho bisogno?‚Äù. Tuttavia, le interfacce servono a risolvere alcuni problemi di\norganizzazione del codice e manutenzione che diventano evidenti quando il progetto\ncresce in complessit√†.\n\n\n\n\n                  \n                  cosa significa interoperabilit√† \n                  \n                \n\nindica in java la sua capacit√† di essere flessibile e la possibilit√† di integrare pi√π linguaggi di programmazione o servizi esterni, Java non √® un ecosistema chiuso\nAnche per i contratti abbiamo un discorso di interoperabilit√† sempre per un discorso di flessibilit√†\n\n\n\n\n                  \n                  clash delle implementazioni \n                  \n                \n\nQuesto termine si dice se c‚Äô√® un conflitto di interessi tra le varie implementazioni come metodi classi ecc‚Ä¶\n\n\nPACKAGE\n\nUn software al giorno d‚Äôoggi contiene migliaia di classi ecc\nI package sono un modo per separare in cassetti le classi che voglio creare\nPosso organizzare i package In pi√π cartelle come se fossero un file system\n\n\n\n                  \n                  un package √® un modo per mettere varie classi in una sorta di file system con la possibilit√† di implementarle ogni volta che richiamiamo questo package in fase di codice \n                  \n                \n\nimport nomepackage.test.progetto il .  serve per muoversi all‚Äôinterno delle cartelle del package come se fossero degli /\n\nuna volta importato il package possiamo creare oggetti di quella classe o fare delle sue sottoclassi\n\nper metterlo si fa import nomepackage\nper crearlo dobbiamo fare un file che poi dovr√† essere compilato\n\n\n\n\n\n                  \n                  I package non hanno nessun rapporto funzionale tra di loro anche se sono uno dentro l&#039;altro \n                  \n                \n\nEsempio creazione package\n \npackage animali; ¬†// creo la mia cartella\n \n  \n \npublic class Cane { ¬†// creo la mia classe\n \n¬† ¬† public void abbaia() {\n \n¬† ¬† ¬† ¬† System.out.println(&quot;Bau Bau!&quot;);\n \n¬† ¬† }\n \n}\n \nUtilizzo la stessa cartella ma utilizzo una variabile diversa\n \npackage animali; ¬†// dico che la classe dovr√† andare dentro la cartella\n \n  \n \npublic class Gatto { ¬†// creo la mia classe\n \n¬† ¬† public void miagola() {\n \n¬† ¬† ¬† ¬† System.out.println(&quot;Miao!&quot;);\n \n¬† ¬† }\n \n}\n \nEsempio utilizzo package\n \nimport animali.Cane; ¬†// utilizzo .Cane per specificare un file\n \n  \n \npublic class Main {\n \n¬† ¬† public static void main(String[] args) {\n \n¬† ¬† ¬† ¬† Cane mioCane = new Cane();\n \n¬† ¬† ¬† ¬† mioCane.abbaia(); ¬†// Stampa: Bau Bau!\n \n¬† ¬† }\n \n}\n \n \nimport animali.Gatto; ¬†// utilizzo .Gatto specificare un file\n \n  \n \npublic class Main {\n \n¬† ¬† public static void main(String[] args) {\n \n¬† ¬† ¬† ¬† Gatto mioGatto = new Gatto();\n \n¬† ¬† ¬† ¬† mioGatto.miagola(); ¬†// Stampa: Miao!\n \n¬† ¬† }\n \n}\n \nSE VOGLIO UTILIZZARE TUTTA LA CARTELLA USO ¬†.*\nimport animali.*; ¬†// utilizzo .* per utilizzare tutta la cartella\nCARRELLATA DI COSE DA RICORDARE\nLESSON: Language Basics\n\n\n                  \n                  DOMANDA D&#039;ESAME:Che tipologie di variabili esistono in Java \n                  \n                \n\nIn senso che ruoli pu√≤ avere\n\nLe variabili globali\nVariabili che descrivono lo stato di un oggetto: campi(fields o attributi) campi statici e campi non statici\nVariabili locali interne a un metodo temporanee\nVariabili dei parametri\nvariabili primitive != variabili in generale\n\n\n\n\n\n                  \n                  Differenza tra parametri e argomenti \n                  \n                \n\n\ni parametri sono quei dati che passiamo a un metodo o funzione\nvoid metodo(int numero, String gino)\ngli argomenti sono quei dati che passiamo quando chiamiamo la funzione\nmetodo(5,&quot;ciao&quot;)\n\n\n\n\n\n                  \n                  Campo(o attributo) statico e non statico \n                  \n                \n\n\nNon statico, ogni oggetto ha i suoi attributi della classe che al massimo se non vengono messi rimangono di default\nStatica, ogni istanza della classe(oggetto) avr√† questo attributo e il suo valore in comune, non √® definibile una costante perch√® nel corso del codice posso modificare il valore del seguente campo e questa cosa varr√† per ogni sua istanza, esempio di una classe con uno standard europeo, ogni oggetto potr√† salvare questo standard e se cambia ogni oggetto avr√† lo standard cambiato. per usare invece le costanti faremo static final\nStaticit√† ha a che fare con la posizione in memoria di quel campo\nHeap indica una prozione di memoria dinamica, qua in questa porzione dinamica avremo ad esempio i new oggetti\n\n\n"},"UNI/ANNO-2/LINGUAGGI/LINGUAGGI-LEZ.5":{"slug":"UNI/ANNO-2/LINGUAGGI/LINGUAGGI-LEZ.5","filePath":"UNI/ANNO 2/LINGUAGGI/LINGUAGGI LEZ.5.md","title":"LINGUAGGI LEZ.5","links":[],"tags":[],"content":"Costanti\nVengono specificate con il modificatore final.\nLe variabili sono scritte tutte in\n\nCAMEL CASE la seconda parola √® con l‚Äôiniziale maiuscola\nSNAKE CASE dove ogni parola √® separata da un _.\n\n\n\nSe io definisco una variabile universale tanto vale che sia anche statica, quindi la definizione corretta sarebbe static final\n\n\n                  \n                  Perch√© static final?\n                  \n                \n\n\nfinal: significa che il valore non pu√≤ essere modificato una volta assegnato.\nstatic: rende la variabile condivisa tra tutti gli oggetti della classe. Se una costante √® universale, static permette di non creare copie della costante per ogni oggetto, ma di condividerla.\n\n\n\nESEMPIO\nclass Esempio {\n    static final int sonoUnaCostante = 10; // Definizione e inizializzazione della                                               costante con camelCase\n    \n    static final int SONO_UNA_COSTANTE = 20; // UPPERCASE + snake_case\n \n    public static void main(String[] args) {\n        System.out.println(&quot;Il valore della costante √®: &quot; + sonoUnaCostante);\n        \n        System.out.println(&quot;Il valore della costante √®: &quot; + SONO_UNA_COSTANTE);\n    }\n}\nDati primitivi\n\nBYTE = 8 bit\nSHORT = 16 bit\nINT = 32 bit\nLONG = 64 bit\n\nQuelli in virgola mobile\n\nFLOAT = 32 bit\nDOUBLE = 64 bit\n\nAltri\n\nBOOLEAN\nCHAR, che √® definito secondo la tabella UNICODE a 16 bit, ma nulla vieta di interpretarlo secondo un determinato encoding\nSTRING, non sono dei dati primitivi bens√¨ di una classe speciale di tipo oggetto, ma Java le riserva un trattamento particolare.\n\nDefault values\nVengono assunti quando un determinato tipo primitivo non √® inizializzato.\n\nTutti gli oggetti, che sono in realt√† dei puntatori, se non inizializzati hanno valore NULL perch√© non puntano a nulla.\nArray\nUn array √® una struttura dati che ti permette di memorizzare pi√π elementi dello stesso tipo in un‚Äôunica variabile.\nTutti gli elementi all‚Äôinterno di un array devono essere dello stesso tipo, e questo tipo viene definito al momento della sua creazione. Se crei un array di interi (int[]), potr√† contenere solo numeri interi.\nESEMPIO\nclass ArrayEsempio{\n\tint[] numeri; // Crea un array di interi\n\t\n\tnumeri = new int[5] // Alloco memoria per 5 interi\n\t\n\tnumeri[0] = 10; // inizializzo il primo elemento\n\tnumeri[1] = 20; // inizializzo il secondo\n\tnumeri[2] = 30; // ecc.\n\tnumeri[3] = 40;\n\tnumeri[4] = 50;\n \n\tSystem.out.println(numeri[2]); // Stampa 30\n}\n \n// OVVIAMENTE PER RIEMPIRE L&#039;ARRAY POSSO UTILIZZARE UN CICLO FOR O ALTRE COSE.\nUn altro modo per creare e inizializzare un array √® questo\nint[] numeri = { \n    10, 20, \n    30, 40, 50\n};\n \n// Qui non devo specificare la dimensione dell&#039;array perch√© Java la calcola in        automatico\n\n\n                  \n                  Differenze tra il primo e il secondo? \n                  \n                \n\n\nIl secondo esempio riguarda un‚ÄôINIZIALIZZAZIONE STATICA, perch√© tutte le informazioni dell‚Äôarray sono contenute all‚Äôinterno del programma stesso\nIl primo esempio riguarda un‚ÄôINIZIALIZZAZIONE DINAMICA (data dal new), perch√© io posso invocare il new quante volte voglio all‚Äôinterno del programma.\n\n\n\nE cos√¨ posso dichiarare altri tipi di array\nbyte[] unArrayDiBytes;\nshort[] unArrayDiShorts;\nlong[] unArrayDiLongs;\nfloat[] unArrayDiFloats;\ndouble[] unArrayDiDoubles;\nboolean[] unArrayDiBooleans;\nchar[] unArrayDiChars;\nString[] unArrayDiStrings;\nArray multidimensionali\nUn array multidimensionale √® un array che contiene altri array come elementi. Questo significa che puoi avere array di array (ad esempio, una ‚Äúmatrice‚Äù), con la particolarit√† che questi possono essere array ‚Äúirregolari‚Äù.\nQuesto significa che ogni riga (o sotto-array) pu√≤ avere una lunghezza diversa.\nESEMPIO\nclass ArrayMultiDim {\n    public static void main(String[] args) {\n        String[][] names = {\n            {&quot;Mr. &quot;, &quot;Mrs. &quot;, &quot;Ms. &quot;}, // lunghezza 3\n            {&quot;Smith&quot;, &quot;Jones&quot;} // lunghezza 2\n        };\n        \n        System.out.println(names[0][0] + names[1][0]); // Mr. Smith\n        \n        System.out.println(names[0][2] + names[1][1]); // Ms. Jones\n    }\n}\nDICHIARAZIONE\n\nString[][] names: dichiara un array bidimensionale di String. In questo caso, names √® un array di array di stringhe.\n\nnames[0] √® un array di stringhe {&quot;Mr. &quot;, &quot;Mrs. &quot;, &quot;Ms. &quot;}.\nnames[1] √® un array di stringhe {&quot;Smith&quot;, &quot;Jones&quot;}.\n\n\n\nPRIMO PRINT\n\nnames[0][0] accede al primo elemento del primo array, che √® &quot;Mr. &quot;.\nnames[1][0]:accede al primo elemento del secondo array, che √® &quot;Smith&quot;.\n\nLa riga System.out.println(names[0][0] + names[1][0]); stampa Mr. Smith, concatenando &quot;Mr. &quot; con &quot;Smith&quot;.\n\n\n\nSECONDO PRINT\n\nnames[0][2]: accede al terzo elemento del primo array, che √® &quot;Ms. &quot;.\nnames[1][1]: accede al secondo elemento del secondo array, che √® &quot;Jones&quot;.\n\nLa riga System.out.println(names[0][2] + names[1][1]); stampa Ms. Jones, concatenando &quot;Ms. &quot; con &quot;Jones&quot;.\n\n\n\nCome si copiano gli Array\nAll‚Äôinterno della classe system, che √® una classe utility fornita dalla libreria standard, √® presente un metodo statico, System.arraycopy, che permette di copiare una parte o tutto il contenuto di un array dentro un altro array.\nQuesto metodo accetta 5 parametri\nSystem.arraycopy(Object src, int srcPos, \n\t\t\t\t Object dest, int destPos, \n\t\t\t\t int length);\nDove\n\nsrc √® l‚Äôarray di origine, da cui copiare i valori.\nsrcPos √® la posizione iniziale nell‚Äôarray di origine, da cui iniziare a copiare.\ndest √® l‚Äôarray di destinazione, dove incollare i valori copiati.\ndestPos √® la posizione iniziale nell‚Äôarray di destinazione, dove iniziare a incollare i valori.\nlength √® il numero di elementi da copiare.\nNB: gli elementi che vengono copiati in dest vanno a sovrascrivere quelli vecchi presenti da destPos in poi (ovviamente in base a length)\n\nESEMPIO\nclass ArrayCopyEsempio {\n    public static void main(String[] args) {\n        int[] arrayOrigine = {1, 2, 3, 4, 5};\n        int[] arrayDestinazione = {10, 20, 30, 40, 50};\n \n        // Copia 3 elementi a partire dalla posizione 1 di arrayOrigine\n        // e li incolla a partire dalla posizione 2 di arrayDestinazione\n        System.arraycopy(arrayOrigine, 1, arrayDestinazione, 2, 3);\n \n        // Stampa arrayDestinazione per vedere il risultato\n        for (int i : arrayDestinazione) {\n            System.out.print(i + &quot; &quot;);\n            /* OUTPUT\n\t\t       {10, 20, 2, 3, 4}\n        }\n    }\n}\n\n\n                  \n                  Spiegazione del For-Each\n                  \n                \n\nIn questo esempio abbiamo utilizzato un ciclo for particolare, ossia il For-Each, che permette di iterare facilmente su ogni elemento di un array senza dover gestire manualmente l‚Äôindice.\nLa sintassi √®\nfor (Tipo variabile : array) {\n   // codice da eseguire per ogni elemento\n\n\n}\n\n- **`Tipo`**: il tipo di dato degli elementi nell&#039;array (ad esempio, `int` se l&#039;array contiene interi).\n- **`variabile`**: un nome che scegli per rappresentare ogni elemento dell&#039;array durante il ciclo; partendo dal primo elemento, ad ogni iterazione la variabile prender√† il valore del prossimo elemento nell&#039;array che specifico.\n- **`array`**: l&#039;array su cui vuoi iterare (nel caso precedente, `arrayDestinazione`).\n\n### Vantaggi del For-Each\n\n\nIl ciclo for-each √® utile perch√© √® semplice da scrivere e evita errori legati agli indici. Tuttavia, √® utile solo se devi leggere gli elementi dell‚Äôarray, perch√© non ti permette di modificare gli elementi nella posizione originale.\n\n\n                  \n                  Altra DOVEROSA precisazione del prof \n                  \n                \n\nTutte le classi, per convenzione, si definiscono al singolare (es. una classe la chiamer√≤ PERSONA e non PERSONE).\nEsiste per√≤ una classe standard in Java che si chiama Arrays.\nMa perch√© il plurale?\nPerch√© all‚Äôinterno di questa sono presenti TUTTE le utilities per gli Array (tranne arraycopy ma il motivo non √® importante).\n\n\nUn altro approccio simile al arraycopy pu√≤ essere copyOfRange\nclass ArrayCopyEsempio {\n    public static void main(String[] args) {\n        int[] arrayOrigine = {1, 2, 3, 4, 5};\n \n        // Creo un nuovo array copiando dall&#039;elemento 2 al 5 (non incluso) di                 arrayOrigne\n        int[] arrayDestinazione = java.util.Arrays.copyOfRange(arrayOrigine, 2, 5)\n \n        // Stampa arrayDestinazione per vedere il risultato\n        for (int i : arrayDestinazione) {\n            System.out.print(i + &quot; &quot;);\n            /* OUTPUT\n\t\t       {2, 3, 4}\n        }\n    }\n}\nOperatori\nSe io scrivo come statement, da solo a++ oppure ++a non cambia nulla.\nMA se io ho a = 5 e scrivo\n\nb = ++a, PRIMA viene incrementato a (a = 6) e poi assegno questo valore a b (b = 6)\nb = a++, PRIMA viene assegnato il valore a b (b = 5) e poi viene incrementato a (a = 6)\n\nTUTTI GLI OPERATORI\n\nSPIEGAZIONE DI ALCUNI\n1. Shift (&lt;&lt;, &gt;&gt;, &gt;&gt;&gt;)\nGli operatori di shift spostano i bit di un numero a sinistra o a destra. Funzionano solo su valori numerici e spostano i bit di un numero binario per modificare il valore.\n\n\n&lt;&lt; (shift a sinistra): sposta i bit a sinistra e riempie con zeri a destra. Ogni spostamento a sinistra equivale a moltiplicare per 2.\nint a = 5; // 5 in binario √® 00000101\nint b = a &lt;&lt; 1; // sposta di 1 bit a sinistra: 00001010\n// b ora vale 10\n\n\n&gt;&gt; (shift a destra con segno): sposta i bit a destra, mantenendo il segno del numero (riempiendo con 0 se positivo o con 1 se negativo).\nint a = 20; // 00010100\nint b = a &gt;&gt; 2; // sposta di 2 bit a destra: 00000101\n// b ora vale 5\n\n\n&gt;&gt;&gt; (shift a destra senza segno): sposta i bit a destra, riempiendo con zeri, indipendentemente dal segno del numero.\n\n\n2. instanceof\nL‚Äôoperatore instanceof verifica se un oggetto √® istanza di un altro.\n√à utile per il controllo del tipo in fase di esecuzione.\nFunziona anche con le istanze non solo con le classi.\nString testo = &quot;Hello&quot;;\nboolean risultato = testo instanceof String; // true, perch√© testo √® di tipo String\n\nEsempio pratico\nclass Animale {}\n \nclass Cane extends Animale {}\n \nclass instanceofprova{\n\tpublic static void(String[] args){\n\t\tAnimale animale = new Animale();\n\t\tCane cane = new Cane();\n \n\t\tSystem.out.println(cane instanceof Animale);  // true, perch√© `cane` √®                                                              un&#039;istanza di `Cane`,                                                              che deriva da                                                                      `Animale`\n\t\tSystem.out.println(animale instanceof Cane);  // false, perch√©                                                                      `animale` √® un                                                                     `Animale` generico e                                                                non un `Cane`\n\t}\n}\n\n\n\n###### 3. **Bitwise AND (&amp;)**\nL‚Äôoperatore **Bitwise AND** (`&amp;`) effettua un‚Äôoperazione logica AND tra i **bit** di due numeri. Funziona confrontando i bit di due numeri binari e ritorna 1 solo se entrambi i bit sono 1.\n```java\nint a = 5;  // 0101 in binario\nint b = 3;  // 0011 in binario\nint risultato = a &amp; b; // 0001 (1 in decimale)\n\n4. Bitwise Exclusive OR (XOR) (^)\nL‚Äôoperatore Bitwise XOR (^) effettua un‚Äôoperazione logica esclusiva OR sui bit. Restituisce 1 solo se i bit sono diversi.\nint a = 5;  // 0101 in binario\nint b = 3;  // 0011 in binario\nint risultato = a ^ b; // 0110 (6 in decimale)\n5. Bitwise Inclusive OR (|)\nL‚Äôoperatore Bitwise OR (|) effettua un‚Äôoperazione logica OR tra i bit. Ritorna 1 se almeno uno dei bit √® 1.\nint a = 5;  // 0101 in binario\nint b = 3;  // 0011 in binario\nint risultato = a | b; // 0111 (7 in decimale)\n6. Operatore Ternario (? :)\nL‚Äôoperatore ternario √® una scorciatoia per l‚Äôistruzione if-else.\nHa la forma condizione ? valoreSeVero : valoreSeFalso, e ritorna un valore in base alla valutazione della condizione.\nint a = 10;\nint b = 20;\nint max = (a &gt; b) ? a : b; // max sar√† uguale a b, quindi 20\n\n\n                  \n                  DOVEROSA DIFFERENZA TRA .print e .println\n                  \n                \n\n\nSystem.out.print() stampa gli elementi su una sola riga\nSystem.out.println() stampa gli elementi andando a capo ad ogni stampa\n\n\n\n\n\n                  \n                  Parentesi doverosa a detta del prof \n                  \n                \n\nAllora, in principio c‚Äôera l‚Äôaski, cos‚Äôera l‚Äôascii? Che non √® il cane quello con gli azzurri, mait era se pronuncia aschi perch√© asci lo diciamo in italiano perch√© s c i per noi si legge cos√¨, per√≤ ehm √® era una tabella che forniva una mappatura tra la maschera di bit presenti in un byte e dei caratteri da rappresentare. Ok? Perch√© immaginate che i caratteri che voi vedete a schermo in gergo glifi, ok? Sono solo una rappresentazione e una rappresentazione che deve eseguire una qualche regola di conformit√†. Ok? Questa regola √® stata definita per la tabella √® stata definita appunto grazie a questa tabella e mi diceva come mappare appunto questi grifi rispetto a una codifica in byte. Ok? Adesso il problema √® che una volera era fatta sta tabella, grosso modo negli primi 127/128 insomma cosi, quindi sostanzialmente primo by primo bit zero, tutti gli altri quello che ne seguiva e erano presenti i carattuni degli alfabeti pi√π noti, quindi ci trovavate sostanzialmente tutte le 26 lettere dell‚Äôalfabeto inglese, piccole, grandi, poi ci trovavate, non mi ricordo se gli accentati sono stati inseriti dopo, non credo che questo dell‚ÄôASP, poi ci trovavate tutta una serie di di di simboli tipici, l‚Äôandore, il trattino, dash e e cos√¨ via. Insomma, mo non andate a chiedere tutti i simboli primi 127, per√≤ diciamo che l√† dentro c‚Äô√® stata tutta roba cristiana che scrive dal 128 in poi. Immaginate che parlo della preistoria\n\n\n√® stato giunto dopo Latinone. S√¨, l‚Äôhanno aggiunto con Leding One. S√¨. Eh, tutto quello che viene da 128 in poi fino a 255 era in realt√† utilizzato, sempre perch√© parliamo della pristoria per la grafica, perch√© perch√© mica c‚Äôera la grafica tutta via che cavete adesso voi con le macchine moderne. Una volta la grafica era semplicemente una serie di caratteri che erano arrangiati di modo da darvi qualcosa di visibile. Non so se avete visto qualche vecchio film anni 80, no? In cui si vedeva per esempio c‚Äôera un form, c‚Äôera un quadratino, il quadratino era fatto col rettangol o era fatto coi simboli di uguale col doppio tilde per i verticali e poi c‚Äôera uno speciale simbolo che era l‚Äôangoletto che aveva le due linee tutti questi simboli poi i cuoricini, le cose di qua e di l√†, eh tutte queste cose qui facevano parte di questa seconda sequenza di caratteri che era, diciamo, io poi concettualmente li ho divisi i primi 127 e i secondi 127. Mo se il fuoricino stava nei primi o nei secondi, non non me lo ricordo, per√≤ insomma il concetto era nei primi c‚Äôera tutto ci√≤ che riguardava la scrittura normale e i simboli pi√π utilizzati comunque nella scrittura e invece tutto il resto era dedicato agli aspetti grafici. Ovviamente questa cosa, diciamo, √® diventata abbastanza inutile nel momento in cui la grafica ha iniziato a basarsi proprio su delle librerie dedicate, sulla possibilit√† di indicare specificamente dei pixel, invece che scrivere sempre, andare a indirizzare carattere per carattere. E quindi, insomma, questa questi 128 successivi sono diventati abbastanza inutili e quindi giustamente a un certo punto italiani, greci, spagnoli, tedeschi, europei che gli piaceva tanto rompere scatole. Gli americani che invece andavano dritti coi loro 26 caratteri buonanotte hanno iniziato a dire ‚ÄúS√¨, per√≤ io c‚Äôho la accentata arriva al tedesco, io c‚Äôho l‚Äôula, sapete quella che poi viene scritta o o e a ee oppure sono i due puntini sopra e che si leggono e e cose simili‚Äù e cos√¨ via. Allora, eh e fino a qua, quindi facciamo il latin che √® rimpiazziamo tutta la roba grafica che non ci serve pi√π, ci imparchiamo dentro, le ha accentate, l‚Äôaccento cos√¨, l‚Äôaccento cos√¨, le entato al 100 cos√¨ al 100 cos√¨ quello pure per i pinnici con la doppia cosa con la tilde eccetera eccetera e quindi oh, siamo fatto contenti tutti, infatti si chiama Letin pi√π o meno questa parte qua. Poi giustamente sono arrivati i cinesi hanno detto ah h che volevo fa‚Äô?\n\n\nEh, dire non lo so che fa, comprimiamo che ci inventiamo. E allora a un certo punto a un certo punto che si fa? Io\n\n\nsi inventa una tabella universale e questa √® stata chiamata appunto viva la fantasia Unicode Universal Code, cio√® una codifica universale nel quale c‚Äôera spazio per tutti, per i cinesi, per i giapponesi, per per i coreani ma pure per la lingua. E quindi a un certo punto felicemente ci abbiamo messo tutti gli alfabeti del mondo, non solo alfabeti, poi perch√© insomma alcuni sono non sono fonetici, quindi non sono alfabetti, per√≤ insomma comunque tutti i glifi possibili immagin inabili e il problema √® che questa tabella era bella grande. Cosa pare una tabella a 32 bit, ok? Per cui enorme, cio√® molto pi√π di molto pi√π spazio di quello che serve. Il problema √® che 32 bit sono un po‚Äô scomodi per fare. Allora, si sono inventati dei delle versioni pi√π corte. Per esempio c‚Äô√® Unicode 16 dove credo che venga coperto quasi tutto e eh e utilizza due B. E poi a un certo punto qualcuno ha avuto una bella idea, ha detto ‚ÄúSentite Boh, vabb√®, fa spazio per tutti, pure sti italiani con gli accenti, le cose, accento cos√¨, accento cos√†, eccetera eccetera. Ma se noi facessimo un metodo compresso in cui io dico se il primo bit √® zero, allora questa cosa dura un byte e quindi devi leggere solo un byte e ci mettiamo le classiche cose con cui abbiamo fatto pace. Se il primo bit √® uno, allora non √® che c‚Äôhai accesso a un altro resto della tabella. Sai che invece devi leggere N2 di B, ok? E quindi tu devi avere sostanzialmente un meccanismo compresso in cui ogni volta devi sapere come andare a leggere il byte successivo sulla base di quello precedente. √à una notifica compressa, √® una di quelle pi√π utilizzate, l‚Äôavrete sicuramente sentita come nome, senza sapere esattamente cosa sia. Si chiama UTF8 ed √® appunto Unicode blabo che cosa, a 8 bit che √® la versione stracompressa in cui, appunto, avete sempre un bit di riferimento che vi dice se dovete andare a ere pi√π informazione perch√© dovete comprendere qualche carattere che non rientra nei primi 128.\n\n\n                  \n                  Anticipazione di una cosa che riprenderemo poi \n                  \n                \n\nMath √® una libreria di funzioni matematiche. Voi mi direte, ‚ÄúNo, ma non ci sono le funzioni, ci sono solo i metodi in Java‚Äù. E infatti math √® una classe che ha solo metodi, cos√¨ come le costanti che sono il greco, il numero dello. Anche i metodi sono tutti statici. E voi mi direte, oddio, pure i metodi, quindi, sono statici. I metodi statici sono pure quelli un universali per una classe, che significa che possono essere imbocati direttamente dalla classe. Ancora una volta la sintassi non vi invocarli anche da un‚Äôistanza, per√≤ poco sensato e nel senso che √® poco chiaro. Se io vedo un metodo chiamato da un‚Äôistanza mi aspetto che sia un metodo gravo. Se io lo chiamo dalla classe capisco che √® un metodo di classe. Quindi, sebbene la senta, √® sconsigliato invocare un metodo statico da una istanza. Meglio invocarlo direttamente dalla classe e far capire che √® un metodo di classe. Se √® un metodo di classe Attenzione, ci sono delle cose che sono riempite in gi√†. Non potete inserire un riferimento non statico all‚Äôinterno di un mezzo statico. Cio√®, se io c‚Äôho la variabile velocit√† della bicicletta e questa √® una variabile non statica perch√© ogni bicicletta c‚Äôha la il valore suo, non potete fare un metodo eh statico della classe bicicletta che faccia riferimento alla velocit√†. Perch√© dice la velocit√† di chi? Visto che questo √® un metodo generale.\nEcco, i metodi statici sapete di fatto cosa sono?\nSono funzioni. Vedete le care vecchie funzioni dei linguaggi tradizionali di programmazione tradizionale intendo prima della programmazione oggetti, no? E non √® che non esistono, esistono di fatti sono i metodi statici perch√© per esempio la classe MATH non √® pensata per avere istanze, nel senso c‚Äô√® un‚Äôistanza della matematica, ok? La classe MATH √® pensata di fatto, pensate che quel math l√† dentro si comporta qui come se fosse un package di funzioni, per√≤ dato che non potete avere la funzione dichiarata senza una classe attaccata, ecco, la classe math si sta comportando come se fosse semplicemente un collettore, proprio come se fosse un package, no, di funzioni e di costanti. Ok? Infatti dentro ci trovate una marea di funzioni matematiche e ci trovate dentro anche le due costanti che vi ho detto prima. Ok? Quindi di fatto il compito delle funzioni, no, √® assolto dai metodi statici. In quel caso, appunto, la classe che contiene, visto che non ha nessuna caratteristica, no, che che che va a essere mantenuta, ecco, di fatto la classe che li contiene si si comporta veramente pi√π come un collettore logico, un po‚Äô con lo stesso lavoro che fa il packaging, cio√® io volevo tutte le funzioni matematiche, dove le metto in una cosa chiamata math. Ma posso mettere le funzioni in Java? No, devo avere i metodi che sono attaccati a una classe. Benissimo, la classe MATH svolge il compito di collettore di tutte le funzioni matematiche.\n\n"},"UNI/ANNO-2/LINGUAGGI/LINGUAGGI-LEZ.6+7":{"slug":"UNI/ANNO-2/LINGUAGGI/LINGUAGGI-LEZ.6+7","filePath":"UNI/ANNO 2/LINGUAGGI/LINGUAGGI LEZ.6+7.md","title":"LINGUAGGI LEZ.6+7","links":["tags/"],"tags":[""],"content":"piccola nota: ringrazio Samuele per aver carryato l‚Äôintera lezione visto\nEspressioni\nUn‚Äôespressione √® una combinazione di variabili, operatori (come +, -, /) e, talvolta, chiamate a metodi, che insieme producono un valore. Ad esempio, 1 + 2 √® un‚Äôespressione che restituisce 3, e anche System.out.println(&quot;Ciao&quot;) √® un‚Äôespressione perch√© esegue un‚Äôazione e ha un valore di ritorno.\nOvviamente il tipo di valore ritornato da un‚Äôespressione dipende dagli elementi usati all‚Äôinterno di essa, ad esempio:\n\nint numero = 10; ritorna un int\nString parola = &quot;ciao&quot;; ritorna una String\n\nPrecedenza degli operatori\nCome visto nella tabella degli operatori nella lezione precedente, ogni operatore ha una ‚Äúprecedenza‚Äù (quelle matematica) che ovviamente Java rispetta.\n\nEsempio: In x + y / 100, Java eseguir√† prima y / 100, poi sommer√† il risultato a x perch√© la divisione ha precedenza sull‚Äôaddizione.\n\nPer ‚Äúovviare‚Äù e per eliminare le ambiguit√† si usano le ().\nStatement\nLo Statement √® un‚Äôistruzione completa, e al suo interno contiene espressioni.\nci sono 4 tipi di Statement:\n\ndi assegnazione `aValue = 8933.234;\ndi dichiarazione double aValue = 8933.234;\nquando si usa ++ o ‚Äî aValue++;\ninvocazione di metodi System.out.println(&quot;Hello World!&quot;);\nespressioni sulla creazione di oggetti Bicycle myBike = new Bicycle();\nE poi soprattutto ci sono i:\n\nControl Flow Statements\nIn Java (e in molti altri linguaggi di programmazione), un control flow Statement √® un‚Äôistruzione che gestisce l‚Äôordine in cui vengono eseguiti i blocchi di codice, determinando il flusso di esecuzione del programma.\nPrima di passare a spiegare i vari tipi di Statements spiegherei cosa sono i blocchi:\nI blocchi\nuna serie di Statements messi insieme e raggruppati dalle parentesi { }\nclass BlockDemo {\n    public static void main(String[] args) {\n        boolean condition = true; // Dichiarazione e inizializzazione di \n                                  // &#039;condition&#039;\n        \n        if (condition) { // Inizio del blocco 1\n            System.out.println(&quot;Condition is true.&quot;); // Stampa se &#039;condition&#039; √® \n                                                      // true\n        } // Fine del blocco 1\n        \n        else { // Inizio del blocco 2\n            System.out.println(&quot;Condition is false.&quot;); // Stampa se &#039;condition&#039; √® \n                                                       // false\n        } // Fine del blocco 2\n    }\n}\nTipi di control flow Statements\n\nCondizionali (if, if-else, switch)\n\n\nif e if-else: Eseguono un blocco di codice solo se una condizione √® vera (true).\n\nint x = 10;\n \nif (x &gt; 5) {\n    System.out.println(&quot;x √® maggiore di 5&quot;);\n} \nelse {\n    System.out.println(&quot;x √® minore o uguale a 5&quot;);\n}\n\nswitch: Seleziona uno tra diversi blocchi di codice in base al valore di una variabile.\n\nint giorno = 1;\n \nswitch (giorno) {\n    case 1:\n        System.out.println(&quot;Luned√¨&quot;);\n        break;\n    case 2:\n        System.out.println(&quot;Marted√¨&quot;);\n        break;\n    default: // opzionale, se non lo metto non restituisce nulla e va bene\n        System.out.println(&quot;Altro giorno&quot;);\n}\n\n\n                  \n                  SWITCH ACCETTA String MA NON ACCETTA float, double, boolean.\n                  \n                \n\n\nCicli (for, while, do-while)\n\n\nfor: Ripete un blocco di codice per un numero definito di volte.\n\nfor (int i = 0; i &lt; 5; i++) {\n    System.out.println(&quot;Ripetizione numero &quot; + i);\n}\n\nwhile: Ripete un blocco finch√© una condizione √® vera.\n\nint i = 0;\n \nwhile (i &lt; 5) {\n    System.out.println(&quot;Ripetizione numero &quot; + i);\n    i++;\n}\n\ndo-while: Simile a while, ma garantisce che il blocco venga eseguito almeno una volta, perch√© la condizione √® verificata alla fine.\n\nint i = 0;\ndo {\n    System.out.println(&quot;Ripetizione numero &quot; + i);\n    i++;\n} while (i &lt; 5);\n\nInterruzioni di flusso (break, continue, return)\nESISTONO DUE TIPI di break\n\n\nbreak senza etichetta: Esce immediatamente dal ciclo o dal blocco switch.\n\nfor (int i = 0; i &lt; 10; i++) {\n    if (i == 5) {\n        break; // Interrompe il ciclo quando i √® 5\n    }\n    System.out.println(i);\n}\n\nbreak con etichetta (labeled): serve per uscire da cicli annidati, in pratica se scrivo un‚Äôetichetta, sotto un ciclo for con dentro un altro ciclo for, con questo tipo di break, se esco dal ciclo pi√π interno mi esce da tutto il blocco.\n\netichetta: // Etichetta per il ciclo esterno\nfor (int i = 0; i &lt; 3; i++) {\n    for (int j = 0; j &lt; 3; j++) {\n        if (i == 1 &amp;&amp; j == 1) {\n            break etichetta; // Esce dal ciclo esterno, si collega a etichetta e \n                             // salta TUTTO il blocco\n        }\n        System.out.println(&quot;i: &quot; + i + &quot;, j: &quot; + j);\n    }\n}\n\ncontinue: Salta l‚Äôiterazione corrente e passa a quella successiva del ciclo.\n\nfor (int i = 0; i &lt; 10; i++) {\n    if (i % 2 == 0) {\n        continue; // Salta i numeri pari\n    }\n    System.out.println(i);\n}\n\nreturn: Termina l‚Äôesecuzione di un metodo e pu√≤ restituire un valore.\n\npublic int somma(int a, int b) {\n    return a + b; // Interrompe il metodo e restituisce il risultato\n}\n\n\n                  \n                  DEVO SEMPRE SCRIVERE COSA RITORNARE, return da solo non va bene.\n                  \n                \n\n\n\n                  \n                  cosa succede se non uso le parentesi { } ad esempio in un if? \n                  \n                \n\njava non si basa sull‚Äôindentazione dobbiamo usare le graffe\n if(x&gt;10) \n\tnon esco;\n\tpiove;\nelse\n\troba;\nlui far√† se si verifica l‚Äôif non esco ma piove lo eseguir√† come un blocco che non dipende dall‚Äôif\n\n\nCLASSI\nUna classica dichiarazione di una classe √® questa\nclass esempioClasse {\n\t// campi\n\t// costruttore \n\t// metodi\n}\nDEFINIZIONI:\n\n\nCampi (o Attributi)\n\nsono variabili che rappresentano le caratteristiche o i dati di un oggetto.\ndefiniscono lo stato di un oggetto e sono dichiarati all‚Äôinterno della classe ma fuori dai metodi.\n\n\n\nCostruttore\n\n√® uno speciale metodo che viene chiamato automaticamente quando si crea un nuovo oggetto di una classe.\nserve per inizializzare i campi di un oggetto.\nha lo stesso nome della classe e non ha un tipo di ritorno.\n\n\n\nMetodi\n\nsono funzioni definite all‚Äôinterno di una classe che permettono di eseguire azioni o comportamenti specifici su un oggetto.\npossono modificare lo stato di un oggetto (cambiando i valori dei campi) o eseguire altre operazioni.\n\n\n\nDefiniamo una classe Automobile\npublic class Automobile {\n    \n    // La classe Automobile ha tre campi\n    public int velocit√†;\n    public int marcia;\n    public int livelloCarburante;\n    \n    // La classe Automobile ha un costruttore\n    public Automobile(int velocit√†Iniziale, int marciaIniziale, int \n                      livelloCarburanteIniziale) {\n        velocit√† = velocit√†Iniziale;\n        marcia = marciaIniziale;\n        livelloCarburante = livelloCarburanteIniziale;\n    }\n    \n    // La classe Automobile ha quattro metodi\n    public void cambiaMarcia(int nuovaMarcia) {\n        marcia = nuovaMarcia;\n    }\n    \n    public void accelera(int incremento) {\n        velocit√† += incremento;\n    }\n    \n    public void frena(int decremento) {\n        velocit√† -= decremento;\n    }\n    \n    public void rifornisci(int carburanteAggiunto) {\n        livelloCarburante += carburanteAggiunto;\n    }\n    \n}\nDove:\n\n\nCampi: velocit√†, marcia, livelloCarburante\n\nvelocit√†: rappresenta la velocit√† attuale dell‚Äôautomobile.\nmarcia: rappresenta la marcia attuale dell‚Äôautomobile.\nlivelloCarburante: rappresenta il livello di carburante nell‚Äôautomobile.\n\n\n\nCostruttore: Automobile(int velocit√†Iniziale, int marciaIniziale, int livelloCarburanteIniziale) che inizializza i campi dell‚Äôautomobile con i valori specificati quando viene creata una nuova istanza.\n\n\nMetodi:\n\ncambiaMarcia(int nuovaMarcia): cambia la marcia dell‚Äôautomobile.\naccelera(int incremento): aumenta la velocit√† dell‚Äôautomobile.\nfrena(int decremento): riduce la velocit√† dell‚Äôautomobile.\nrifornisci(int carburanteAggiunto): aggiunge carburante al serbatoio.\n\n\n\nSottoclasse\nPossiamo dare pi√π informazioni ad una classe, ad esempio immaginiamo che esempioClasse sia una sottoclasse:\nclass esempioClasse extends SuperClasse implements Interfaccia{\n\t// campi\n\t// costruttore \n\t// metodi\n}\nQuindi sappiamo che esempioClasse √® una sottoclasse di SuperClasse che implementa interfaccia\nCREIAMO ORA UNA SOTTOCLASE CHE ESTENDE AUTOMOBILE\npublic class AutomobileSportiva extends Automobile {\n    \n    // La sottoclasse AutomobileSportiva ha un campo\n    public int potenzaMotore; // potenza del motore in cavalli\n    \n    // La sottoclasse AutomobileSportiva ha un costruttore\n    public AutomobileSportiva(int potenzaIniziale, int velocit√†Iniziale,\n                              int marciaIniziale, int livelloCarburanteIniziale) {\n        super(velocit√†Iniziale, marciaIniziale, livelloCarburanteIniziale);\n        potenzaMotore = potenzaIniziale;\n    }\n    \n    // La sottoclasse AutomobileSportiva ha un metodo\n    public void aumentaPotenza(int incremento) {\n        potenzaMotore += incremento;\n    }  \n}\nHa tutte le caratteristiche di Automobile ma\n\nha un campo in pi√π, potenzaMotore\nil suo costruttore riprende quello di Automobile (con super) e aggiunge potenzaMotore\nha un metodo nuovo, aumentaPotenza\n\nIN GENERALE LA DICHIARAZIONE DI UNA CLASSE HA QUESTE COMPONENTI, IN ORDINE\n\nmodificatori come public, private e altri (che vedremo poi).\nil nome della classe.\nil nome della classe padre (superclass), se presente, deve essere preceduta da extends. Una classe pu√≤ essere figlia di un solo padre.\nl‚Äôinterfaccia, se presente, deve essere preceduta da implements. Se implementi pi√π interfacce, separale con ,.\nil corpo della classe deve trovarsi tra {}\n\nTipi di variabili\n\nVariabili di istanza (o campi):\n\nsono variabili definite direttamente all‚Äôinterno di una classe ma fuori da qualsiasi metodo.\nrappresentano le caratteristiche o lo stato di un oggetto della classe e sono quindi memorizzate per ogni istanza creata (ogni sottoclasse ha queste caratteristiche), e per questo vengono chiamate campi o variabili di istanza.\nsono composti da tre componenti, in ordine\n\nzero o pi√π modificatori, come public o private\nil tipo\nil nome\n\n\n\n\n\npublic class Automobile {\n    // Variabili di istanza\n    private int velocit√†;\n    private int marcia;\n    private int livelloCarburante;\n    \n    // Costruttore per inizializzare le variabili di istanza\n    public Automobile(int velocit√†Iniziale, int marciaIniziale, int \n                      livelloCarburanteIniziale) {\n        velocit√† = velocit√†Iniziale;\n        marcia = marciaIniziale;\n        livelloCarburante = livelloCarburanteIniziale;\n    }\n}\n\nVariabili locali:\n\nsono dichiarate all‚Äôinterno di un metodo, un blocco di codice, o un costruttore.\nesistono solo all‚Äôinterno di quello specifico metodo o blocco e non possono essere utilizzate all‚Äôesterno di esso.\nnon conservano il valore quando il metodo termina.\n\n\n\npublic class EsempioVariabiliLocali {\n\t\n    public void calcolaDistanza() {\n        // Variabile locale\n        int distanzaPercorsa = 100;\n        \n        // Uso della variabile locale\n        System.out.println(&quot;La distanza percorsa √®: &quot; + distanzaPercorsa + &quot; km&quot;);\n    }\n}\n\nParametri:\n\nsono variabili che vengono dichiarate all‚Äôinterno della firma di un metodo.\nservono per ricevere valori passati al metodo quando viene chiamato.\nesistono solo all‚Äôinterno del metodo in cui sono definiti.\n\n\n\npublic class EsempioParametri {\n\t\n    public void impostaVelocit√†(int nuovaVelocit√†) {\n        // `nuovaVelocit√†` √® un parametro\n        System.out.println(&quot;Imposta la velocit√† a: &quot; + nuovaVelocit√† + &quot; km/h&quot;);\n    }\n}\nModificatori d‚Äôaccesso\nAbbiamo visto prima due modificatori, public e private (ma ce ne sono anche altri).\nQuesti servono per definire chi pu√≤ accedere a variabili (campi), metodi e costruttori di una classe:\n\n\npublic: rende accessibile un campo o un metodo a tutte le altre classi. Se un campo √® public, pu√≤ essere visto e modificato direttamente da qualunque classe (sottoclassi e non).\n\n\nprivate: limita l‚Äôaccesso a un campo o un metodo solo alla classe stessa. Questo significa che nessun‚Äôaltra classe pu√≤ accedere direttamente ai campi private.\n\n\n\n\n                  \n                  anche il main √® in una classe quindi non pu√≤ accedere ai campi privati di altre classi \n                  \n                \n\nIncapsulamento\n√à un concetto che consiste nel mantenere i dati privati all‚Äôinterno della classe, permettendo l‚Äôaccesso solo tramite metodi pubblici. Questo permette di controllare e proteggere i dati di una classe e di evitare che vengano modificati in modo imprevisto o non autorizzato.\npublic class Persona {\n    \n    // Campo privato\n    private String nome;\n    \n    // Costruttore per inizializzare il nome\n    public Persona(String nomeIniziale) {\n        nome = nomeIniziale; \n    }\n    \n    // Metodo pubblico per ottenere il valore di nome (getter)\n    public String getNome() {\n        return nome;\n    }\n    \n    // Metodo pubblico per impostare un nuovo valore per nome (setter)\n    public void setNome(String nuovoNome) {\n        if (nuovoNome != null &amp;&amp; !nuovoNome.isEmpty()) { // controllo per evitare \n                                                         // nomi vuoti\n            nome = nuovoNome; \n        } else {\n            System.out.println(&quot;Il nome non pu√≤ essere vuoto.&quot;);\n        }\n    }\n}\nI metodi get e set servono per accedere ai campi privati dall‚Äôesterno della classe\n\nun getter restituisce il valore di un campo\nun setter contente di modificate il valore di un campo\n\nCOSE NON CAPITE A LEZIONE DA LUCA\n\n\n                  \n                  Un metodo statico non puo accederea gli attributi dell&#039;oggetto \n                  \n                \n\nCosa significa static?\n\nUn metodo o una variabile dichiarata come static appartiene alla classe stessa, non a una singola istanza (oggetto) della classe.\nQuesto significa che puoi usare i metodi o le variabili static senza creare un oggetto della classe.\n\nVariabili di istanza vs Variabili statiche\n\nVariabili di istanza: sono specifiche per ogni oggetto della classe. Ogni volta che crei un nuovo oggetto, ottiene la propria copia di queste variabili.\nVariabili statiche: sono condivise da tutti gli oggetti della classe e appartengono alla classe stessa, non a singoli oggetti.\n\nPerch√© un metodo static non pu√≤ accedere alle variabili di istanza?\n\n\nUn metodo static non ‚Äúvede‚Äù nessuna istanza della classe (cio√® nessun oggetto specifico). Poich√© le variabili di istanza appartengono a singoli oggetti, un metodo static non pu√≤ accedervi direttamente, perch√© non sa quale oggetto dovrebbe ‚Äúvedere‚Äù.\n\n\nInvece, un metodo static pu√≤ accedere solo alle variabili e metodi statici, perch√© questi appartengono alla classe, proprio come il metodo static.\n\n\n                  \n                  Si parte da questa frase \n                  \n                \n\nLa dimensione dei dati primitivi √® invariante perch√® tutto √® adattato alla jvm il byte √® un byte invece un char √® un carattere 16bit¬†flat.\nIn java ‚Äúflat‚Äù si riferisce al fatto che il tipo di dato √® di dimensione fissa e non cambia indipendentemente dalla piattaforma o dal sistema operativo su cui gira il programma. In Java, i tipi primitivi (come byte, int, char) hanno una dimensione precisa e invariabile, che √® garantita dalla Java Virtual Machine (JVM).\nQuando si dice che un char √® un carattere ‚Äú16-bit flat‚Äù in Java, significa che:\n\nOgni variabile di tipo char occupa esattamente 16 bit (2 byte) di spazio in memoria.\nQuesto √® un valore fisso e non dipende dalla piattaforma (Windows, Linux, ecc.) o dall‚Äôarchitettura del sistema (32-bit o 64-bit).\n\n\n\nMetodi\nGli unici elementi di base richiesti nella dichiarazione di un metodo sono\n\nil tipo restituito\nil nome\nun paio di parentesi ()\nun corpo tra le graffe {}\n\nIN GENERALE, la dichiarazione di un metodo ha sei componenti, in ordine.\npublic int calcolaDoppio(int numero) {     return numero * 2; }\n\n\nModificatori\n\npublic\nprivate\necc.\n\n\n\nTipo di Ritorno\n\nnel nostro caso int, il che vuol dire che quel metodo restituir√† un intero\nallo stesso modo abbiamo float, double, ecc.\nse un metodo non restituisce alcun valore si usa void\n\n\n\nNome del metodo Viene utilizzato come un‚Äôetichetta che ci permette di chiamare o riferirci a questo metodo in altre parti del programma.\n\nnel nostro caso calcolaDoppio (convenzionalmente in java si usa il camelCase).\n\n\n\nLista di parametri Sono variabili di input che il metodo riceve per lavorare. Se un metodo non richiede parametri, si usano parentesi vuote ().\n\nnel nostro caso (int numero)\n\n\n\nLista di eccezioni (la vedremo poi)\n\n\nCorpo del metodo √à il blocco di codice tra graffe {}. Pu√≤ contenere calcoli, dichiarazioni di variabili locali, controlli condizionali, ecc.\n\nnel nostro caso { return numero * 2; }.\n\n\n\nNomi di un metodo\nper quanto uno possa dare qualsiasi nome a un metodo ci sono dei nomi che vengono usati per convenzione, scritti in camelCase\n\nrun\nrunFast\ngetBackground\ngetFinalData\ncompareTo\nsetX\nisEmpty\n\nDEFINIZIONE: FIRMA La firma del metodo (o method signature) √® una combinazioni di due componenti della dichiarazione di un metodo.\n\nnome del metodo\ntipi dei parametri del metodo, nell‚Äôordine in cui appaiono\n\nLa firma di un metodo non include n√© il tipo di ritorno n√© i nomi dei parametri; conta solo il nome del metodo e i tipi dei parametri.\nPerch√© la Firma del Metodo √® Importante?\nLa firma del metodo √® ci√≤ che distingue un metodo dagli altri all‚Äôinterno di una classe. Java utilizza la firma per capire quale metodo chiamare in caso di overloading (sovraccarico di metodi), cio√® quando esistono pi√π metodi con lo stesso nome ma con tipi o numeri di parametri diversi.  Esempio Consideriamo questi metodi\n&gt;public class Calcolatrice {     public int somma(int a, int b) {         return a + b;     }      public double somma(double a, double b) {         return a + b;     }      public int somma(int a, int b, int c) {         return a + b + c;     } }\nIn questo esempio, tutti e tre i metodi si chiamano somma, ma le loro firme sono diverse:\n\nsomma(int, int) ‚Äì nome del metodo somma e parametri int, int.\nsomma(double, double) ‚Äì nome del metodo somma e parametri double, double.\nsomma(int, int, int) ‚Äì nome del metodo somma e parametri int, int, int.\n\nMetodi di Overload\nJava distingue i metodi con lo stesso nome all‚Äôinterno di una classe dalle differenze nel passaggio di parametri\nSe vuoi ad esempio usare dei metodi simili in una classe sarebbe una rottura trovare dei nuovi modi per chiamare ogni metodo, e qui entra in gioco l‚Äôoverloading\npublic class DataArtist {\n    ...\n    public void draw(String s) {\n        ...\n    }\n    public void draw(int i) {\n        ...\n    }\n    public void draw(double f) {\n        ...\n    }\n    public void draw(int i, double f) {\n        ...\n    }\n}\n \nsono tutti dei metodi distinti perch√© alla loro chiamata richiedono argomenti diversi\nCostruttori\nUn costruttore √® un blocco di codice speciale in una classe che viene chiamato quando viene creato un nuovo oggetto. Serve per inizializzare l‚Äôoggetto, impostando i valori iniziali dei campi (attributi) secondo le specifiche desiderate.\nCome Appare un Costruttore? Un costruttore:\n\nHa lo stesso nome della classe.\nNon ha un tipo di ritorno (non pu√≤ essere void o altro).\n\nCreare un oggetto con un costruttore Riprendendo la classe Automobile che abbiamo visto prima, possiamo creare un oggetto inserendo nel main questo:\nAutomobile fiatPunto = new Automobile(0, 1, 60)\nQuesto codice:\n\nAlloca spazio in memoria per un nuovo oggetto Automobile.\nChiama il costruttore Automobile(int, int, int) per inizializzare i campi velocit√†, marcia, e livelloCarburante con i valori 0, 1, e 60, rispettivamente.\n\nCostruttori Multipli Una classe pu√≤ avere pi√π costruttori, ciascuno con un diverso numero e tipo di parametri. Questo √® utile per creare oggetti con diverse configurazioni iniziali.\npublic class Bicycle {     \nprivate int gear;     \nprivate int cadence;     \nprivate int speed;      // Costruttore senza argomenti (no-argument constructor)     \npublic Bicycle() {         \ngear = 1;         \ncadence = 10;         \nspeed = 0;    \n} \n}\nCostruttori di Default Se non dichiari nessun costruttore, il compilatore Java crea ‚Äúautomaticamente‚Äù (se lo crea da solo ma noi non lo vediamo) un costruttore di default senza argomenti per la tua classe. Questo costruttore chiama il costruttore senza argomenti della superclasse, e al massimo mette i valori di default degli attributi che abbiamo messo nella classe.\nUso dei Costruttori della Superclasse In una classe che estende un‚Äôaltra (sottoclasse), puoi chiamare il costruttore della superclasse usando super(...). Questo permette di inizializzare i campi della superclasse.\nPassare informazioni a un metodo o ad un costruttore\nDue concetti fondamentali\n\nParametri: sono le variabili dichiarate nella firma del metodo o del costruttore. Sono come ‚Äúsegnaposto‚Äù per i dati che il metodo user√† quando viene chiamato.\nArgomenti: sono i valori reali passati al metodo al momento della chiamata, che devono corrispondere in tipo e ordine ai parametri.\n\nESEMPIO\npublic class Calcolatrice {\n    \n    // Metodo che somma due numeri\n    public int somma(int numero1, int numero2) {\n        int risultato = numero1 + numero2;\n        return risultato;\n    }\n}\n \npublic class Main {\n    public static void main(String[] args) {\n        Calcolatrice calc = new Calcolatrice(); // Crea un oggetto Calcolatrice\n        \n        int risultato = calc.somma(5, 3); // Chiama il metodo somma con gli \n                                          // argomenti 5 e 3\n        System.out.println(&quot;La somma √®: &quot; + risultato); // Stampa: La somma √®: 8\n    }\n}\n\nParametri: int numero1, int numero2\nArgomenti: 5 (assegnato a int numero1) e 3 (assegnato a int numero2)\n\nPassare un numero variabile di argomenti\nQuando non sappiamo in anticipo quanti argomenti verranno passati al metodo possiamo usare una funzionalit√† java chiamata varargs (variadic arguments).\nCome funziona?\nQuando dichiari un metodo, scrivi\n\ntipo del parametro\ntre puntini e spazio (... )\nnome parametro\nIn questo modo, all‚Äôinterno del metodo questo parametro verr√† trattato come un array.\n\nESEMPIO\npublic class Calcolatrice {\n\t\n    // Metodo con varargs che accetta un numero variabile di int\n    public int somma(int... numeri) {  // ho usato il varargs, numeri verr√† \n                                       // trattato come un array di interi (int[])\n        int sommaTotale = 0;\n        for (int numero : numeri) {  // utilizzo il for-each\n            sommaTotale += numero;\n        }\n        return sommaTotale;\n    }\n}\n \n// vediamo nel main come funziona\npublic class Main {\n    public static void main(String[] args) {\n        Calcolatrice calc = new Calcolatrice();\n\t\t\n        System.out.println(calc.somma(1, 2, 3));          // Output: 6\n        System.out.println(calc.somma(10, 20));           // Output: 30\n        System.out.println(calc.somma(5, 10, 15, 20, 25)); // Output: 75\n        System.out.println(calc.somma());                 // Output: 0 (nessun \n                                                          // numero passato)\n    }\n}\n\n\n                  \n                   Cosa Accade in Questo Codice?\n                  \n                \n\n\nQuando chiamiamo calc.somma(1, 2, 3), numeri diventa un array [1, 2, 3], e il metodo restituisce 6.\nQuando chiamiamo calc.somma(10, 20), numeri √® [10, 20], e il metodo restituisce 30.\nQuando chiamiamo calc.somma(5, 10, 15, 20, 25), numeri √® [5, 10, 15, 20, 25], e il metodo restituisce 75.\nQuando chiamiamo calc.somma(), numeri √® un array vuoto [], e il metodo restituisce 0.\n\n\n\nUTILIT√Ä PRATICA DEL VARARGS\nIl varargs pu√≤ accettare anche tipi di dati contemporaneamente utilizzando Object... NOME\n\n\n                  \n                  OBJECT \n                  \n                \n\nIn Java, Object √® un tipo di dato (pi√π precisamente, √® la classe base di tutte le classi).\nQuindi io posso creare un array di Object (Object[]) che pu√≤ contenere qualsiasi tipo di oggetto.\n\n\nESEMPIO\npublic class Utility {\n \n    // Metodo con varargs di tipo Object, accetta qualsiasi tipo di oggetto\n    public void stampaOggetti(Object... oggetti) {\n        for (Object oggetto : oggetti) {\n            System.out.println(oggetto);\n        }\n    }\n}\n \n// ora utilizziamolo nel main\npublic class Main {\n    public static void main(String[] args) {\n        Utility cose = new Utility();\n\t\t\n        // Passiamo diversi tipi di argomenti\n        cose.stampaOggetti(&quot;Ciao&quot;, 123, 45.67, true, &#039;A&#039;);\n    }\n}\nOUTPUT\nCiao\n123\n45.67\ntrue\nA\nLIMITAZIONI DI VARARGS\n\n\nPosso passare un solo parametro varargs per metodo.\nESEMPIO VALIDO\npublic void metodoConVarargs(int... numeri) {\n    // codice\n}\nESEMPIO NON VALIDO\n\n\n\tpublic void metodoNonValido(int... numeri, String... parole) { \n\t    // codice\n\t}\n \n\n\nIl parametro varargs (...) deve essere l‚Äôultimo nella lista di parametri\nESEMPIO VALIDO\npublic void metodoConVarargs(String nome, int... Cose) {\n    // codice\n}\nESEMPIO NON VALIDO\n\n\n\tpublic void metodoNonValido(int... Cose, String nome) { \n\t    // codice\n\t}\nShadowing in java\nIn java non si mettono parametri con lo stesso nome in un metodo\npublic void exampleMethod(int number, int number) {\n    // This will cause a compilation error\n}\n \nper√≤ potrebbe accadere che tu abbia dei parametri che hanno lo stesso nome di alcuni attributi della classe, per ovviare a questo usiamo il this ma lo vedremo poi\npublic class Circle {\n    private int x, y, radius;\n    public void setOrigin(int x, int y) {\n        ...\n    }\n}\nOGGETTI\nLi abbiamo gi√† visti, ma facciamo un altro esempio.\nProveremo a creare due oggetti Giocatore e Squadra\npublic class Giocatore {\n    String nome;\n    int numero;\n \n    // Costruttore per inizializzare nome e numero\n    public Giocatore(String n, int num) {\n        nome = n;   // Assegna il parametro `n` al campo `nome`\n        numero = num; // Assegna il parametro `num` al campo `numero`\n    }\n \n    // Metodo per cambiare il numero di maglia\n    public void cambiaNumeroMaglia(int nuovoNumero) {\n        numero = nuovoNumero; // Cambia il numero di maglia\n    }\n \n    // Metodo per visualizzare le informazioni del giocatore\n    public void mostraInfo() {\n        System.out.println(&quot;Nome: &quot; + nome + &quot;, Numero: &quot; + numero);\n    }\n}\n \npublic class Main {\n    public static void main(String[] args) {\n        // Creiamo alcuni oggetti Giocatore\n        Giocatore Rin = new Giocatore(&quot;Rin&quot;, 10);\n        Giocatore Isagi = new Giocatore(&quot;Isagi&quot;, 11);\n \n        // Cambiamo il numero di maglia dei giocatori\n        Rin.cambiaNumeroMaglia(11);\n        Isagi.cambiaNumeroMaglia(10);\n \n        // Visualizziamo le informazioni dei giocatori\n        Rin.mostraInfo();\n        Isagi.mostraInfo();\n    }\n}\n \nAccedere ai campi di un oggetto all‚Äôinterno della classe\nQuando scrivi un metodo all‚Äôinterno di una classe, puoi accedere direttamente ai campi (o attributi) della classe semplicemente usando i loro nomi. Vediamo un esempio con una classe Rettangolo che ha due campi: larghezza e altezza.\npublic class Rettangolo {\n    int larghezza;\n    int altezza;\n\t\n    // Costruttore per impostare larghezza e altezza\n    public Rettangolo(int w, int h) {\n        larghezza = w;\n        altezza = h;\n    }\n\t\n\t// Metodo per calcolare l&#039;area del rettangolo\n    public int calcolaArea() {\n        return larghezza * altezza;\n    }\n}\nQui:\n\nAll‚Äôinterno della classe Rettangolo, possiamo accedere ai campi larghezza e altezza direttamente usando i loro nomi (larghezza e altezza) perch√© siamo all‚Äôinterno della stessa classe.\n\nQuando chiamiamo mostraDimensioni(), questo metodo stampa i valori di larghezza e altezza dell‚Äôoggetto.\nAccedere ai campi e/o metodi di un oggetto dall‚Äôesterno della classe\nQuando usi un oggetto della classe Rettangolo in un‚Äôaltra classe, come nel main, per accedere ai suoi campi hai bisogno di usare il nome dell‚Äôoggetto seguito da un punto (.), e poi il nome del campo.\npublic class Main {\n    public static void main(String[] args) {\n        // Creiamo un oggetto Rettangolo\n        Rettangolo rettangolo1 = new Rettangolo(10, 20);\n\t\t\n        // Accediamo ai campi dall&#039;esterno della classe Rettangolo\n        System.out.println(&quot;Larghezza di rettangolo1: &quot; + rettangolo1.larghezza);\n        System.out.println(&quot;Altezza di rettangolo1: &quot; + rettangolo1.altezza);\n    }\n    \n\t\t// Chiamiamo il metodo calcolaArea sull&#039;oggetto rettangolo1\n        int area = rettangolo1.calcolaArea();\n\t\n        // Stampiamo l&#039;area\n        System.out.println(&quot;L&#039;area di rettangolo1 √®: &quot; + area);\n}\nQui:\n\nrettangolo1.larghezza accede al campo larghezza dell‚Äôoggetto rettangolo1.\nrettangolo1.altezza accede al campo altezza dell‚Äôoggetto rettangolo1.\nrettangolo1.calcolaArea() accede al metodo calcoloArea() dell‚Äôoggetto rerttangolo1.\n\nPoich√© stiamo accedendo ai campi dall‚Äôesterno della classe Rettangolo, dobbiamo usare il riferimento all‚Äôoggetto (rettangolo1) per specificare di quale oggetto stiamo parlando.\nOgni oggetto ha i propri campi\nOggetti dello stesso tipo hanno campi con lo stesso nome, ma ogni oggetto ha la propria copia di quei campi. Questo significa che se creiamo due oggetti Rettangolo, ognuno avr√† i propri valori per larghezza e altezza.\npublic class Main {\n    public static void main(String[] args) {\n        // Creiamo due oggetti Rettangolo con dimensioni diverse\n        Rettangolo rettangolo1 = new Rettangolo(10, 20);\n        Rettangolo rettangolo2 = new Rettangolo(15, 25);\n\t\t\n        // Mostriamo le dimensioni dei due rettangoli\n        System.out.println(&quot;Dimensioni di rettangolo1: Larghezza = &quot; + \n                            rettangolo1.larghezza + &quot;, Altezza = &quot; + \n                            rettangolo1.altezza);\n        System.out.println(&quot;Dimensioni di rettangolo2: Larghezza = &quot; + \n                            rettangolo2.larghezza + &quot;, Altezza = &quot; + \n                            rettangolo2.altezza);\n    }\n}\nQui, rettangolo1 e rettangolo2 hanno campi larghezza e altezza indipendenti. Quando accediamo a rettangolo1.larghezza o rettangolo2.larghezza, vediamo i valori specifici di ciascun oggetto.\nCreare un Oggetto e Accedere Direttamente al Campo\nPuoi anche creare un nuovo oggetto e accedere immediatamente a uno dei suoi campi, senza salvare l‚Äôoggetto in una variabile. Ad esempio:\nint altezza = new Rettangolo(10, 20).altezza;\nSystem.out.println(&quot;Altezza del nuovo rettangolo: &quot; + altezza);\nIn questo caso:\n\nCreiamo un nuovo Rettangolo con larghezza = 10 e altezza = 20.\nAccediamo direttamente al campo altezza e salviamo il valore in altezza.\n\nDopo questa riga, non abbiamo pi√π nessun riferimento al Rettangolo creato, quindi l‚Äôoggetto potrebbe essere eliminato dalla memoria dal Garbage Collector perch√© non √® pi√π utilizzabile.\nGarbage Collector\nIl Garbage Collector (GC) in Java √® un meccanismo automatico che gestisce la memoria, liberando spazio occupato da oggetti non pi√π utilizzati dal programma. In pratica, quando un oggetto non ha pi√π riferimenti che lo puntano, il Garbage Collector lo elimina per recuperare la memoria.\nCome Funziona il Garbage Collector?\n\n\nCreazione di Oggetti: Ogni volta che creiamo un nuovo oggetto con new, Java riserva uno spazio in memoria per quell‚Äôoggetto.\n\n\nRiferimenti agli Oggetti: Finch√© una variabile punta a quell‚Äôoggetto, esso √® considerato ‚Äúin uso‚Äù. Se la variabile cambia valore o esce dal suo ambito (come una variabile locale che viene eliminata al termine di un metodo), l‚Äôoggetto pu√≤ diventare non pi√π raggiungibile.\n\n\nOggetti Non Raggiungibili: Quando non ci sono pi√π riferimenti a un oggetto, Java lo considera non pi√π necessario. Questo √® un segnale per il Garbage Collector che l‚Äôoggetto pu√≤ essere eliminato dalla memoria.\n\n\nEsecuzione del Garbage Collector: Java, in automatico e a intervalli regolari, esegue il Garbage Collector per trovare e rimuovere questi oggetti inutilizzati, liberando cos√¨ la memoria per nuovi oggetti.\n\n\nESEMPIO\npublic class Main {\n    public static void main(String[] args) {\n        Persona p1 = new Persona(&quot;Mario&quot;); // Crea un nuovo oggetto Persona\n        Persona p2 = new Persona(&quot;Luigi&quot;); // Crea un altro oggetto Persona\n        \n        p1 = null; // p1 non punta pi√π a &quot;Mario&quot;\n        p2 = null; // p2 non punta pi√π a &quot;Luigi&quot;\n        \n        // A questo punto, entrambi gli oggetti &quot;Mario&quot; e &quot;Luigi&quot; non sono pi√π \n        // raggiungibili e saranno eliminati dal Garbage Collector in un momento \n        // successivo\n    }\n}\nRitorno di un valore da un metodo\nUn metodo in Java ritorna al punto in cui √® stato chiamato in tre situazioni:\n\nQuando completa tutte le istruzioni all‚Äôinterno del metodo.\nQuando raggiunge un‚Äôistruzione return.\nQuando lancia un‚Äôeccezione (un concetto che verr√† trattato successivamente).\n\nIn altre parole, appena il metodo ha finito di eseguire il suo lavoro in uno di questi modi, restituisce il controllo al codice che lo ha invocato.\nDichiarare il Tipo di Ritorno di un Metodo\nQuando si dichiara un metodo, si deve specificare il tipo di dato che il metodo restituir√†. Questo viene indicato prima del nome del metodo. All‚Äôinterno del corpo del metodo, utilizziamo l‚Äôistruzione return per specificare il valore che vogliamo restituire.\nMetodo void (che Non Ritorna Valori)\nUn metodo dichiarato come void non restituisce alcun valore. Poich√© non restituisce nulla, non √® necessario includere un‚Äôistruzione return all‚Äôinterno del metodo.\nTuttavia, √® possibile utilizzare return; per uscire dal metodo in determinati punti, se necessario. In questo caso, return; funziona come un‚Äôistruzione per uscire dal metodo e basta, senza restituire alcun valore.\nESEMPIO\npublic void stampaMessaggio() {\n    System.out.println(&quot;Questo √® un messaggio.&quot;);\n    return; // Questo return termina l&#039;esecuzione del metodo\n}\n\n\n                  \n                  Se provo a far ritornare qualcosa dal void mi da errore. Posso solo usare return;\n                  \n                \n\nMetodi che Non Sono Dichiarati void\nQualsiasi metodo che non √® dichiarato void deve avere un‚Äôistruzione return con un valore da restituire, in questo formato:\nreturn valoreDiRitorno;\nIl tipo di dato del valore restituito (dopo return) deve corrispondere al tipo di ritorno dichiarato del metodo. Ad esempio, se un metodo √® dichiarato per restituire un int, non √® possibile restituire un valore boolean, perch√© i tipi non corrispondono.\n\n\n                  \n                  MANCA LA PARTE RETURN AN OBJECT E RETURN A CLASS OR INTERFACE \n                  \n                \n\nParola chiave: This\nIn Java, la parola chiave this rappresenta il riferimento all‚Äôoggetto corrente. Serve per distinguere i campi (o attributi) dell‚Äôoggetto dai parametri del metodo o del costruttore, soprattutto quando hanno lo stesso nome.\nESEMPIO\nImmaginiamo di avere una classe Persona con un campo nome che rappresenta il nome di una persona. Vogliamo creare un costruttore che prenda un parametro nome per impostare il valore di questo campo.\npublic class Persona {\n    String nome; // Campo della classe\n\t\n    // Costruttore\n    public Persona(String nome) {\n        // Usando `this` per distinguere il campo `nome` dal parametro `nome`\n        this.nome = nome;\n    }\n}\nIn questo esempio:\n\nString nome √® un campo della classe Persona.\nNel costruttore, nome √® anche il nome del parametro.\n\nQuando scriviamo this.nome = nome;:\n\nthis.nome si riferisce al campo nome della classe Persona (l‚Äôoggetto stesso).\nnome (senza this) si riferisce al parametro del costruttore.\n\nIL MAIN RIMANE COME LO CONOSCIAMO, IL ‚ÄúCAMBIAMENTO‚Äù AVVIENE SOLO NELLA CLASSE\nCOSE NON CAPITE A LEZIONE DA LUCA\n\n\n                  \n                  Un metodo statico non puo accederea gli attributi dell&#039;oggetto \n                  \n                \n\nCosa significa static?\n\nUn metodo o una variabile dichiarata come static appartiene alla classe stessa, non a una singola istanza (oggetto) della classe.\nQuesto significa che puoi usare i metodi o le variabili static senza creare un oggetto della classe.\n\nVariabili di istanza vs Variabili statiche\n\nVariabili di istanza: sono specifiche per ogni oggetto della classe. Ogni volta che crei un nuovo oggetto, ottiene la propria copia di queste variabili.\nVariabili statiche: sono condivise da tutti gli oggetti della classe e appartengono alla classe stessa, non a singoli oggetti.\n\nPerch√© un metodo static non pu√≤ accedere alle variabili di istanza?\n\n\nUn metodo static non ‚Äúvede‚Äù nessuna istanza della classe (cio√® nessun oggetto specifico). Poich√© le variabili di istanza appartengono a singoli oggetti, un metodo static non pu√≤ accedervi direttamente, perch√© non sa quale oggetto dovrebbe ‚Äúvedere‚Äù.\n\n\nInvece, un metodo static pu√≤ accedere solo alle variabili e metodi statici, perch√© questi appartengono alla classe, proprio come il metodo static.\n\n\n                  \n                  Si parte da questa frase \n                  \n                \n\nLa dimensione dei dati primitivi √® invariante perch√® tutto √® adattato alla jvm il byte √® un byte invece un char √® un carattere 16bit¬†flat.\nIn java ‚Äúflat‚Äù si riferisce al fatto che il tipo di dato √® di dimensione fissa e non cambia indipendentemente dalla piattaforma o dal sistema operativo su cui gira il programma. In Java, i tipi primitivi (come byte, int, char) hanno una dimensione precisa e invariabile, che √® garantita dalla Java Virtual Machine (JVM).\nQuando si dice che un char √® un carattere ‚Äú16-bit flat‚Äù in Java, significa che:\n\nOgni variabile di tipo char occupa esattamente 16 bit (2 byte) di spazio in memoria.\nQuesto √® un valore fisso e non dipende dalla piattaforma (Windows, Linux, ecc.) o dall‚Äôarchitettura del sistema (32-bit o 64-bit).\n\n\n"},"UNI/ANNO-2/LINGUAGGI/LINGUAGGI-LEZ.8":{"slug":"UNI/ANNO-2/LINGUAGGI/LINGUAGGI-LEZ.8","filePath":"UNI/ANNO 2/LINGUAGGI/LINGUAGGI LEZ.8.md","title":"LINGUAGGI LEZ.8","links":[],"tags":[],"content":"Livelli di Accesso\n\n\npublic: visibile a tutti. Se un campo o un metodo √® public, qualsiasi classe, in qualsiasi pacchetto, pu√≤ accedervi.\n\n\nprotected: visibile all‚Äôinterno del package in cui √® definito, e nelle sottoclassi (anche se sono in un altro pacchetto). Viene usato spesso quando vuoi che una variabile o un metodo sia accessibile solo dalle classi che derivano da quella principale.\n\n\npackage-private (nessun modificatore): se non scrivi nulla, il campo o metodo √® visibile solo all‚Äôinterno del package in cui si trova la classe. Questo √® utile quando vuoi che qualcosa sia accessibile alle classi che fanno parte dello stesso gruppo (pacchetto), ma non fuori.\n\n\nprivate: visibile solo all‚Äôinterno della classe in cui √® dichiarato. private √® il modificatore pi√π restrittivo e viene usato quando non vuoi che nessun‚Äôaltra classe possa accedere a quella variabile o metodo.\n\n\nTABELLA\nIn questa tabella possiamo vedere, in base al modificatore, chi pu√≤ vederne il contenuto\nNB: per WORLD si intende dentro e fuori il pacchetto.\n\nclass significa se gli elementi in quella classe possono vedere se stessi\ngli elementi che stanno nello stesso package possono vedersi tra di loro?\nda una sottoclasse posso vedere gli elementi della super classe\nal livello globale posso vedere gli elementi delle altre classi ecc‚Ä¶\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMODIFICATORECLASSIPACCHETTOSOTTOCLASSIWORLDpublicSISISISIprotectedSISISINOnessun modificatoreSISINONOprivateSINONONO\nESEMPI\npublic class Alpha {\n\t// CAMPI\n    public int campoPubblico;   // Visibile a tutti\n    protected int campoProtetto; // Visibile solo nel pacchetto e nelle sottoclassi\n    int campoSenzaModificatore; // Visibile solo nel pacchetto\n    private int campoPrivato;   // Visibile solo all&#039;interno di Alpha\n\t\n    \n    // METODI\n    public void metodoPubblico() { /*...*/ }\n    protected void metodoProtetto() { /*...*/ }\n    void metodoSenzaModificatore() { /*...*/ }\n    private void metodoPrivato() { /*...*/ }\n}\nALTRO ESEMPIO\nImmaginiamo di avere due pacchetti cos√¨\n\nOra vediamo dove posso vedere i membri della classe Alpha (ossia le sue variabili e i suoi metodi) in base ai modificatori che abbiamo visto prima\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMODIFICATOREALPHABETAALPHASUBGAMMApublicSISISISIprotectedSISISINOnessun modificatoreSISINONOprivateSINONONO\n\n\n                  \n                  Alcuni consigli utili \n                  \n                \n\nConsigli Pratici\n\n\nUsa private il pi√π possibile: rende il codice pi√π sicuro, perch√© nessuna classe pu√≤ modificare direttamente i campi privati.\n\n\nEvita campi public, a meno che siano costanti (cio√® variabili il cui valore non cambia). Questo perch√© i campi pubblici rendono difficile cambiare l‚Äôimplementazione della tua classe in futuro senza rompere il codice di chi la usa.\n\n\nUtilizza protected solo per le sottoclassi: √® utile quando pensi che le classi che derivano dalla tua (subclassi) abbiano bisogno di accedere a un campo o metodo, ma altre classi no.\n\n\nScegli package-private (nessun modificatore) per metodi e campi che devono essere usati solo da classi dello stesso pacchetto, ma non dovrebbero essere accessibili da fuori.\n\n\n\n\n\nIn Java, la parola chiave static viene utilizzata per definire membri a livello di classe, il che significa che appartengono alla classe stessa piuttosto che a una specifica istanza della classe. Questo √® applicabile sia alle variabili che ai metodi.\nVariabili di Classe (Campi Statici)\nQuando un campo √® dichiarato come static, significa che esiste solo una copia di quella variabile, condivisa tra tutte le istanze della classe. Questo √® utile per i dati che devono essere coerenti tra tutti gli oggetti.\npublic class Bicicletta {\n    private int id;\n    private static int numeroDiBiciclette = 0;\n\t\n    public Bicicletta() {\n        id = ++numeroDiBiciclette;\n    }\n}\nIn questo esempio, numeroDiBiciclette √® un campo statico che tiene traccia di quante istanze della classe Bicicletta sono state create. Ogni nuovo oggetto Bicicletta incrementa questo conteggio e assegna a s√© stesso un id unico.\nMetodi di Classe (Metodi Statici)\nI metodi statici sono associati alla classe piuttosto che a un oggetto particolare. Possono essere chiamati senza creare un‚Äôistanza della classe.\npublic class Bicicletta {\n    private static int numeroDiBiciclette = 0;\n \n    public static int getNumeroDiBiciclette() {\n        return numeroDiBiciclette;\n    }\n}\nQui, getNumeroDiBiciclette √® un metodo statico che restituisce il numero totale di istanze Bicicletta create.\nPu√≤ essere chiamato usando Bicicletta.getNumeroDiBiciclette() senza bisogno di istanziare un oggetto Bicicletta (ad esempio posso chiamarlo direttamente nel main).\nil metodo dipende dallo stato dell‚Äôoggetto che lo chiama\nE se io volessi fare qualcosa di indipendente dallo stato dell‚Äôoggetto?\nuso static per fare funzioni\nCostanti\nOvviamente posso usare static anche con le costanti, in combinazione con final (che non mi permette pi√π di modificarla).\n\nInizializzazione campi\nL‚Äôinizializzazione dei campi di una classe pu√≤ essere gestita in diversi modi.\nInizializzazione diretta\n√à possibile assegnare un valore iniziale a un campo direttamente nella sua dichiarazione. Questo approccio √® semplice e funziona bene quando il valore √® noto e non richiede logica complessa.\npublic class Esempio {\n    private int numero = 10;\n    private String testo = &quot;Ciao&quot;;\n}\nInizializzazione nei costruttori\nI costruttori permettono di inizializzare i campi al momento della creazione di un‚Äôistanza della classe. Questo √® utile quando l‚Äôinizializzazione dipende da parametri o richiede logica specifica.\npublic class Esempio {\n    private int numero;\n    private String testo;\n\t\n    public Esempio(int numero, String testo) {\n        this.numero = numero;\n        this.testo = testo;\n    }\n}\nBlocchi di Inizializzazione\nBlocco di Inizializzazione {}:\nViene eseguito ogni volta che un nuovo oggetto Esempio viene creato, indipendentemente da quale costruttore viene chiamato.\npublic class Esempio {\n    private int numero;\n    private String testo;\n \n    // Blocco di inizializzazione\n    {\n        numero = 5;\n        testo = &quot;Inizializzato&quot;;\n    }\n \n    public Esempio() {\n        // Il blocco di inizializzazione viene eseguito prima di questo costruttore\n    }\n \n    public Esempio(int numero) {\n        this.numero = numero;\n        // Il blocco di inizializzazione viene eseguito prima di questo costruttore\n    }\n} \nQui, numero viene impostato su 5 e testo su ‚ÄúInizializzato‚Äù.\nCostruttori:\nOgni costruttore viene eseguito dopo il blocco di inizializzazione.\nNel costruttore senza parametri, il valore di numero sar√† 5 (impostato nel blocco di inizializzazione).\n\nNel costruttore con parametro, numero verr√† impostato su 5 dal blocco di inizializzazione, ma poi sar√† sovrascritto dal valore passato come parametro.\n\n\n\n                  \n                  Perch√© Usare un Blocco di Inizializzazione? \n                  \n                \n\nImmagina di avere del codice di inizializzazione che vuoi eseguire ogni volta che crei un oggetto\ndella classe, ma non vuoi ripeterlo in ogni costruttore. Il blocco di inizializzazione ti permette di\nscrivere quel codice una sola volta, e viene eseguito sempre prima di qualsiasi costruttore.\n\n\nBlocchi di Inizializzazione Statici\nPer i campi statici, che appartengono alla classe piuttosto che alle istanze, si utilizzano blocchi di inizializzazione statici.\nQuesti vengono eseguiti una sola volta, quando la classe viene caricata.\npublic class Esempio {\n    private static int valoreStatico;\n \n    static {\n        valoreStatico = 100;\n    }\n}\nPICCOLA PARENTESI SUL CONCETTO STATIC\nSi pu√≤ applicare su 3 cose:\n\nattributi\n\nquando un attributo cambia per qualsiasi oggetto che istanzia la classe\n\n\nmetodi\n\nnon varia in base allo stato dell‚Äôoggetto, quindi non ha senso chiamare l‚Äôoggetto\nPossono essere chiamati senza creare un‚Äôistanza della classe.\nsi deve fare un eventuale passaggio di parametri per comunicare con questo tipo di metodo\nsi chiama facendo nomeclasse.nomemetodo(parametri)\n\n\nclassi annidate\n\nla classe dentro non pu√≤ accedere direttamente alla classe fuori\n\n\n\nClassi annidate\nQuando abbiamo una classe con dentro un‚Äôaltra classe\n\npossono essere statiche o dinamiche\n\nShadowing in classi annidate:\n\nLo shadowing si verifica quando una dichiarazione di una variabile in un determinato ambito (scope) ha lo stesso nome di una dichiarazione in un ambito esterno. In tali casi, la variabile nell‚Äôambito interno ‚Äúoscura‚Äù quella nell‚Äôambito esterno, rendendo quest‚Äôultima inaccessibile direttamente tramite il suo nome.\nquando siamo nella classe interna e vogliamo parlare\n\ndella variabile locale al metodo: non usiamo nulla nomevar\ndella variabile interna alla classe: usiamo this.nomevar\nvariabile esterna: usiamo nomeclasse.this.nomevar\n\n\n\npublic class Esterna {\n    int x = 10;\n \n    class Interna {\n        int x = 20;\n \n        void mostraValori(int x) {\n            System.out.println(&quot;x locale: &quot; + x); // Variabile locale al metodo\n            System.out.println(&quot;x di Interna: &quot; + this.x); // Variabile di Interna\n            System.out.println(&quot;x di Esterna: &quot; + Esterna.this.x); // Variabile di Esterna\n        }\n    }\n \n    public static void main(String[] args) {\n        Esterna esterna = new Esterna();\n        Esterna.Interna interna = esterna.new Interna();\n        interna.mostraValori(30);\n    }\n}\n\n\n                  \n                  a che serve usare classi annidate? \n                  \n                \n\nin generale il concetto √® dell‚Äôincapsulation, si usa un esempio di una macchina con uno specifico sportello, magari abbiamo una classe che va bene solo con una determinata classe, lo sportello\nnon lo avr√≤ mai al di fuori di quella classe dove lo chiamo dentro\n\n"},"UNI/ANNO-2/LINGUAGGI/LINGUAGGI-LEZ.9":{"slug":"UNI/ANNO-2/LINGUAGGI/LINGUAGGI-LEZ.9","filePath":"UNI/ANNO 2/LINGUAGGI/LINGUAGGI LEZ.9.md","title":"LINGUAGGI LEZ.9","links":[],"tags":[],"content":"Classi Locali\nLe classi locali sono delle classi definite all‚Äôinterno di un blocco (ad esempio un metodo, ciclo, istruzione).\nPosso dichiararle ovunque nel codice, purch√© all‚Äôinterno di un blocco delimitato da {}.\npublic void exampleMethod() {\n    class LocalClass {\n        void printMessage() {\n            System.out.println(&quot;Sono una classe locale!&quot;);\n        }\n    }\n    \n    LocalClass local = new LocalClass();\n    local.printMessage();\n}\nIn questo caso il metodo exampleMethod crea una classe.\nAccesso ai membri esterni alle classi locali\nUna classe locale pu√≤ accedere ai membri esterni ad essa in queste modalit√†\n\nCLASSE LOCALE DEFINITA IN UN METODO STATICO\n\npu√≤ accedere solo a membri statici\n\n\n\npublic class StaticExample { // Classe esterna\n    static String staticMessage = &quot;Ciao statico!&quot;; // Membro statico\n    String instanceMessage = &quot;Ciao istanza!&quot;; // Membro di istanza (non \n                                              //accessibile direttamente)\n\t\n    public static void staticMethod() { // Metodo statico\n        // Classe locale definita dentro un contesto statico\n        class LocalClass {\n            void printMessage() {\n                System.out.println(staticMessage); // OK, il membro √® statico\n                System.out.println(instanceMessage); // ERRORE: non pu√≤ accedere a                                                                 membri non statici\n            }\n        }\n    }\n}\n\nCLASSE LOCALE DEFINITA IN UN METODO NON STATICO\n\npu√≤ accedere a qualsiasi membro\n\n\n\npublic class NonStaticExample { // Classe esterna\n    static String staticMessage = &quot;Ciao statico!&quot;; // Membro statico\n    String instanceMessage = &quot;Ciao istanza!&quot;; // Membro di istanza \n\t\n    public void nonStaticMethod() { // Metodo NON statico\n        // Classe locale definita dentro un contesto non statico\n        class LocalClass {\n            void printMessage() {\n                System.out.println(staticMessage); // OK\n                System.out.println(instanceMessage); // OK \n\t        }\n\t    }\n    }\n}\nAccesso a variabili locali\nLe classi locali possono accedere alle variabili locali del metodo in cui sono inserite solo se sono definite final, senza non va bene.\npublic class LocalVariableExample {\n\tpublic void validateNumber() {\n\t    final int numberLength = 10; // VA BENE\n\t    class PhoneNumber {\n\t        void validate(String number) {\n\t            System.out.println(&quot;Validating number of length &quot; + numberLength);\n\t        }\n\t    }\n\t}\n}\nShadowing nelle Classi Locali\nNel caso in cui ci fossero due variabili o metodi identici, uno fuori dal metodo in cui √® definita la classe locale e uno all‚Äôinterno della classe locale, quest‚Äôultimo va a nascondere (shadow) il primo.\npublic class ShadowingExample {\n\tString message = &quot;Classe esterna&quot;;\n\tpublic void shadowExample() {\n\t    class LocalClass {\n\t        String message = &quot;Classe locale&quot;;\n\t        void printMessage() {\n\t            System.out.println(message); // Stampa &quot;Classe locale&quot;\n\t        }\n\t    }\n\t}\n}\nCosa NON posso nelle classi locali\n\n\nNON POSSO definire membri statici (es. `static String message)\n\ntuttavia se sono variabili posso farlo (es. static final int numero = 10)\n\n\n\nNON POSSO implementare un‚Äôinterfaccia\n\n\npublic class NotInterface {\n\tpublic void wrongMetodo() {\n\t\tclass LocalClass implements Interface { // NON POSSO FARLO\n\t\t\t// COSE\n\t\t}\n\t}\n}\n\nNON POSSO avere inizializzatori statici (es. metodo statico)\n\npublic class MetodoStaticoInClasseLocale {\n\tpublic void pisello() {\n\t\tclass LocalClass { \n\t\t\tpublic static void metodoStatico() { // NON POSSO FARLO\n\t\t\t\t// COSE\n\t\t\t}\n\t\t}\n\t}\n}\n\nPossono accedere solo ai membri della classe esterna e ai membri locali finali o effettivamente finali.\n\nIN PRATICA credo che le classi locali non possano accedere ai membri di altre classi locali.\n\n\n\nAnonymous Classes\nLe anonymous classes sono molto utili quando vuoi creare una classe ‚Äúal volo‚Äù dentro (per esempio) un main.\nNel senso, se devo creare una classe per fare un qualcosa di molto semplice, piuttosto che crearla esternamente posso scriverla direttamente nel main.\nUtilit√† delle classi anonime\n\nimplementare velocemente un‚Äôinterfaccia.\nestendere una classe esistente e personalizzarne il comportamento.\nQuando vuoi evitare di creare una classe separata per qualcosa di semplice (scritto prima)\n\nSINTASSI BASE\nAnonymousClass classe = new AnonymousClass() { // il nome lo scelgo sul momento\n    // Corpo della classe anonima: metodi e campi\n};\nESEMPIO SEMPLICE: implementazione di un interfaccia\ninterface Saluto {\n    void sayHello();\n}\n \npublic class AnonymousExample {\n    public static void main(String[] args) {\n        // Creazione di una classe anonima che implementa Saluto\n        Saluto ciao = new Saluto() { // il nome √® lo stesso dell&#039;interfaccia\n            @Override\n            public void sayHello() {\n                System.out.println(&quot;Ciao, classe anonima!&quot;);\n            }\n        };\n\t\t\n        ciao.sayHello(); // Stampa &quot;Ciao, classe anonima!&quot;\n    }\n}\nScrivere\nSaluto ciao = new Saluto() {\n\t// COSE\n};\n√® come scrivere\nclass ciao implements Saluto {\n\t// COSE\n}\nESEMPIO SEMPLICE: estensione di una classe\nL‚Äôidea √® scrivere questo ma Dog deve essere una classe anonima.\nclass Animal {\n    void speak() {\n        System.out.println(&quot;Sono un animale.&quot;);\n    }\n}\n \nclass Dog extends Animal {\n\t@Override\n    void speak() {\n        System.out.println(&quot;Bau! Sono un cane.&quot;);\n        }\n}\nSOLUZIONE\nclass Animal {\n    void speak() {\n        System.out.println(&quot;Sono un animale.&quot;);\n    }\n}\n \npublic class AnonymousExample {\n    public static void main(String[] args) {\n        // Creazione di una classe anonima che estende Animal\n        Animal dog = new Animal() {\n            @Override\n            void speak() {\n                System.out.println(&quot;Bau! Sono un cane.&quot;);\n            }\n        };\n\t\t\n        dog.speak(); // Stampa &quot;Bau! Sono un cane.&quot;\n    }\n}\nAccesso a variabili locali\nLe anonymous classes possono accedere a:\n\nMembri statici e di istanza della classe esterna.\nVariabili locali del metodo, ma solo se sono dichiarate final o effettivamente finali.\n\nRestrizioni delle classi anonime\n\nNon puoi dichiarare un costruttore, ma puoi usare un inizializzatore di istanza.\nNon possono contenere membri statici, a meno che siano costanti (static final).\nPossono avere campi e metodi aggiuntivi, ma questi non sono visibili se usi un‚Äôinterfaccia o una classe madre come riferimento (questo perch√©, ad esempio, Dog √® visto come Animal).\n"},"UNI/ANNO-2/LINGUAGGI/LINGUAGGI.ESERCITAZIONE-3":{"slug":"UNI/ANNO-2/LINGUAGGI/LINGUAGGI.ESERCITAZIONE-3","filePath":"UNI/ANNO 2/LINGUAGGI/LINGUAGGI.ESERCITAZIONE 3.md","title":"LINGUAGGI.ESERCITAZIONE 3","links":[],"tags":[],"content":"posso avere un overload anche se ho un metodo di una sotto interfaccia uguale all‚Äôinterfaccia\nil costruttore di default ha 0 parametri infatti non aggiunge nulla\n\nil costruttore di default chiamera disperato il costruttore della classe superiore ma che non corrisponde con nessun‚Äôaltro costruttore con 0 parametri, quindi chiamera a sua volta Object che non mette nulla\nStatic √® detta campo di classe, valore universalmente acceduto da quella classe\ngerarchia di static\nUso StudenteTV per definire la matricola\nprotected\n"},"UNI/ANNO-2/LINGUAGGI/Orale-Java":{"slug":"UNI/ANNO-2/LINGUAGGI/Orale-Java","filePath":"UNI/ANNO 2/LINGUAGGI/Orale Java.md","title":"Orale Java","links":[],"tags":[],"content":"TEOREMA BOHM JACOPINI\nOgni algoritmo pu√≤ essere implementato utilizzando solo tre strutture di controllo fondamentali:\n\n\n\nSequenza ‚Üí esecuzione di istruzioni una dopo l‚Äôaltra.\n\n\n\n\nSelezione ‚Üí scelta condizionale (if‚Ä¶then‚Ä¶else).\n\n\n\n\nIterazione ‚Üí ripetizione (while, for).\n\n\n\nPROGRAMMAZIONE A OGGETTI (OOP)\n\nNasce per rendere pi√π intuitiva la programmazione\n\nPRINCIPI FONDAMENTALI della OOP\n\nIncapsulamento\n\nOrganizzare il codice dividendo i problemi in pi√π parti (classi, metodi).\nNascondere i dettagli implementativi, mostrando solo ci√≤ che serve all‚Äôutilizzatore (information hiding).\nNon significa ‚Äúsicurezza‚Äù, ma leggibilit√† e manutenibilit√†.\nSi realizza tramite modificatori di accesso (private, public, protected).\nAccessors (get) ‚Üí metodi che leggono attributi privati.\nMutators (set) ‚Üí metodi che modificano attributi privati.\n\n\nAstrazione\n\nConsiste nel lavorare con modelli semplificati (classi, interfacce, oggetti) senza conoscere i dettagli interni.\nPermette di concentrarsi sul cosa fa un oggetto, non su come lo fa.\nEsempio: usare List&lt;String&gt; senza sapere se dietro c‚Äô√® un ArrayList o un LinkedList.\n\n\nEreditariet√†\n\nPermette a una classe (sottoclasse) di riutilizzare attributi e metodi di un‚Äôaltra (superclasse).\nRiduce ridondanze e favorisce il riuso del codice.\nSupporta la costruzione di gerarchie (es. Veicolo ‚Üí Auto, Moto).\nIn Java √® singola (una sola superclasse), ma si possono usare pi√π interfacce.\n\n\nPolimorfismo\n\nCapacit√† di un linguaggio di gestire in modo uniforme entit√† con comportamenti diversi.\nDue forme principali:\n\nOverloading (polimorfismo statico/di compilazione) ‚Üí stesso nome di metodo ma parametri diversi.\nOverriding (polimorfismo dinamico/di runtime) ‚Üí una sottoclasse ridefinisce un metodo della superclasse con comportamento diverso.\n\n\n\n\n\nCOME FUNZIONA LA JAVA VIRTUAL MACHINE\n\nil codice sorgente(il codice in Java) e il file sar√† contraddistinto in .Java\nil bytecode √® il risultato dell‚Äôoperazione di compilazione fatta da Javac il file sar√† in .class\nLa jvm traduce in real-time il bytecode(.class) in linguaggio macchina\n\n\nELEMENTI FONDAMENTALI DELLA PROGRAMMAZIONE A OGGETTI\nCLASSI\nIn Java una classe √® il modello che definisce lo stato e i comportamenti degli oggetti. Una dichiarazione tipica comprende campi, costruttori e metodi.\n\nI campi (o attributi) sono variabili che descrivono lo stato dell‚Äôoggetto.\nIl costruttore √® un metodo speciale che inizializza i campi quando l‚Äôoggetto viene creato.\nI metodi definiscono le azioni che l‚Äôoggetto pu√≤ compiere e possono modificare i campi o eseguire altre operazioni.\n\nLe classi possono essere estese tramite ereditariet√†: una sottoclasse eredita campi e metodi della superclasse e pu√≤ aggiungere elementi propri.\nIn generale, la dichiarazione di una classe pu√≤ includere: modificatori di accesso (public, private), il nome della classe, un‚Äôeventuale superclasse (extends), eventuali interfacce (implements), e infine il corpo racchiuso tra {}.\nMETODI\n\nazioni eseguibili da un oggetto.\nun metodo public int calcolaDoppio(int numero) {     return numero * 2; }\nprevede\n\nmodificatori\ntipo di ritorno\nnome del metodo\n\nscritto in camel case calcolaDoppio\n\n\nlista di parametri\ncorpo del metodo con return\n\n\nFIRMA DEL METODO\n\nLa firma del metodo √® ci√≤ che distingue un metodo dagli altri all‚Äôinterno di una classe.\ncomposta da:\n\n\n\n\nNome del metodo\nTipi dei parametri (nell‚Äôordine in cui appaiono)\n\n\nPermette a Java di identificare i metodi univocamente.\nServe a distinguere i metodi in caso di overloading (sovraccarico).\n\nOGGETTI\n\nUn oggetto √® un‚Äôistanza di una classe.\nContiene i propri campi (stato) e pu√≤ eseguire metodi (comportamenti).\nPi√π oggetti della stessa classe condividono la struttura, ma hanno copie indipendenti dei campi.\nClasse nomeOggetto = new Classe(parametriCostruttore);\nAccedere ai dati dell‚Äôoggetto\n\nDentro la classe ‚Üí basta il nome del campo/metodo.\nFuori dalla classe ‚Üí serve il riferimento all‚Äôoggetto + . (dot notation).\n\n\n\nINTERFACCE\nLe interfacce in Java servono principalmente per definire un insieme di metodi generici che devono essere implementati da varie classi.\n\nLe interfacce si possono definire come dei contratti che vanno rispettati dalle varie classi che lo firmano e che devono OBBLIGATORIAMENTE applicare quei metodi  definiti\nservono a risolvere alcuni problemi di organizzazione del codice e manutenzione che diventano evidenti quando il progetto cresce in complessit√†.\n\nvariabili in java\n\nle variabili possono essere primitive e non\n\nquelle primitive sono quelle solite come int float ecc‚Ä¶\n\n\nse invece non si precisa si intendono i ruoli che possono avere le variabili in java\n\nVariabili di istanza\n\ndichiarate dentro le classi\n\n\nVariabili statiche\n\ndichiarate dentro le classi ma come static\n\n\nVariabili locali\n\ndichiarate dentro un metodo o un costruttore\n\n\nVariabili parametro\n\nSono le variabili dichiarate nella firma di un metodo o costruttore.\n\n\n\n\n\nPACKAGE\n\nI package sono contenitori logici per organizzare classi e interfacce.\nServono a strutturare il codice come un file system (cartelle ‚Üî package).\nFacilitano la gestione, il riuso e l‚Äôevitare conflitti di nomi.\nI . (punti) nei package funzionano come / nelle cartelle:\n\nimport progetto.modulo.util.*;\n\n\nI package non hanno relazioni gerarchiche funzionali:\n\nprogetto.modulo ‚â† sottoclasse di progetto.\n\n\nServono solo per organizzazione, non per ereditariet√†.\n\nTIPI DI DATO\n‚Üí forniti dal linguaggio, non sono oggetti.\n\ninteri: byte, short, int, long\nfloating-point: float, double\ncaratteri: char\nbooleani: boolean\nTipi di riferimento (reference types)\n‚Üí puntano a oggetti nello heap.\nclassi (String, Scanner, ArrayList ‚Ä¶)\narray (int[], String[] ‚Ä¶)\ninterfacce\ntipi definiti dall‚Äôutente (classi custom)\n\nSTRING\nNon √® un tipo primitivo, ma una classe (java.lang.String).\n\nle stringhe sono oggetti di questa classe\nsono immutabili, ogni volta crei un nuovo oggetto\nMetodo .equals() confronta i contenuti delle stringhe.\nlength() ‚Üí lunghezza della stringa\ncharAt(int i) ‚Üí carattere in posizione i\nsubstring(int a, int b) ‚Üí sottostringa\ntoUpperCase(), toLowerCase()\nindexOf(), lastIndexOf()\nequals(), equalsIgnoreCase()\nstartsWith(), endsWith()\ntrim(), replace(), split()\n\nTO STRING\ntoString() √® un metodo ereditato dalla classe base Object, quindi tutte le classi in Java lo possiedono (anche se non lo riscriviamo).\nServe per ottenere una rappresentazione testuale (stringa) dell‚Äôoggetto.\nEsempio base:\nObject o = new Object();  System.out.println(o.toString());`\n\ncome output tipico hai l‚Äôidentificativo dell‚Äôoggetto\nse invece fai override puoi printare quello che vuoi\n\nVARARGS\nIn Java i varargs permettono di passare un numero variabile di argomenti a un metodo. Sono implementati come array e possono essere usati con qualsiasi tipo, anche con Object... per accettare oggetti diversi. Hanno per√≤ due limiti: ce ne pu√≤ essere uno solo per metodo e deve essere l‚Äôultimo parametro.\npublic int somma(int... numeri) {\nInfine, i varargs possono essere dichiarati anche come Object...\nARRAY\nUn array √® una struttura dati che ti permette di memorizzare pi√π elementi dello stesso tipo in un‚Äôunica variabile. Tutti gli elementi all‚Äôinterno di un array devono essere dello stesso tipo, e questo tipo viene definito al momento della sua creazione.\n\ncreazione array\n\nstatica\n\nint[] numeri = {1, 2, 3, 4, 5};\n\n\ndinamica\n\nint[] numeri = new int[5];\nentrambi hanno dimensione fissa\n\n\n\n\n\nMULTIDIMENSIONALE\n\n√à un array di array.\nIl caso pi√π comune √® la matrice bidimensionale (int[][]), ma puoi avere anche pi√π dimensioni (int[][][]).\nint[][] matrice = new int[3][4]; \n\nintint[][] matrice = {\n    {1, 2, 3},\n    {4, 5, 6},\n    {7, 8, 9}};\nCAMPO STATIC e FINAL\n\n\nUn campo static appartiene alla classe, non all‚Äôistanza.\n\n\nSignifica che tutti gli oggetti condividono la stessa variabile.\n\n\nViene caricato in memoria una sola volta quando la classe √® caricata dalla JVM.\n\n\nUn campo final non pu√≤ essere modificato dopo l‚Äôinizializzazione.\n\n\nDiventa una costante se √® anche static.\n\n\nSe √® un riferimento a un oggetto, il riferimento non pu√≤ cambiare, ma l‚Äôoggetto pu√≤ essere modificato (se √® mutabile).\n\n\nESPRESSIONI\nUn‚Äôespressione in Java √® una combinazione di:\n\nletterali (es. 5, &quot;ciao&quot;)\nvariabili\noperatori (+, -, *, /, &amp;&amp;, ecc.)\nchiamate a metodi\nche insieme producono un valore.\nJava rispetta la precedenza matematica degli operatori\n\nSTATEMENT\n\nUno statement √® un‚Äôistruzione completa che il compilatore pu√≤ eseguire.\nOgni statement termina con ; (tranne blocchi e strutture di controllo).\nDentro uno statement possono esserci espressioni, ma uno statement non sempre restituisce un valore.\nExpression statements\n\nassegnazioni ‚Üí a = 10;\nincremento/decremento ‚Üí a++;\ninvocazioni di metodi ‚Üí System.out.println(&quot;Ciao&quot;);\ncreazione oggetti ‚Üí Bici b = new Bici();\n\n\nDeclaration statements\n\ndichiarazione e opzionale inizializzazione di variabili ‚Üí int x = 5;\n\n\nControl flow statements\n\ncondizionali ‚Üí if, if-else, switch\ncicli ‚Üí for, while, do-while\ninterruzioni ‚Üí break, continue, return\n\n\nBlocco ({ })\n\ninsieme di pi√π statement trattati come uno solo.\nMolto usato in if, cicli e metodi.\n\n\n\nMODIFICATORI DI ACCESSO\n\n\npublic: rende accessibile un campo o un metodo a tutte le altre classi. Se un campo √® public, pu√≤ essere visto e modificato direttamente da qualunque classe (sottoclassi e non).\n\n\nprivate: limita l‚Äôaccesso a un campo o un metodo solo alla classe stessa. Questo significa che nessun‚Äôaltra classe pu√≤ accedere direttamente ai campi private.\nINCAPSULAMENTO IN JAVA\nsi realizza principalmente usando:\n\n\ncampi privati (private) ‚Üí non accessibili direttamente dall‚Äôesterno;\n\n\nmetodi pubblici (public) ‚Üí getter e setter per controllare l‚Äôaccesso.\n\n\nprotected\n\n\nUn membro protected (campo, metodo o costruttore):\n\n√à visibile all‚Äôinterno dello stesso package (come il default).\n√à visibile anche nelle sottoclassi, anche se queste si trovano in un package diverso.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nModificatoreStessa classeStesso packageSottoclasse (anche in altro package)Altre classipublic‚úÖ‚úÖ‚úÖ‚úÖprotected‚úÖ‚úÖ‚úÖ‚ùådefault‚úÖ‚úÖ‚ùå‚ùåprivate‚úÖ‚ùå‚ùå‚ùå\nCOSTRUTTORI\nUn costruttore √® un blocco di codice speciale in una classe che viene chiamato quando viene creato un nuovo oggetto. Serve per inizializzare l‚Äôoggetto, impostando i valori iniziali dei campi (attributi) secondo le specifiche desiderate.\n\nHa lo stesso nome della classe.\nNon ha un tipo di ritorno (non pu√≤ essere void o altro).\n\n    public Persona(String nome, int eta) {\n        this.nome = nome;  // &quot;this&quot; serve a distinguere il campo dall&#039;argomento\n        this.eta = eta;\n    }\nGARBAGE COLLECTOR\nGarbage Collector\n\nProcesso automatico della JVM che libera memoria eliminando gli oggetti non pi√π raggiungibili (cio√® senza riferimenti attivi nel programma).\n\nSHADOWING\n\nLo shadowing si verifica quando una variabile locale o un parametro ha lo stesso nome di un campo della classe.\nIn questo caso, la variabile pi√π ‚Äúvicina‚Äù (quella locale) nasconde il campo della classe.\nPer distinguere i due si usa la keyword this.\n\nCLASSI ANNIDATE\nIn Java puoi dichiarare una classe dentro un‚Äôaltra. Esistono quattro tipi principali:\n\nInner class (non statica)\n\nLegata a un‚Äôistanza della classe esterna.\nPu√≤ accedere ai membri anche privati della classe esterna.\n\n\n\nclass Esterna {\n    private String messaggio = &quot;Ciao dal fuori&quot;;\n \n    class Interna {\n        void stampa() {\n            System.out.println(messaggio); // accede al privato di Esterna\n        }\n    }\n}\n\nStatic nested class\n\nDichiarata con static.\nNon dipende da un‚Äôistanza della classe esterna, quindi non pu√≤ accedere direttamente ai campi non statici.\n\n\n\nclass Esterna {\n    static class Interna {\n        void stampa() {\n            System.out.println(&quot;Sono una classe statica annidata!&quot;);\n        }\n    }\n}\n \npublic class Main {\n    public static void main(String[] args) {\n        Esterna.Interna in = new Esterna.Interna();\n        in.stampa();\n    }\n}\n\nLocal class\n\nDefinita dentro un metodo.\n√à visibile solo dentro quel metodo.\n\n\n\nclass Esterna {\n    void metodo() {\n        class Locale {\n            void stampa() {\n                System.out.println(&quot;Classe locale dentro un metodo&quot;);\n            }\n        }\n        new Locale().stampa();\n    }\n}\n\nAnonymous class\n\nCreata ‚Äúal volo‚Äù senza nome, di solito per implementare interfacce o estendere classi con un‚Äôistanza unica.\n\n\n\n \npublic class Main {\n    public static void main(String[] args) {\n        Animale cane = new Animale() {\n            void verso() {\n                System.out.println(&quot;Bau!&quot;);\n            }\n        };\n        cane.verso();\n    }\n}\nFACTORY\n\nUna factory √® un design pattern creazionale: serve a delegare la creazione degli oggetti a un metodo o a una classe separata.\nInvece di scrivere sempre new Classe(), chiedi a una ‚Äúfabbrica‚Äù di restituirti un oggetto.\nQuesto ti permette di nascondere i dettagli di costruzione e rendere il codice pi√π flessibile.\nIncapsulamento ‚Üí nasconde la logica di creazione.\n\ninterface Animale {\n    void verso();\n}\n \nclass Cane implements Animale {\n    public void verso() { System.out.println(&quot;Bau!&quot;); }\n}\n \nclass Gatto implements Animale {\n    public void verso() { System.out.println(&quot;Miao!&quot;); }\n}\n \nclass AnimaleFactory {\n    public static Animale creaAnimale(String tipo) {\n        if (tipo.equals(&quot;cane&quot;)) return new Cane();\n        else if (tipo.equals(&quot;gatto&quot;)) return new Gatto();\n        else return null;\n    }\n}\n \npublic class Main {\n    public static void main(String[] args) {\n        Animale a = AnimaleFactory.creaAnimale(&quot;cane&quot;);\n        a.verso(); // Output: Bau!\n    }\n}\nLE ANNOTAZIONI\n\nSono dei tag speciali (@...) che aggiungono metadati a classi, metodi, variabili, ecc.\nServono a:\n\ndare istruzioni al compilatore (es. @Override),\nfornire informazioni extra a chi legge o a strumenti esterni.\nüëâ Sono quindi una forma di metaprogrammazione (programmare usando metadati).\n\n\n\nCaratteristiche\n\nPossono avere campi/attributi.\nPossono essere multiple sulla stessa entit√†.\nPossono essere ripetibili (@Repeatable).\nSi creano con @interface.\n\nAnnotazioni pi√π utili (da sapere all‚Äôesame)\n\n@Override ‚Üí indica che un metodo sta sovrascrivendo un altro.\n@Deprecated ‚Üí segnala che un metodo o classe √® in disuso.\n@SuppressWarnings ‚Üí evita warning del compilatore.\n\nMeta-annotazioni essenziali\nCon reflection puoi:\n\n\nOttenere informazioni su una classe\n\nNome, package, metodi, costruttori, campi.\n\n\n\nLeggere annotazioni a runtime\n\nUtile per frameworks come JUnit, Spring, Hibernate.\n\n\n\nInvocare metodi dinamicamente\n\nAnche senza conoscerli in fase di compilazione.\n\n\n\nCreare oggetti dinamicamente\n\nSenza usare new, ma caricando la classe per nome.\n\n\n\n@Retention ‚Üí specifica fino a quando l‚Äôannotazione √® visibile (solo codice, bytecode, runtime).\n\n\n\nSOURCE ‚Üí solo nel codice (sparisce in compilazione).\nCLASS ‚Üí resta nel bytecode, ma non leggibile a runtime.\nRUNTIME ‚Üí leggibile anche con reflection.\n\n\n@Target ‚Üí definisce dove pu√≤ essere usata (metodo, classe, campo).\n@Repeatable ‚Üí permette di applicare pi√π volte la stessa annotazione.\n\nclass Animale {\n     @Deprecated     \n     void versoVecchio() \n     { System.out.println(&quot;verso&quot;); }      \n     @Override     \n     public String toString() {\n              return &quot;Animale&quot;;     \n              } }\nABSTRACT\n\nUna classe astratta √® una classe che non pu√≤ essere istanziata direttamente.\nServe come modello per le sottoclassi.\nPu√≤ contenere:\n\nmetodi concreti (gi√† implementati);\nmetodi astratti (solo dichiarati, senza corpo).\n\n\n\nabstract class Animale {\n    abstract void verso();          // metodo astratto\n    void dormi() {                  // metodo concreto\n        System.out.println(&quot;Zzz...&quot;);\n    }\n}\n \nclass Cane extends Animale {\n    @Override\n    void verso() {\n        System.out.println(&quot;Bau!&quot;);\n    }\n}\n \npublic class Main {\n    public static void main(String[] args) {\n        Animale a = new Cane(); // ok, istanza di sottoclasse\n        a.verso();  // Output: Bau!\n        a.dormi();  // Output: Zzz...\n    }\n}\n\nmetodi astratti\nNon hanno corpo (; al posto delle parentesi).\nDevono essere implementati da una sottoclasse concreta.\n\nEXCEPTION\n\nEvento anomalo che interrompe il normale flusso di esecuzione.\nIn Java, le eccezioni sono oggetti che viaggiano nello stack delle chiamate (call stack) finch√© non trovano un gestore (catch).\nSe nessun gestore la intercetta ‚Üí il programma termina.\nle eccezioni hanno una loro gerarchia\n\nThrowable\n\nclasse generale delle exception e degli errori poi abbiamo\n\nException\n\neventi gestibili dal programma\nchecked\n\nsono risolte a compile time\n\n\nunchecked\n\nsono risolte a run time\n\n\n\n\nError\n\nIndica problemi gravi\nterminano il programma\n\n\n\n\n\n\n\n\n\nPER GESTIRE LE EXCEPTION ABBIAMO\n\ntry-catch\n\nprova uno statement, se fallisce gestisci l‚Äôeccezione con un altro statement.\n\n\n\ntry {\n    int risultato = 10 / 0;   // genera ArithmeticException\n} catch (ArithmeticException e) {\n    System.out.println(&quot;Errore: divisione per zero!&quot;);\n}\n\nfinally\n\nprova il codice ma esegue sempre lo statement dentro finally\n\n\n\ntry {\n    // codice\n} finally {\n    System.out.println(&quot;Eseguito comunque&quot;);\n}\n \n\nthrows\n\nDichiara che un metodo pu√≤ lanciare eccezioni ‚Üí il chiamante deve gestirle.\n\n\n\npublic void leggiFile() throws IOException { ... }\n\nthrow\n\nLancia manualmente un‚Äôeccezione.\n\n\n\nif (x &lt; 0) {\n    throw new IllegalArgumentException(&quot;Numero negativo&quot;);\n}\n \nGENERICS\n\nServono per parametrizzare i tipi in java come classi, interfacce e metodi\ngestiscono il casting a compile time\nT √® un placeholder viene deciso quando istanzi la classe\n\npublic class Box&lt;T&gt; {\n    private T content;\n \n    public void setContent(T content) {\n        this.content = content;\n    }\n \n    public T getContent() {\n        return content;\n    }\n}\n \nBox&lt;String&gt; box = new Box&lt;&gt;();\nbox.setContent(&quot;Hello&quot;);\nString value = box.getContent(); // Nessun cast necessario\nSystem.out.println(value);\n \nsui metodi\npublic &lt;T&gt; void stampa(T valore) {\n    System.out.println(valore);\n}\n \nstampa(10);       // T = Integer\nstampa(&quot;ciao&quot;);   // T = String\nPuoi limitare il tipo con extends o super:\nclass NumeroBox&lt;T extends Number&gt; { // solo tipi numerici\n    private T numero;\n}\nWILDCARD\nLa wildcard √® un segnaposto che indica ‚Äúqualche tipo sconosciuto‚Äù in una struttura generica.\nServe quando non ti importa il tipo preciso, ma vuoi comunque accettare pi√π possibilit√†.\nal posto di scrivere T metto ? per indicare un tipo di dato generico che non ci interessa\n\novviamente non possiamo fare operazioni specifiche per un certo tipo di dato\n\nDIAMOND\n\nSenza diamond (Java 6)\nList&lt;String&gt; lista = new ArrayList&lt;String&gt;();\nCon diamond (Java 7+)\nList&lt;String&gt; lista = new ArrayList&lt;&gt;();\n\nCOLLECTIONS\n\nLe Collections sono un framework che racchiudono diverse strutture dati\n\ntutte queste sono interfacce\nCollection (interfaccia base ‚Üí gruppi di elementi)\n\nList ‚Üí ordinata, ammette duplicati (ArrayList, LinkedList).\nSet ‚Üí elementi unici, no duplicati (HashSet, TreeSet).\nQueue / Deque ‚Üí strutture FIFO o code a doppia estremit√† (LinkedList, ArrayDeque).\n\n\nMap (non estende Collection, √® separata)\n\nStruttura chiave ‚Üí valore (HashMap, TreeMap, LinkedHashMap).\n\n\n\nOperazioni principali\n\nList: add, remove, get, size.\nSet: add, remove, ma niente duplicati.\nQueue/Deque: addFirst, addLast, removeFirst, removeLast.\nMap: put, get, remove, containsKey, keySet, values.\n\nModi per iterare\n\nfor-each\nfor (String s : list) System.out.println(s);\nIterator (hasNext(), next(), remove()).\nStream API ‚Üí operazioni aggregate (filter, map, forEach).\n\nOperazioni di gruppo (bulk)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMetodoCosa facontainsAllRitorna true se tutti gli elementi della collezione specificata sono presenti nella collezione presa in considerazione.addAllAggiunge tutti gli elementi di un‚Äôaltra collezione alla collezione target.removeAllRimuove dalla collezione target tutti gli elementi presenti in un‚Äôaltra collezione.retainAllMantiene solo gli elementi comuni tra la collezione target e quella specificata.clearRimuove tutti gli elementi dalla collezione target.\nList&lt;String&gt; list = new ArrayList&lt;&gt;();\nlist.add(&quot;Apple&quot;);\nlist.add(&quot;Banana&quot;);\n \nfor (String s : list) {\n    System.out.println(s);\n}\n \nMap&lt;String, Integer&gt; map = new HashMap&lt;&gt;();\nmap.put(&quot;Apple&quot;, 1);\nSystem.out.println(map.get(&quot;Apple&quot;)); // 1"},"UNI/ANNO-2/LINGUAGGI/PROLOG/ESAMI-COMPLETO-PROLOG":{"slug":"UNI/ANNO-2/LINGUAGGI/PROLOG/ESAMI-COMPLETO-PROLOG","filePath":"UNI/ANNO 2/LINGUAGGI/PROLOG/ESAMI COMPLETO PROLOG.md","title":"ESAMI COMPLETO PROLOG","links":[],"tags":[],"content":"ESAME 1\nStanno girando sui social media dei messaggi apparentemente senza senso. Sembrano infatti delle sequenze di lettere casuali. Sono evidentemente dei messaggi in codice. Sfruttando la potenza del prolog, si vuole costruire il codificatore ed il decodificatore che realizzino queste codifiche:\n\n\nLa prima versione di messaggio codificato in √® il messaggio originale in cui tutte le parole sono invertite e il loro ordine √® mantenuto\n\n\nLa seconda versione di messaggio codificato √® la prima versione di codifica in cui poi ciascuna parola inverte la prima e l‚Äôultima lettera\n\n\nLa terza versione di codifica √® la seconda versione in cui la prima e l‚Äôultima parola sono scambiate\n\n\n\nSi ricorda che esiste il built-in string_codes(STRING, LIST_OF_CHARS)\nSOLUZIONE 1\n%esame sui codificatori 3 codifiche diverse\n%codifica 1 chiede di invertire le parole\n%codifica 2 chiede di prendere codifica 1 e invertire il primo e l‚Äôultimo carattere di ogni parola\n%codifica 3 chiede di prendere codifica 2 e invertire prima e ultima parola\n%dividiparole semplicemente seziona la stringa in sottostringhe tagliando il carattere 32 = spazio in codice ascii\ndividiparole([],[]).\ndividiparole([32|T],L):-!,  %questo in particolare serve a escludere parole vuote\ndividiparole(T,L).\ndividiparole(L,[Word|Rest]):-\nprendiparole(L,Word,RestoLista),\ndividiparole(RestoLista,Rest).\n%prendiparole √® ausiliario a dividiparole,\n% essenzialmente prende la stringa intera e restituisce come secondo parametro la parola troncata da 32\nprendiparole([],[],[]).\nprendiparole([32|T],[],T):-!.\nprendiparole([T|L],[T|L2],Rest):-\nprendiparole(L,L2,Rest).\n%invertiparole molto semplicemente ogni parola della lista di sottoliste (parole)\ninvertiparole([],[]).\ninvertiparole([H|T],[H1|T1]):-\nreverse(H,H1),\ninvertiparole(T,T1).\n%unisciparole ricrea la lista iniziale decapsulando le sottoliste e inserendo 32 tra una e l‚Äôaltra\nunisciparole([],[]).\nunisciparole([W],W).\nunisciparole([W|Res],L):-\nunisciparole(Res,L1),\nappend(W,[32|L1],L).\n%la prima codifica richiesta\ncodifica1(L,L1):-\nstring_codes(L,T),\ndividiparole(T,R),\ninvertiparole(R,C),\nunisciparole(C,S),\nstring_codes(L1,S).\n%tutto cio che √® scritto qui sopra serve per codifica1, sotto ci saranno parti aggiuntive per le altre codifiche\n%PARTI AGGIUNTIVE PER CODIFICA2:\n%invertilettere inverte il primo e l‚Äôultimo elemento della lista passata\ninvertilettere([],[]).\ninvertilettere([X,Y],[Y,X]).\ninvertilettere([H|T],[H1|T1]):-\nappend(X,[H1],T),\nappend(X,[H],T1).\n%passaparole utilizzato per passare le singole parole a invertilettere\npassaparole([],[]).\npassaparole([H|T],[H1|L]):-\npassaparole(T,L),\ninvertilettere(H,H1).\n%CODIFICA2: si comporta come richiesto con l‚Äôaggiunta dei predicati\ncodifica2(L,L1):-\nstring_codes(L,T),\ndividiparole(T,R),\ninvertiparole(R,C),\npassaparole(C,D),\nunisciparole(D,S),\nstring_codes(L1,S).\n%CODIFICA3: sfrutta inverti lettere per invertire le parole\ncodifica3(L,L1):-\nstring_codes(L,T),\ndividiparole(T,R),\ninvertiparole(R,C),\npassaparole(C,D),\ninvertilettere(D,A),\nunisciparole(A,S),\nstring_codes(L1,S).\nESAME 2\nIl mondo sta cambiando ed esistono delle specie di animali e di piante pi√π esposte all‚Äôinquinamento umano. Onde capire se l‚Äôinquinamento umano torna nelle nostre tavole, si vuole costruire una rete i cui nodi sono le specie e la relazione √® la relazione di chi mangia chi.\nData la rete, se un animale o pianta √® inquinata, il mangiante ad una certa distanza n √® inquinato 0.87^n.\nPer costruire questa rete, si vuole utilizzare Wikipedia nella quale la relazione √® espressa in maniera testuale con frasi del tipo:\n\n\nIl cavallo si nutre di biada.\n\n\nIl cibo del cavallo √® la biada.\n\n\nIl cavallo mangia la biada.\n\n\nIl ragno si nutre di rosmarino.\n\n\nSi vogliono portare tutte queste frasi alla forma canonica:\n\n\nmangia(cavallo, biada)\n\n\nmangia(ragno, rosmarino)\n\n\nper costruire la rete di relazione di mangiare delle specie.\nTrovare un sistema generale per risolvere la sfida.\nSOLUZIONE 2\n/* query example:\ncodifica1(‚ÄúIl cavallo si nutre di biada\nIl cibo del pony e la ciccia\nIl pony si nutre di ciccia\nIl maile mangia la cicoria\nIl ragno si nutre di rosmarino‚Äù,L).\n*/\n:- dynamic mangia/2.\n%dividiparole semplicemente seziona la stringa in sottostringhe tagliando il carattere 32 = spazio in codice ascii\ndividiparole([],[]).\ndividiparole([32|T],L):-!, ¬†%questo in particolare serve a escludere parole vuote\n¬† ¬† dividiparole(T,L).\ndividiparole(L,[Word|Rest]):-\n¬† ¬† prendiparole(L,Word,RestoLista),\n¬† ¬† dividiparole(RestoLista,Rest).\n%prendiparole √® ausiliario a dividiparole,\n% essenzialmente prende la stringa intera e restituisce come secondo parametro la parola troncata da 32\nprendiparole([],[],[]).\nprendiparole([32|T],[],T):-!.\nprendiparole([T|L],[T|L2],Rest):-\n¬† ¬† prendiparole(L,L2,Rest).\nconvertiparole([],[]).\nconvertiparole([H|T],[H1|T1]):-\n¬† ¬† atom_codes(H2,H),\n¬† ¬† downcase_atom(H2,H1),\n¬† ¬† convertiparole(T,T1).\nrecuperaFrasi([],[]).\nrecuperaFrasi([H|T],[H1|T1]):-\n¬† ¬† string_codes(H,H1),\n¬† ¬† recuperaFrasi(T,T1).\nrichiamaDividi([],[]).\nrichiamaDividi([H|T],[H1|T1]):-\n¬† ¬† dividiparole(H,H1),\n¬† ¬† richiamaDividi(T,T1).\nrichiamaConverti([],[]).\nrichiamaConverti([H|T],[H1|T1]):-\n¬† ¬† richiamaConverti(T,T1),\n¬† ¬† convertiparole(H,H1).\n%la prima codifica richiesta\ncodifica1(L,L1):-\n¬† ¬† string_lines(L,A),\n¬† ¬† recuperaFrasi(A,B),\n¬† ¬† richiamaDividi(B,C),\n¬† ¬† richiamaConverti(C,L1),\n¬† ¬† grafo(L1).\n% --- predicato principale ---\nestrai_mangia(FraseList, mangia(S,O)) :-\n¬† ¬† once(phrase(frase(mangia(S,O)), FraseList)).\n% --- Regole principali della grammatica ---\nfrase(F) ‚áí pattern_nutre(F).\nfrase(F) ‚áí pattern_mangia(F).\nfrase(F) ‚áí pattern_cibo(F).\nskip_word ‚áí [_]. ¬† ¬† ¬† % salta una parola qualsiasi\nskip_words ‚áí skip_word, skip_words.\nskip_words ‚áí [].\n% --- pattern ‚ÄúX si nutre di Y‚Äù ---\npattern_nutre(mangia(S,O)) ‚áí\n¬† ¬† skip_words, [S,si,nutre,di,O], skip_words.\npattern_mangia(mangia(S,O)) ‚áí\n¬† ¬† skip_words, [S,mangia,la,O]|[S,mangia,il,O]|[S,mangia,lo,O]|[S,mangia,gli,O]|[S,mangia,i,O]|[S,mangia,le,O], skip_words.\npattern_cibo(mangia(S,O)) ‚áí\n¬† ¬† skip_words, [il,cibo,del,S,e,la,O]|[il,cibo,del,S,e,il,O]|[il,cibo,del,S,e,lo,O]|[il,cibo,del,S,e,gli,O]|[il,cibo,del,S,e,le,O]|[il,cibo,del,S,e,i,O], skip_words.\ngrafo(L):-\n¬† ¬† retractall(mangia(,)),\n¬† ¬† write(‚ÄòInizio inserimento frasi nel database‚Ä¶‚Äô), nl,\n¬† ¬† asserisciFrasi(L).\nasserisciFrasi([]).\nasserisciFrasi([H|T]):-\n¬† ¬† ( estrai_mangia(H,C) ‚Üí ¬†% se la frase viene parsata correttamente\n¬† ¬† ¬† ¬† assertz(C)\n¬† ¬† ;\n¬† ¬† ¬† ¬† true ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬†% altrimenti ignora la frase e continua\n¬† ¬† ),\n¬† ¬† asserisciFrasi(T).\nESAME 3\nSi vuole costruire un analizzatore di messaggi nascosti all‚Äôinterno di sequenze di lettere apparentemente senza senso. Un messaggio di n parole √® scritto nella seguente maniera:\n\n\nSi metta un indice i = 0\n\n\nPer ogni parola in sequenza nella frase, si metta parola[i] nella stringa se esiste, spazio se non esiste e si incrementi i di 1\n\n\nSe esiste almeno una parola in cui parola[i] esiste, si torni al passo precedente\n\n\nSi scriva un predicato prolog:\nlunghezza_messaggio(Messaggio,N)\nche sia vero se N √® la lunghezza del Messaggio in numero di parole. Come da bravi decodificatori, si √® individuato che in ogni messaggio c‚Äô√® la preposizione ‚Äúper‚Äù.\nSi scriva poi:\ndecodifica_messaggio(Messaggio,MessaggioDecodificato)\nche sia vero se MessaggioDecodificato √® il messaggio celato dentro Messaggio. Si tenga a mente il predicato precedente.\nDecodificare questo messaggio:\n‚Äúigspdmicpfla teialea t ann nrmt sgeeoa i na dr oe‚Äù\nSOLUZIONE 3\n% Student exercise profile\n:- set_prolog_flag(occurs_check, error).        % disallow cyclic terms\n:- set_prolog_stack(global, limit(8 000 000)).  % limit term space (8Mb)\n:- set_prolog_stack(local,  limit(2 000 000)).  % limit env\n%X=elemento da cercare, N=posizione in cui si trova X nella lista, L=lista in cui cercare X,\n%L1=gli elementi di L a sinistra di X (X escluso), L2=gli elementi di L a destra di X (X escluso)\nelemAt(X,N,[X|R],[],R,N).\nelemAt(X,N,[K|R],[K|R1],R2,Count):- %Count deve essere inizializzato a 0\nCount2 is Count+1,\nelemAt(X,N,R,R1,R2,Count2).\n% per ognuno dei predicati worker, la Stringa deve contenere uno spazio a fine parola, ad es: Stringa=[‚Äúmario rossi ‚Äù]\ndecodificatore_1_worker(Stringa,StringaAggiustata):-\nstring_codes(Stringa,X),\ndecodificatore_1(X,[],StringaAggiustata).\ndecodificatore_2_worker(Stringa,StringaAggiustata):-\nstring_codes(Stringa,X),\ndecodificatore_2(X,[],StringaAggiustata).\ndecodificatore_3_worker(Stringa,StringaAggiustata):-\nstring_codes(Stringa,X),\ndecodificatore_3(X,[],StringaAggiustata).\ndecodificatore_1([],Acc,Stringa_nuova):-\nstring_codes(Stringa_nuova,Acc), !.\ndecodificatore_1(Chars,Acc,Stringa_nuova):-\nelemAt(32,_,Chars,L,D,0),\naggiusta_stringa_1(L,NewL),\nappend(NewL,[32],NewerL),\nappend(Acc,NewerL,Acc2),\ndecodificatore_1(D,Acc2,Stringa_nuova).\naggiusta_stringa_1(Chars,CharsAggiustati):-\nreverse(Chars,CharsAggiustati).\ndecodificatore_2([],Acc,Stringa_nuova):-\nstring_codes(Stringa_nuova,Acc), !.\ndecodificatore_2(Chars,Acc,Stringa_nuova):-\nelemAt(32,_,Chars,L,D,0),\naggiusta_stringa_2(L,NewL),\nappend(NewL,[32],NewerL),\nappend(Acc,NewerL,Acc2),\ndecodificatore_2(D,Acc2,Stringa_nuova).\naggiusta_stringa_2(Chars,CharsAggiustati):-\nreverse(Chars,CharsNuovi),\nswapfl(CharsNuovi, CharsAggiustati).\n%Acc √® una lista di liste di numeri\ndecodificatore_3([],Acc,Stringa_nuova):-\nswapfl(Acc,NewAcc),\nestrai_caratteri(NewAcc,[],Chars), %chars √® un unica lista di numeri\nstring_codes(Stringa_nuova,Chars).\n%chars √® una lista di interi\ndecodificatore_3(Chars,Acc,Stringa_nuova):-\nelemAt(32,_,Chars,L,D,0),\naggiusta_stringa_2(L,NewL),\nappend(NewL,[32],NewerL),\nappend(Acc,[NewerL],Acc2), %cos√¨ facendo Acc sar√† una lista di liste\ndecodificatore_3(D,Acc2,Stringa_nuova).\nestrai_caratteri([],Acc,Acc).\n%H √® una lista di numeri\nestrai_caratteri([H|T],Acc,Chars):-\nappend(Acc,H,NewAcc),\nestrai_caratteri(T,NewAcc,Chars).\nswapfl([First|Middle1], List2) :- %inverte il primo ed ultimo elemento della lista\nappend(Middle, [Last], Middle1),\nappend([Last|Middle], [First], List2).\nESAME 4\nSi vis pacem, para bellum‚Äù\nVogliamo aiutare l‚Äôesercito romano ad essere preparato in caso di attacco per evitargli rischi inutili.\nAbbiamo scoperto che i Daci hanno dei dardi potentissimi ma prevedibili se utilizzati nel campo di battaglia. Infatti, dividendo il campo di battaglia in una griglia di n√ón quadrati, si sa che il dardo pu√≤ colpire il bersaglio su traiettorie orizzontali, verticali o diagonali fino ad una distanza di m quadrati indipendentemente dalla direzione. Conosciamo anche l‚Äôarsenale dei Daci e dispongono solo di k di questi dardi micidiali. I dardi possono essere utilizzati solo con la luce del giorno.\nI Daci controllano tutta la met√† destra del campo di battaglia e siccome i romani hanno delle buone torri di avvistamento mobili, riescono a vedere di notte dove vengono posizionati i dardi micidiali. Possono dunque posizionare agevolmente le loro coorti in posizioni nelle quali possono stare tranquilli per, eventualmente, sferrare il contrattacco.\nDal momento che possiedono un calcolatore a corde che funziona in Prolog, gli serve un programma Prolog che sia in grado di emettere rapidamente la posizione che devono tenere le v coorti romane.\n\nSe vi pare pi√π semplice, considerate n=10, k=4, m=6 e v=5. Sarebbe gradita una soluzione parametrica.\nSOLUZIONE 4\n% Student exercise profile\n:- set_prolog_flag(occurs_check, error).        % disallow cyclic terms\n:- set_prolog_stack(global, limit(8 000 000)).  % limit term space (8Mb)\n:- set_prolog_stack(local,  limit(2 000 000)).  % limit environment space\n%vero se la torre √® fuori dalla traiettoria verticale\ncheck_verticale(dardo(XD,YD,M),torre(XD,YT)):-\nDstY is YD-M,\nYT &lt; DstY,!. %sta abastanza sopra\ncheck_verticale(dardo(XD,YD,M),torre(XD,YT)):-\nDstY is YD+M,\nYT &gt; DstY,!. %sta abastanza sotto\ncheck_verticale(dardo(XD,,),torre(XT,_)):-\nXD=XT.\n%vero se la torre √® fuori dalla traiettoria orizzontale\ncheck_orizzontale(dardo(XD,YD,M),torre(XT,YD)):-\nDstX is XD-M,\nXT &lt; DstX,!.\ncheck_orizzontale(dardo(XD,YD,M),torre(XT,YD)):-\nDstX is XD+M,\nXT &gt; DstX,!.\ncheck_orizzontale(dardo(,YD,),torre(_,YT)):-\nYD=YT.\n%vero se la torre NON √® fuori dalla traiettoria diagonale\ncheck_diagonale(dardo(XD,YD,M),torre(XT,YT)):-\nSafe is abs(XD-XT),\nSafe =:= abs(YD-YT),\nSafe&lt;M.\ntorri([],_).\n%vedi se torre √® safe per ogni elem. di dardi, poi richiama con TT\ntorri([Torre|Altre], Dardi) :-\nforall(member(Dardo, Dardi), %forall √® vero se la variabile √® vera per tutte le condizioni (2¬∞ parametro)\n(check_verticale(Dardo, Torre),\ncheck_orizzontale(Dardo, Torre),\nnot(check_diagonale(Dardo,Torre)))),\ntorri(Altre, Dardi).\nESAME 5\nSi vuole costruire un analizzatore di messaggi nascosti all‚Äôinterno di sequenze di lettere apparentemente senza senso. ¬†\nUn messaggio di n parole √® scritto nella seguente maniera:\n\nSi metta un indice i = 0 ¬†\nPer ogni parola in sequenza nella frase, si metta parola[i] nella stringa se esiste, spazio se non esiste e si incrementi di 1 ¬†\nSe esiste almeno una parola in cui parola[i] esiste, si torni al passo precedente ¬†\nSi scriva un predicato prolog:\nlunghezza_messaggio(Messaggio,N)\nche sia vero se N √® la lunghezza del Messaggio in numero di parole. ¬†\n\nCome da bravi decodificatori, si √® individuato che in ogni messaggio c‚Äô√® la preposizione ‚Äúper‚Äù.\nSi scriva poi:\ndecodifica_messaggio(Messaggio,MessaggioDecodificato)\nche sia vero se MessaggioDecodificato √® il messaggio celato dentro Messaggio. ¬†\nSi tenga a mente il predicato precedente.\nDecodificare questo messaggio:\n‚Äúigspdmicpf lateiala ea tan n nrmt sgee oai na dr oe‚Äù\nSOLUZIONE 5\n% Student exercise profile\n:- set_prolog_flag(occurs_check, error).        % disallow cyclic terms\n:- set_prolog_stack(global, limit(8 000 000)).  % limit term space (8Mb)\n:- set_prolog_stack(local,  limit(2 000 000)).  % limit env\n%X=elemento da cercare, N=posizione in cui si trova X nella lista, L=lista in cui cercare X,\n%L1=gli elementi di L a sinistra di X (X escluso), L2=gli elementi di L a destra di X (X escluso)\nelemAt(X,N,[X|R],[],R,N).\nelemAt(X,N,[K|R],[K|R1],R2,Count):- %Count deve essere inizializzato a 0\nCount2 is Count+1,\nelemAt(X,N,R,R1,R2,Count2).\n% per ognuno dei predicati worker, la Stringa deve contenere uno spazio a fine parola, ad es: Stringa=[‚Äúmario rossi ‚Äù]\ndecodificatore_1_worker(Stringa,StringaAggiustata):-\nstring_codes(Stringa,X),\ndecodificatore_1(X,[],StringaAggiustata).\ndecodificatore_2_worker(Stringa,StringaAggiustata):-\nstring_codes(Stringa,X),\ndecodificatore_2(X,[],StringaAggiustata).\ndecodificatore_3_worker(Stringa,StringaAggiustata):-\nstring_codes(Stringa,X),\ndecodificatore_3(X,[],StringaAggiustata).\ndecodificatore_1([],Acc,Stringa_nuova):-\nstring_codes(Stringa_nuova,Acc), !.\ndecodificatore_1(Chars,Acc,Stringa_nuova):-\nelemAt(32,_,Chars,L,D,0),\naggiusta_stringa_1(L,NewL),\nappend(NewL,[32],NewerL),\nappend(Acc,NewerL,Acc2),\ndecodificatore_1(D,Acc2,Stringa_nuova).\naggiusta_stringa_1(Chars,CharsAggiustati):-\nreverse(Chars,CharsAggiustati).\ndecodificatore_2([],Acc,Stringa_nuova):-\nstring_codes(Stringa_nuova,Acc), !.\ndecodificatore_2(Chars,Acc,Stringa_nuova):-\nelemAt(32,_,Chars,L,D,0),\naggiusta_stringa_2(L,NewL),\nappend(NewL,[32],NewerL),\nappend(Acc,NewerL,Acc2),\ndecodificatore_2(D,Acc2,Stringa_nuova).\naggiusta_stringa_2(Chars,CharsAggiustati):-\nreverse(Chars,CharsNuovi),\nswapfl(CharsNuovi, CharsAggiustati).\n%Acc √® una lista di liste di numeri\ndecodificatore_3([],Acc,Stringa_nuova):-\nswapfl(Acc,NewAcc),\nestrai_caratteri(NewAcc,[],Chars), %chars √® un unica lista di numeri\nstring_codes(Stringa_nuova,Chars).\n%chars √® una lista di interi\ndecodificatore_3(Chars,Acc,Stringa_nuova):-\nelemAt(32,_,Chars,L,D,0),\naggiusta_stringa_2(L,NewL),\nappend(NewL,[32],NewerL),\nappend(Acc,[NewerL],Acc2), %cos√¨ facendo Acc sar√† una lista di liste\ndecodificatore_3(D,Acc2,Stringa_nuova).\nestrai_caratteri([],Acc,Acc).\n%H √® una lista di numeri\nestrai_caratteri([H|T],Acc,Chars):-\nappend(Acc,H,NewAcc),\nestrai_caratteri(T,NewAcc,Chars).\nswapfl([First|Middle1], List2) :- %inverte il primo ed ultimo elemento della lista\nappend(Middle, [Last], Middle1),\nappend([Last|Middle], [First], List2).\nESAME 6\nIl Gestore di Servizi di Trasporto Pullman (40‚Äô)\nSi vuole realizzare un servizio di erogazione di biglietti per tratte coperte da pullman.\nIl costo di ogni biglietto √® proporzionale alle tratte che devono essere svolte per giungere dalla stazione di partenza alla destinazione.\nOgni tratta, gi√† disponibile in un database, √® rappresentata da una lunghezza in kilometri, da un codice di tipologia tratta (e.g. nazionale blu, nazionale grigio, regionale blu, regionale grigio), dalla classe dei mezzi disponibili (normale, comfort, deluxe) e dalle stazioni ai due estremi.\nOgni codice di tipologia tratta ha un costo per chilometro, ed le classi comfort e deluxe hanno un coefficiente moltiplicativo di costo rispetto alla classe di viaggio normale (unico se trattasi di tutto il sistema).\nUn utente pu√≤ specificare partenza e destinazione e ricevere delle proposte di biglietto per tutte le possibili combinazioni disponibili di tratte (e di tipologie su di esse), tipi di pullman, calcolate automaticamente dal sistema.\nPer ogni biglietto √® necessario rappresentare le seguenti informazioni: la partenza, la destinazione, la sequenza delle tratte ed il tipo di mezzo ad esse associate, ed il prezzo del biglietto.\nPer lo svolgimento del compito, ignoriamo gli aspetti delle tabelle orarie (assumiamo che vi siano continuamente dei pullman in partenza da ogni stazione ad intervalli molto brevi).\nCoefficienti moltiplicativi\n\nFatt. moltip. comfort: 1,3\nFatt. moltip. deluxe: 1,7\nCosto chilometri per categoria\nnaz-grigio: 15 cent\nnaz-blu: 10 cent\nreg-grigio: 10 cent\nreg-blu: 8 cent\n\nTabella delle tratte\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTrattadist.tipo-trattaclasseRoma-Firenze200kmnaz-blu, naz-grigiotuttiRoma-Pisa220kmnaz-blunormale, comfortFirenze-Pisa50kmreg-blucomfort, deluxeFirenze-Bologna60kmreg-blu, naz-blututtiRoma-Ancona200kmreg-blu, reg-grigionormaleRoma-Pescara150kmreg-blu, reg-grigionormaleRoma-Napoli170kmnaz-blunormaleNapoli-Foggia80kmreg-blu, reg-grigionormale, comfortFoggia-Pescara100kmreg-blunormale\nSOLUZIONE 6\n% Student exercise profile\n:- set_prolog_flag(occurs_check, error).        % disallow cyclic terms\n:- set_prolog_stack(global, limit(8 000 000)).  % limit term space (8Mb)\n:- set_prolog_stack(local,  limit(2 000 000)).  % limit environment space\n%tratta, distanza, tipo tratta\ntratta(roma-firenze, 200, naz-blu).\ntratta(roma-firenze, 200, naz-grigio).\ntratta(roma-pisa, 220, naz-blu).\ntratta(firenze-pisa, 50, reg-blu).\ntratta(firenze-bologna, 60, reg-blu).\ntratta(firenze-bologna, 60, naz-blu).\ntratta(roma-ancona,200,reg-blu).\ntratta(roma-ancona,200,reg-grigio).\ntratta(roma-pescara,150,reg-blu).\ntratta(roma-pescara,150,reg-grigio).\ntratta(roma-napoli, 170, naz-blu).\ntratta(napoli-foggia, 80, reg-blu).\ntratta(napoli-foggia, 80, reg-grigio).\ntratta(foggia-pescara, 100, reg-blu).\ntipo_tratta(naz-grigio, 15).\ntipo_tratta(naz-blu, 10).\ntipo_tratta(reg-grigio, 10).\ntipo_tratta(reg-blu, 8).\n%in input: partenza e destinazione\n%output: percorso con tutte le tappe per arrivare a destinazione spendendo il meno possibile\nconnessi(A, B, Distanza, Tipo) :-\ntratta(A-B, Distanza, Tipo).\nconnessi(A, B, Distanza, Tipo) :-\ntratta(B-A, Distanza, Tipo).\npercorso_economico(Partenza, Destinaz, Tappe, CostoMinimo) :-\n%prendi TUTTI i percorsi da una tappa all‚Äôaltra, ed ordinali per costo\nsetof(Costo-Tappe, percorso_con_costo(Partenza, Destinaz, [Partenza], Tappe, 0, Costo), Percorsi),\nPercorsi = [CostoMinimo-Tappe | _].  % Il primo √® il pi√π economico, grazie a setof/3\npercorso_con_costo(Citt√†, Citt√†, Acc, Tappe, Costo, Costo):-\nreverse(Acc, Tappe). %perch√® Visitate √® in ordine inverso alle tappe fatte\npercorso_con_costo(Corrente, Destinazione, Visitate, Tappe, CostoParziale, CostoTotale) :-\nconnessi(Corrente, Prossima, _, Tipo),\n+ member(Prossima, Visitate),  % Evita cicli\ntipo_tratta(Tipo, Prezzo),\nNuovoCosto is CostoParziale + Prezzo, %vediamo il prezzo della tratta trovata e lo aggiungiamo al costo attuale\npercorso_con_costo(Prossima, Destinazione, [Prossima|Visitate], Tappe, NuovoCosto, CostoTotale).\nESAME 7\nmatrice di caratteri, la consegna non √® nota\nSOLUZIONE 7\n% Student exercise profile\n:- set_prolog_flag(occurs_check, error).        % disallow cyclic terms\n:- set_prolog_stack(global, limit(8 000 000)).  % limit term space (8Mb)\n:- set_prolog_stack(local,  limit(2 000 000)).  % limit environment space\n:- discontiguous quadrato/5.\n%X=elemento da cercare, N=posizione in cui ci troviamo nella lista, L=lista ordinata,\n%L1=gli elementi di L a sinistra di X, L2=gli elementi di L a destra di X\nelemAt(X,N,L,R1,R2):- elemAt(X,N,L,R1,R2,0).\nelemAt(X,N,[X|R],[],R,N).\nelemAt(X,N,[K|R],[K|R1],R2,Count):-\nCount2 is Count+1,\nelemAt(X,N,R,R1,R2,Count2).\nlinea(,,[]):- fail. %non √® necessario perch√® tanto prolog se ne occuper√† da solo ma vabb√®\nlinea(A,Len,[H|]):-\ncontrolla_seq(A,Len,H),!.\nlinea(A,Len,[|T]):-\nlinea(A,Len,T).\ncontrolla_seq(A, L, Lista) :-controlla_seq_aux(A, L, Lista, 0).\ncontrolla_seq_aux(_, L, , L).% Caso di successo: contatore ha raggiunto L\ncontrolla_seq_aux(, _, [], ):- fail.% Se la lista √® finita e non abbiamo raggiunto L, fallisce\ncontrolla_seq_aux(A, L, [A|T], C) :-% Se l‚Äôelemento corrente √® A, incrementiamo il contatore\nC1 is C + 1,\ncontrolla_seq_aux(A, L, T, C1).\ncontrolla_seq_aux(A, L, [|T], _) :-% Se l‚Äôelemento corrente non √® A, resettiamo il contatore\ncontrolla_seq_aux(A, L, T, 0).\nquadrato(,,,0,):- !. %trovato, C=0 (Il cut non funziona?)\nquadrato(,,[],,):-fail.\n%versione giusta: trova A nella sua posizione,vedi se c‚Äô√® la sequenza da quella posizione, ripeti per le altre Len liste\n%C uguale a Len all‚Äôinizio\nquadrato(A,Len,L):-\nquadrato(A,Len,L,Len).\n%1^ iterazione, trovo A per la prima volta\nquadrato(A,Len,[H|T],C):-\nelemAt(A,N,H,,R),\ncontrolla_seq(A,Len,[A|R]),\nC2 is C-1, %trovata, abbiamo altri C2 lati da cercare\nquadrato(A,Len,T,C2,N).\n%non ho trovato A a questa iteraz. di tipo 1\nquadrato(A,Len,[|T],_):-\nquadrato(A,Len,T,Len).\n%2^ iteraz., ho trovato A una volta, ora devo ricercarlo nelle prossime C liste in posiz. N\nquadrato(A,Len,[H|T],C,N):-\nelemAt(A,N,H,_,R),\ncontrolla_seq(A,Len,[A|R]),\nC2 is C-1,\nquadrato(A,Len,T,C2,N).\n%non abbiamo trovato il quadrato, od un lato √® meno lungo del previsto, ri-inizia dalla 1^ iteraz.\nquadrato(A,Len,[|T],,_):-\nquadrato(A,Len,T,Len).\nLISTA COMANDI SAFE DA USARE\n\nappend(L1,L2,L3) ‚Üí unisce due liste (L3 = L1 + L2).\nmember(Elem,L) ‚Üí vero se Elem appartiene a L.\nreverse(L,Lrev) ‚Üí vero se Lrev √® la lista L al contrario.\nlength(L,N) ‚Üí vero se N √® la lunghezza di L.\nis_list(L) (o list(L) in alcuni dialetti) ‚Üí vero se L √® una lista.\n\nüîπ Gestione atomi, stringhe e numeri\n\natom(A) ‚Üí vero se A √® un atomo.\nnumber(A) ‚Üí vero se A √® un numero.\nstring_codes(String,List) ‚Üí converte tra stringa e lista di codici carattere.\natom_codes(Atom,List) ‚Üí converte tra atomo e lista di codici carattere.\ndowncase_atom(A,Lower) ‚Üí converte un atomo in minuscolo.\nabs(N) ‚Üí restituisce il valore assoluto.\n\nüîπ Gestione della conoscenza dinamica\n\nassertz(Fatto) ‚Üí aggiunge un fatto alla base di conoscenza.\nretractall(Head) ‚Üí rimuove tutti i fatti che unificano con Head.\ndynamic/1 ‚Üí dichiara un predicato dinamico (per poter fare assert/retract).\n\nüîπ Controllo e meta-predicati\n\nonce(Goal) ‚Üí prova Goal una sola volta.\nforall(Cond,Az) ‚Üí vero se per tutti i Cond √® vera Az.\nnot(Goal) oppure \\+(Goal) ‚Üí negazione come fallimento.\n!/0 (cut) ‚Üí impedisce backtracking oltre il punto in cui si trova.\n\nüîπ I/O\n\nwrite(Term) ‚Üí scrive un termine su output.\nnl ‚Üí va a capo.\n\nüîπ Gestione ambiente Prolog\n\nset_prolog_flag(Flag,Value) ‚Üí imposta un parametro del motore Prolog (es. memoria, controlli).\n\nüîπ Raccolta di soluzioni\n\nsetof(X,Goal,Set) ‚Üí raccoglie in Set tutti gli X che soddisfano Goal, senza duplicati e ordinati.\n"},"UNI/ANNO-2/LINGUAGGI/PROLOG/GUIDA-CHAT":{"slug":"UNI/ANNO-2/LINGUAGGI/PROLOG/GUIDA-CHAT","filePath":"UNI/ANNO 2/LINGUAGGI/PROLOG/GUIDA CHAT.md","title":"GUIDA CHAT","links":[],"tags":[],"content":"Sei uno studente di Prolog all‚Äôesame su SWISH prolog, hai a disposizione solo un‚Äôora per risolvere un esercizio. L‚Äôesercizio √® simile a quelli presenti nel file LineaGuida_Prolog.md (codificatori, predicati come dividiparole, invertiparole, gestione di stringhe, liste, grafi, DFS/BFS, ecc.). Devi scrivere la soluzione in modo dichiarativo, senza ottimizzazioni troppo avanzate, usando solo i predicati consentiti (append/3, atom/1, number/1, member/2, list/1, reverse/2, length/2). La soluzione deve sembrare fatta da uno studente medio, con: - qualche piccolo errore o imprecisione (es. un commento non preciso, una clausola un po‚Äô ripetitiva, un uso non ottimale di append). - codice che funziona a grandi linee ma non perfetto. - spiegazione minima o commenti scritti in fretta. Risultato atteso: un file di codice Prolog abbastanza corretto ma con stile ‚Äúda compito in aula fatto in fretta‚Äù, senza sembrare scritto da un esperto."},"UNI/ANNO-2/LINGUAGGI/PROLOG/LineaGuida_Prolog":{"slug":"UNI/ANNO-2/LINGUAGGI/PROLOG/LineaGuida_Prolog","filePath":"UNI/ANNO 2/LINGUAGGI/PROLOG/LineaGuida_Prolog.md","title":"LineaGuida_Prolog","links":[],"tags":[],"content":"üìë Linea guida Prolog ‚Äì Esercizi e Comandi\n1. Predicati built-in per il compito\n\nappend(L1,L2,L3) ‚Üí unisce due liste: L3 = L1 + L2.\natom(A) ‚Üí vero se A √® un atomo (es. a, pippo).\nnumber(A) ‚Üí vero se A √® un numero.\nmember(Elem,L) ‚Üí vero se Elem appartiene alla lista L.\nlist(L) ‚Üí vero se L √® una lista.\nreverse(L,Lrev) ‚Üí vero se Lrev √® la lista L al contrario.\nlength(L,N) ‚Üí vero se N √® la lunghezza di L.\n\n\n2. Esercizi sui codificatori\n2.1. Codifica 1 ‚Äì Invertire le parole\ncodifica1(L,L1):-\n    string_codes(L,T),\n    dividiparole(T,R),\n    invertiparole(R,C),\n    unisciparole(C,S),\n    string_codes(L1,S).\n2.2. Codifica 2 ‚Äì Scambiare primo/ultimo carattere\ncodifica2(L,L1):-\n    string_codes(L,T),\n    dividiparole(T,R),\n    invertiparole(R,C),\n    passaparole(C,D),\n    unisciparole(D,S),\n    string_codes(L1,S).\n2.3. Codifica 3 ‚Äì Invertire prima/ultima parola\ncodifica3(L,L1):-\n    string_codes(L,T),\n    dividiparole(T,R),\n    invertiparole(R,C),\n    passaparole(C,D),\n    invertilettere(D,A),\n    unisciparole(A,S),\n    string_codes(L1,S).\n\n3. Esame ‚Äì Decodifica messaggio\n\nPredicato principale: decodifica_messaggio/2\nPredicati ausiliari: dividiparole, prendiparole, lunghezza_messaggio, conta32, maxlen, predicatoPrincipe\n\n\n4. Esame ‚Äì Codice grafo\n4.1. Parsing frasi con DCG\n\nPattern:\n\nX si nutre di Y\nX mangia Y\nil cibo del X e la Y\n\n\n\n4.2. Costruzione grafo\n\nPredicato principale: grafo/1\nInserimento frasi: asserisciFrasi/1\n\n\n5. Esercizi vari\n5.1. Operatori logici\n:- op(700, fy, not).\nnot(P):- P,!,fail.\nnot(_).\n5.2. Operatori personalizzati\n:- op(700, yfx, ha).\n:- op(500, yfx, di).\n:- op(300, fx, il).\n:- op(300, fx, la).\n \nmario ha la macchina di dario.\ngiovanni ha il cestino di mario.\n5.3. Massimi\nmax(A,B,A):- number(A), number(B), A &gt; B.\nmax(A,B,B):- number(A), number(B), B &gt; A.\n \nmaxlist([A],A).\nmaxlist([A|T],A):- maxlist(T,B), A &gt;= B.\nmaxlist([A|T],B):- maxlist(T,B), B &gt; A.\n5.4. Implementazione manuale di reverse e append\nreversed([],[]).\nreversed([H|T],X):- reversed(T,Y), append2(Y,[H],X).\n \nappend2([],Z,Z).\nappend2([H|T],Y,[H|Z]):- append2(T,Y,Z).\n\n6. Grafi\n6.1. Path\nedge(a,b). edge(b,c). edge(c,d). edge(d,e).\npath(X,Z):- edge(X,Z).\npath(X,Y):- edge(X,Z), path(Z,Y).\n6.2. DFS (profondit√†)\n\nsolve/2 ‚Äì versione base\nsolve2/2 ‚Äì evita cicli\nsolve3/3 ‚Äì profondit√† limitata\n\n6.3. BFS (ampiezza)\n\nvisitabfs/2\nsolve4/2 con breadthfirst\n\nDECODIFICATORI\n% Student exercise profile\n:- set_prolog_flag(occurs_check, error).        % disallow cyclic terms\n:- set_prolog_stack(global, limit(8 000 000)).  % limit term space (8Mb)\n:- set_prolog_stack(local,  limit(2 000 000)).  % limit env\n%X=elemento da cercare, N=posizione in cui si trova X nella lista, L=lista in cui cercare X,\n%L1=gli elementi di L a sinistra di X (X escluso), L2=gli elementi di L a destra di X (X escluso)\nelemAt(X,N,[X|R],[],R,N).\nelemAt(X,N,[K|R],[K|R1],R2,Count):- %Count deve essere inizializzato a 0\nCount2 is Count+1,\nelemAt(X,N,R,R1,R2,Count2).\n% per ognuno dei predicati worker, la Stringa deve contenere uno spazio a fine parola, ad es: Stringa=[‚Äúmario rossi ‚Äù]\ndecodificatore_1_worker(Stringa,StringaAggiustata):-\nstring_codes(Stringa,X),\ndecodificatore_1(X,[],StringaAggiustata).\ndecodificatore_2_worker(Stringa,StringaAggiustata):-\nstring_codes(Stringa,X),\ndecodificatore_2(X,[],StringaAggiustata).\ndecodificatore_3_worker(Stringa,StringaAggiustata):-\nstring_codes(Stringa,X),\ndecodificatore_3(X,[],StringaAggiustata).\ndecodificatore_1([],Acc,Stringa_nuova):-\nstring_codes(Stringa_nuova,Acc), !.\ndecodificatore_1(Chars,Acc,Stringa_nuova):-\nelemAt(32,_,Chars,L,D,0),\naggiusta_stringa_1(L,NewL),\nappend(NewL,[32],NewerL),\nappend(Acc,NewerL,Acc2),\ndecodificatore_1(D,Acc2,Stringa_nuova).\naggiusta_stringa_1(Chars,CharsAggiustati):-\nreverse(Chars,CharsAggiustati).\ndecodificatore_2([],Acc,Stringa_nuova):-\nstring_codes(Stringa_nuova,Acc), !.\ndecodificatore_2(Chars,Acc,Stringa_nuova):-\nelemAt(32,_,Chars,L,D,0),\naggiusta_stringa_2(L,NewL),\nappend(NewL,[32],NewerL),\nappend(Acc,NewerL,Acc2),\ndecodificatore_2(D,Acc2,Stringa_nuova).\naggiusta_stringa_2(Chars,CharsAggiustati):-\nreverse(Chars,CharsNuovi),\nswapfl(CharsNuovi, CharsAggiustati).\n%Acc √® una lista di liste di numeri\ndecodificatore_3([],Acc,Stringa_nuova):-\nswapfl(Acc,NewAcc),\nestrai_caratteri(NewAcc,[],Chars), %chars √® un unica lista di numeri\nstring_codes(Stringa_nuova,Chars).\n%chars √® una lista di interi\ndecodificatore_3(Chars,Acc,Stringa_nuova):-\nelemAt(32,_,Chars,L,D,0),\naggiusta_stringa_2(L,NewL),\nappend(NewL,[32],NewerL),\nappend(Acc,[NewerL],Acc2), %cos√¨ facendo Acc sar√† una lista di liste\ndecodificatore_3(D,Acc2,Stringa_nuova).\nestrai_caratteri([],Acc,Acc).\n%H √® una lista di numeri\nestrai_caratteri([H|T],Acc,Chars):-\nappend(Acc,H,NewAcc),\nestrai_caratteri(T,NewAcc,Chars).\nswapfl([First|Middle1], List2) :- %inverte il primo ed ultimo elemento della lista\nappend(Middle, [Last], Middle1),\nappend([Last|Middle], [First], List2)."},"UNI/ANNO-2/LINGUAGGI/PROLOG/Lista-comandi-chat-gpt":{"slug":"UNI/ANNO-2/LINGUAGGI/PROLOG/Lista-comandi-chat-gpt","filePath":"UNI/ANNO 2/LINGUAGGI/PROLOG/Lista comandi chat gpt.md","title":"Lista comandi chat gpt","links":[],"tags":[],"content":"comandi utilizzabili per il compito:\nappend(L1,L2,L3) ‚Üí unisce due liste: L3 = L1 + L2. atom(A) ‚Üí vero se A √® un atomo (es. a, pippo). number(A) ‚Üí vero se A √® un numero. member(Elem,L) ‚Üí vero se Elem appartiene alla lista L. list(L) ‚Üí vero se L √® una lista. reverse(L,Lrev) ‚Üí vero se Lrev √® la lista L al contrario. length(L,N) ‚Üí vero se N √® la lunghezza di L.\nEsame codificatori\n%esame sui codificatori 3 codifiche diverse\n%codifica 1 chiede di invertire le parole\n%codifica 2 chiede di prendere codifica 1 e invertire il primo e l&#039;ultimo carattere di ogni parola\n%codifica 3 chiede di prendere codifica 2 e invertire prima e ultima parola\n \n \n \n%dividiparole semplicemente seziona la stringa in sottostringhe tagliando il carattere 32 = spazio in codice ascii\ndividiparole([],[]).\n \n \ndividiparole([32|T],L):-!,  %questo in particolare serve a escludere parole vuote\n    dividiparole(T,L).\n \ndividiparole(L,[Word|Rest]):-\n    prendiparole(L,Word,RestoLista),\n    dividiparole(RestoLista,Rest).\n \n%prendiparole √® ausiliario a dividiparole,\n% essenzialmente prende la stringa intera e restituisce come secondo parametro la parola troncata da 32\nprendiparole([],[],[]).\n \nprendiparole([32|T],[],T):-!.\n \nprendiparole([T|L],[T|L2],Rest):-\n    prendiparole(L,L2,Rest).\n    \n \n%invertiparole molto semplicemente ogni parola della lista di sottoliste (parole)\ninvertiparole([],[]).\n \ninvertiparole([H|T],[H1|T1]):-\n              reverse(H,H1),\n              invertiparole(T,T1).\n \n \n \n%unisciparole ricrea la lista iniziale decapsulando le sottoliste e inserendo 32 tra una e l&#039;altra \nunisciparole([],[]).\nunisciparole([W],W).\n \nunisciparole([W|Res],L):-\n    unisciparole(Res,L1),\n    append(W,[32|L1],L).\n    \n    \n%la prima codifica richiesta\ncodifica1(L,L1):-\n    string_codes(L,T),\n    dividiparole(T,R),\n    invertiparole(R,C),\n    unisciparole(C,S),\n    string_codes(L1,S).\n \n \n%tutto cio che √® scritto qui sopra serve per codifica1, sotto ci saranno parti aggiuntive per le altre codifiche\n \n%PARTI AGGIUNTIVE PER CODIFICA2:\n \n%invertilettere inverte il primo e l&#039;ultimo elemento della lista passata\ninvertilettere([_],[_]).\ninvertilettere([X,Y],[Y,X]).\ninvertilettere([H|T],[H1|T1]):-\n    append(X,[H1],T),\n    append(X,[H],T1).\n   \n%passaparole utilizzato per passare le singole parole a invertilettere\npassaparole([],[]).\npassaparole([H|T],[H1|L]):-\n    passaparole(T,L),\n    invertilettere(H,H1).\n \n%CODIFICA2: si comporta come richiesto con l&#039;aggiunta dei predicati\ncodifica2(L,L1):-\n    string_codes(L,T),\n    dividiparole(T,R),\n    invertiparole(R,C),\n    passaparole(C,D),\n    unisciparole(D,S),\n    string_codes(L1,S).\n \n \n \n \n%CODIFICA3: sfrutta inverti lettere per invertire le parole\ncodifica3(L,L1):-\n    string_codes(L,T),\n    dividiparole(T,R),\n    invertiparole(R,C),\n    passaparole(C,D),\n    invertilettere(D,A),\n    unisciparole(A,S),\n    string_codes(L1,S).\n \n \n \ncodificatori esame 2\n \ndecodifica_messaggio(Messaggio,Decodifica):-\n    codifica1(Messaggio,B),\n    predicatoPrincipe(B,Messaggio2,0),\n    string_codes(Decodifica,Messaggio2).\n \n \ndividiparole([],[]).\ndividiparole([32|T],L):-!,\n    dividiparole(T,L).\ndividiparole(T,[Word|Rest]):-\n    prendiparole(T,Word,Restolista),\n    dividiparole(Restolista,Rest).\n \nprendiparole([],[],[]).\nprendiparole([32|Resto],[],Resto):-!.\nprendiparole([H|T],[H|T1],Resto):-\n    prendiparole(T,T1,Resto).\n \n \ncodifica1(A,B):-\n    string_codes(A,C),\n    dividiparole(C,B).\n \n \n \nlunghezza_messaggio([],0).\nlunghezza_messaggio([_|T],N):-\n    lunghezza_messaggio(T,N1),\n    N is N1 + 1.\n \n \nconta32([],0):-!.\nconta32([32|T],N):-\n    conta32(T,N1),\n    N is N1+1,!.\nconta32([_|T],N):-\n    conta32(T,N),!.\n \n \n \n \nmaxlen([],0).\nmaxlen([P|Ps],M):-\n    length(P,L),\n    maxlen(Ps,M1),\n    M is max(L,M1).\n \n \n% caso base: se nessuna parola ha una lettera a posizione N, stop\npredicatoPrincipe(Messaggio,[],N):-\n    maxlen(Messaggio,M),\n    N &gt;= M.\n \n% passo ricorsivo\npredicatoPrincipe(Messaggio,C,N):-\n    % qui so che almeno una parola ha una lettera\n    passaparole(Messaggio,H,N),\n    N1 is N+1,\n    predicatoPrincipe(Messaggio,T,N1),\n    append(H,T,C).\n \n \n    \npassaparole([],[],_).\npassaparole([Parola|Resto],[H|T],Number):-\n    codificatore(Parola,H,Number),\n    passaparole(Resto,T,Number).\n    \ncodificatore([],32,_).\ncodificatore([H|_],H,0).\ncodificatore([_|T],Letter,Number):-\n    Number1 is Number-1,\n    codificatore(T,Letter,Number1).\n \nEsame codice grafo\n/* query example:\n \ncodifica1(&quot;Il cavallo si nutre di biada\n \nIl cibo del pony e la ciccia\n \nIl pony si nutre di ciccia\n \nIl maile mangia la cicoria\n \nIl ragno si nutre di rosmarino&quot;,L).\n \n*/\n \n  \n  \n \n:- dynamic mangia/2.\n \n%dividiparole semplicemente seziona la stringa in sottostringhe tagliando il carattere 32 = spazio in codice ascii\n \ndividiparole([],[]).\n \n  \n  \n \ndividiparole([32|T],L):-!, ¬†%questo in particolare serve a escludere parole vuote\n \n¬† ¬† dividiparole(T,L).\n \n  \n \ndividiparole(L,[Word|Rest]):-\n \n¬† ¬† prendiparole(L,Word,RestoLista),\n \n¬† ¬† dividiparole(RestoLista,Rest).\n \n  \n \n%prendiparole √® ausiliario a dividiparole,\n \n% essenzialmente prende la stringa intera e restituisce come secondo parametro la parola troncata da 32\n \nprendiparole([],[],[]).\n \n  \n \nprendiparole([32|T],[],T):-!.\n \n  \n \nprendiparole([T|L],[T|L2],Rest):-\n \n¬† ¬† prendiparole(L,L2,Rest).\n \n  \n \nconvertiparole([],[]).\n \nconvertiparole([H|T],[H1|T1]):-\n \n¬† ¬† atom_codes(H2,H),\n \n¬† ¬† downcase_atom(H2,H1),\n \n¬† ¬† convertiparole(T,T1).\n \n  \n  \n \nrecuperaFrasi([],[]).\n \nrecuperaFrasi([H|T],[H1|T1]):-\n \n¬† ¬† string_codes(H,H1),\n \n¬† ¬† recuperaFrasi(T,T1).\n \n  \n \nrichiamaDividi([],[]).\n \nrichiamaDividi([H|T],[H1|T1]):-\n \n¬† ¬† dividiparole(H,H1),\n \n¬† ¬† richiamaDividi(T,T1).\n \n  \n \nrichiamaConverti([],[]).\n \nrichiamaConverti([H|T],[H1|T1]):-\n \n¬† ¬† richiamaConverti(T,T1),\n \n¬† ¬† convertiparole(H,H1).\n \n%la prima codifica richiesta\n \ncodifica1(L,L1):-\n \n¬† ¬† string_lines(L,A),\n \n¬† ¬† recuperaFrasi(A,B),\n \n¬† ¬† richiamaDividi(B,C),\n \n¬† ¬† richiamaConverti(C,L1),\n \n¬† ¬† grafo(L1).\n \n  \n \n% --- predicato principale ---\n \nestrai_mangia(FraseList, mangia(S,O)) :-\n \n¬† ¬† once(phrase(frase(mangia(S,O)), FraseList)).\n \n  \n \n% --- Regole principali della grammatica ---\n \nfrase(F) --&gt; pattern_nutre(F).\n \nfrase(F) --&gt; pattern_mangia(F).\n \nfrase(F) --&gt; pattern_cibo(F).\n \n  \n \nskip_word --&gt; [_]. ¬† ¬† ¬† % salta una parola qualsiasi\n \nskip_words --&gt; skip_word, skip_words.\n \nskip_words --&gt; [].\n \n  \n \n% --- pattern &quot;X si nutre di Y&quot; ---\n \npattern_nutre(mangia(S,O)) --&gt;\n \n¬† ¬† skip_words, [S,si,nutre,di,O], skip_words.\n \n  \n \npattern_mangia(mangia(S,O)) --&gt;\n \n¬† ¬† skip_words, [S,mangia,la,O]|[S,mangia,il,O]|[S,mangia,lo,O]|[S,mangia,gli,O]|[S,mangia,i,O]|[S,mangia,le,O], skip_words.\n \n  \n \npattern_cibo(mangia(S,O)) --&gt;\n \n¬† ¬† skip_words, [il,cibo,del,S,e,la,O]|[il,cibo,del,S,e,il,O]|[il,cibo,del,S,e,lo,O]|[il,cibo,del,S,e,gli,O]|[il,cibo,del,S,e,le,O]|[il,cibo,del,S,e,i,O], skip_words.\n \n  \n  \n \ngrafo(L):-\n \n¬† ¬† retractall(mangia(_,_)),\n \n¬† ¬† write(&#039;Inizio inserimento frasi nel database...&#039;), nl,\n \n¬† ¬† asserisciFrasi(L).\n \n  \n \nasserisciFrasi([]).\n \nasserisciFrasi([H|T]):-\n \n¬† ¬† ( estrai_mangia(H,C) -&gt; ¬†% se la frase viene parsata correttamente\n \n¬† ¬† ¬† ¬† assertz(C)\n \n¬† ¬† ;\n \n¬† ¬† ¬† ¬† true ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬†% altrimenti ignora la frase e continua\n \n¬† ¬† ),\n \n¬† ¬† asserisciFrasi(T).\nCodici a caso\nnum(Number)‚áí [Number] , {number(Number)}.\nf(Ris)‚áí num(Val1), oper(OP), num(Val2), {P=.. [OP,Val1,Val2], Ris is P}.\noper(+)‚áí [pi√π].\noper(-)‚áí [meno].\noper(/)‚áí [diviso].\noper(*)‚áí [per].\n%query di esempio: f(Ris,[4, per, 8],R).\n% DEFINIZIONE DELL‚ÄôOPERATORE NOT\n% espressione della frase ‚ÄúMary ama tutti gli animali, ma non i serpenti‚Äù\n% con il predicato likes\n:-op(700,fy,not).\nnot(P):-\nP,!,fail.\nnot(_).\nanimal(camaleonte).\nanimal(pincopallino).\nanimal(serpente).\nsnake(serpente).\nlikes(mary, X):-\nanimal(X),\nnot snake(X).\n%esercizio su ridefinzione operatori per rispondere alla sintassi normale di una frase\n:-op(700, yfx, ha).\n:-op(500, yfx, di).\n:-op(300, fx, il).\n:-op(300,fx, la).\nmario ha la macchina di dario.\ngiovanni ha il cestino di mario.\n% max= massimo tra due numeri\nmax(A,B,A):-\nnumber(A),\nnumber(B),\nA&gt;B.\nmax(A,B,B):-\nnumber(A),\nnumber(B),\nB&gt;A.\n% maxlist= massimo all interno di una lista,\n% ATTENZIONE: in caso di non funzionamento inserire il predicato number come sopra.\nmaxlist([A],A).\nmaxlist([A|T],A):-\nmaxlist(T,B),\nA&gt;=B.\nmaxlist([A|T],B):-\nmaxlist(T,B),\nB&gt;A.\n% implementazione fatta a mano di reverse:\n% ATTENZIONE: in questo esempio utiliziamo append2 fatto da me\n% √® possibile utilizzarla con ‚Äúappend‚Äù che √® built-in\nreversed([],[]).\nreversed([H|T],X):-\nreversed(T,Y),\nappend2(Y,[H],X).\n%  implementazione fatta a mano di append\nappend2([],Z,Z).\nappend2([H|T],Y,[H|Z]):-\nappend2(T,Y,Z).\n%  implementazione fatta a mano di append\nappend2([],Z,Z).\nappend2([H|T],Y,[H|Z]):-\nappend2(T,Y,Z).\nedge(a,b).\nedge(b,c).\nedge(c,d).\nedge(d,e).\nedge(f,e).\nedge(a,e).\npath(X,Z):- edge(X,Z).\npath(X,Y):-\nedge(X,Z),\npath(Z,Y).\n%un modo per rappresentare tutte le transizioni di stato\n% ATTENZIONE, il modo in cui rappresnetiamo le transizioni\n% dipende dal grafo che stiamo rappresentando\n% quindi non esiste un modo univoco\ns([[A|RA],B,C],[RA,[A|B],C]).\ns([[A|RA],B,C],[RA,B,[A|C]]).\ns([B,[A|RA],C],[[A|B],RA,C]).\ns([B,[A|RA],C],[B,RA,[A|C]]).\ns([B,C,[A|RA]],[[A|B],C,RA]).\ns([B,C,[A|RA]],[B,[A|C],RA]).\n%predicato per trovare l‚Äôobbiettivo che cerchiamo\ngoal(Situation):-\nmember([a,b,c], Situation).\n%DFS\nsolve(N,[N]):-\ngoal(N).\nsolve(N,[N|Sol1]):-\ns(N,N1),\nsolve(N1,Sol1).\n/*\nL‚Äôidea che sta alla base di questo tipo di ricerca √® la seguente:\nPer trovare il percorso che rappresenta la soluzione, Sol, dato un nodo N, ed almeno un nodo obiettivo:\nSe N √® la l‚Äôobiettivo, allora Sol = [N], altrimenti\nSe esiste un nodo connesso a N, detto N1, tale che esista una soluzione Sol1 da N1 ad un nodo obiettivo, allora Sol = [N | Sol1]\n*/\n%un modo per rappresentare tutte le transizioni di stato\n% ATTENZIONE, il modo in cui rappresnetiamo le transizioni\n% dipende dal grafo che stiamo rappresentando\n% quindi non esiste un modo univoco\ns([[A|RA],B,C],[RA,[A|B],C]).\ns([[A|RA],B,C],[RA,B,[A|C]]).\ns([B,[A|RA],C],[[A|B],RA,C]).\ns([B,[A|RA],C],[B,RA,[A|C]]).\ns([B,C,[A|RA]],[[A|B],C,RA]).\ns([B,C,[A|RA]],[B,[A|C],RA]).\n%predicato per trovare l‚Äôobbiettivo che cerchiamo\ngoal(Situation):-\nmember([a,b,c], Situation).\n% DFS VERSIONE 2:\n% QUESTA VERSIONE FA SI CHE SI RICORDI IL PERCORSO SVOLTO FIN ORA\n% PER NON TORNARE SU CONFIGURAZIONI GI√† VISITATE ED EVITARE UN LOOP\n% (attenzione: quando parliamo di configurazioni gi√† visitate parilamo di nodi di un grafo).\nsolve2( Node, Solution)  :-\ndepthfirst2( [], Node, Solution).\ndepthfirst2( Path, Node, [Node | Path] )  :-\ngoal( Node).\ndepthfirst2( Path, Node, Sol) :-\ns( Node, Node1),\nnot(member( Node1, Path)),\ndepthfirst2( [Node | Path], Node1, Sol).\n/*\nL‚Äôidea che sta alla base di questo tipo di ricerca √® la seguente:\nPer trovare il percorso che rappresenta la soluzione, Sol, dato un nodo N, ed almeno un nodo obiettivo:\nSe N √® la l‚Äôobiettivo, allora Sol = [N], altrimenti\nSe esiste un nodo connesso a N, detto N1, tale che esista una soluzione Sol1 da N1 ad un nodo obiettivo, allora Sol = [N | Sol1]\n*/\n%visitaBFS grafo\narco(a,b).\narco(a,c).\narco(a,d).\narco(b,z).\narco(b,x).\narco(c,y).\narco(c,z).\narco(z,s).\narco(s,u).\nconnessione(X,Y):-\narco(X,Y).\nsetog(H,C):-\nsetof(Y,connessione(H,Y),C),\nwrite(C),nl.\nsetog(_,[]).\nfrontiera([],[]).\nfrontiera([X],L):-\nsetog(X,L).\nfrontiera([H|T], L):-\nsetog(H,C),\nappend(C,Z,L),\nfrontiera(T,Z).\nvisitabfs([],[]).\nvisitabfs(X,L):-\nfrontiera(X,C),\nappend(C,Y,L),\nvisitabfs(C,Y).\n%visitaBFS grafo\narco(a,b).\narco(a,c).\narco(a,d).\narco(b,z).\narco(b,x).\narco(c,y).\narco(c,z).\narco(z,s).\narco(s,u).\nconnessione(X,Y):-\narco(X,Y).\nsetog(H,C):-\nsetof(Y,connessione(H,Y),C),\nwrite(C),nl.\nsetog(_,[]).\nfrontiera([],[]).\nfrontiera([X],L):-\nsetog(X,L).\nfrontiera([H|T], L):-\nsetog(H,C),\nappend(C,Z,L),\nfrontiera(T,Z).\nvisitabfs([],[]).\nvisitabfs(X,L):-\nfrontiera(X,C),\nappend(C,Y,L),\nvisitabfs(C,Y).\n/*\nVISITA BFS DEL GRAFO:\nVERSIONE ADATTATA CON DEI PREDICATI CHE FORMANO DEI FATTI\nquery tipica: solve4(nodo(start,b),Situation).\n*/\nnodo(start,a).\nnodo(a,b).\nnodo(a,c).\nnodo(a,d).\nnodo(a,e).\nnodo(a,f).\nnodo(b,c).\nnodo(b,f).\nnodo(b,e).\nnodo(f,c).\nnodo(e,c).\nnodo(f,h).\nnodo(h,m).\nnodo(m,n).\nnodo(n,y).\nnodo(d,k).\nnodo(k,y).\nnodo(y,z).\nnodo(z,x).\ngoal(nodo(_,x)).\nsolve4( Start, Solution)  :-\nbreadthfirst( [ [Start] ] , Solution).\nbreadthfirst( [ [Node | Path] | _] , [Node | Path] )  :-\ngoal(Node).\nbreadthfirst( [Path | Paths] , Solution)  :-\nextend( Path, NewPaths),\nappend( Paths, NewPaths, Paths1),\nbreadthfirst( Paths1, Solution).\nextend( [nodo(X,Y) | Path], NewPaths)  :-\nbagof( [nodo(Y,Z), nodo(X,Y) | Path],\n(  nodo(Y,Z), not(member( nodo(Y,Z), [nodo(X,Y) | Path] )) ),\nNewPaths),\n!.\nextend( _, [] ).\n/*\nL‚Äôidea che sta alla base di questo tipo di ricerca √® la seguente:\nData una lista di possibili percorsi:\nSe la testa della prima lista √® un obiettivo, allora quel percorso √® la soluzione\nAltrimenti rimuovi il primo percorso dalla lista dei candidati,\ngenera tutti i percorsi che fanno uno step in pi√π del percorso appena\neliminato e inseriscili in coda alla lista dei percorsi candidati e analizza\nil percorso che ora si trova in testa alla lista dei possibili percorsi\n*/\n%un modo per rappresentare tutte le transizioni di stato\n% ATTENZIONE, il modo in cui rappresnetiamo le transizioni\n% dipende dal grafo che stiamo rappresentando\n% quindi non esiste un modo univoco\ns([[A|RA],B,C],[RA,[A|B],C]).\ns([[A|RA],B,C],[RA,B,[A|C]]).\ns([B,[A|RA],C],[[A|B],RA,C]).\ns([B,[A|RA],C],[B,RA,[A|C]]).\ns([B,C,[A|RA]],[[A|B],C,RA]).\ns([B,C,[A|RA]],[B,[A|C],RA]).\n%predicato per trovare l‚Äôobbiettivo che cerchiamo\ngoal(Situation):-\nmember([a,b,c], Situation).\n% DFS VERSIONE 3:\n% QUESTA VERSIONE LIMIT√† LA PROFONDIT√†, OVVERO IL NUMERO DI NODI VISITATI\nsolve3( Node, Solution, Max)  :-\ndepthfirst3( Node, Solution, Max).\ndepthfirst3( Node, [Node], _)  :-\ngoal( Node).\ndepthfirst3( Node, [Node | Sol], Maxdepth)  :-\nMaxdepth &gt; 0,\ns( Node, Node1),\nMax1 is Maxdepth - 1,\ndepthfirst3( Node1, Sol, Max1).\n/*\nL‚Äôidea che sta alla base di questo tipo di ricerca √® la seguente:\nPer trovare il percorso che rappresenta la soluzione, Sol, dato un nodo N, ed almeno un nodo obiettivo:\nSe N √® la l‚Äôobiettivo, allora Sol = [N], altrimenti\nSe esiste un nodo connesso a N, detto N1, tale che esista una soluzione Sol1 da N1 ad un nodo obiettivo, allora Sol = [N | Sol1]\n*/"},"UNI/ANNO-2/LINGUAGGI/PROLOG/PROLOG-ESERCIZI":{"slug":"UNI/ANNO-2/LINGUAGGI/PROLOG/PROLOG-ESERCIZI","filePath":"UNI/ANNO 2/LINGUAGGI/PROLOG/PROLOG ESERCIZI.md","title":"PROLOG ESERCIZI","links":[],"tags":[],"content":"E1. Aggiungi altri fatti alla famiglia, ad esempio: padre(anna, marco)., e verifica con query chi sono i nonni di marco.\nE2. Definisci un predicato madre/2 e prova a creare la regola nonna/2.\nE3. Query: trova tutti i padri, e tutti i figli di gianni.\nE4. Prova a chiedere a Prolog: ?- padre(X, anna). ‚Üí chi √® X?\nLezione 15 settembre ‚Äì Liste e ricorsione\nE5. Scrivi un predicato my_length/2 e testalo con: ?- my_length([1,2,3,4], N).\nE6. Scrivi un predicato my_member/2 e verifica se c √® membro di [a,b,c,d].\nE7. Implementa somma_lista/2 e prova con ?- somma_lista([5,7,2], S)..\nE8. Implementa conta_occorrenze/3 e trova quante volte a appare in [a,b,a,c,a].\nLezione 16 settembre ‚Äì Strutture e termini complessi\nE9. Usa stessa_funzione/2 e chiedi: ?- stessa_funzione(mangia(cane,osso), mangia(gatto,pesce)).\nE10. Costruisci un albero binario con almeno 5 nodi e verifica con conta_nodi/2 quanti nodi ci sono.\nE11. Prova foglia/1 con pi√π nodi diversi: uno con figli e uno senza.\nE12. Scrivi stessa_struttura/2 e confronta due alberi con stessa forma ma valori diversi."},"UNI/ANNO-2/LINGUAGGI/PROLOG/PROLOG-LEZ.1":{"slug":"UNI/ANNO-2/LINGUAGGI/PROLOG/PROLOG-LEZ.1","filePath":"UNI/ANNO 2/LINGUAGGI/PROLOG/PROLOG LEZ.1.md","title":"PROLOG LEZ.1","links":[],"tags":[],"content":"Perfetto üí™ iniziamo con la lezione del 14 settembre: basi di Prolog, regole, fatti, query e unificazione.\nTi scrivo in modo chiaro, con spiegazioni + esempi pratici che puoi copiare in un file .pl.\n\nüìò Lezione 14 settembre ‚Äì Basi di Prolog\n1. Cos‚Äô√® Prolog\n\n\nProlog √® un linguaggio dichiarativo: tu descrivi i fatti e le regole del problema, e Prolog trova le soluzioni tramite unificazione e backtracking.\n\n\nNon dici ‚Äúcome fare le cose‚Äù passo per passo (stile Python o C), ma cosa √® vero nel tuo mondo.\n\n\n\n2. Fatti\nUn fatto rappresenta una verit√† del mondo che stai modellando.\nEsempio (famiglia):\npadre(mario, gianni).  padre(gianni, luca).\npadre(luca, anna).\nQui stai dicendo:\n\n\nMario √® padre di Gianni.\n\n\nGianni √® padre di Luca.\n\n\nLuca √® padre di Anna.\n\n\n\n3. Regole\nUna regola permette di definire relazioni complesse a partire dai fatti.\nLa forma √®:\ntesta :- corpo.\nSignifica: ‚Äútesta √® vera se corpo √® vero‚Äù.\nEsempio: definire il predicato nonno(X,Y):\nnonno(X,Y) :- padre(X,Z), padre(Z,Y).\nLeggilo cos√¨:\n\n‚ÄúX √® nonno di Y se X √® padre di Z e Z √® padre di Y‚Äù.\n\n\n4. Query\nLe query (interrogazioni) si scrivono nel prompt Prolog con ?-.\nEsempi:\n?- padre(mario, gianni). true.   ?- padre(mario, X). X = gianni.`\nOppure:\n?- nonno(mario, anna). true.\nQui Prolog ha usato i fatti e la regola per rispondere.\n\n5. Unificazione\nL‚Äôunificazione √® l‚Äôalgoritmo con cui Prolog prova a rendere uguali due termini.\n\n\nFunziona con sostituzioni di variabili.\n\n\n√à alla base della risoluzione dei predicati.\n\n\nEsempi:\n?- X = mario. X = mario.\n?- padre(mario, X) = padre(mario, gianni).  X = gianni.\n?- padre(mario, X) = padre(gianni, luca).  false.`\n\n6. Backtracking\nSe ci sono pi√π soluzioni, Prolog esplora tutte le possibilit√†.\nEsempio:\ncolore(rosso).  colore(verde).\ncolore(blu).   ?- colore(X).\nX = rosso ;  X = verde ;\nX = blu.\nProlog restituisce tutte le soluzioni possibili, una alla volta.\n\n7. Esercizi pratici\nüëâ Crea un file famiglia.pl con:\npadre(mario, gianni). padre(gianni, luca). padre(luca, anna).  nonno(X,Y) :- padre(X,Z), padre(Z,Y).\nPoi prova queste query:\n\n\n?- padre(mario, gianni).\n\n\n?- padre(mario, X).\n\n\n?- nonno(mario, anna).\n\n\n?- nonno(gianni, anna).\n\n\n\n8. Riassunto veloce\n\n\nFatti = cose vere.\n\n\nRegole = definizioni logiche.\n\n\nQuery = domande a Prolog.\n\n\nUnificazione = rende uguali due termini con sostituzioni.\n\n\nBacktracking = esplora tutte le soluzioni possibili.\nüìò Lezione 15 settembre ‚Äì Liste e ricorsione\n\n\n1. Liste in Prolog\nLe liste sono strutture fondamentali, scritte tra [ ].\nEsempi:\n[]                % lista vuota  [1,2,3]           % lista di numeri\n[a,b,c]           % lista di atomi  [1, pippo, X]     % lista mista con variabile`\nSi possono anche scrivere come testa | coda:\n[H|T]\n\n\nH = primo elemento (head).\n\n\nT = resto della lista (tail).\n\n\nEsempi:\n?- [H|T] = [1,2,3].  H = 1, T = [2,3].\n?- [H|T] = [a].  H = a, T = [].`\n\n2. Predicati built-in per le liste\nI principali che il prof ti lascia usare:\n\n\nmember(X,L) ‚Üí vero se X appartiene a L.\n\n\nappend(L1,L2,L3) ‚Üí unisce due liste e le mette in L3.\n\n\nlength(L,N) ‚Üí vero se N √® la lunghezza della lista L.\n\n\nreverse(L,R) ‚Üí vero se R √® la lista L al contrario.\n\n\nEsempi:\n?- member(b, [a,b,c]). true.   ?- append([1,2], [3,4], X). X = [1,2,3,4].\n?- length([a,b,c], N). N = 3.   ?- reverse([1,2,3], R). R = [3,2,1].`\n\n3. Ricorsione sulle liste\nMolti predicati si implementano ricorsivamente:\n\n\nCaso base ‚Üí lista vuota [].\n\n\nCaso ricorsivo ‚Üí lista [H|T].\n\n\nEsempio: definire my_length/2\nmy_length([], 0).                     % Caso base my_length([_|T], N) :-                % Caso ricorsivo     my_length(T, N1),     N is N1 + 1.\nIn Prolog _ √® la variabile anonima, cio√®: ‚Äúqui c‚Äô√® qualcosa, ma non mi interessa‚Äù.\nProva:\n?- my_length([a,b,c], N). N = 3.\n\nEsempio: definire my_member/2\nmy_member(X, [X|_]).                  % Caso 1: X √® la testa my_member(X, [_|T]) :-                % Caso 2: cerca nella coda     my_member(X, T).\nProva:\n?- my_member(2, [1,2,3]). true.   ?- my_member(4, [1,2,3]). false.`\n\nEsempio: definire my_append/3\nmy_append([], L, L).                  % Caso base my_append([H|T], L2, [H|R]) :-        % Caso ricorsivo     my_append(T, L2, R).\nProva:\n?- my_append([1,2], [3,4], X).  X = [1,2,3,4].`\n\n4. Esercizi pratici\nüëâ Prova a scrivere questi predicati da solo:\n\n\n                  \n                  1. somma_lista(Lista, Somma) ‚Üí somma tutti i numeri in una lista.\n                  \n                \n\nsomma_lista([],0).\nsomma_lista([H|T],S) :-\n    somma_lista(T,S1),  S is H+S1.\n\n\n\n\n                  \n                  2. conta_occorrenze(X, Lista, N) ‚Üí conta quante volte X appare.\n                  \n                \n\nconta_occorrenze(X,[],0).\nconta_occorrenze(X,[X|T],N):-\n    conta_occorrenze(X,T,N1), N is N1+1.\nconta_occorrenze(X,[H|T],N):-\n    conta_occorrenze(X,T,N). \n\n\n\n\n                  \n                  3. maggiore_di(Lista, N, Filtrata) ‚Üí restituisce solo gli elementi &gt; N.\n                  \n                \n\nmaggiore_di([], N, []).\nmaggiore_di([X|T],N,R):-\n    X&gt;N,\n     maggiore_di(T,N,L), \n       append([X],L,R).\n    \nmaggiore_di([X|T],N,R):-\n    X=&lt;N,\n     maggiore_di(T,N,R).\n\n\n(Sono gli scheletri che userai pi√π avanti per gli esercizi sugli esami.)\n\n5. Riassunto veloce\n\n\nLe liste sono [ ] o [H|T].\n\n\nmember/2, append/3, length/2, reverse/2 ‚Üí strumenti fondamentali.\n\n\nQuasi tutto si fa con ricorsione:\n\n\nCaso base: lista vuota.\n\n\nCaso ricorsivo: [H|T].\n\n\n\n\nüìò Lezione 16 settembre ‚Äì Strutture e termini complessi\n1. Che cos‚Äô√® un termine in Prolog\nIn Prolog tutto √® un termine.\nEsistono diversi tipi di termini:\n\n\nNumeri ‚Üí es. 3, 4.5.\n\n\nAtomi ‚Üí simboli che iniziano con lettera minuscola o scritti tra apici: rosso, pippo, &#039;Ciao&#039;.\n\n\nVariabili ‚Üí iniziano con lettera maiuscola o _: X, Persona.\n\n\nListe ‚Üí es. [a,b,c], che in realt√† sono una notazione speciale.\n\n\nStrutture (o termini complessi) ‚Üí hanno un nome e degli argomenti:\nnome(arg1, arg2, ..., argN)\n\n\nEsempi di strutture:\nmangia(cavallo, biada). ama(romeo, giulietta). colore(auto, rosso).\n\n2. Funtore e arit√†\nQuando parliamo di strutture, dobbiamo distinguere due concetti fondamentali:\n\n\nFuntore ‚Üí √® il nome della struttura.\n\n\nIn mangia(cavallo, biada) il funtore √® mangia.\n\n\nIn ama(romeo, giulietta) il funtore √® ama.\n\n\n\n\nArity (arit√†) ‚Üí √® il numero di argomenti della struttura.\n\n\nmangia(cavallo, biada) ha arit√† 2.\n\n\ncolore(auto, rosso, vecchia) ha arit√† 3.\n\n\npadre(mario) ha arit√† 1.\n\n\n\n\nIn Prolog si scrive spesso ‚Äúfuntore/arit√°‚Äù per identificare un predicato:\n\n\nmangia/2 ‚Üí significa ‚Äúil predicato mangia con 2 argomenti‚Äù.\n\n\npadre/1 ‚Üí significa ‚Äúil predicato padre con 1 argomento‚Äù.\n\n\n\n3. Unificazione tra strutture\nProlog pu√≤ unificare due strutture solo se hanno lo stesso funtore e la stessa arit√†.\nSe i nomi o il numero di argomenti non coincidono, fallisce.\nEsempi:\n?- mangia(X, biada) = mangia(cavallo, Y). X = cavallo, Y = biada.\nQui entrambe le strutture hanno:\n\n\nfuntore = mangia\n\n\narit√† = 2\n\n\nQuindi Prolog le fa combaciare unificando X = cavallo e Y = biada.\n\nAltro esempio:\n?- mangia(cavallo, biada) = mangia(ragno, rosmarino). false.\nQui il funtore √® lo stesso (mangia), l‚Äôarit√† √® la stessa (2),\nma gli argomenti non si possono far coincidere ‚Üí quindi fallisce.\n\nAltro caso:\n?- mangia(cavallo, biada) = ama(romeo, giulietta). false.\nQui addirittura il funtore cambia (mangia vs ama), quindi non c‚Äô√® speranza di unificazione.\n\n4. Predicato functor/3\nProlog ha un predicato built-in che permette di ‚Äúanalizzare‚Äù una struttura:\nfunctor(Term, Funtore, Arity).\nEsempi:\n?- functor(mangia(cavallo, biada), F, A). F = mangia, A = 2.   ?- functor(ama(romeo, giulietta), F, A). F = ama, A = 2.`\nQuindi puoi controllare se due termini hanno lo stesso funtore e arit√†:\nstessa_firma(T1, T2) :-      functor(T1, F, A),\nfunctor(T2, F, A).\n\n5. Strutture come alberi\nLe strutture possono essere viste come alberi:\n\n\nil funtore √® la radice,\n\n\ngli argomenti sono i sottoalberi.\n\n\nEsempio:\nmangia(cavallo, biada) ‚Üí albero con radice mangia e due figli cavallo e biada.\nQuesta idea √® utile per esercizi tipo ‚Äúdue alberi hanno la stessa forma?‚Äù.\nEsempio: stessa struttura\nstessa_struttura(nil, nil).  stessa_struttura(nodo(,SX1,DX1),nodo(,SX2,DX2)) :-\nstessa_struttura(SX1, SX2),      stessa_struttura(DX1, DX2).`\nUso:\n?- stessa_struttura(nodo(1,nil,nil), nodo(a,nil,nil)). true.   ?-stessa_struttura(nodo(1,nil,nil),nodo(a,nil,nodo(b,nil,nil))). false.`\n\n6. Esercizi pratici\n\n\n                  \n                  1. Definisci stessa_arita(T1,T2) ‚Üí vero se due termini hanno lo stesso numero di argomenti.\n                  \n                \n\nstessa_arita(T1,T2):-\n    functor(T1,_,A),functor(T2,_,A2),\n    A=A2.\n\n\n\n\n                  \n                  2. Definisci stesso_funtore(T1,T2) ‚Üí vero se due termini hanno lo stesso nome.\n                  \n                \n\nstesso_funtore(T1,T2):-\n    functor(T1,F,_),functor(T2,F1,_),\n    F=F1.\n\n\n\n\n                  \n                  3. Definisci foglia/1 per un albero binario del tipo nodo(Val, nil, nil).\n                  \n                \n\nfoglia(nodo(_,nil,nil)).\n\n\n\n\n                  \n                  1. Definisci conta_nodi(T, N) che conta i nodi di un albero binario.\n                  \n                \n\nconta_nodi(nil,0).\nconta_nodi(nodo(_,nil,nil),1).\nconta_nodi(nodo(_,SX,DX),N):-\n    conta_nodi(SX,N1),\n\tconta_nodi(DX,N2),\n    N is N1+N2+1.\n \n\n\n\n7. Riassunto\n\n\nUn termine complesso √® funtore(arg1,...,argN).\n\n\nFuntore = nome del predicato.\n\n\nArity = numero di argomenti.\n\n\nDue termini si unificano solo se hanno stesso funtore e arit√†.\n\n\nCon functor/3 puoi estrarre funtore e arit√† da un termine.\n\n\nLe strutture si possono vedere come alberi, e si trattano con ricorsione.\n\n\n\nüëâ Domani (17 settembre) vediamo fail e cut: due strumenti per gestire il backtracking di Prolog e simulare il not."},"UNI/ANNO-2/LINGUAGGI/PROLOG/PROLOG-LEZ.2":{"slug":"UNI/ANNO-2/LINGUAGGI/PROLOG/PROLOG-LEZ.2","filePath":"UNI/ANNO 2/LINGUAGGI/PROLOG/PROLOG LEZ.2.md","title":"PROLOG LEZ.2","links":[],"tags":[],"content":"üìò Lezione 17 settembre ‚Äì fail, cut e il not\n1. Backtracking in Prolog (ripasso veloce)\n\n\nQuando fai una query, Prolog cerca soluzioni.\n\n\nSe trova una soluzione, la propone.\n\n\nSe chiedi altre (;), Prolog torna indietro (backtracking) e cerca altre strade.\n\n\nEsempio:\ncolore(rosso). colore(verde). colore(blu).   ?- colore(X). X = rosso ; X = verde ; X = blu.`\n\n2. Il predicato fail\n\n\nfail/0 √® un predicato che fallisce sempre.\n\n\nServe per forzare Prolog a cercare altre soluzioni.\n\n\nEsempio:\nstampa_colore :-      colore(X),     write(X), nl,     fail.     % forza backtracking`\nUso:\n?- stampa_colore. rosso verde blu false.\nüìå Qui fail obbliga Prolog a continuare a cercare altri colore(X).\nQuando non ne trova pi√π ‚Üí false.\nüëâ fail viene spesso usato per ‚Äúfare tutte le soluzioni‚Äù (es. stampa, conteggio).\n\nwrite(X)\n‚Üí stampa a video il valore di X.\n‚Üí Se X = rosso, stampa rosso.\nnl\n‚Üí va a capo (‚Äúnew line‚Äù).\n\n\n3. Il predicato cut (!)\n\n\n!/0 √® chiamato cut (taglio).\n\n\nServe per bloccare il backtracking oltre un certo punto.\n\n\nEsempio:\nmassimo(X,Y,X) :- X &gt;= Y, !.  massimo(X,Y,Y).`\nCosa succede:\n\n\nSe X &gt;= Y, allora la prima regola √® vera e il ! impedisce a Prolog di provare la seconda regola.\n\n\nSe X &lt; Y, la prima regola fallisce e Prolog passa alla seconda.\n\n\nUso:\n?- massimo(5,3,R). R = 5.  ?- massimo(2,7,R). R = 7.\nSenza cut, Prolog proverebbe comunque entrambe le regole e magari darebbe pi√π soluzioni inutili.\n\n4. Il not in Prolog\nProlog non ha un not nativo (logica classica ‚â† logica di Prolog).\nPer√≤ si pu√≤ simulare con cut e fail:\nnot(P) :- P, !, fail.   % se P √® vero ‚Üí fallisci not(_).                 % se P √® falso ‚Üí questa regola va in porto\nnot(P):- \n    P, !, fail. \nnot(_).\n\nEsempi:\n?- not(rosso = verde). true.  ?- not(rosso = rosso). false.\nüìå Attenzione: questo not √® il cosiddetto negation as failure:\n‚Äúqualcosa √® falso se non si pu√≤ dimostrare che √® vero‚Äù.\n\n5. Cut rosso vs cut verde\nIn teoria si distinguono due tipi di cut:\n\n\nCut rosso ‚Üí cambia il significato logico del programma (forza una scelta, pu√≤ eliminare soluzioni corrette).\n\n\nCut verde ‚Üí serve solo a rendere pi√π efficiente il programma (non cambia il significato).\n\n\nEsempio cut verde (ottimizzazione):\npari(X) :- X mod 2 =:= 0, !. pari(_).\nQui il cut evita di controllare altre regole inutili.\n\n6. Esercizi pratici\n\n\n                  \n                  1. Definisci massimo/3 con cut (gi√† visto).\n                  \n                \n\nmassimo(X,Y,X):-\n    X&gt;=Y, !.\nmassimo(_,Y,Y).\n\n\n\n\n                  \n                  2. Definisci assoluto(X,Y) che calcola il valore assoluto usando cut.\n                  \n                \n\n    assoluto(X,X) :- X &gt;= 0, !. \n    assoluto(X,Y) :- Y is -X.\n\n\n\n\n                  \n                  3. Implementa not/1 con cut e fail.\n                  \n                \n\nnot(P):- \n    P, !, fail. \nnot(_).\n\n\n\n7. Riassunto\n\n\nfail ‚Üí fallisce sempre, utile per forzare il backtracking.\n\n\ncut ‚Üí blocca il backtracking, serve per ottimizzare o per forzare scelte.\n\n\nnot ‚Üí si implementa con cut + fail (negation as failure).\n\n\nUsare cut e fail richiede attenzione: possono cambiare la logica del programma.\n\n\nüìò Lezione 18 settembre ‚Äì assert, retract e univ\n1. La base di conoscenza in Prolog\nQuando scrivi un programma Prolog, definisci una base di conoscenza (KB) con:\n\n\nFatti ‚Üí cose sempre vere.\n\n\nRegole ‚Üí relazioni dedotte dai fatti.\n\n\nMa Prolog permette anche di aggiungere o rimuovere fatti e regole durante l‚Äôesecuzione.\n\n2. assert/1 ‚Äì aggiungere fatti o regole\n\n\nassert(X) aggiunge il fatto/regola X alla base di conoscenza.\n\n\nasserta(X) lo aggiunge in testa, assertz(X) in coda (di solito non importa).\n\n\nEsempio:\n?- assert(padre(pippo, pluto)). true.  ?- padre(pippo, Y). Y = pluto.\nüìå Dopo la query, la base di conoscenza ha un fatto in pi√π.\n\n3. retract/1 ‚Äì rimuovere fatti o regole\n\n\nretract(X) rimuove la prima clausola che unifica con X.\n\n\nSe ci sono pi√π fatti uguali, puoi richiamare ; per rimuoverne altri.\n\n\nEsempio:\n?- assert(padre(topolino, minnie)). true.  ?- retract(padre(topolino, minnie)). true.  ?- padre(topolino, minnie). false.\n\n4. Uso insieme di assert e retract\nPuoi aggiornare la KB ‚Äúal volo‚Äù.\nEsempio: contatore che si incrementa:\n:- dynamic contatore/1. contatore(0).  incrementa :-     retract(contatore(N)),     N1 is N + 1,     assert(contatore(N1)).\nUso:\n?- incrementa. true.  ?- incrementa. true.  ?- contatore(X). X = 2.\nüìå :- dynamic nome/Arity. serve a dire a Prolog che quel predicato pu√≤ essere modificato.\n\n5. L‚Äôoperatore =.. (univ)\n=.. permette di convertire un termine in una lista con il funtore e gli argomenti.\nSintassi:\nTerm =.. Lista\n\n\nDa termine a lista:\n?- mangia(cavallo, biada) =.. L. L = [mangia, cavallo, biada].\n\n\nDa lista a termine:\n?- T =.. [ama, romeo, giulietta]. T = ama(romeo, giulietta).\n\n\nüìå √à utile quando vuoi ‚Äúmanipolare‚Äù i predicati come dati.\n\n6. listing/1 (solo per curiosit√†)\nlisting/1 stampa tutte le definizioni di un predicato.\nEsempio:\n?- listing(padre/2). padre(mario, gianni). padre(gianni, luca). true.\nNon √® fondamentale per l‚Äôesame, ma utile per il debug.\n\n7. Esercizi pratici\n\n\nAggiungi un fatto dinamico con assert e verifica che sia interrogabile.\n\n\nRimuovi un fatto con retract.\n\n\nScrivi un predicato aggiungi_amico(X,Y) che fa assert(amico(X,Y)).\n\n\nScrivi un predicato toglie_amico(X,Y) che fa retract(amico(X,Y)).\n\n\nUsa =.. per trasformare somma(2,3,5) in [somma,2,3,5].\n\n\nUsa = .. per costruire dinamicamente un fatto tipo studente(pippo,30) a partire da una lista.\n\n\n\n8. Riassunto\n\n\nassert/1 ‚Üí aggiunge fatti o regole alla KB.\n\n\nretract/1 ‚Üí rimuove fatti o regole.\n\n\n= .. univ ‚Üí converte un termine ‚Üî lista [funtore, arg1, arg2,‚Ä¶].\n\n\nlisting/1 ‚Üí stampa i predicati (solo di supporto).\n\n\nüìò Lezione 19 settembre ‚Äì Definite Clause Grammars (DCG)\n1. Perch√© servono le DCG\n\n\nSenza DCG, analizzare frasi significa lavorare manualmente con liste di simboli: [il,cavallo,mangia,la,biada].\n\n\nCon DCG puoi scrivere regole grammaticali pi√π leggibili e lasciare a Prolog il lavoro di gestire le liste.\n\n\nSono molto usate per parsing, linguaggio naturale, compilatori, trasformazioni di testo.\n\n\n\n2. Sintassi base\nUna regola DCG si scrive con --&gt; invece di :-.\nEsempio:\nfrase --&gt; soggetto, predicato.   soggetto ‚áí [cavallo].\nsoggetto --&gt; [ragno].   predicato ‚áí [mangia, biada].\npredicato --&gt; [mangia, rosmarino].\nUso:\n?- frase([cavallo,mangia,biada], []). true.  ?- frase([ragno,mangia,rosmarino], []). true.\nüìå Una regola p --&gt; q,r. equivale a:\np(L0,L2) :- q(L0,L1), r(L1,L2).\nQuindi le DCG sono solo zucchero sintattico per gestire liste di simboli.\n\n3. Esempio: grammatica semplice\nCostruiamo una grammatica che riconosce frasi del tipo ‚Äúil cavallo mangia la biada‚Äù.\nfrase --&gt; articolo, nome, verbo, articolo, nome.   articolo ‚áí [il].\narticolo --&gt; [la].   nome ‚áí [cavallo].\nnome --&gt; [biada].  nome ‚áí [ragno].\nnome --&gt; [rosmarino].  verbo ‚áí [mangia].`\nUso:\n?- frase([il,cavallo,mangia,la,biada], []). true.   ?- frase([il,ragno,mangia,rosmarino], []). true.`\n\n4. DCG con variabili (estrazione di significato)\nPossiamo ‚Äúestrarre‚Äù la struttura logica da una frase.\nfrase(mangia(Soggetto, Oggetto)) --&gt;      articolo, nome(Soggetto), verbo, articolo, nome(Oggetto).   articolo ‚áí [il]. articolo ‚áí [la].\nnome(cavallo) --&gt; [cavallo].  nome(biada)   ‚áí [biada].\nnome(ragno)   --&gt; [ragno].  nome(rosmarino) ‚áí [rosmarino].\nverbo --&gt; [mangia].\nUso:\n?- frase(X, [il,cavallo,mangia,la,biada], []).  X = mangia(cavallo, biada).\n?- frase(X, [il,ragno,mangia,rosmarino], []).  X = mangia(ragno, rosmarino).`\nüìå Qui DCG non solo controlla la frase, ma costruisce direttamente il fatto logico.\n\n5. DCG con ricorsione\nLe DCG gestiscono anche frasi composte.\nEsempio: pi√π nomi di fila ‚Üí lista:\nnomi([N|Ns]) --&gt; nome(N), nomi(Ns). nomi([])     --&gt; [].  nome(cavallo)   --&gt; [cavallo]. nome(biada)     --&gt; [biada].\nUso:\n?- nomi(L, [cavallo,biada,cavallo], []). L = [cavallo, biada, cavallo].\n\n6. Dove servono per l‚Äôesame\n\n\nEsercizio rete alimentare (09/07): frasi tipo ‚ÄúIl cavallo si nutre di biada‚Äù ‚Üí mangia(cavallo,biada).\n\n\nCon DCG puoi definire pi√π regole per catturare tutte le varianti (mangia, si nutre di, il cibo √®‚Ä¶).\n\n\nEsempio:\nfrase(mangia(Soggetto, Oggetto)) --&gt;      [il], nome(Soggetto), [mangia], [la], nome(Oggetto).  frase(mangia(Soggetto, Oggetto)) --&gt;      [il], nome(Soggetto), [si, nutre, di], nome(Oggetto).\n\n7. Esercizi pratici\n\n\nScrivi una DCG che riconosce frasi tipo:\n\n\n‚Äúil cane ama il gatto‚Äù ‚Üí ama(cane,gatto)\n\n\n‚Äúil topo odia il formaggio‚Äù ‚Üí odia(topo,formaggio)\n\n\n\n\nScrivi una DCG che riconosce una lista di numeri [1,2,3] e la traduce in somma(6).\n\n\nEstendi la DCG dell‚Äôesercizio alimentare per riconoscere almeno 3 modi diversi di esprimere la stessa relazione.\n\n\n\n8. Riassunto\n\n\nDCG = notazione pi√π leggibile per analizzare stringhe/lista di simboli.\n\n\nSintassi: --&gt;.\n\n\nDietro le quinte: p(L0,L2) :- q(L0,L1), r(L1,L2).\n\n\nCon le variabili puoi trasformare frasi in strutture logiche.\n\n"},"UNI/ANNO-2/LINGUAGGI/PROLOG/PROLOG-LEZ.3":{"slug":"UNI/ANNO-2/LINGUAGGI/PROLOG/PROLOG-LEZ.3","filePath":"UNI/ANNO 2/LINGUAGGI/PROLOG/PROLOG LEZ.3.md","title":"PROLOG LEZ.3","links":[],"tags":[],"content":"üìò Lezione 20 settembre ‚Äì Definire operatori e precedenza in Prolog\n1. Perch√© gli operatori?\nIn Prolog, sotto il cofano, anche le espressioni pi√π semplici sono termini.\nPer esempio l‚Äôespressione aritmetica 1 + 2 * 3 non √® ‚Äúun calcolo‚Äù, ma un termine annidato, equivalente a:\n+(1, *(2,3))\nChiaramente nessuno vuole scrivere sempre cos√¨. Per questo Prolog permette di dichiarare operatori, in modo da rendere pi√π leggibile il codice e decidere chi lega pi√π forte e in che ordine interpretare una sequenza di simboli.\n\n2. Come si dichiara un operatore\nSi usa il predicato:\nop(Precedenza, Tipo, Nome).\n\n\nPrecedenza: √® un numero da 1 a 1200.\nPi√π il numero √® fottutamente piccolo, pi√π l‚Äôoperatore ‚Äúlega forte‚Äù (cio√® viene valutato prima).\n\n\nTipo: indica se l‚Äôoperatore √® infisso, prefisso o postfisso, e come si comporta con altri operatori della stessa cazzo di precedenza.\n\n\nNome: √® l‚Äôatomo che diventa l‚Äôoperatore (es. and, or, ++).\n\n\nEsempio semplice:\n:- op(500, yfx, plus).\nDichiara plus come operatore infix (in mezzo) con precedenza 500.\n\n3. Cosa significano x e y\nQuesta √® la parte che spesso sembra misteriosa.\nLe lettere x e y dicono se l‚Äôargomento pu√≤ avere la stessa precedenza dell‚Äôoperatore:\n\n\nx ‚Üí l‚Äôargomento deve avere precedenza pi√π alta (numero pi√π basso).\n\n\ny ‚Üí l‚Äôargomento pu√≤ avere precedenza uguale o pi√π alta.\n\n\nQuesto serve a decidere se puoi scrivere catene senza parentesi, e in che direzione si associano.\n\n4. Infix: associativit√†\nSe definisci un operatore infix (tra due argomenti), hai tre possibilit√†:\n\n\nyfx ‚Üí associativo a sinistra\nEsempio: con plus/2 dichiarato yfx, Prolog interpreta:\n1 plus 2 plus 3   ‚áí   plus(plus(1,2), 3)\n\n\nxfy ‚Üí associativo a destra\nUtile per potenze:\n2 pow 3 pow 2   ‚áí   pow(2, pow(3,2))\n\n\nxfx ‚Üí non associativo\nVietate le catene:\na eq b eq c   ‚áí   ERRORE senza parentesi\n\n\n\n5. Prefix e Postfix\nGli operatori possono stare anche prima o dopo dell‚Äôargomento:\n\n\nPrefisso (fx/fy): esempio not a.\n\n\nfx: l‚Äôargomento deve avere precedenza pi√π alta.\n\n\nfy: l‚Äôargomento pu√≤ avere stessa precedenza ‚Üí permette catene tipo not not a.\n\n\n\n\nPostfisso (xf/yf): meno usati, ma possibili.\n\n\nxf: l‚Äôargomento a sinistra deve avere precedenza pi√π alta.\n\n\nyf: pu√≤ avere la stessa ‚Üí puoi scrivere cose tipo a !! (se definito).\n\n\n\n\n\n6. Precedenza nella pratica\nUna regola utile da ricordare √®: numeri pi√π piccoli = operatori pi√π forti.\nQuindi, se vuoi simulare un po‚Äô di algebra di merda:\n\n\n* intorno a 400\n\n\n+ intorno a 500\n\n\ncomparazioni (&lt;, =, ‚Ä¶) intorno a 700\n\n\nlogica (and, or) intorno a 800‚Äì900\n\n\n:- e , molto esterni (intorno a 1000‚Äì1200)\n\n\nEsempio:\n:- op(300, fy, not). :- op(800, yfx, and). :- op(850, yfx, or).\nCos√¨ Prolog interpreta in modo naturale le cazzo di operazioni:\nnot a and b or c   ‚áí   or(and(not(a), b), c)\n\n7. Esempi concreti\nSomma left-associativa\n:- op(500, yfx, plus).\nUso:\n?- 1 plus 2 plus 3. plus(plus(1,2), 3).\nPotenza right-associativa\n:- op(400, xfy, pow).\nUso:\n?- 2 pow 3 pow 2. pow(2, pow(3,2)).\nOperatore prefisso\n:- op(300, fy, not).\nUso:\n?- not not a. not(not(a)).\n\n8. Buone pratiche\n\n\nNon ridefinire operatori gi√† esistenti (=, is, :- ‚Ä¶).\n\n\nUsa gli operatori solo se rendono il codice pi√π leggibile.\n\n\nQuando hai dubbi, metti sempre le parentesi: hanno precedenza massima.\n\n\n\n9. Esercizi consigliati\n\n\nDefinisci and e or con precedenze tali che not leghi pi√π di and e and pi√π di or. Verifica il parse di not a or b and not c.\n\n\nDefinisci un operatore ** right-associativo e prova 2 ** 3 ** 2.\n\n\nDefinisci un operatore eq non associativo e verifica che a eq b eq c dia errore.\n\n\n\n10. Riassunto finale\n\n\nIn Prolog tutto √® un termine.\n\n\nop/3 ti permette di dichiarare operatori con precedenza e associativit√†.\n\n\nx e y regolano se gli argomenti possono avere stessa precedenza (influenza le catene).\n\n\nNumeri pi√π bassi = legano pi√π forte.\n\n\nUsare operatori √® comodo, ma va fatto con giudizio.\n\n\nüìò Lezione 21 settembre ‚Äì findall, bagof, setof\n1. Il problema di fondo\nDi solito, Prolog ti d√† una soluzione di merda alla volta.\nEsempio:\ncolore(rosso). colore(verde). colore(blu).  ?- colore(X). X = rosso ; X = verde ; X = blu.\nSe vuoi una lista con tutte le soluzioni ([rosso, verde, blu]), hai bisogno di strumenti appositi: findall, bagof e setof.\n\n2. findall/3\nSintassi\nfindall(Termine, Goal, Lista).\n\n\nTermine ‚Üí cosa raccogliere.\n\n\nGoal ‚Üí la query da eseguire.\n\n\nLista ‚Üí la lista di tutte le istanze del cazzo trovate.\n\n\nEsempio semplice\n?- findall(X, colore(X), L). L = [rosso, verde, blu].\nSe non ci sono soluzioni\nfindall restituisce sempre una lista, anche se vuota:\n?- findall(X, animale(X), L). L = [].\nüìå Importante: findall ignora variabili libere nel Goal. Quindi se ci sono variabili non vincolate, non separa i risultati per valori diversi ‚Üí mette tutto insieme.\n\n3. bagof/3\nSintassi\nbagof(Termine, Goal, Lista).\nSimile a findall, ma tratta le variabili libere come parametri.\nCosa significa? Che separa i risultati in base alle variabili non legate.\nEsempio\npadre(mario, gianni). padre(mario, luca).  padre(gianni, anna).\n?- bagof(Figlio, padre(Padre, Figlio), L).  Padre = mario,  L = [gianni, luca] ;\nPadre = gianni, L = [anna].\nQui Padre √® variabile libera: quindi bagof ti d√† un risultato per ogni valore di Padre.\nSe vuoi ignorare una variabile libera\nPuoi usare l‚Äôoperatore ^ per ‚Äúbloccare‚Äù una variabile:\n?- bagof(Figlio, Padre^padre(Padre, Figlio), L).  L = [gianni, luca, anna].`\n\n4. setof/3\nSintassi\nsetof(Term, Goal, Lista).\n√à identico a bagof, ma in pi√π fa queste troiate:\n\n\nOrdina la lista in ordine crescente.\n\n\nElimina i duplicati.\n\n\nEsempio\ncolore(rosso). colore(verde). colore(rosso).  ?- setof(X, colore(X), L). L = [rosso, verde].\n\n5. Differenze riassunte\n\n\nfindall ‚Üí piglia tutto, sempre in una lista (anche vuota). Non distingue variabili libere.\n\n\nbagof ‚Üí raggruppa i risultati per ogni combinazione di variabili libere.\n\n\nsetof ‚Üí come bagof, ma i risultati sono ordinati e senza duplicati.\n\n\n\n6. Esempi comparativi\nDatabase\npadre(mario, gianni). padre(mario, luca). padre(gianni, anna). padre(gianni, luca).   % duplicato intenzionale\nfindall\n?- findall(F, padre(P, F), L). L = [gianni, luca, anna, luca].\n‚Üí tutto in una lista unica, duplicati inclusi.\nbagof\n?- bagof(F, padre(P, F), L). P = gianni, L = [anna, luca] ; P = mario,  L = [gianni, luca].\n‚Üí risultati separati per P.\nsetof\n?- setof(F, padre(P, F), L). P = gianni, L = [anna, luca] ; P = mario,  L = [gianni, luca].\n‚Üí come bagof, ma liste ordinate e senza duplicati.\n\n7. Esercizi pratici\n\n\nUsa findall per raccogliere tutti i colori in una lista.\n\n\nUsa bagof per ottenere i figli di ciascun padre separatamente.\n\n\nUsa setof per ottenere tutti i padri distinti ordinati alfabeticamente.\n\n\nCrea un predicato figli(Padre, ListaFigli) che usa bagof.\n\n\n\n8. Riassunto\n\n\nfindall/3: raccoglie tutto in una lista (anche vuota).\n\n\nbagof/3: separa i risultati in base alle variabili libere.\n\n\nsetof/3: come bagof, ma ordina e rimuove duplicati.\n\n\n^ serve a bloccare una variabile quando non vuoi che venga considerata ‚Äúlibera‚Äù.\n\n\nüìò Lezione 22 settembre ‚Äì Ripasso generale di Prolog (teoria + esempi minimi)\n\n1. Basi del Prolog\n\nFatti ‚Üí verit√† assolute:\n\npadre(mario, gianni).\n\nRegole ‚Üí ‚Äúse‚Ä¶ allora‚Ä¶‚Äù:\n\nnonno(X,Y) :- padre(X,Z), padre(Z,Y).\n\nQuery ‚Üí domande:\n\n?- padre(mario, gianni).   % true ?- padre(mario, X).        % X = gianni\nüëâ Unificazione: Prolog prova a rendere due termini uguali sostituendo variabili.\nüëâ Backtracking: Prolog cerca pi√π soluzioni esplorando alternative.\n\n2. Liste e ricorsione\n\n\nSintassi: [a,b,c] oppure [H|T].\n\n\nPredicati built-in:\n\n\nmember(X,L).      % vero se X √® in L append(L1,L2,L3).  % L3 = L1+L2 length(L,N).      % N = lunghezza di L reverse(L,R).     % R = L al contrario`\n\nRicorsione tipica:\n\nmy_length([],0). my_length([_|T],N) :- my_length(T,N1), N is N1+1.\n\n3. Strutture e alberi\n\n\nTermine complesso = funtore(arg1,...,argN).\n\n\nFuntore = nome, Arity = numero di argomenti.\n\n\nEsempio:\nmangia(cavallo, biada).   % funtore = mangia, arit√† = 2\n\nRicorsione su alberi:\n\nstessa_struttura(nil,nil). stessa_struttura(nodo(_,SX1,DX1), nodo(_,SX2,DX2)) :-     stessa_struttura(SX1,SX2),     stessa_struttura(DX1,DX2).\n\n4. Cut e Fail\n\nfail ‚Üí fallisce sempre ‚Üí forza backtracking.\n\nstampa_colore :- colore(X), write(X), nl, fail.\n\ncut (!) ‚Üí blocca backtracking.\n\nmassimo(X,Y,X) :- X &gt;= Y, !. massimo(_,Y,Y).\n\nnot simulato:\n\nnot(P) :- P, !, fail. not(_).\n\n5. Assert, Retract, Univ\n\nModifica dinamica della KB:\n\n:- dynamic padre/2. ?- assert(padre(gianni, anna)). ?- retract(padre(gianni, anna)).\n\n=.. (univ): converte tra termine e lista.\n\n?- mangia(cavallo,biada) =.. L. L = [mangia,cavallo,biada].  ?- T =.. [ama,romeo,giulietta]. T = ama(romeo,giulietta).\n\n6. DCG (Definite Clause Grammars)\n\nUsate per riconoscere/parlare frasi ‚Üí --&gt;.\n\nfrase(mangia(S,O)) --&gt; [il], nome(S), [mangia], [la], nome(O).  nome(cavallo) --&gt; [cavallo]. nome(biada)   --&gt; [biada].\nUso:\n?- frase(X,[il,cavallo,mangia,la,biada],[]). X = mangia(cavallo, biada).\n\n7. Operatori\n\nDichiarazione:\n\n:- op(500, yfx, plus).\n\n\nPrecedenza: 1‚Äì1200 (numero pi√π piccolo = pi√π forte).\n\n\nx/y ‚Üí se l‚Äôargomento pu√≤ avere stessa precedenza.\n\n\nyfx ‚Üí associativo a sinistra.\n\n\nxfy ‚Üí associativo a destra.\n\n\nxfx ‚Üí non associativo.\n\n\n\n\nEsempio potenza:\n:- op(400, xfy, pow). ?- 2 pow 3 pow 2. pow(2, pow(3,2)).\n\n8. Raccolta soluzioni: findall, bagof, setof\n\n\nfindall(T,Goal,L) ‚Üí raccoglie tutte le soluzioni (anche se 0 ‚Üí []).\n\n\nbagof(T,Goal,L) ‚Üí separa per variabili libere.\n\n\nsetof(T,Goal,L) ‚Üí come bagof, ma lista ordinata senza duplicati.\n\n\nEsempio:\npadre(mario, gianni). padre(mario, luca). padre(gianni, anna).  ?- findall(F,padre(P,F),L). L = [gianni,luca,anna].  ?- bagof(F,padre(P,F),L). P = gianni, L = [anna] ; P = mario,  L = [gianni,luca].  ?- setof(F,padre(P,F),L). P = gianni, L = [anna] ; P = mario,  L = [gianni,luca].\n\n9. Schema pratico da esame\nüëâ Quando leggi un esercizio, chiediti:\n\n\nDevo navigare liste/alberi? ‚Üí ricorsione + append/member.\n\n\nDevo stampare o forzare pi√π soluzioni? ‚Üí fail.\n\n\nDevo scegliere un‚Äôunica regola? ‚Üí cut.\n\n\nDevo aggiungere/rimuovere fatti? ‚Üí assert/retract.\n\n\nDevo riconoscere frasi? ‚Üí DCG.\n\n\nDevo raccogliere tutte le soluzioni? ‚Üí findall/bagof/setof.\n\n\nDevo scrivere elegante? ‚Üí magari definire operatori con op/3.\n\n\n\n10. Esercizi di ripasso veloce\n\n\nDefinisci conta_occorrenze(X,L,N) con ricorsione.\n\n\nUsa not/1 per definire diverso(X,Y).\n\n\nScrivi una DCG che traduce [il,ragno,mangia,rosmarino] in mangia(ragno,rosmarino).\n\n\nCon bagof, trova i figli di ogni padre in una KB familiare.\n\n\nDefinisci ** come operatore infix right-associativo per potenze.\n\n\n\n‚úÖ Riassunto finale\nIn 8 giorni abbiamo visto:\n\n\nFatti, regole, query, unificazione e backtracking.\n\n\nListe e ricorsione.\n\n\nStrutture e alberi.\n\n\nCut, fail e not.\n\n\nAssert, retract e =‚Ä¶\n\n\nDCG per parsing.\n\n\nOperatori personalizzati.\n\n\nRaccolta soluzioni con findall/bagof/setof.\n\n\nCon questo zoccolo teorico puoi affrontare gli esercizi d‚Äôesame. Da domani si passa ai casi pratici (Language Model, rete alimentare, campo di battaglia)."},"UNI/ANNO-2/LINGUAGGI/PROLOG/PROLOG-ORALE":{"slug":"UNI/ANNO-2/LINGUAGGI/PROLOG/PROLOG-ORALE","filePath":"UNI/ANNO 2/LINGUAGGI/PROLOG/PROLOG ORALE.md","title":"PROLOG ORALE","links":[],"tags":[],"content":"Definizione generale\nProlog √® un linguaggio dichiarativo: viene descritto con i fatti e le regole che definiscono un dominio.\nLa risoluzione delle query avviene tramite due meccanismi principali: unificazione e backtracking.\n\nUna query in Prolog √® una domanda: chiede se un certo obiettivo pu√≤ essere dedotto dalla base di conoscenza da noi scelta (fatti e regole).\n\nUn fatto rappresenta una verit√† semplice del dominio.\nUna regola ha la forma: Testa :- Corpo.\nDove la Testa √® il predicato da dimostrare e il Corpo sono le condizioni che devono essere soddisfatte perch√© la regola sia vera.\n\n\n\nUnificazione\nL‚Äôunificazione √® il processo con cui Prolog confronta due termini e cerca di renderli uguali trovando valori per le variabili, se necessario.\nIn pratica √® il ‚Äúmeccanismo di confronto‚Äù che decide se due cose possono essere considerate la stessa.\nüëâ √à diverso da una semplice uguaglianza matematica: qui si tratta di strutturare e legare variabili.\nBacktracking\nIl backtracking √® una tecnica di esplorazione sistematica dello spazio delle soluzioni che permette a Prolog di cercare soluzioni ripercorrendo le scelte non deterministiche quando un ramo fallisce. In pratica, il sistema torna indietro allo stato logico precedente e prova un‚Äôalternativa.\nIn Prolog questo avviene automaticamente, senza bisogno di istruzioni esplicite del programmatore.\n\n\nOgni chiamata che pu√≤ avere pi√π soluzioni crea un punto di scelta: il sistema conserva le alternative possibili.\n\nSe un goal fallisce, Prolog fa un redo: torna all‚Äôultimo punto di scelta, annulla le sostituzioni fatte dopo di esso e prova la successiva alternativa.\n\n\n\nI punti di scelta nascono quando ci sono pi√π clausole per lo stesso predicato, disgiunzioni, predicati non deterministici o pi√π unificazioni possibili.\n\n\nNota:\n\nIl predicato fail forza il fallimento e quindi il backtracking.\nL‚Äôoperatore cut (!), invece, limita lo spazio di ricerca tagliando tutte le alternative successive.\n\nTermini e variabili\nIn Prolog tutto √® un termine: atomi, numeri, variabili e termini composti.\nSu questi elementi si costruiscono fatti, regole e strutture tramite unificazione e risoluzione.\nIl termine\nIl termine √® l‚Äôunit√† sintattica di base e pu√≤ essere:\n\nuna costante (atomo o numero),\n\nGli atomi sono nomi senza significato intrinseco, es. sole, x, taco.\nI numeri possono essere interi o decimali.\n\n\nuna variabile,\n\nLe variabili iniziano con lettera maiuscola o con underscore _, secondo la convenzione sintattica di Prolog.\n\n\nun termine composto.\n\nTermine composto\nI termini composti sono formati da un funtore (nome del predicato) e da una lista di argomenti tra parentesi, separati da virgole.\nIl numero di argomenti √® detto arit√†.\nStrutture dati\nIn Prolog, una struttura √® un termine composto usato per raggruppare pi√π informazioni sotto un unico funtore.\nLa sintassi √®:\nfuntore(arg1, arg2, ..., argN)\n\nGli argomenti sono separati da virgole e racchiusi tra parentesi.\nServono per rappresentare insiemi di dati omogenei o logicamente collegati.\nSono molto usate per modellare record e oggetti del dominio, mantenendo una sintassi semplice e regolare.\n\nEsempi:\n\n\npersona(mario, 30, roma)\n\n\npunto(2, 5)\n\n\ncolore(rgb, 255, 0, 0)\n\n\nTermine composto = concetto di base del linguaggio (elemento sintattico: funtore + argomenti).\n\n\nStruttura dati = uso pratico di un termine composto per rappresentare informazione in modo organizzato.\n\n\nModellare la base di conoscenza\nLa base di conoscenza in Prolog pu√≤ essere aggiornata dinamicamente tramite predicati speciali:\n\nassert ‚Üí aggiunge un nuovo fatto o regola.\nretract ‚Üí rimuove un fatto o regola gi√† presente.\nuniv (=..) ‚Üí permette di scomporre o costruire termini in modo dinamico.\n\nQuesti strumenti consentono di creare nuove strutture o modificare quelle esistenti, rendendo il programma pi√π flessibile.\nDCG (Definite Clause Grammar)\nLe DCG sono una notazione dichiarativa per descrivere grammatiche in Prolog.\nVengono automaticamente tradotte in clausole con due argomenti ‚Äúnascosti‚Äù che rappresentano la parte di input ancora da analizzare.\nSono molto usate per:\n\nanalizzare stringhe,\nriconoscere linguaggi,\ncostruire semplici parser.\n\nEsempio base:\nfrase --&gt; soggetto, predicato. \n\nsoggetto --&gt; [mario]. \npredicato --&gt; [corre].\n\nQuery:\n?- frase([mario, corre], []). ‚Üí true\nRaggruppamenti\nIn Prolog, i predicati findall/3, bagof/3 e setof/3 servono a raccogliere tutte le soluzioni di un Goal in una lista.\nLa forma generale √®:\nPredicato(Template, Goal, Lista)\n\n\nTemplate ‚Üí cosa raccogliere\nGoal ‚Üí obiettivo da soddisfare\nLista ‚Üí lista delle istanze del Template generate dal Goal\n\nLe variabili che compaiono in Goal ma non in Template sono dette libere e vengono trattate in modo diverso dai tre predicati.\nfindall/3\n\nSintassi: findall(Template, Goal, Lista).\nRaccoglie tutte le soluzioni, mantenendo ordine e duplicati.\nSe non ci sono soluzioni ‚Üí Lista = [].\nLe variabili libere in Goal vengono considerate esistenziali.\n\nbagof/3\n\nSintassi: bagof(Template, Goal, Lista).\nCome findall/3, ma fallisce se non ci sono soluzioni.\nLe variabili libere in Goal causano un raggruppamento:\n‚Üí viene generata una lista per ciascuna diversa istanziazione delle variabili libere.\n\nsetof/3\n\nSintassi: setof(Template, Goal, Insieme).\nCome bagof/3, ma restituisce una lista ordinata e senza duplicati.\nL‚Äôordinamento segue quello di sort/2 (prima numeri, poi atomi, poi strutture).\n"},"UNI/ANNO-2/LINGUAGGI/PROLOG/student_exercise_profile":{"slug":"UNI/ANNO-2/LINGUAGGI/PROLOG/student_exercise_profile","filePath":"UNI/ANNO 2/LINGUAGGI/PROLOG/student_exercise_profile.md","title":"student_exercise_profile","links":[],"tags":[],"content":"Student Exercise Profile\n% Impostazioni di configurazione Prolog\n:- set_prolog_flag(occurs_check, error).        % disallow cyclic terms\n:- set_prolog_stack(global, limit(8 000 000)).  % limit term space (8Mb)\n:- set_prolog_stack(local,  limit(2 000 000)).  % limit env\nPredicato elemAt/6\n% elemAt(X, N, L, L1, L2, Count)\n% X = elemento da cercare\n% N = posizione in cui si trova X nella lista\n% L = lista in cui cercare X\n% L1 = gli elementi di L a sinistra di X (X escluso)\n% L2 = gli elementi di L a destra di X (X escluso)\n \nelemAt(X, N, [X|R], [], R, N).\nelemAt(X, N, [K|R], [K|R1], R2, Count) :-\n    Count2 is Count + 1,\n    elemAt(X, N, R, R1, R2, Count2).\nWorker: decodificatore_1_worker/2\n% La Stringa deve contenere uno spazio a fine parola, es: [&quot;mario rossi &quot;]\ndecodificatore_1_worker(Stringa, StringaAggiustata) :-\n    string_codes(Stringa, X),\n    decodificatore_1(X, [], StringaAggiustata).\ndecodificatore_1/3 e aggiusta_stringa_1/2\ndecodificatore_1([], Acc, Stringa_nuova) :- \n    string_codes(Stringa_nuova, Acc), !.\n \ndecodificatore_1(Chars, Acc, Stringa_nuova) :-\n    elemAt(32, _, Chars, L, D, 0),\n    aggiusta_stringa_1(L, NewL),\n    append(NewL, [32], NewerL),\n    append(Acc, NewerL, Acc2),\n    decodificatore_1(D, Acc2, Stringa_nuova).\n \naggiusta_stringa_1(Chars, CharsAggiustati) :-\n    reverse(Chars, CharsAggiustati).\nWorker: decodificatore_2_worker/2\ndecodificatore_2_worker(Stringa, StringaAggiustata) :-\n    string_codes(Stringa, X),\n    decodificatore_2(X, [], StringaAggiustata).\ndecodificatore_2/3 e aggiusta_stringa_2/2\ndecodificatore_2([], Acc, Stringa_nuova) :-\n    string_codes(Stringa_nuova, Acc), !.\n \ndecodificatore_2(Chars, Acc, Stringa_nuova) :-\n    elemAt(32, _, Chars, L, D, 0),\n    aggiusta_stringa_2(L, NewL),\n    append(NewL, [32], NewerL),\n    append(Acc, NewerL, Acc2),\n    decodificatore_2(D, Acc2, Stringa_nuova).\n \naggiusta_stringa_2(Chars, CharsAggiustati) :-\n    reverse(Chars, CharsNuovi),\n    swapfl(CharsNuovi, CharsAggiustati).\nWorker: decodificatore_3_worker/2\ndecodificatore_3_worker(Stringa, StringaAggiustata) :-\n    string_codes(Stringa, X),\n    decodificatore_3(X, [], StringaAggiustata).\ndecodificatore_3/3, estrai_caratteri/3 e swapfl/2\n% Acc √® una lista di liste di numeri\ndecodificatore_3([], Acc, Stringa_nuova) :-\n    swapfl(Acc, NewAcc),\n    estrai_caratteri(NewAcc, [], Chars), % chars √® una singola lista di numeri\n    string_codes(Stringa_nuova, Chars).\n \ndecodificatore_3(Chars, Acc, Stringa_nuova) :-\n    elemAt(32, _, Chars, L, D, 0),\n    aggiusta_stringa_2(L, NewL),\n    append(NewL, [32], NewerL),\n    append(Acc, [NewerL], Acc2), % Acc diventa lista di liste\n    decodificatore_3(D, Acc2, Stringa_nuova).\n \n% Estrazione dei caratteri da lista di liste\nestrai_caratteri([], Acc, Acc).\nestrai_caratteri([H|T], Acc, Chars) :-\n    append(Acc, H, NewAcc),\n    estrai_caratteri(T, NewAcc, Chars).\n \n% swapfl/2: inverte il primo ed ultimo elemento della lista\nswapfl([First|Middle1], List2) :-\n    append(Middle, [Last], Middle1),\n    append([Last|Middle], [First], List2)."},"UNI/ANNO-2/LINGUAGGI/PROMPT":{"slug":"UNI/ANNO-2/LINGUAGGI/PROMPT","filePath":"UNI/ANNO 2/LINGUAGGI/PROMPT.md","title":"PROMPT","links":[],"tags":[],"content":"PROMPT PER JAVA\nScrivi un programma in Java semplice e ben strutturato rispettando adeguatamente la consegna del pdf CAMBIANOME.pdf se necessario leggi oralejava.pdf che rispetti le convenzioni di stile: - nomi in camelCase per variabili e metodi, PascalCase per le classi; - usa il singolare per il nome delle classi e degli oggetti; usa invece il plurale solo per array o collezioni. Il codice deve essere pulito, leggibile e commentato nelle parti principali. Non usare concetti avanzati come generics troppo complessi, lambda o stream, deve sembrare che sia fatto da uno studente di informatica universitario con il suo primo esame di java.\n\nil tutto deve essere fatto su eclipse quindi con le classi divise in file differenti\nrispetta saldamente la consegna\n\nSPIEGAZIONE CODICE DI JAVA\nSpiega in modo chiaro e conciso il seguente codice Java. Concentrati soprattutto sui passaggi pi√π complessi, come l‚Äôuso di classi annidate, ereditariet√†, polimorfismo, interfacce, generics, override/overload e gestione delle eccezioni.\nNon soffermarti troppo sulle istruzioni di base (es. dichiarazione di variabili primitive o semplici System.out.println).\nLa spiegazione deve essere ordinata, con esempi e paragrafi brevi che chiariscono la logica e il ruolo di ogni parte del codice.\n\ninoltre √® gradito se spiegassi l‚Äôidea del codice cosa fa ogni classe, i metodi usati ecc‚Ä¶\n\nPROMPT PER PROLOG\nSei uno studente di Prolog all‚Äôesame su SWISH Prolog ti √® stato consegnato l‚Äôesame che ti mando alla fine del prompt.\n\nDevi scrivere la soluzione in modo dichiarativo, usando solo i predicati visti e analizzati negli esami precedenti che ti ho fornito e che si trovano su ESAMI COMPLETO PROLOG.pdf\n√® FONDAMENTALE che tu faccia degli esami simili a quelli che gi√† ho svolto perch√© altrimenti non sembrano fatti dallo studente e si devono usare solo i comandi presenti nel pdf degli esami precedenti, non si possono usare altre operazioni!\nDeve sembrare che √® stato svolto in 1 ora quindi\ncodice funzionante senza ottimizzazioni avanzate e non troppo perfetto\nbasati il pi√π possibile sugli esami forniti in precedenza, cos√¨ che tu possa farli in modo che piacciano al professore\nil prof non ha mai usato write\nspiegazioni minime, commenti rapidi.\nsfrutta anche predicati che sono stati creati negli esami precedenti e riscrivili se utili, cos√¨ sei sicuro di non inventare cose che il professore non vuole\necco l‚Äôesame:\n\nSPIEGAZIONE CODICE PROLOG\nSpiega il codice Prolog qui sopra in modo chiaro e conciso, come se lo stessi raccontando al professore subito dopo l‚Äôesame sapendo per√≤ che IO non ho mai studiato prolog, quindi spiega bene i concetti ecc.\nConcentrati su:\n\nla logica dell‚Äôesercizio e come funziona il predicato principale e anche gli altri predicati, in modo chiaro per ogni predicato usato,\nspiega il funzionamento in prolog di ogni predicato con una spiegazione ben fatta per ogni predicato non troppo lunga ma chiara ed esaustiva\nle parti pi√π complesse o meno intuitive (es. uso di append, reverse, gestione di liste/stringhe),\ngli errori, imprecisioni o ingenuit√† presenti (commenti vaghi, clausole ripetitive, test non esaustivi),\nspiegare perch√© ‚Äúfunziona a grandi linee‚Äù ma non √® ottimizzato.\nNon fare una lezione troppo teorica, ma una spiegazione riga per riga anche per√≤, semplice e diretta, in stile studente che racconta ‚Äúcosa ha fatto e perch√©‚Äù.\nscrivi il testo in modo pi√π chiaro e leggibile come se fosse una sorta di guida, spiegando per bene ci√≤ che fai, non deve essere solo un elenco\n"},"UNI/ANNO-2/PROBABILIT√Ä/CAP-1-RIASSUNTO-MEGA-SUPREMO-PER-CAPIRE-PROB":{"slug":"UNI/ANNO-2/PROBABILIT√Ä/CAP-1-RIASSUNTO-MEGA-SUPREMO-PER-CAPIRE-PROB","filePath":"UNI/ANNO 2/PROBABILIT√Ä/CAP 1 RIASSUNTO MEGA SUPREMO PER CAPIRE PROB.md","title":"CAP 1 RIASSUNTO MEGA SUPREMO PER CAPIRE PROB","links":[],"tags":[],"content":"üß© 1. Introduzione: perch√© usare la probabilit√† negli algoritmi\nIl capitolo inizia con un‚Äôidea importante:\nüëâ La probabilit√† serve per controllare l‚Äôincertezza e l‚Äôefficienza.\nGli autori mostrano che in informatica possiamo usare la casualit√† non solo per modellare fenomeni incerti (come errori o dati rumorosi), ma anche per progettare algoritmi pi√π semplici e veloci.\nQuesti sono detti algoritmi randomizzati.\n\nüîπ Primo esempio: verificare un‚Äôidentit√† polinomiale\nSupponiamo di voler verificare se due polinomi sono uguali:\nF(x) = G(x)\nIn teoria, potresti espandere tutto e confrontare i coefficienti ‚Äî ma questo √® lento.\nInvece, si pu√≤ fare cos√¨:\n\nScegli un numero casuale r (per esempio tra 1 e 100d, dove d √® il grado massimo dei polinomi).\nCalcola F(r) e G(r).\nSe i risultati sono diversi ‚Üí i polinomi non sono uguali.\nSe sono uguali ‚Üí probabilmente lo sono davvero.\n\n\nü§î Perch√© ‚Äúprobabilmente‚Äù?\n√à possibile (anche se raro) che due polinomi diversi assumano lo stesso valore per un certo r.\nMa questo pu√≤ accadere al massimo in d punti diversi, dove d √® il grado del polinomio.\nQuindi la probabilit√† di errore √® al pi√π:\n\\frac{d}{100d} = \\frac{1}{100}\nüëâ Con una sola prova hai solo l‚Äô1% di errore.\nRipetendo la prova pi√π volte con numeri casuali diversi, la probabilit√† di errore decresce esponenzialmente.\nüìò √à un esempio classico di algoritmo randomizzato con errore controllato:\nnon garantisce sempre la correttezza, ma √® molto veloce e quasi sempre giusto.\n\nüé≤ 1.2 ‚Äì Axiomi di probabilit√†\nDopo l‚Äôesempio pratico, gli autori formalizzano i concetti matematici su cui si basa la probabilit√†.\n\nüî∏ Lo spazio di probabilit√†\nUn esperimento casuale (come ‚Äúscegli un numero tra 1 e 100d‚Äù) √® descritto da:\n\n\nSpazio campionario \\Omega:\ninsieme di tutti i possibili risultati.\n‚Üí Nell‚Äôesempio: \\Omega = \\{1, 2, \\dots, 100d\\}.\n\n\nEventi: sottoinsiemi di \\Omega.\n‚Üí Esempio: ‚Äúil numero scelto √® pari‚Äù.\n\n\nFunzione di probabilit√† \\Pr:\nassegna a ogni evento un numero tra 0 e 1, con tre propriet√† fondamentali (gli assiomi di Kolmogorov):\n\n0 \\leq \\Pr(E) \\leq 1\n\\Pr(\\Omega) = 1\nSe due eventi non si sovrappongono,\n\\Pr(E_1 \\cup E_2) = \\Pr(E_1) + \\Pr(E_2)\n\n\n\n\nPer eventi qualsiasi (anche sovrapposti) vale:\n\\Pr(E_1 \\cup E_2) = \\Pr(E_1) + \\Pr(E_2) - \\Pr(E_1 \\cap E_2)\nQuesto √® utile per combinare pi√π probabilit√†.\n\n‚öñÔ∏è La ‚ÄúUnion Bound‚Äù\nUna regola semplice ma potentissima:\n\\Pr(E_1 \\cup E_2 \\cup \\dots \\cup E_n) \\leq \\Pr(E_1) + \\Pr(E_2) + \\dots + \\Pr(E_n)\nIn parole povere:\n\nLa probabilit√† che accada almeno uno degli eventi √® al massimo la somma delle loro probabilit√†.\n\n√à uno strumento fondamentale per ottenere stime superiori (upper bounds) in probabilit√† e analisi di algoritmi.\n\nüßÆ Ritorno all‚Äôalgoritmo dei polinomi\nApplichiamo ora le definizioni all‚Äôesempio iniziale:\n\nLo spazio campionario √® \\{1, 2, \\dots, 100d\\}.\nOgni numero ha probabilit√† \\frac{1}{100d}.\n\nL‚Äôevento ‚Äúl‚Äôalgoritmo sbaglia‚Äù √® che r sia una radice del polinomio F(x) - G(x).\nPoich√© ci sono al massimo d radici:\n\\Pr(\\text{errore}) \\leq \\frac{d}{100d} = \\frac{1}{100}\nSe si ripete l‚Äôesperimento k volte (scegliendo r indipendenti):\n\\Pr(\\text{errore in tutte le prove}) \\leq \\left(\\frac{1}{100}\\right)^k\nüëâ Quindi l‚Äôerrore scende esponenzialmente con il numero di ripetizioni.\n\nüß† Indipendenza e probabilit√† condizionata\nPer comprendere meglio i calcoli precedenti, servono due concetti base.\nüîπ Eventi indipendenti\nDue eventi E e F sono indipendenti se:\n\\Pr(E \\cap F) = \\Pr(E) \\Pr(F)\ncio√®: sapere che uno accade non cambia la probabilit√† dell‚Äôaltro.\n\nüîπ Probabilit√† condizionata\nDefinita come:\n\\Pr(E \\mid F) = \\frac{\\Pr(E \\cap F)}{\\Pr(F)}\ncio√®: la probabilit√† che accada E sapendo che F √® accaduto.\n\nüîÅ Applicazione all‚Äôalgoritmo randomizzato\n\nCon sostituzione: ogni scelta √® indipendente ‚áí si pu√≤ moltiplicare le probabilit√†.\nSenza sostituzione: le prove sono collegate ‚áí si usa la probabilit√† condizionata.\n\n\nüß© 1.3 ‚Äì Verifying Matrix Multiplication\nVerificare una moltiplicazione di matrici in modo probabilistico\nQuesta sezione mostra un‚Äôidea potente: usare la probabilit√† per rendere efficienti verifiche molto costose.\n\nüîπ Il problema\nAbbiamo tre matrici quadrate A, B e C, ciascuna di dimensione n \\times n.\nVogliamo verificare se:\nA \\times B = C\nIl metodo diretto ‚Äî calcolare A \\times B e confrontarlo con C ‚Äî richiede O(n^3) operazioni,\ncio√® milioni di moltiplicazioni per matrici grandi.\nTroppo lento, soprattutto se vogliamo solo controllare che il risultato sia corretto.\n\nüîπ L‚Äôidea randomizzata\nInvece di rifare tutta la moltiplicazione, scegli un vettore casuale r di dimensione n \\times 1\n(ad esempio con valori 0 o 1 scelti a caso).\nPoi calcola:\nA(Br) \\quad \\text{e} \\quad Cr\ne confrontali:\n\nSe A(Br) = Cr, probabilmente A \\times B = C.\nSe A(Br) \\neq Cr, sicuramente A \\times B \\neq C.\n\n\nüîπ Cosa significano A(Br) e Cr\nBr significa ‚Äúmoltiplica la matrice B per il vettore casuale r‚Äù:\nottieni un nuovo vettore, combinazione delle colonne di B.\nPoi moltiplichi A per quel risultato: A(Br).\nQuesto equivale ad applicare prima B, poi A al vettore r.\nCr √® invece la moltiplicazione della matrice C per lo stesso vettore r.\n‚û°Ô∏è In sintesi, il test confronta due vettori:\n\nil risultato di applicare A e B in cascata,\ncon quello di applicare direttamente C.\n\n\nüîπ Perch√© funziona\nSe A \\times B = C, allora per ogni vettore r vale:\nA(Br) = (AB)r = Cr\nQuindi il test sar√† sempre vero.\nSe invece A \\times B \\neq C, definiamo:\nD = A \\times B - C\nPoich√© D \\neq 0, vogliamo verificare se:\nDr = 0\ncio√® se la combinazione delle colonne di D data da r restituisce il vettore nullo.\nSe D \\neq 0, quasi sempre ci sar√† almeno un vettore r per cui Dr \\neq 0.\nSolo in casi rari (con probabilit√† \\le \\frac{1}{2}) potremmo scegliere casualmente un vettore che ‚Äúnasconde‚Äù l‚Äôerrore.\nRipetendo il test pi√π volte con vettori diversi, la probabilit√† di errore scende esponenzialmente:\n\\Pr(\\text{errore dopo $k$ prove}) \\le \\left(\\frac{1}{2}\\right)^k\n\nüîπ Vantaggi\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMetodoComplessit√†AccuratezzaClassicoO(n^3)EsattaProbabilisticoO(n^2)Quasi certa (errore ‚â§ (1/2)^k)\nüëâ √à un esempio di algoritmo Monte Carlo:\nusa la casualit√† per ottenere risultati pi√π rapidi, accettando un piccolissimo margine d‚Äôincertezza.\n\nüé≤ 1.4 ‚Äì Conditional Probability and Independence\nProbabilit√† condizionata e indipendenza\nGli autori introducono ora formalmente i concetti di probabilit√† condizionata e indipendenza, gi√† usati negli esempi precedenti.\n\nüîπ Probabilit√† condizionata\n\\Pr(E \\mid F) = \\frac{\\Pr(E \\cap F)}{\\Pr(F)}\nSi legge:\n\n‚ÄúLa probabilit√† che accada E, dato che √® accaduto F.‚Äù\n\n\nüìò Esempio\nIn un mazzo di 52 carte:\n\nE: ‚Äú√® un re‚Äù ‚Üí 4 carte\nF: ‚Äú√® una figura‚Äù (re, donna o fante) ‚Üí 12 carte\n\nPoich√© E \\cap F = E:\n\\Pr(E \\mid F) = \\frac{\\Pr(E)}{\\Pr(F)} = \\frac{4/52}{12/52} = \\frac{1}{3}\nQuindi, sapendo che √® uscita una figura, la probabilit√† che sia un re √® 1/3.\n\nüîπ Regola del prodotto\nDalla definizione di probabilit√† condizionata:\n\\Pr(E \\cap F) = \\Pr(F) \\times \\Pr(E \\mid F)\noppure anche:\n\\Pr(E \\cap F) = \\Pr(E) \\times \\Pr(F \\mid E)\nQuesta √® la base per molti calcoli, incluso il Teorema di Bayes.\n\nüîπ Indipendenza\nDue eventi E e F sono indipendenti se:\n\\Pr(E \\cap F) = \\Pr(E) \\Pr(F)\ncio√® sapere che uno accade non cambia la probabilit√† dell‚Äôaltro.\nE quindi anche:\n\\Pr(E \\mid F) = \\Pr(E)\n\nüé≤ Esempio\nLancio due monete:\n\nE: ‚Äúla prima moneta √® testa‚Äù\nF: ‚Äúla seconda moneta √® testa‚Äù\n\n‚Üí Sono indipendenti, perch√© l‚Äôesito della prima non influisce sulla seconda.\n\nüß† 1.5 ‚Äì Naive Bayesian Classifier\nUn‚Äôapplicazione della probabilit√† condizionata alla classificazione\nQuesta sezione fa da ponte tra probabilit√† e intelligenza artificiale, mostrando come usare il Teorema di Bayes per classificare oggetti o dati in categorie.\n\nüîπ Il modello probabilistico\nVogliamo stimare:\n\\Pr(C \\mid x) = \\frac{\\Pr(C) \\times \\Pr(x \\mid C)}{\\Pr(x)}\ndove:\n\nC = categoria (es. ‚Äúspam‚Äù o ‚Äúnon spam‚Äù)\nx = insieme delle caratteristiche osservate (es. parole di un‚Äôemail)\n\nüëâ L‚Äôobiettivo √® scegliere la categoria C che massimizza \\Pr(C \\mid x).\n\nüîπ Cosa significa categoria\nUna categoria √® una classe o etichetta che identifica il tipo di oggetto:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOggettoCategorie possibiliEmailSpam / Non spamImmagineGatto / CaneRecensionePositiva / Negativa\nIl sistema osserva un insieme di caratteristiche x (es. le parole di un testo)\ne cerca la categoria pi√π probabile.\n\nüîπ Cosa significa \\Pr(x \\mid C)\n\n‚ÄúLa probabilit√† di osservare le caratteristiche x, sapendo che l‚Äôoggetto appartiene alla categoria C.‚Äù\n\nEsempio:\n\n\\Pr(x \\mid \\text{spam}) = probabilit√† che un‚Äôemail di spam contenga ‚Äúlotteria‚Äù e ‚Äúpremio‚Äù\n\\Pr(x \\mid \\text{non spam}) = probabilit√† che un‚Äôemail normale contenga le stesse parole\n\n\nüîπ L‚Äôassunzione ‚Äúnaive‚Äù\nNella realt√† le caratteristiche non sono indipendenti (‚Äúlotteria‚Äù e ‚Äúpremio‚Äù compaiono spesso insieme).\nMa per semplificare i calcoli si assume che, dato C, siano indipendenti.\n\\Pr(x \\mid C) = \\Pr(x_1, x_2, \\dots, x_n \\mid C) = \\prod_i \\Pr(x_i \\mid C)\nIl simbolo \\prod_i indica il prodotto di tutte le probabilit√† individuali \\Pr(x_i \\mid C).\nEsempio:\n\\Pr(x \\mid \\text{spam}) = 0.8 \\times 0.7 \\times 0.4 = 0.224\n\nüîπ Il simbolo ‚Äú‚àù‚Äù (proporzionale a)\nIl teorema di Bayes completo √®:\n\\Pr(C \\mid x) = \\frac{\\Pr(C) \\Pr(x \\mid C)}{\\Pr(x)}\nPoich√© \\Pr(x) √® uguale per tutte le categorie (√® lo stesso messaggio), possiamo ignorarlo e scrivere:\n\\Pr(C \\mid x) \\propto \\Pr(C) \\times \\Pr(x \\mid C)\nIl simbolo ‚Äú‚àù‚Äù significa ‚Äúproporzionale a‚Äù,\ncio√® differisce solo per un fattore costante \\frac{1}{\\Pr(x)}.\n\nüîπ Esempio numerico completo\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParola\\Pr(\\text{parola} \\mid \\text{spam})\\Pr(\\text{parola} \\mid \\text{non spam})‚Äúlotteria‚Äù0.80.1‚Äúpremio‚Äù0.70.05\nE sappiamo che:\n\\Pr(\\text{spam}) = 0.4, \\quad \\Pr(\\text{non spam}) = 0.6\nAllora:\n\\Pr(\\text{spam} \\mid x) \\propto 0.4 \\times (0.8 \\times 0.7) = 0.224\n\\Pr(\\text{non spam} \\mid x) \\propto 0.6 \\times (0.1 \\times 0.05) = 0.003\nPoich√© 0.224 \\gg 0.003, il messaggio √® classificato come spam.\n\nüîπ Intuizione finale\n\n\\Pr(C) ‚Üí quanto √® comune quella categoria (‚Äúquanto spesso ricevo spam‚Äù).\n\\Pr(x \\mid C) ‚Üí quanto il contenuto √® tipico di quella categoria.\n\\Pr(C \\mid x) ‚Üí quanto √® probabile che il messaggio appartenga a quella categoria, dato il contenuto.\n\nPoich√© \\Pr(x) √® costante, possiamo semplicemente scegliere la categoria con:\n\\Pr(C) \\Pr(x \\mid C) \\text{ massimo.}\n‚úÖ In pratica, √® cos√¨ che funzionano i classificatori Naive Bayes negli algoritmi di machine learning."},"UNI/ANNO-2/PROBABILIT√Ä/CAP-2":{"slug":"UNI/ANNO-2/PROBABILIT√Ä/CAP-2","filePath":"UNI/ANNO 2/PROBABILIT√Ä/CAP 2.md","title":"CAP 2","links":[],"tags":[],"content":"üìò Capitolo 2 ‚Äì Variabili casuali discrete e aspettativa\nüéØ Introduzione\nNel capitolo precedente abbiamo visto come la probabilit√† serva a stimare quanto spesso accadono certi eventi.\nOra facciamo un passo oltre: vogliamo capire quali valori numerici pu√≤ assumere un evento casuale e, soprattutto, quanto ci aspettiamo in media da esso.\nPer farlo introduciamo uno strumento fondamentale: la variabile casuale, detta anche variabile aleatoria.\n\nüîπ 2.1 ‚Äì Variabili casuali e aspettativa\nUna variabile casuale (o aleatoria) √® una funzione che associa a ciascun possibile esito di un esperimento casuale un numero reale:\nX : \\Omega \\to \\mathbb{R}\ndove:\n\n\\Omega √® lo spazio campionario, cio√® l‚Äôinsieme di tutti i possibili esiti;\nX(\\omega) √® il numero che la variabile assegna all‚Äôesito \\omega.\n\nüëâ Quindi X non √® un evento, ma una quantit√† che dipende dal caso.\n\nüî∏ Esempio 1 ‚Äì Il lancio di un dado\nLanci un dado a sei facce.\n\\Omega = \\{1, 2, 3, 4, 5, 6\\}\nDefiniamo la variabile casuale:\nX(\\omega) = \\omega\nIn altre parole, X √® il numero uscito sul dado.\nOgni valore x ha probabilit√†:\n\\Pr(X = x) = \\frac{1}{6}, \\quad x = 1, 2, \\dots, 6\n\nüîπ 2.1.1 ‚Äì Il concetto di aspettativa\nIl valore atteso o aspettativa, indicato con E[X], √® la media ponderata di tutti i valori che X pu√≤ assumere, usando come peso le loro probabilit√†:\nE[X] = \\sum_x x \\cdot \\Pr(X = x)\nüëâ In parole semplici:\nE[X] rappresenta il valore medio teorico che otterremmo se ripetessimo l‚Äôesperimento infinite volte.\n\nüî∏ Esempio 2 ‚Äì La media del dado\nE[X] = \\frac{1 + 2 + 3 + 4 + 5 + 6}{6} = 3.5\n‚ö†Ô∏è Nota: 3.5 non √® un valore che pu√≤ uscire, ma √® la media teorica dei risultati.\nSe lanci un dado molte volte, la media dei numeri ottenuti si avviciner√† a 3.5.\nüëâ √à un concetto astratto ma predittivo: ci dice ‚Äúin media‚Äù cosa aspettarci dal fenomeno.\n\nüîπ 2.1.2 ‚Äì Differenza tra evento e variabile casuale\nUn evento √® una proposizione che pu√≤ essere vera o falsa (es. ‚Äúesce 6‚Äù).\nUna variabile casuale assegna un numero a ciascun evento possibile.\nEsempio:\n\n\nEvento: ‚Äúesce un numero pari‚Äù\n‚Üí \\Pr(\\text{pari}) = \\frac{3}{6} = 0.5\n\n\nVariabile casuale: ‚Äúil numero uscito‚Äù\n‚Üí E[X] = 3.5\n\n\nüìò Quindi E[X] non √® una probabilit√†, ma la media dei valori numerici che la variabile pu√≤ produrre.\n\nüîπ 2.1.3 ‚Äì Famiglie di variabili casuali: indici sopra e sotto\nSpesso dobbiamo descrivere pi√π variabili casuali collegate, come in una sequenza di esperimenti.\nX_1, X_2, \\dots, X_n\nrappresentano n variabili distinte, ad esempio i risultati di pi√π lanci di un dado.\n\nX_1, X_2, X_3: risultati del primo, secondo, terzo dado\n(X_1)^2 o X^2: il quadrato del valore di X, utile per la varianza o per E[X^2]\n\n\nüî∏ Esempio pratico\nLanci due dadi tre volte.\n\nX^1_1: risultato del primo dado al primo lancio\nX^2_1: risultato del secondo dado al primo lancio\nX^1_2, X^2_2: risultati al secondo lancio\n\nDefiniamo la somma:\nS_i = X^1_i + X^2_i\nS_i √® la somma dei due dadi nell‚Äôesperimento i-esimo.\nTutte queste sono variabili casuali, ciascuna con la propria aspettativa.\n\nüîπ 2.1.4 ‚Äì Linearit√† dell‚Äôaspettativa\nUna delle propriet√† pi√π eleganti e potenti:\nE[X + Y] = E[X] + E[Y]\ned √® sempre vera, anche se X e Y non sono indipendenti.\n\nüí° Esempio 3 ‚Äì Due dadi\nLanci due dadi e definiamo:\nX_1 = \\text{risultato del primo dado}, \\quad X_2 = \\text{risultato del secondo dado}\nSia X = X_1 + X_2.\nAllora:\nE[X] = E[X_1 + X_2] = E[X_1] + E[X_2]\nPoich√© E[X_1] = E[X_2] = 3.5, otteniamo:\nE[X] = 3.5 + 3.5 = 7\nüëâ Il valore medio della somma dei due dadi √® 7.\n\nüîπ 2.1.5 ‚Äì Quando l‚Äôaspettativa non esiste\nSe i valori possibili di X crescono troppo velocemente rispetto alle loro probabilit√†,\nla somma che definisce E[X] non converge.\nEsempio:\nX = 2^i \\quad \\text{con probabilit√†} \\quad \\frac{1}{2^i}\nAllora:\n\\sum_i 2^i \\cdot \\frac{1}{2^i} = \\infty \\quad \\Rightarrow \\quad E[X] = \\infty\nQuesto succede con distribuzioni a coda pesante, tipiche di fenomeni economici o di rete.\n\nüîπ 2.1.6 ‚Äì Inizio: la disuguaglianza di Jensen\nSpesso ci interessa non solo E[X], ma anche E[f(X)], cio√® la media di una funzione di X.\nSe f √® convessa, allora vale la disuguaglianza di Jensen:\nE[f(X)] \\ge f(E[X])\n\nüí° Esempio 4 ‚Äì L‚Äôarea di un quadrato\nSia X la lunghezza del lato di un quadrato casuale e f(X) = X^2 la sua area.\nPoich√© f √® convessa:\nE[X^2] &gt; (E[X])^2\nüëâ La media delle aree √® pi√π grande dell‚Äôarea calcolata sulla media dei lati.\nQuesto spiega perch√© la varianza non √® mai nulla anche quando la media √® costante.\n\nüß© Sintesi finale\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConcettoSignificatoEsempio / FormulaVariabile casualeFunzione che assegna un numero a ogni esito possibileX : \\Omega \\to \\mathbb{R}Probabilit√† di un valoreQuanto spesso X assume un certo valore\\Pr(X = x)Aspettativa E[X]Media pesata dei valori di XE[X] = \\sum x \\Pr(X = x)Linearit√†La media della somma √® la somma delle medieE[X + Y] = E[X] + E[Y]JensenPer funzioni convesse: E[f(X)] \\ge f(E[X])E[X^2] &gt; (E[X])^2Indici X_1, X_2Sottoscritti = variabili diverse, soprascritti = esperimenti diversiS_i = X^1_i + X^2_i\nüìò Capitolo 2 ‚Äì Variabili casuali discrete e aspettativa\nüîπ Pagine 27‚Äì32 ‚Äì Variabili Bernoulli, Binomiali e Aspettativa Condizionata\n\nüß© Introduzione\nAbbiamo imparato che una variabile casuale (o aleatoria) √® una funzione che associa un numero a un evento casuale.\nOra ci concentriamo su due tipi fondamentali di variabili discrete ‚Äî Bernoulli e Binomiale ‚Äî e su come calcolare aspettative condizionate, cio√® medie ‚Äúsapendo che qualcosa √® successo‚Äù.\nQueste idee sono la base della probabilit√† applicata, dagli algoritmi randomizzati alle simulazioni statistiche.\n\nüîπ 2.2 ‚Äì Variabili casuali Bernoulli e binomiali\nüéØ Variabile di Bernoulli\nLa variabile di Bernoulli √® il modello pi√π semplice: pu√≤ valere solo 0 o 1.\nX =\n\\begin{cases}\n1 &amp; \\text{con probabilit√† } p \\\\\n0 &amp; \\text{con probabilit√† } 1 - p\n\\end{cases}\nüìò Interpretazione pratica:\n\n1 = successo (es. ‚Äúesce testa‚Äù, ‚Äúevento accaduto‚Äù)\n0 = fallimento\n\n\nüí° Esempio intuitivo\nLancio una moneta con probabilit√† p = 0.7 di testa.\nDefinisco X = 1 se esce testa, X = 0 se esce croce.\n‚Üí X √® una variabile di Bernoulli.\n\nüìä Aspettativa e varianza\nE[X] = 1 \\cdot p + 0 \\cdot (1 - p) = p\nüëâ In media, il valore di X coincide con la probabilit√† di successo.\nLa varianza, cio√® quanto X varia rispetto alla sua media, √®:\n\\mathrm{Var}(X) = p(1 - p)\nüìà √à massima quando p = 0.5, cio√® quando il risultato √® pi√π incerto.\n\nüîπ Variabile Binomiale\nOra immaginiamo di ripetere l‚Äôesperimento n volte, in modo indipendente.\nOgni prova ha probabilit√† p di successo.\nDefiniamo:\nX_i =\n\\begin{cases}\n1 &amp; \\text{se la i-esima prova √® un successo} \\\\\n0 &amp; \\text{altrimenti}\n\\end{cases}\nLa somma dei successi:\nX = X_1 + X_2 + \\dots + X_n\n√® una variabile binomiale.\nEssa conta quanti successi otteniamo in n prove.\n\nüßÆ Distribuzione binomiale\n\\Pr(X = k) = \\binom{n}{k} p^k (1 - p)^{n - k}\nüìò Dove:\n\nn = numero di prove\nk = numero di successi\np = probabilit√† di successo per prova\n\n\\binom{n}{k} = \\frac{n!}{k! \\, (n - k)!}\nrappresenta il numero di modi per scegliere quali prove risultano vincenti.\n\nüîç Come leggere la formula\n\nIl termine p^k (1 - p)^{n - k} √® la probabilit√† di una singola sequenza con k successi e n - k fallimenti.\nIl coefficiente \\binom{n}{k} conta tutte le sequenze possibili che producono k successi.\nMoltiplicando otteniamo la probabilit√† complessiva di ottenere esattamente k successi.\n\n\nüí° Esempio concreto\nLancio una moneta equa (p = 0.5) tre volte.\nVoglio la probabilit√† di ottenere 2 teste:\n\\Pr(X = 2) = \\binom{3}{2} (0.5)^2 (0.5)^1 = 3 \\times 0.25 \\times 0.5 = 0.375\nüëâ Probabilit√† = 37,5%\n\nüéØ Esempio generale\nImmagina un test con 10 domande a scelta multipla,\ne ogni risposta ha probabilit√† p = 0.25 di essere giusta ‚Äúa caso‚Äù.\nLa probabilit√† di azzeccarne esattamente 4 √®:\n\\Pr(X = 4) = \\binom{10}{4} (0.25)^4 (0.75)^6 \\approx 0.146\nüëâ Circa 14,6%.\n\n‚öôÔ∏è Aspettativa e varianza della binomiale\nUsiamo la linearit√† dell‚Äôaspettativa:\nE[X] = E[X_1 + X_2 + \\dots + X_n] = E[X_1] + \\dots + E[X_n]\nPoich√© ogni E[X_i] = p, abbiamo:\nE[X] = n p\nüëâ In media, ci aspettiamo n p successi su n prove.\n\nVarianza\nPoich√© le prove sono indipendenti:\n\\mathrm{Var}(X) = \\mathrm{Var}(X_1 + X_2 + \\dots + X_n) = \\mathrm{Var}(X_1) + \\dots + \\mathrm{Var}(X_n)\ne dato che \\mathrm{Var}(X_i) = p(1 - p):\n\\mathrm{Var}(X) = n p (1 - p)\nLa deviazione standard √®:\n\\sigma = \\sqrt{n p (1 - p)}\n\nüí¨ Interpretazione intuitiva\nSe lanci una moneta 100 volte (n = 100, p = 0.5):\nE[X] = 100 \\times 0.5 = 50\n\\sigma = \\sqrt{100 \\times 0.5 \\times 0.5} = 5\nüëâ In media ottieni 50 teste, con oscillazioni tipiche di ¬±5.\nRisultati tra 45 e 55 sono i pi√π probabili; 20 o 80 sono estremamente rari.\n\nüß† Osservazione importante\nIl valore atteso E[X] non indica la probabilit√† che accada qualcosa,\nma la media numerica dei valori che X assume.\n\\Pr(X = E[X]) \\text{ pu√≤ essere basso, ma } E[X] \\text{ rappresenta il ‚Äúcentro‚Äù della distribuzione.}\n\nüîπ 2.3 ‚Äì Aspettativa condizionata (introduzione)\nSpesso vogliamo capire l‚Äôaspettativa sapendo che √® accaduto un certo evento.\nLa media condizionata di X dato un evento A si scrive:\nE[X \\mid A] = \\sum_x x \\cdot \\Pr(X = x \\mid A)\nEssa rappresenta la media dei valori di X considerando solo i casi in cui A √® vero.\n\nüí° Esempio\nSia X il numero di teste in due lanci di moneta.\nAbbiamo E[X] = 1.\nSe sappiamo che √® uscita almeno una testa (evento A), i casi possibili sono:\n\\{ TH, HT, HH \\}\nAllora:\nE[X \\mid A] = \\frac{1 + 1 + 2}{3} = \\frac{4}{3}\nüëâ Sapendo che √® uscita almeno una testa, ci aspettiamo 1,33 teste in media.\n\nüîπ Legge delle aspettative totali\nUna propriet√† fondamentale:\nE[X] = E[E[X \\mid A]]\nCio√®:\n\nla media complessiva √® la media delle medie condizionate,\npesate con le probabilit√† degli eventi corrispondenti.\n\n\nüí° Esempio pratico\nSupponiamo che un algoritmo funzioni su due tipi di input:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTipoProbabilit√†Tempo medioFacile0.85sDifficile0.220s\nAllora:\nE[\\text{tempo}] = 0.8 \\times 5 + 0.2 \\times 20 = 8 \\text{ secondi}\nüëâ L‚Äôaspettativa globale √® la media ponderata delle aspettative condizionate.\nüéØ Introduzione\nFinora abbiamo visto variabili casuali binomiali, che contano quanti successi avvengono in un numero fisso di prove.\nOra cambiamo prospettiva: vogliamo sapere quante prove servono prima di ottenere il primo successo.\nüëâ Questo √® il punto di partenza per la distribuzione geometrica.\n\nüîπ 2.4 ‚Äì La distribuzione geometrica\nüî∏ Definizione\nLa variabile geometrica X rappresenta il numero di prove necessarie fino al primo successo in una sequenza di esperimenti indipendenti,\nognuno con probabilit√† di successo p.\n\\Pr(X = k) = (1 - p)^{k - 1} p, \\quad k = 1, 2, 3, \\dots\nüìò Significato:\n\nLe prime (k - 1) prove falliscono (ognuna con probabilit√† (1 - p))\nLa k-esima prova √® un successo (con probabilit√† p)\n\n\nüí° Esempio intuitivo\nLancio una moneta e voglio sapere quanti lanci servono prima di ottenere testa, con p = 0.5:\n\\Pr(X = 1) = 0.5 \\quad \\text{‚Üí testa al primo lancio}\n\\Pr(X = 2) = 0.5^2 = 0.25 \\quad \\text{‚Üí croce, poi testa}\n\\Pr(X = 3) = 0.5^3 = 0.125 \\quad \\text{‚Üí due croci, poi testa}\n‚Ä¶e cos√¨ via.\n\n‚öôÔ∏è Aspettativa della distribuzione geometrica\nIl numero medio di prove necessarie per il primo successo √®:\nE[X] = \\frac{1}{p}\nüëâ Se la probabilit√† di successo √® bassa, servono pi√π prove in media.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npE[X]Significato0.52in media, due lanci per una testa0.110in media, dieci tentativi per un successo0.01100eventi molto rari ‚Üí attese lunghe\n\n‚öñÔ∏è Varianza della geometrica\n\\mathrm{Var}(X) = \\frac{1 - p}{p^2}\nüëâ La variabilit√† cresce molto quando il successo √® raro (p piccolo).\n\nüß≠ Interpretazione intuitiva\nLa distribuzione geometrica modella il tempo di attesa fino al primo evento ‚Äúpositivo‚Äù.\n√à il modello naturale per situazioni del tipo:\n\nprimo successo in una sequenza di esperimenti,\nprimo pacchetto corretto in una rete rumorosa,\nprima collisione evitata in un sistema casuale.\n\nüìà √à la base per descrivere tempi di attesa e conteggi di tentativi nei processi casuali."},"UNI/ANNO-2/PROBABILIT√Ä/PROBABILIT√Ä-INDICE":{"slug":"UNI/ANNO-2/PROBABILIT√Ä/PROBABILIT√Ä-INDICE","filePath":"UNI/ANNO 2/PROBABILIT√Ä/PROBABILIT√Ä INDICE.md","title":"PROBABILIT√Ä INDICE","links":["UNI/ANNO-2/PROBABILIT√Ä/CAP-1-RIASSUNTO-MEGA-SUPREMO-PER-CAPIRE-PROB","UNI/ANNO-2/PROBABILIT√Ä/CAP-2"],"tags":[],"content":"CAP 1 RIASSUNTO MEGA SUPREMO PER CAPIRE PROB\nCAP 2"},"UNI/ANNO-2/RETI/1.LIVELLO-DI-APPLICAZIONE":{"slug":"UNI/ANNO-2/RETI/1.LIVELLO-DI-APPLICAZIONE","filePath":"UNI/ANNO 2/RETI/1.LIVELLO DI APPLICAZIONE.md","title":"1.LIVELLO DI APPLICAZIONE","links":[],"tags":[],"content":"\n\n                  \n                  lista argomenti \n                  \n                \n\n\nPila protocollare\nLivello di applicazione\n\nArchitetture del livello di applicazione\n\nPeer to peer\n\ntit for tat\ntorrent\nchunk\n\n\nClient Server\n\n\nSocket cosa sono\nProtocolli di applicazione\n\nHTTP\ncosa √®\n\nDatagramma\nv1\nv2\nv3\n\n\nBiscottini\nDNS\n\nSERVER DNS\niterativa\nricorsiva\n\n\nEmail\n\nUser agent\nServer mail\nSMTP\nIMAP\n\n\nWeb Cache\nRTT\n\n\n\n\n\n\n\nGenerici\n\ndefinizione di internet\n\nInfrastruttura composta da un insieme di reti interconnesse tra loro\n\n\nHost\n\nospitano le applicazioni di rete\nsi trovano ai bordi di internet\ncomunicano attraverso pacchetti di dati\ninoltrati da altri dispositivi come router e switch\n\n\nISP\n\norganizzazioni che offrono l‚Äôaccesso a internet a utenti o varie aziende\nsono interconnessi tra loro per garantire il corretto funzionamento della rete\nse locali sono nei margini della rete\nse globali sono nel nucleo della rete\n\n\nCommutazione di una rete\n\nTecniche di scambio di pacchetti seguendo determinate regole\nCommutazione di pacchetto\n\nIl singolo messaggio viene diviso in pacchetti di L bit\nviene inviato il singolo pacchetto senza flussi di bit\n\n\nCommutazione di circuito\n\nviene dedicato un collegamento tra mittente e destinatario e vengono inviati i bit in sequenza\n\n\n\n\nLan o Wan\n\nLocal Area Network\nWide Area Network\n\n\nNucleo di rete\n\n√à un insieme di commutatori di pacchetti e link tra i vari host che sono poi collegate alle varie periferie di rete\ngli utenti non ci accedono direttamente\nazioni:\n\ninoltro\n\nattraverso una tabella di inoltro, invia i pacchetti a una determinata interfaccia\n\n\ninstradamento\n\nindica il percorso che viene fatto da una serie di router per arrivare a destinazione da una radice\nfatto attraverso algoritmi\n\n\n\n\nviene calcolato instradamento e poi inoltro\n\n\n\nsicurezza di internet\n\nuna interfaccia di rete, quindi collegata alla rete\n\npu√≤ vedere tutti i pacchetti che ci passano\nwireshark\n\n\nip spoofing\n\nfingo di avere un‚Äôaltro indirizzo IP nella rete\n\n\n\n\nprotocolli\n\ninsieme di regole che definiscono i metodi per la comunicazione tra dispositivi nella rete\n\n\nDivisione in livelli della TCP/IP pila protocollare\n\nApplicazione\n\nsupporto alle applicazioni di rete con protocolli come HTTP che inviano messaggi\n\n\nTrasporto\n\nTrasferimento di segmenti tra processi come UDP e TCP\n\n\nRete\n\ntrasporto di datagrammi, pacchetti di rete tra host con indirizzo IP e protocolli IP\n\n\nCollegamento\n\nTrasferimento di frame tra dispositivi vicini\n\n\nFisico\n\nTrasferimento di bit veri e propri su link\n\n\n\n\nincapsulamento dei dati tra i vari livelli\n\n\nLivello di applicazione\n\n\ndefinizione\n\n√à un livello nella pila protocollare\ninteragisce con l‚Äôutente o con le applicazioni di rete\n\nfornendo i servizi di rete ad essi\n\n\n\n\n\narchitetture\n\nclient server chi sono?\n\nsono due attori detti host all‚Äôinterno della rete che comunicano tra loro scambiandosi messaggi\nserver\n\ndeve essere sempre attivo e deve rispondere alle richieste degli host\nindirizzo IP noto dai client\n\n\nclient\n\ncomunica con i server inviando richieste\n\n\n\n\npeer-to-peer\n\narchitettura che prevede un insieme di host che fanno sia da client che da server, sono detti peer\n\nogni peer condivide i file che ha gi√† scaricato ai peer candidati pi√π vicini\nutilizza determinate tecniche per ottimizzare lo scambio tra peer\n\n\ntorrent\n\nfile che ha tracker dei i vari peer\n\n\npeer-to-peer vs client server\n\nClient server\n\nlineare senza variazioni\n\n\npeer-to-peer\n\ndipende da il numero di utenti che condividono i dati e che li scaricano\n\n\n\n\ntit for tat\n\ntecnica di ottimizzazione del peer-to-peer\nin un intervallo di secondi vengono ogni volta definiti i peer che sono destinati a scambiare i chunk\n\nogni tanto ne viene scelto uno a caso per vedere se era candidato e utile\n\n\n\n\n\n\n\n\n\nprocessi\n\nsono un programma in esecuzione su un host\n\naccedono alla rete tramite il livello di trasporto\nma per comunicare con il livello di applicazione dove abbiamo le varie applicazione di rete vengono usate le socket\n\nsono interfacce software, permettono di comunicare con i processi che lavorano al livello di trasporto, quindi fanno da tramite con il livello di applicazione\nsono identificate da una coppia formata da\n\nIP\n\nidentifica l‚Äôhost\n\n\nPorta\n\nidentifica l‚Äôapplicazione\nalcune porte sono gi√† standardizzate per alcune applicazioni\n\n\n\n\n\n\n\n\n\n\n\n\nprotocollo del livello di applicazione\n\nsi dividono in 2 tipi\n\nproprietari\n\nnon sono noti e vengono usate da applicazioni private tipo skype\n\n\npubblici\n\nsono noti e standardizzati tipo HTTP\n\n\n\n\nvertono su\n\nsicurezza\n\ni livelli di trasporto non garantiscono chiss√† che sicurezza ma quelli di applicazione la possono migliorare con cifrature tipo TLS\n\n\ntroughput minimo garantito\nperdita di messaggi\nsensibilit√† al fattore tempo\n\n\napplicazioni che usano protocolli di trasporto\n\nHTTP usa TCP\nSMTP usa TCP\nGiochi interattivi TCP e UDP\nVoIP usa UDP\n\n\n\n\n\nHTTP\n\nalla base delle applicazioni web\n\nsfrutta il paradigma client server\npresente sulla porta 80\nconsente lo scambio di messaggi di richiesta HTTP\nvengono scambiare risorse\n\n\npassaggi che compongono una richiesta HTTP\n\nil client tenta di aprire una connessione TCP al server sulla porta 80, creando una socket, successivamente il server la riceve e accetta o meno la connessione, il client invia una richiesta HTTP al server, il server fornisce la risorsa, viene chiusa la connessione TCP\n\n\nMESSAGGIO HTTP\n\n√® composto da\n\nriga di richiesta\n\nversione HTTP, URL richiesto, metodo HTTP usato(get put‚Ä¶)\n\n\nintestazione\n\ninformazioni riguardo chi effettua la richiesta, formato, se ci sono cookie o meno ecc‚Ä¶\n\n\ncorpo del messaggio\n\ncontiene i dati inviati dal server\n\n\n\n\n\n\nMetodi HTTP\n\nPOST\nGET\nHEAD\nPUT\n\n\nVersioni a grandi linee\n\n1.0\n\nogni connessione creata TCP era uno scambio di un solo messaggio\nnon persistenti, quindi la connessione termina, gli altri sono persistenti\n\n\n1.1\n\nconsentiva di fare GET multiple di dati con politica FIFO\n\n\n2.0\n\nsenza richieste venivano inviati pi√π messaggi ma con priorit√† non FIFO\ni messaggi venivano inviati alternati tra loro divisi in frame, invio interlacciato\n\n\n3.0\n\nusa UDP con QUIC al livello di applicazione per gestire problemi di sicurezza e perdita dei messaggi\n\n\n\n\n\n\n\n\nRTT\n\ntempo che impiega un pacchetto per andare dal client al server e dal server al client\nvariabile in base a eventuali congestioni ecc‚Ä¶\n\n\n\n\nCodici di stato\n\nper ogni errore esiste un codice di stato che si trova nell‚Äôintestazione dei messaggi\n1xx messaggi informativi,\n2xx successo,\n3xx risorsa spostata,\n4xx errore,\n5xx errore server\n\n\n\nI cookie\n\nil protocollo HTTP √® stateless, quindi login non funzionano ad esempio\nper salvare eventuali client vengono o salvati gli stati in memoria sui due dispositivi client e server oppure si usano i cookie\n\ni cookie sono codici identificativi per client\ni cookie dopo la prima connessione effettuata vengono scambiati nell‚Äôheader delle richieste HTTP\nessi vengono salvati in un database dei server e vengono forniti al client, il client salver√† il proprio cookie ad esempio nel browser\n\n\n\n\n\n\nWeb Cache\n\nintermediario tra client e server\nse ha gi√† una risorsa di una eventuale richiesta HTTP la fornisce senza interpellare il server effettivo\nogni risorsa ha un TTL time to live\npu√≤ essere locale, interna al host client oppure un server come i proxy che fanno da client\nvengono usate per migliorare l‚Äôefficienza dei server e evitare congestioni\n\n\n\n\nPosta elettronica\n\napplicazione che simula lo scambio di lettere attraverso user agent e mail server\n\ntra server di posta avviene uno scambio attraverso SMTP\nuno user agent per inviare una mail la invia al suo server mail attraverso il protocollo SMTP, a sua volta questo server lo invia al server mail del destinatario attraverso il protocollo SMTP, per prelevare le mail viene usato IMAP dallo user agent\nperch√© SMTP non pu√≤ fare pull\n\n\npassaggi SMTP\n\nusa il protocollo TCP\n\neffettua prima di tutto il TCP handshake con la richiesta TCP che viene accettata\nsuccessivamente viene effettuato un handshake SMTP per presentare le due parti\nviene inviato il messaggio, come corpo ha il contenuto della mail\n\n\n\n\nHTTP VS SMTP\n\nHTTP √® di tipo pull, il client riceve dei dati solo se li richiede\nSMTP √® di tipo push, il client riceve dei dati anche se non li richiede(server mail del destinatario)\n\n\n\n\n\n\nDNS\n\nServizio di rete decentralizzato(con pi√π server) che consente la conversione di indirizzi URL in IP attraverso un Database\nCi sono 3 server noti di tipo DNS\n\nroot\n\nindirizza a quale server TLD riferirsi\n\n\nTop Level Domain\n\nforniscono la parte finale dei domini e rimandano a quelli autoritativi che sono meno generici, hanno solo .com ecc‚Ä¶\n\n\nAutoritativi\n\nServer DNS che contengono indirizzi IP completi richiesti\n\n\n\n\nrichiesta DNS pu√≤ essere\n\nricorsiva\n\ni server DNS a partire da quello locale si risolvono da soli interrogandosi a vicenda\n\n\niterativa\n\nil server DNS locale interroga i vari Server DNS personalmente\n\n\n\n\n\n\n\n\n\nURL\n\nindirizzo che contiene sito di riferimento che poi dovr√† essere convertito in IP\nrisorse di riferimento richieste dopo lo /\n\n\n\nstreaming video\n\nstreaming invio di sequenze di dati che vengono riprodotte\nsequenza di immagini codificate per ottimizzare il peso\nbitrate\n\nunit√† di misura che indica quanti bit vengono trasmessi al secondo\nfisso o variabile\n\n\nviene usato TCP per evitare perdite\n\ncon HTTP pu√≤ essere scelta la qualit√† scegliendo la determinata risorsa\n\n\nCDN\n\nserver nel mondo che hanno stessi contenuti video per rispondere alle eccessive richieste\n\n\n\n\n"},"UNI/ANNO-2/RETI/2.LIVELLO-DI-TRASPORTO":{"slug":"UNI/ANNO-2/RETI/2.LIVELLO-DI-TRASPORTO","filePath":"UNI/ANNO 2/RETI/2.LIVELLO DI TRASPORTO.md","title":"2.LIVELLO DI TRASPORTO","links":[],"tags":[],"content":"l&gt;[!tip]- lista puntata\n\n\nLivello di trasporto\n\nmultiplexing\ndemultiplexing\nProtocolli del livello di trasporto\n\nUDP\n\nSegmento UDP\nchecksum\nsenza handshake\n\n\nTCP\n\nMTU\nMSS\nsegmento TCP\nHandshake\n\n1 via\n2 vie\n\n\nfinestra di ricezione\nNumero di sequenza\nACK\nControllo del flusso\n\n\n\n\nTrasferimenti su canali inaffidabili\n\nRDT\nGBN\nRipetizione selettiva\n\n\nEsempi di congestione\n\ncaso 1\ncaso 2\ncaso 3\n\n\nControllo della congestione\n\nend to end\nassistito dalla rete\n\nBit ECN ECE\n\n\n\n\nGestioni del tasso di invio\n\nAIMD(Additive Increase Multiplicative Decrease)\nslow start\ncongestion avoidance\nfast recovery\n\n\nTCP RENO\nTCP CUBIC\nTCP VEGAS\nTCP √® fair?\n\n\n\n\nLivello di trasporto\n\nintroduzione breve\n\nlivello che consente la comunicazione tra processi su host differenti mediante protocolli e segmenti\n\n\ntecniche di smistamento dei dati mediante IP+porta\n\nmultiplexing\n\neffettuato al lato mittente\ni segmenti di ciascun processo vengono compattati e inviati, differenziati poi da una intestazione\n\n\ndemultiplexing\n\neffettuato al lato destinatario\ntramite le intestazioni dei singoli segmenti viene definito a quale processo socket destinare quel determinato segmento\nsi divide in\n\ncon connessione\n\nvengono creare socket passive\n\n\nsenza\n\n√® sufficiente IP+porta\n\n\n\n\n\n\n\n\n\n\n\nUDP\n\ndefinizione\n\nProtocollo di trasporto veloce senza handshake, con ritrasmissione\n\n\nutilizzi\n\nDNS\nDHCP\nHTTP/3 con QUIC\n\n\nstruttura del segmento\n\nIntestazione, in cui abbiamo porta di origine, porta di destinazione, lunghezza, checksum\n\norigine serve solo se si vuole inviare eventualmente una risposta\n\n\ndati dell‚Äôapplicazione\n\n\nchecksum\n\nspazio di dati all‚Äôinterno di UDP con lo scopo di rilevare errori e eventualmente ritrasmettere\nil mittente calcola la checksum e la invia al destinatario\nil destinatario calcola a sua volta la checksum e la confronta con quella inviata dal mittente\n\nse tutti i bit sono a 1 allora non vi sono errori\n\n\n\n\n\n\nModello teorico RDT\n\n\n\naffidabilit√† con RDT\n\nRDT Reliable Data Transfer, modello astratto che indica come gestire un canale inaffidabile per garantire la corretta trasmissione dei dati √® diviso in versioni\n\nesso venne poi usato come idea per TCP\n\n\n1.0\n\ncanale affidabile, mittente e destinatario devono solo aspettare di essere interpellati per inviare o ricevere dati\n\n\n2.0\n\ncanale inaffidabile ma con segmenti che vengono inviati in ordine, vengono introdotti ACK e NAK\nil mittente prima di rimettersi in attesa di inviare un nuovo segmento attende uno di questi due segnali\nil destinatario invia ACK o NAK se i dati ricevuti sono ok oppure corrotti\nproblematiche:\n\ni segnali possono essere anche essi corrotti\nnel dubbio viene inviato ma presenterebbe delle duplicazioni\n\n\n\n\n2.1\n\nintroduce numero di sequenza per evitare duplicazioni\nil numero di sequenza viene usato tra mittente e destinatario per capire se sono sullo stesso numero di sequenza\nil mittente invia un pacchetto con un numero di sequenza 0 o 1, si aspetta un ACK con lo stesso numero dal destinatario se √® differente allora ci sono problematiche\nsono ancora usati ACK e NAK\n\n\n2.2\n\nrimuove i NAK, se invio un ACK non corrispondente √® come se sto inviando un NAK\n\n\n3.0\n\naggiunge RTT, ovvero una soglia di tempo per attendere un segnale necessario per effettuare una ritrasmissione\nusata per gestire perdite e non solo errori\n\n\n\n\n\ntrasferimento dati con stop and wait  vs pipeline\n\nstop and wait viene inviato un segmento e si attende un riscontro per esso\npipeline, vengono inviati in sequenza i segmenti e poi vengono accumulati su una pipe i rispettivi ACK, nel caso del mittente, per il destinatario i veri e propri segmenti\n\n\n\n\nGBN\n\nprotocollo teorico che prevede utilizzo di finestre\n\nper tenere conto dei segmenti confermati, in attesa di conferma, ancora da inviare\nse in una sequenza di N segmenti un segmento non viene confermato, il mittente dovr√†, dopo il timeout rinviare tutti da quel segmento in poi\n\n\n\n\n\n\ncon ripetizione selettiva\n\nmigliora la GBN\nogni segmento √® una istanza a se numerata, non devo reinviare tutta la sequenza ma solo il singolo interessato\n\n\n\n\nTCP\n\n\nintroduzione\n\nprotocollo di trasporto affidabile basato su connessione tra gli host e correzione di errori\n\n\n\ndettagli sul segmento MSS e MTU\n\nMSS rappresenta la massima dimensione di un segmento, escludendo l‚Äôintestazione\nMTU rappresenta la massima dimensione di un datagramma del protocollo IP che racchiude anche il segmento\n\n\n\n\nsegmento PDU del TCP\n\nsi divide in\n\nintestazione\n\nnumeri di porta origine e destinazione checksum, ack, numero di sequenza, receive window\n\n\ncorpo, i dati effettivi\n\n\n\n\n\n\nnumero di sequenza e ACK\n\nogni byte √® numerato sequenzialmente\nil campo numero di sequenza include il primo byte di sequenza\nil campo ACK include l‚Äôultimo byte a essere confermato\n\n\n\nRTT Round Trip Time\n\nsoglia di tempo che deve attendere un mittente prima di effettuare un reinvio se non si ricevono segnali\nviene stimato calcolando una media degli ACK ricevuti\n\n\n\nControllo e gestione del flusso\n\nTCP permette al mittente di gestire il flusso di dati che pu√≤ ricevere il buffer  del destinatario, per evitare saturazioni del buffer\nreceive window\n\ncampo dell‚Äôintestazione TCP per definire quanti byte pu√≤ ancora ricevere il buffer del destinatario\n\n\n\n\n\n\nTCP con handshake\n\nprocedura che instaura un collegamento sicuro tra due host\nmalgrado aumenti l‚Äôoverhead dovuto a questa procedura diminuisce notevolmente la perdita di dati attraverso segnali di ACK scambiati tra le due parti\n2 vie\n\nil mittente invia una richiesta di collegamento al destinatario\nil destinatario manda una conferma con un segnale di ACK\nla connessione √® stabilita e i due possono comunicare fino alla chiusura\nproblemi: perdita del segnale di ACK o di richiesta\n\n\n3 vie\n\ncome quello a 2 vie solo che adesso anche il mittente deve inviare a sua volta un ACK dell‚ÄôACK del destinatario e per iniziare la sincronizzazione viene usato un Synbit che deve essere uguale tra i due\n\nquesti ACK sono identificati da\nACKbit\n\nsemplice ACK 1=NAK       0=ACK\n\n\nACKnum\n\nindica fino a quale sequenza di byte ha ricevuto i dati\n\n\n\n\nBit di reset\n\nin caso di errori √® possibile terminare repentinamente la connessione stabilita\n\n\nChiusura connessione TCP\n\nViene inviato un Finbit=1\nil destinatario invier√† un Finbit=1+ACK\nil mittente invia un ACK e basta\n\n\n\n\n\n\n\n\n\nattacco Syn flood\n\nvengono inviate molteplici richieste di handshake per far crashare un server\nsi risolve con i cookie\n\nil client dovr√† rispondere con il cookie assegnato altrimenti non alloca memoria\n\n\n\n\n\nCongestione\n\n\ndefinizione\n\nfenomeno che avviene quando il carico da inviare supera la capacit√† di risorse che supporta la rete\n\n\n\nscenario 1\n\nbreve descrizione\n\nrouter con buffer illimitato, ogni coppia mittente/destinatario ha il suo collegamento al router\nse aumenta il troughput pi√π di R/2 si presentano rallentamenti\n\n\n\n\n\n\nscenario 2\n\nbreve descrizione\n\nbuffer del router limitato\nritrasmissioni presenti al livello di trasporto non di applicazione\nsi divide in 3 sotto-scenari\n\ncaso 1 ideale, buffer libero\n\ni pacchetti vengono inviati regolarmente\nil mittente sa quando il buffer √® pieno\n\n\ncaso 2, buffer pieno e conoscenza meno perfetta della situazione\n\nvengono scartati pacchetti e ritrasmissioni\n\n\ncaso 3, timeout prematuro\n\ntimeout non impostato correttamente\nduplicazioni\n\n\n\n\n\n\n\n\n\n\n\nscenario 3\n\nbreve descrizione\n\n4 host\npercorsi multi hop\ntimeout e ritrasmissioni\n\n\nproblematiche\n\nhost adiacenti a router prendono tutta la banda possibile\n\n\n\n\n\n\ncontrollo della congestione 2 approcci\n\nend-to-end\n\nil controllo della congestione √® demandato solo al mittente, che effettuer√† dei calcoli\n\ndella finestra di ricezione prende solo ed esclusivamente il cwnd, ovvero i byte che devono ancora essere ACK e anche quelli non inviati\ncalcolando poi cwnd/RTT riesce a definire circa il tasso di invio\nnon preciso\n\n\n\n\nassistito dalla rete\n\nil router invia dei pacchetti informativi detti choke al destinatario, lui li rimanda il mittente insieme a eventuali ACK\ninformano del loro stato di congestione\nusato in TCP ECN\n\n\n\n\n\ngestione del tasso di invio.\n\nconcetto di AIMD\n\nAdditive increase Multiplicative Decrease\nquesto concetto regola dinamicamente gli MSS\nMaximum Segment Size, ovvero regola quanti segmenti pu√≤ inviare prima di attendere una ricezione\ninizia da 1 aumenta additivamente ad ogni RTT e appena avviene un fault gli cwnd vengono dimezzati\n\n\n\n\n\n\nfasi di gestione del tasso di invio\n\nslow start\n\nsi inizia piano e poi ad ogni RTT cwnd si raddoppia\n\n\ncongestion avoidance\n\nviene usata una variabilesstresh che definisce un limite per cui si smette di crescere esponenzialmente(slow start) ma linearmente\n\n\ngestione errori\n\nse non si ricevono ACK(timeout)\n\nentra in timeout e dimezza sstresh e cwnd=1\n\n\nse riceve 1 o 2 ACK duplicati\n\nprova semplicemente a ritrasmetterli\n\n\nse invece ne riceve 3 duplicati\n\naumenta notevolmente cwnd per aumentare il tasso di trasmissione\npoi entra in fast recovery\n\n\n\n\nfast recovery\n\nquando si verifica una perdita, triplo ACK duplicato si entra in fast recovery\nquesta fase dura 1RTT per attendere l‚Äôack del pacchetto perso\nquindi si entra in congestion avoidance partendo da\n\ncwnd=cwnd \\ del \\ blocco \\ precedente+3 \\ tutto \\ fratto \\ 2\n\n\n\n\n\n\n\nevoluzioni TCP\n\nTCP Reno\n\nimplementazione di TCP che utilizza un algoritmo con fast recovery e dimezzamento di 1 MSS quando si ha un ACK\n\n\nTCP Cubic\n\nutilizza W_{max}, dimensione della finestra nel momento in cui avviene una congestione\n\nsuccessivamente a una congestione viene ogni volta dimezzata la velocit√† di trasmissione  e viene settata una variabile K nei pressi di W_{max}\nprima di K si cresce velocemente in un valore compreso tra K e W_{max} meno velocemente\nogni volta viene causata la congestione\n\n\n\n\nTCP Vegas\n\nevoluzione di CUBIC\ncalcola una stima e vede ogni volta se viene rispettata effettivamente\n\n\nECN\n\npresente in alcune implementazioni di TCP\nvengono usate due variabili\n\nECN\n\nil router le invia per segnalare congestioni\n\n10 non c‚Äô√®\n11 c‚Äô√®\n\n\n\n\nECE\n\nle invia il destinatario al mittente\n1 se c‚Äô√®\n0 se non c‚Äô√®\n\n\n\n\n\n\n\n\n\n\nfairness di TCP e UDP\n\nTCP √® fair perch√© il troughput √® dato da R/K\n\novvero il numero la capacit√† del collegamento fratto il numero delle connessioni\n\n\nTCP paralleli\n\nse dallo stesso host faccio pi√π socket con pi√π richieste TCP non diventa pi√π fair\n\n\nUDP non √® fair perch√© non pu√≤ controllare il tasso di trasmissione\n\n\n\nEvoluzioni protocolli di trasporto\n\nQUIC\n\nusa UDP e al livello di applicazione implementa le varie sicurezze e migliorie\ntipo TCP ha HOL(Head Of Line blocking) QUIC no\nessendo pi√π recente √® meno supportato\n\n\n\n\n"},"UNI/ANNO-2/RETI/3.LIVELLO-DI-RETE":{"slug":"UNI/ANNO-2/RETI/3.LIVELLO-DI-RETE","filePath":"UNI/ANNO 2/RETI/3.LIVELLO DI RETE.md","title":"3.LIVELLO DI RETE","links":[],"tags":[],"content":"\n\n                  \n                  macro argomenti lista \n                  \n                \n\nLivello di rete\n\ndefinizione\n\nProtocollo IP\n\nbest effort\ncosa cerca di fare\n\nriduzione perdita datagrammi\nconsegna con basso ritardo\nconsegna in ordine\n\n\n\n\nil livello di rete si divide in 2 principali funzioni\n\nInoltro\n\nbasato su destinazione\n\nIP classful addressing\nNotazione CIDR\n\nRoute Aggregation\n\n\nTCAM+priority encoder\ncome ottiene IP un ISP\nICANN\n\n\ngeneralizzato\n\ntabella di flusso\nmatch+action+counter+priority\n\n\n\n\ninstradamento\n\n\nFrammentazione datagrammi\n\nPMTUD\n\n\nla rete inoltre si pu√≤ dividere in 2 principali piani\n\npiano di controllo\npiano dati\n\n\nSDN\n\ncosa sono\ndove sono posizionate\nsouthbound northbound\nOpenflow\n\n\nRouter\n\ntabella di inoltro\ntabella di routing\nsottorete\nporta di ingresso\nporta di uscita\ncommutazione\n\ncentralizzata\ndecentralizzata\n3 tipologie\n\nMemoria\nbus\nCrossbar switch\nmultistage\n\n\n\n\ngestione buffer dei router\n\n3 politiche\n\ntail drop\npriorit√†\nmarcatura\n\n\n\n\n\n\nDHCP\n\nDiscovery\nOffer\nRequest\nAck\n\n\nNAT\n\ncome funziona\n\n\nIpv6\n\ntunneling\n\n\nAS\n\nintra-AS\n\nbackbone\nnodi interni\n\n\ninter-AS\nOSPF\nBGP\n\nI-BGP\nE-BGP\nrotta BGP\n\nAS-PATH\nNext-HOP\n\n\nsessione BGP\n\n\n\n\nICMP\n\nmessaggi ICMP\ntraceroute\n\n\nAlgoritmi di instradamento\n\nGlobali\nNon globali\ncentralizzati\ndecentralizzati\nstatici\ndinamici\nDijkstra\nVector Distance\n\n\n\n\n\n\n\nLIVELLO DI RETE\n\n\nIntroduzione*\n\nil livello di rete si occupa di trasportare datagrammi da un host mittente a un host destinatario che possono trovarsi anche su reti differenti\n\n\n\nDescrizione protocollo IP*\n\nprotocollo fondamentale del livello di rete, si occupa del vero e proprio trasferimento dei datagrammi attraverso una rete di dispositivi\n√à BEST EFFORT, non da garanzie dei servizi che offre ma fa del suo meglio\n\nservizi che vuole offrire la rete:\n\nservizi per il singolo datagramma\n\nconsegna garantita\nconsegna con ritardo ridotto\n\n\nservizi per datagrammi multipli(flussi)\n\nconsegna in ordine\nbanda di trasferimento minima garantita\nframmenti che arrivano a intervalli regolari\n\n\n\n\n\n\nDATAGRAMMA IP\n\nintestazione con indirizzi IP sorgente e destinazione, lunghezza totale del datagramma versione e TTL, protocollo usato al livello superiore, checksum\ncorpo dati\n\n\n\n\n\n\nFRAMMENTAZIONE DATAGRAMMI\n\nse un datagramma supera la MTU(Maximum Transmission Unit)\nviene frammentato con stesso identificatore\n\nflag che indica se √® l‚Äôultimo del suo blocco,\noffset per indicare dove si inserisce nel datagramma totale\n\n\nseguendo questi campi viene riassemblato nel destinatario finale\nPMTUD (Path Maximum Transmission Unit Discovery)\n\nobiettivo: scoprire quanto deve essere grande al massimo la MTU in 2 modi\n\n\n\nICMP invia un datagramma con obbligo di non frammentazione, se riceve una segnalazione dal router che da un obbligo di frammentazione allora bisogna modificare la MTU con quella suggerita da parte del router\n\n\n\n\nMitigazione durante l‚Äôhandshake, insomma viene accordato prima\n\n\n\n\n\n\n\n\n\nfunzioni chiave del livello di rete\n\ninoltro\n\nsi occupa dell‚Äôeffettivo invio dei datagrammi\nsi divide in:\n\nbasato sulla destinazione\n\nusa indirizzo IP e la tabella di inoltro\n\n\ngeneralizzato\n\nguarda altri campi come il protocollo e il servizio\nusato su reti pi√π complesse\ntipo Match+Action\n\n\n\n\n\n\ninstradamento\n\nprocesso che calcola i percorsi nella rete serve per effettuare un inoltro dei datagrammi coerente con l‚Äôinfrastruttura di rete\n\n\n\n\n\nclassful addressing\n\nutilizzo di classi prima dell‚Äôinvenzione di CIDR per definire indirizzi IP\n\n\n\ncome trovare Ip nell‚Äôinoltro basato sulla destinazione\n\ni router hanno un sacco di IP sulla tabella di inoltro\n\ncome capire l‚ÄôIP di input a quale appartiene?\n\nCIDR standard di formattazione che divide IP in 2 parti indirizzo subnet e indirizzo host\n\nfunziona tipo indirizzo/16, indica che i primi 16 bit sono della subnet e i successivi 32-16 sono dell‚Äôhost\n\n\npotremmo avere pi√π IP simili in termini di bit, viene effettuata una ricerca della corrispondenza sulla tabella fino ai bit meno significativi, l‚Äôindirizzo con pi√π informazioni viene selezionato\n\n\n\n\nTCAM+ priority encoder\n\nusata per rappresentare le tabelle di inoltro\nTCAM √® una memoria speciale che permette di trovare la riga con l‚ÄôIP adeguato in un tempo ridotto\nquando ci sono pi√π indirizzi IP simili, entra in gioco il priority encoder che sceglier√† quello con la priorit√† pi√π alta\n\n\n\n\n\n\ndivisione in 2 del livello di rete\n\npiano dei dati\n\nfunzione locale dei router che decide come inoltrare un datagramma\n\n\npiano di controllo\n\nsi occupa della logica globale della rete\n\n\n\n\n\n\nSDN(Software-Defined Networking)*\n\narchitettura dove il piano di controllo √® centralizzato in un unico server per tutta la rete\n\nrouter esecutori il controller calcola lui le tabelle di inoltro\n\n\nposizionamento di SDN\n\nabbiamo il piano dei dati con i vari router e le AS\npoi a un livello intermedio abbiamo le SDN con il controller\nancora sopra abbiamo il piano di controllo con le varie applicazioni di gestione della rete\n\n\n\n\n\n\ncome √® fatto il controller delle SDN\n\n√® diviso in\n\nLivello di interfaccia con le applicazioni\n\nLivello che si collega alle app del piano di controllo, attraverso varie API north-bound fornisce a loro dell informazioni\n\n\nGestione dello stato di rete\n\nDatabase che contiene le varie info sulla rete, router, link, host e switch\n\n\nComunicazione con i dispositivi che controlla\n\nAttraverso protocolli come Open Flow comunica con i vari dispositivi della rete come switch ecc‚Ä¶\nquesto insieme di protocolli √® detto Southbound API\n\n\n\n\n\n\n\n\n\n\n\nRouter*\n\ndispositivi di rete che hanno il compito di instradare datagrammi\nse non c‚Äô√® la SDN si divide in\n\npiano di controllo\n\nvia software\n\n\npiano dati\n\nhardware\n\n\nstruttura di commutazione\n\ncomponente del router che permette di instradare i datagrammi da una porta di ingresso a una di uscita\n\n\nporte di ingresso\n\ninterfacce destinate all‚Äôingresso dei datagrammi ai router\nogni porta deve ricevere e processare un datagramma in modo veloce\n√® divisa in step\n\nterminazione di linea\n\nriceve i bit grezzi e li passa al successivo step\n\n\nelaborazione al livello di collegamento\n\ninterpreta il frame e decapsula il datagramma\n\n\nricerca e inoltro\n\nguarda il datagramma e capisce a quale struttura di commutazione inoltrarlo\n\n\n\n\n\n\nporte di uscita\n\nprende input da un commutatore e poi esegue gli step inversi delle porte di ingresso\n\n\naccodamento in entrata e in uscita\n\nin entrata potrei avere problemi di HOL\nin uscita potrei avere problemi di buffer troppo pieno e quindi scarti\n\n\n\n\n\n\n\n\nCommutazione*\n\n\ncomponente del router che permette di instradare i datagrammi da una porta di ingresso a una di uscita\n\ncentralizzata\n\ntutto passa per una cpu unica del router\n\n\ndecentralizzata\n\nogni porta del router ha una sua piccola cpu che elabora a quale porta di uscita mandare il pacchetto\n\n\n3 strutture\n\n1 memoria\n\ntutte le porte hanno una memoria condivisa\ni datagrammi vengono copiati dentro essa e le porte di uscita copiano il tutto\nlento\n\n\n2 bus\n\nbus tra le porte di entrata e uscita\n\nproblemi di concorrenza del bus\n\n\n\n\n3 interconnessione\n\nparallelismo\nsi divide in\n\ncrossbar\n\nmatrice di bus\n\n\nmultistage\n\npiccoli switch tra le due porte che indirizzano il tutto\n\n\n\n\n\n\n\n\n\n\n\n\nGestione del buffer*\n\ntroppo buffering causa aumenti di RTT facendo allocare troppi pacchetti nella rete\n3 politiche di scarto\n\ntail drop\n\nviene scartato l‚Äôultimo che arriva\n\n\npriorit√†\n\ni pacchetti hanno una priorit√†\n\n\nmarcatura\n\nprima di scartare invia dei segnali come ECN per avvisare che il buffer √® pieno\n\n\n\n\n3 algoritmi di scheduling per decidere quali mandare prima\n\nFCFS first come first served\n\nil primo che arriva √® il primo ad uscire\n\n\ncon priorit√†\n\nogni pacchetto viene classificato con una sua priorit√† e viene definito in quale ordine inviarli\nstarvation: una delle code potrebbe non essere mai selezionata\n\n\nRR Round Robin\n\nsempre diviso in classi ma si invia un po di tutto\n\n\nWFQ Weighted Fair Queuing\n\nogni priorit√† ha un suo spazio di banda per mantenere le cose fair\n\n\n\n\n\n\n\n\nIndirizzi IP e gestioni varie\n\n\nSottorete\n\ndefinizione\n\ninsieme di dispositivi che possono comunicare tra loro senza dover passare per un router ma uno switch si\n\n\n\n\n\nDHCP(Dynamic Host Configuration Protocol)\n\ndefinizione\n\n√® una alternativa al sistema manuale dove bisognava scrivere gli indirizzi IP in fase di inizializzazione della macchina\nin DHCP √® presente un server che assegna ai nuovi host in ingresso un IP dinamico che pu√≤ variare nel tempo\n\nquesto server si trova di solito interno ai router\n\n\n\n\n4 step del DHCP\n\n\n\nDiscover\n\n\nl‚Äôhost che entra nel server manda un broadcast per trovare se ci sono DHCP disponibili\n\n\n\n\nOffer\n\n\nil DHCP offre un indirizzo IP all‚Äôhost\n\n\n\n\nRequest\n\n\nl‚Äôhost conferma l‚ÄôIP offerto al DHCP\n\n\n\n\nAck\n\n\nil DHCP invia un Ack di assegnazione dell‚ÄôIP\n\n\n\n\nnon serve solo per IP\n\nsuggerisce quale Server DNS usare\nRouter First-Hop da usare\n\novvero router gateway, colui che si collega ad altre reti non interne facendo da tramite\n\n\n\n\n\n\n\n\nCome si ottengono IP pubblici/privati da condividere con la tua rete\n\nISP ha un grande blocco di indirizzi che assegner√† a sua volta ad ogni rete che ne richiede\n\nun ISP ha magari indirizzoIP/x\n\nquesto significa che ho i primi x bit fissi e gli altri posso usarli per definire IP di rete da condividere con i richiedenti\nse x=20 posso dare 2^{32-20} indirizzi IP\n\n\n\n\nRoute aggregation\n\n√® una tecnica di aggregazione di indirizzi IP per alleggerire la tabella di instradamento condivisa tra i vari ISP/grandi router\nognuno scrive sulla tabella solo il blocco di indirizzi senza precisarli tutti\nse un indirizzo IP specifico passa a un‚Äôaltra rete quella determinata rete deve fornire pi√π dettagli di quell‚Äôindirizzo IP\n\nricordiamo che viene data la precedenza alle corrispondenze migliori\n\n\n\n\n\n\n\nICANN\n\norganizzazione centrale che gestisce gli indirizzi IP al livello mondiale\n\nfornisce questi indirizzi IP a 5 grandi fornitori RR\n\nquesti 5 RR forniscono poi i vari blocchi di indirizzi agli ISP\n\n\n\n\n\n\n\nNAT(Network Address Translation)\n\ndefinizione\n\ngli indirizzi IPv4 sono limitati\n√® una tecnica che riduce gli indirizzi IPv4\nper ovviare a questo problema esistono ad esempio dei router NAT che consentono di utilizzare solo un indirizzo IP pubblico per tutta la rete che gestiscono\ni dispositivi della rete avranno un indirizzo IP privato\nil router NAT dovr√† ogni volta cambiare le varie intestazioni dei datagrammi mettendo l‚ÄôIP pubblico, i dispositivi esterni alla rete vedranno solo il router NAT come dispositivo nella rete e poi dovr√† essere lui a condividere i datagrammi corretti nella rete interna al dispositivo corretto\nper ricordarsi a chi deve condividere quel datagramma utilizza una tabella NAT con salvate le varie occorrenze\n\n\n\n\n\n\nIPv6\n\ndescrizione\n\nNasce per aumentare i possibili IP\n√® a 128 bit non a 32\n\n\ntunneling\n\nnon √® retrocompatibile ma ci sono router misti che usano entrambi gli IP\n\nlavorano su reti miste con router Dual Stack\nho un datagramma IPv6 che deve passare in una rete IPv4, per farlo incapsulo IPv6 in IPv4 e poi de capsulo il tutto\n\n\n\n\ncosa avviene nella frammentazione\n\nframmentazione non presente, scopro la MTU del datagramma IPv6 con PMTUD\n\n\n\n\n\n\nTabella dei flussi o di inoltro\n\nper capire dove inoltrare i vari datagrammi esiste questa tabella\nper gli inoltri di tipo generalizzato avevamo detto che non era sufficiente un indirizzo IP e basta\n\nvengono usati dei dati interni al datagramma ricercati con la funzione Match\nche poi forniscono le informazioni per una determinata Action che deve fare il router\n\ninoltro, scarto, modifica e se siamo in un SDN pu√≤ essere inviato al controller\n\n\nda qui nasce Match+ Action che √® la vera e propria tabella\nse due Match hanno due action diverse viene data una priorit√† alle Action  vince quella con priorit√† maggiore\n\n\n\n\n\n\nOpen flow\n\nconcetto\n\nrappresenta uno standard che caratterizza la struttura delle reti a SDN, dove il piano di controllo √® demandato a un controller\nOpenFlow ha una tabella che contiene\n\nMatch, √® diviso in livelli perch√© l‚Äôinformazione potrebbe stare su quello di collegamento, di rete, di trasporto\nAction azioni che si possono fare come blocchi\nPriorit√†, per Match con pi√π Action\nContatore dei byte o dei pacchetti, che tiene conto di quelli che hanno usato una certa regola\n\n\n\n\nprotocollo\n\nprotocollo utilizzato dai dispositivi OpenFlow come router ecc‚Ä¶ che permette di comunicare con il server controller della SDN\n\n\n\n\n\n\nLoad Balancing\n\ncaratteristica dell‚Äôinoltro generalizzato\nconsente di spalmare il carico su pi√π porte per instradare pi√π pacchetti che vanno a uno stesso indirizzo IP\n\n\n\nMiddleBox\n\ndispositivi che forniscono servizi all‚Äôinterno della rete e che non sono router\ncome i firewall o i NAT o i DHCP\n\n\n\nAlgoritmi di instradamento\n\ndefinizione\n\nAlgoritmi che si occupano di riempire la tabella di instradamento, cercando un percorso migliore con la distanza minore possibile tra i vari dispositivi nella rete\n\n\ntipologie\n\nGlobale\n\nha una visione ampia della rete\n\n\nNon globale\n\nnon ha bisogno di avere una visione ampia\n\n\nCentralizzato\n\ncalcolo dei percorsi centralizzato\nconoscenza globale della rete\n\n\nDecentralizzati (link-state)\n\nogni dispositivo deve calcolare i percorsi\ninizialmente il router conosce solo i costi dei dispositivi adiacenti\n\n\n\n\ninoltre anche\n\nstatici\n\ncambiano raramente\nrichiedono aggiornamenti manuali\n\n\ndinamici\n\nsi aggiornano automaticamente al variare dei costi dei vari collegamenti tra nodi\n\n\n\n\nDijkstra\n\nalgoritmo Globale link-state che consente di trovare il percorso migliore ha un funzionamento iterativo\n\n\nVector Distance\n\n√à di tipo decentralizzato\nSi basa sull‚Äôequazione di Bellman-Ford e funziona cos√¨: ogni router sa quanto costa raggiungere le reti vicine, e scambia informazioni con i router vicini per scoprire nuovi percorsi. Nel tempo, ogni router costruisce una tabella che indica: la distanza verso ogni rete e da quale router passare per raggiungerla nel modo pi√π economico.\ncambio dei costi\nproblema di conteggio infinito\n\ninversione avvelenata\n\n\n\n\n\nAS (Autonomous System)\n\ndefinizione\n\ninsieme di router scalabili interconnessi tra loro che si trovano nella stessa ISP o amministrazione di rete\nstrategia per gestire in modo scalabile l‚Äôinstradamento\n\n\ndifferenza tra\n\nintra-AS\n\ntutti i router che si trovano nella stessa AS e condividono gli stessi protocolli\n\n\ninter-AS\n\ninsieme dove deve essere effettuato un routing tra AS differenti, attraverso dei router gateway che appunto li collegano tra di loro\n\n\n\n\n\n\n\nprotocolli usati nell‚Äôintra-AS\n\nRIP\nEIGRP\nOSPF\n\ndefinizione\n\ndi tipo Link-State, i router si scambiano tra loro le varie informazioni di instradamento in broadcast(flooding) e aggiornano cos√¨ la mappa di instradamento\nil messaggio usa protocollo TCP e algoritmi di Dijkstra per effettuare i calcoli\n\n\n√® divisa in 2 livelli ma riguarda comunque tutta la intra-AS\n\nArea Locale\n\nsottoinsieme della rete senza router gateway\n\n\nBackbone\n\nDorsale che collega tutti i dispositivi della stessa area intra-AS\n\n\n\n\nestensioni associate\n\nper reti senza SDN viene usato OSPF, permettendo di scambiare informazioni utili per effettuare instradamenti corretti senza uso di SDN\nMPLS-TE protocollo che consente di evitare congestione\n\n\n\n\n\n\n\n\nBGP protocollo usato nella inter-AS\n\ndefinizione\n\npermette di far comunicare tra loro i vari router gateway si divide in due modalit√†\n\n\ni-BGP\n\nmodalit√† che consente di inviare informazioni alla intra-AS riguardo le cose che vengono inviate dalla inter-AS\n\n\ne-BGP\n\nmodalit√† che consente lo scambio di informazioni tra AS esterne\nfunziona attraverso annunci\n\n\nsessione BGP\n\n√® una connessione TCP semi permanente tra i router gateway detti peers\n\n\nmessaggi BGP\n\nservono per stabilire e mantenere la connessione TCP tra peer\n\nkeepalive\n\nserve per mantenere la connessione attiva\n\n\nopen\n\navvia connessione tra due peer\n\n\nupdate\n\nannuncia nuove rotte o ritira vecchie rotte\n\n\nnotification\n\nsegnalazione di errori\n\n\n\n\n\n\nconcetto di rotta BGP\n\ninsieme di informazioni inviate tra AS che indicano il percorso da seguire\n\nprefisso\n\nindica la rete di destinazione con il vero e proprio indirizzo\n\n\nattributi\n\ninformazioni sul percorso per evitare cicli oppure trovare facilmente il primo router di salto\n\n\nAS-PATH\n\nindica il vero e proprio percorso, la successione di AS\n\n\nNext-Hop\n\nrappresenta il router gateway\n\n\n\n\n\n\nEsempio con o senza percorsi multipli\n\nsolo i router gateway possono modificare router di next hop per indicare ‚Äúse volete inviare ad altre AS passate per me‚Äù\nun router che lavora in inter-AS annuncia anche l‚ÄôAS-PATH ovvero il percorso che deve seguire per raggiungere quella determinata destinazione\nsu percorsi multipli √® simile solo che vengono seguite delle policy\n\n\nCriteri usati da router BGP per riempire tabella di instradamento\n\n1.Next Hop modificato\n\ni router gateway modificano il Next-Hop su loro stessi cos√¨ i dispositivi nella intra-AS devono solo raggiungerlo seguendo un percorso nella inter-AS mediante OSPF\n\n\n2.Next Hop non modificato\n\nil router gateway non modifica il Next-Hop e lascia quello da lui raggiungibile di un‚Äôaltra AS, i dispositivi interni devono capire che devono passare per il router gateway\n\n\n3.Instradamento a patata bollente\n\nse ci sono pi√π percorsi simili prende quello meno costoso mandando il pacchetto nella inter-AS meno costosa per far passare il traffico il pi√π velocemente possibile\n\n\n4.Forzare percorsi tramite annunci\n\nannuncio=azione di inviare un messaggio update tramite BGP\nper non intasare il traffico della sessione BGP vengono inviati solo gli annunci pi√π utili\nse ad esempio so che un AS pu√≤ raggiungerne un altro senza passare per un determinato AS, esso sceglie di non annunciare il proprio percorso\n\n\n\n\n\nIP ANYCAST\n\ndefinizione\n\npi√π server con stesso indirizzo IP pubblico, il client avr√† scambi con quello pi√π vicino\noffrono stessi contenuti o servizi\n\n\n\n\nIngegneria del traffico\n\ndefinizione\n\ninsieme di tecniche che consentono di modulare e ottimizzare il traffico della rete\n\n\n\nConcetto di IBN(Intent-Based-Networking)\n\ndefinizione\n\nsistema dichiarativo che funziona attraverso intenti per modificare la struttura della rete in modo automatizzato\nes: voglio ridurre la latenza tra due router, spiego l‚Äôintento e essi verranno configurati in tal maniera\ncolui che effettua queste modifiche √® il controller SDN\n\n\n\nODL e ONOS\n\ndefinizioni\n\ndue tipi di controller\nODL\n\nusa API per comunicare con applicazioni\n\n\nONOS\n\ncontroller che usa nel pratico il concetto IBN con gli intenti\n\n\n\n\n\nICMP(Internet Control Message Protocol)\n\n\ncosa √®\n\nprotocollo incapsulato nel protocollo IP consente di scambiare messaggi utili per la gestione tra host e router\n\n\n\nmessaggio ICMP\n\ncomposto da\n\ntipo\ncodice\nchecksum\naltri dati\n\n\n\n\n\ntipi di messaggio\n\n1.Echo Request(0) o Reply\n\npermettono di capire se un host √® raggiungibile e con quale distanza\n\n\n2.Destination Unreachable(3)\n\nutilizzato per segnalare Host non raggiungibili\n\n\n3.Source Quench\n\npermetteva di segnalare congestioni ora deprecato\n\n\n4.TTL expired(8)\n\nserve per quando imposti un determinato limite di hop utilizzando un contatore TTL che decrementa ad ogni hop\nse arriva a 0 invia questo segnale\n\n\n\n\n\n\nTraceroute\n\nstrumento di diagnostica per capire quanti hop deve effettuare un pacchetto sonda per raggiungere un determinato punto di destinazione\ndi volta in volta si incrementano i TTL\n\n\n\n\nnuova versione ICMPv6\n\nadattato ai nuovi router che non fanno troppa frammentazione\n\n\n\nGestione delle reti\n\ndescrizione e componenti\n\nper gestire una rete adeguatamente si ha bisogno di\n\nserver di gestione\n\nserver che raccoglie dati e invia comandi per configurare i dispositivi della rete\n\n\ndispositivi di rete da gestire\n\nrouter switch ecc‚Ä¶\n\n\ndati\n\ndati utilizzati per gestire la rete come statistiche varie\n\n\nagente di gestione\n\nSoftware di gestione della rete\n\n\nprotocollo di gestione di rete\n\nprotocolli utilizzati per comunicare ai dispositivi i vari cambiamenti\n\n\n\n\n\n\nmetodi per gestire una rete\n\nCLI\n\nlinea di comando manuale\nmetodo diretto ma non scalabile anche se prevede uso di eventuali script automatizzati\n\n\nSNMP/MIB\n\ninterfaccia server che usa come protocollo di comunicazione per i dispositivi SNMP\ni dati raccolti sono organizzati in MIB\nnon propriamente automatizzato\n\n\nNETCONF/YANG\n\nYANG √® un linguaggio astratto che consente di configurare delle reti\nla configurazione e la modifica di questi YANG per poi cambiare i dispositivi remoti sono mediante un protocollo NETCONF\nconsente commit atomici\nideale per reti complesse, dinamiche e centralizzate\n\n\n\n\n"},"UNI/ANNO-2/RETI/4.LIVELLO-DI-COLLEGAMENTO":{"slug":"UNI/ANNO-2/RETI/4.LIVELLO-DI-COLLEGAMENTO","filePath":"UNI/ANNO 2/RETI/4.LIVELLO DI COLLEGAMENTO.md","title":"4.LIVELLO DI COLLEGAMENTO","links":[],"tags":[],"content":"\n\n                  \n                  riassunto \n                  \n                \n\n\nLivello di collegamento\nDispositivi\n\nNIC\nincapsulamento decapsulamento\n\n\nservizi\n\nframing\ncontrollo del flusso\naccesso al collegamento\n\naccessi multipli MAC\n\n\nidentificare i dispositivi MAC\n\nIEE\n\n\nrilevazione e correzione di errori\n\nritrasmissioni\nnon\n\n\n\n\ntipi di collegamento\n\nhalf duplex\nfull duplex\n\n\ncollegamento\n\nend-to-end\nbroadcast\n\n\nprotocolli di gestione dell‚Äôaccesso multiplo\n\nsuddivisione di canale\n\nTDMA\nFDMA\n\n\naccesso multiplo\n\nSLOTTED ALOHA\nUNSLOTTED ALOHA\nCSMA\nCSMA/CD\n\n\na turni presi\n\nPOLLING\nTOKEN PASSING\n\n\n\n\nSwitch\n\ntabella di commutazione\n\n\nEthernet\n\nframe\ndominio di collisione\n\n\nLAN\nMAC\n\nNIC\n\n\nProtocollo ARP\n\nARP reply\nARP request\n\n\nVLAN\n\nVLAN a switch singolo\nVLAN a switch multipli\nEVPN\nID VLAN 802.1Q\n\n\nReti Wireless\n\ngestione frequenza\n2 modalit√†\n\ncon infrastruttura\nsenza infrastruttura\n\n\nattenuazione del segnale\nriflessione del segnale\n\ntempo di coerenza\n\n\ninterferenza dei segnali\n\nSNR\nBER\n\n\nterminali nascosti\n\n\nCDMA\nWi-Fi standard 802.11\n\nBSS\nGestione frequenze\nAccesso\n\nmodalit√† passiva\nattiva\n\n\nCSMA/CA\n\nDIFS\nSIFS\n\n\nprenotazione\n\nRTS\nCTS\n\n\n\n\nBluetooth\n\nPiconet PAN\nMaster\nBootstrapping\n\nneighbor discovery\npaging\n\n\n\n\nReti 4G/5G\n\nUE\nBase Station\nHSS\nMME\nP-GW\nS-GW\nmobilit√† handoff\n\nrouting diretto\nindiretto\n\n\n\n\nReti LTE\n\npiano di controllo\npiano di dati\ntunneling\n\n\nhome network\nvisited network\n\n\n\nLIVELLO DI COLLEGAMENTO\n\nintroduzione\n\nil livello di collegamento si occupa di trasferire i datagrammi da un nodo a quello fisicamente adiacente lungo il percorso\n\nha una visione pi√π dettagliata su dispositivi come switch\n\n\nil livello di collegamento si serve di frame, con al loro interno i datagrammi incapsulati\n\n\nservizi del livello di collegamento\n\nFraming\n\nprocesso di incapsulamento dei datagrammi che provengono dal livello di rete aggiungendo intestazione e trailer che servono a delimitare la singola unit√†\n\n\nAccesso al collegamento\n\neffettuare un accesso al mezzo di trasmissione condiviso tra dispositivi si usano protocolli MAC(Medium Access Control)\nper identificare i dispositivi che condividono questo stesso mezzo di trasmissione si usano gli indirizzi MAC che identificano univocamente la scheda di rete del dispositivo, √® statico a differenza degli IP che lavorano sul livello di rete\n\n\nConsegna affidabile tra nodi adiacenti\n\nservizi che rilevano errori, usati soprattutto in reti wireless dove ci sono errori pi√π frequenti\n\n\nControllo del flusso\n\nRegola la velocit√† di trasmissione del singolo collegamento\n\n\nRilevazione degli errori e correzione\n\nOgni protocollo di collegamento ha controllo sui vari errori e possono essere risolti con o senza ritrasmissioni\n\nARQ(Automatic Repeat reQuest) con ritrasmissioni\nFEC(Forward Error Correction) senza ritrasmissioni\n\n\n\n\n\n\ntipi di trasmissione\n\nHalf duplex\n\nLa trasmissione non pu√≤ essere simultanea da entrambe le direzioni\n\nWifi\n\n\n\n\nFull duplex\n\nLa trasmissione √® simultanea per entrambe le direzioni\n\nEthernet\n\n\n\n\n\n\nLivello di collegamento negli host\n\ncome componenti del livello di collegamento gli host hanno la scheda di rete detta\n\nNIC(Network Interface Card) che fa da intermediario sia del livello fisico che quello di collegamento\n\n\nCome √® fatto un host\n\nmittente\n\nil mittente sfrutta il controller nella scheda di rete per\n\nincapsulare il datagramma dentro un frame\naggiungere vari bit di controllo\ngestire flusso trasferimento affidabile ecc‚Ä¶\n\n\nla CPU dell‚Äôhost consente di costruire i dati e interagisce con la NIC(Network Interface Card) per assemblare il pacchetto\n\n\ndestinatario\n\nil controller della scheda di rete\n\nverifica eventuali errori nei bit ricevuti\ngestisce anche lui trasferimento affidabile e flusso\nestrae il datagramma dal frame\n\n\nla CPU in questo caso prende i dati e li passa ai livelli superiori rete trasporto ecc‚Ä¶\n\n\n\n\n\n\n\n\nRilevazione degli errori\n\n\nintroduzione alla rilevazione degli errori\n\nper rilevare errori si usano tecniche come l‚Äôutilizzo di un codice EDC(Error Detection and Correction)\n\nquando vengono inviati dei dati D viene aggiunto questo codice EDC\nquesto codice EDC viene generato a partire da una funzione applicata sui dati D\nuna volta generato viene inviato al destinatario\nil destinatario adesso riceve questi dati D ci riapplica la funzione e vede se corrisponde a EDC precedente\nnon √© super affidabile e in pi√π c‚Äô√® overhead\n\n\n\n\n\n\n3 tecniche utilizzate per fare controllo sugli errori migliori di EDC\n\nBit di parit√†\n\nObbiettivo\n\nvengono presi i dati in bit e vengono aggiunti eventuali bit per rendere il numero di 1 totali pari\ndopo aver inviato il tutto se il numero di bit a 1 compreso quello di parit√† sono dispari, errore\nunico problema se ho errori su un numero di bit pari ritornerei comunque a una sequenza pari quindi non rileverei errori\nvengono spesso usate matrici di bit per verificarli\nparit√† bidimensionale\n\ncreare una matrice per calcolare parit√† su righe e colonne\ncomprende anche un bit globale\n\n\n\n\nChecksum\n\nObbiettivo\n\nIl checksum √® un meccanismo di controllo dell‚Äôintegrit√† dei dati che viene usato principalmente a livelli superiori come quello di trasporto con UDP TCP ecc‚Ä¶ oppure anche sul livello di rete come IP\n\nil mittente prende il contenuto del pacchetto come una sequenza di interi, la somma facendo il complemento a 1\n\novvero la somma con i suoi bit normali e la sua controparte in complemento a 1\n\n\nil risultato viene a sua volta complementato a 1 e lo inserisce nel campo checksum\n\n\nil ricevente somma tutto compreso checksum\n\ncontrolla se il risultato sono tutti 1 per vedere se non ci sono errori\n\n\n\n\n\n\nCRC\n\nSistema estremamente affidabile per rilevare errori\nil mittente tratta i dati come una lunga sequenza di bit e li divide per un polinomio binario predefinito\n\nil resto della divisione CRC viene allegato al frame\n\n\nil destinatario svolge la stessa divisione e verifica il resto\n\nse √® 0 i dati sono probabilmente corretti altrimenti c‚Äô√® stato un errore nella trasmissione\n\n\n\n\n\n\n\n\n\nCollegamenti e accesso multiplo\n\nPunto a Punto\n\ncollegamento di tipo punto a punto\ncomposta da un trasmittente e un ricevente\n\n\nBroadcast\n\ncanale di collegamento che comprende pi√π nodi che trasmettono e piu nodi che ricevono\npresentano problemi di accesso multiplo da risolvere\n\n\n\nGestione accesso multiplo\n\nIniziamo con la spiegazione di un protocollo ideale MAC\n\nMultiple Access Channel\nin modo ideale √® previsto che se in un collegamento ho pi√π nodi ho trasmissione pari a R/M\nse invece ho solo un dispositivo avr√≤ velocit√† R totale\ninattuabile\n\n\n\nTipi di protocolli ad accesso multiplo reali\n\n\nsi dividono in\n\nChannel Partitioning\n\ncon canale suddiviso\nogni nodo ha una sua fetta del canale\nle fette rimanenti sono inutilizzate\n\n\nRandom Access\n\nil canale presenta collisioni e per risolverle vengono fatte ritrasmissioni e operazioni di recover\n\n\nTaking Turns\n\ni nodi usano il canale a turno\ni nodi con maggiore priorit√† potrebbero avere il turno pi√π duraturo\n\ntipo i nodi con pi√π materiale da inviare\n\n\n\n\n\n\n\nQuelli a Channel Partitioning\n\nTDMA\n\nil canale viene suddiviso per istanti temporali fissi\n\ndetti time slot\nogni nodo ha il suo timeslot\nin quel timeslot ha accesso completo\ngli slot inutilizzati si dicono idle\n\n\n\n\n\n\n\n\nFDMA\n\nil canale viene suddiviso in spettri di frequenze diverse interna un cavo FDM\nogni nodo trasmette sulla sua frequenza non alla massima velocit√†\n\n\n\n\nQuelli ad Accesso casuale\n\nSLOTTED ALOHA\n\nl‚Äôuso del collegamento √® diviso in slot temporali\nogni nodo che vuole inviare qualcosa accede attende il prossimo slot temporale libero e vi accede\n\nse viene occupato prima da qualche altro nodo avviene una collisione e deve attendere il time slot successivo\n\n\nogni nodo decide in autonomia quando trasmettere\npossono esserci collisioni frequenti o inutilizzi di slot temporali\ni nodi devono essere sincronizzati\nun nodo pu√≤ utilizzare il canale in modo efficace con una probabilit√† del 37% del tempo\n\n\n\n\n\n\nUNSLOTTED ALOHA\n\nsenza sincronizzazione tra nodi\n\ntrasmettono finch√© non avviene una collisione\ni nodi non aspettano il time slot successivo\n\n\ndiminuisce probabilit√† di efficienza arrivando al 18%\n\n\n\nCSMA\n\nil nodo prima di trasmettere ascolta il canale e vede se √® libero o occupato\npossono comunque esserci collisioni dovute a ritardi di propagazione\n\n\n\nCSMA/CD\n\nmiglioria di CSMA con una detection delle collisioni\nil nodo che trasmette rimane in ascolto di eventuali collisioni\nse avviene smette di trasmettere cos√¨ non viene sprecata banda per un frame che andrebbe perso\n\nnon funziona bene via wireless\n\n\nfunzionamento\n\nun nodo sta trasmettendo nel collegamento, allo stesso tempo si mette in ascolto per vedere se ci sono collisioni in atto\nse un nodo prova a collegarsi il nodo che trasferiva i dati lo rileva\nsi interrompe la trasmissione dei nodi coinvoli nella collisione\nviene segnalata\ne poi viene assegnato un tempo casuale di accesso ad ogni nodo coinvolto e si riprende cos√¨ il tutto\n\n\n\n\n\n\nQuelli a Taking Turns\n\nPOLLING\n\n√® presente un controllore centralizzato che dice ai nodi quanti frame possono trasmettere al massimo per un dato turno\nil fatto che ci sia un controllore aumenta il ritardo ma allo stesso tempo si riducono collisioni o slot inutilizzati\nusato nel Bluetooth\n\n\n\n\n\n\nToken Passing\n\nToken che viene passato per ogni nodo, chi lo ha pu√≤ usare il collegamento\n\n\n\n\nGestione via cavo di\n\ndownstream\n\nvengono usati canali FDM in broadcast\n\n\nupstream\n\nviene usato il sistema ad accesso casuale\n\n\nper mettere d‚Äôaccordo i vari modem via cavo viene usato uno standard DOCSIS che precisa quali tipologie di politiche di accesso devono essere usate\n\n\n\nLAN\n\nDefinizione\n\nLocal Area Network\nindica una area ristretta come una casa o una scuola\n\n\nspesso si usano Ethernet o Wifi\n\nIndirizzi MAC\n\ndescrizione\n\nPer identificare un dispositivo di rete ad esempio una scheda di rete per effettuare uno scambio dei frame abbiamo bisogno di un indirizzo MAC, √® a 48 bit ed √® memorizzato nella ROM della NIC Network Interface Card\n\n\ncome vengono scelti IEE\n\nente internazionale che ha lo scopo di gestire e fornire indirizzi MAC ai vari produttori di NIC\n\n\n\nDa IP a MAC\n\nViene utilizzato un protocollo ARP che ha una tabella ARP dove sono presenti\n\nOgni nodo IP nella LAN con le sue interfacce e il suo Indirizzo MAC con anche un TTL per la validit√† dell‚Äôinformazione\n\n\n\n\nProtocollo ARP\n\nCome funziona Se la tabella non presenta il MAC di un dato IP\n\nse un nodo nella rete vuole avere il MAC di un dispositivo usa il protocollo ARP che invier√† un broadcast di richiesta con quel determinato indirizzo IP\nil dispositivo corretto risponde\nora potr√† essere popolata la tabella ARP\n\n\nAttacco ARP SPOOFING o POISONING\n\nviene inviata una risposta ARP falsa fingendosi di avere un‚Äôaltro indirizzo IP\nfai confluire il traffico verso di te puoi intercettarlo oppure puoi fare un attacco Dos associando 1000 indirizzi IP allo stesso MAC\n\n\n\n\nCome inviare un datagramma a un nodo non adiacente nella rete\n\nSe il destinatario si trova su un‚Äôaltra sottorete allora bisogna instradare il frame a un router gateway\nviene creato un frame con all‚Äôinterno il datagramma IP con le varie informazioni\nil router riceve il frame e lo decapsula, vede il datagramma che l‚ÄôIP √® da inoltrare a un altro dispositivo\nre incapsula il tutto e lo invia alla interfaccia dello switch corretta con il giusto destinatario\n\n\n\nETHERNET\n\ncosa √®\n\nStandard di comunicazione utilizzato per le reti LAN cablate\n\n\nframe ethernet\n\ncomposto da\n\npreambolo\n\nsincronizza il ricevente e segnala quando un frame inizia\n\n\nMac di destinazione\nMAC di sorgente\nTipo di protocollo incapsulato nel payload per poi de capsularlo e vedere cosa c‚Äô√®\nDati\nCodici di controllo errori CRC\n\n\nTutti gli standard di Ethernet usano stesso frame\n\n\n\nsicurezza di ethernet\n\n√® senza handshake\nvengono gestiti accessi multipli come ad esempio con CSMA/CD\nle altre sicurezze varie vengono gestite ai livelli superiori\n\n\nConcetto di dominio di collisione\n\npunto in cui si condivide stesso mezzo di trasmissione\nsi pu√≤ verificare una collisione tra vari frame ethernet se si trasmette insieme\nsi consiglia di ridurre i dispositivi collegati a un singolo collegamento\n\n\n\nSwitch Ethernet\n\nCosa sono\n\nLo switch √® un dispositivo che lavora sul livello di collegamento\nha il compito di memorizzare e inoltrare i frame Ethernet\n\n\nCaratteristiche\n\n√® plug and play non devi configurarlo\n\n\nTabella di commutazione degli Switch\n\nOgni switch ha una sua tabella di commutazione con un\n\nindirizzo MAC del nodo\ninterfaccia che conduce al nodo\nTTL\n\n\nlo switch auto riempie le varie tabelle\n\nogni volta che riceve un frame aggiunge alla tabella il mittente\n\n\n\n\nCosa fa lo switch quando riceve un frame\n\nAggiorna la Switch table mettendo il mittente\nse il mittente ha stessa porta del destinatario allora non serve che ci sia questo passaggio per lo switch e scarta il pacchetto\nse √® su un‚Äôaltra porta lo inoltra facendo lo switching\nse non ha nella tabella il destinatario fa una operazione di flood per trovarlo\n\n\nDifferenze con i router\n\ngli switch lavorano sul livello di collegamento i router no\ngli switch possono lavorare con pochi dispositivi perch√© usano una tabella normale\n\n\n\n\nVLAN\n\n\ncosa sono\n\nSe si ha bisogno di utilizzare il concetto e la comodit√† delle LAN su reti di grandi dimensioni senza per√≤ dover ricorrere a un solo Switch che non garantirebbe privacy e problemi di dimensioni della tabella\nesistono le VLAN\n\nsi possono usare switch differenti per rimanere sulla stessa rete ma allo stesso tempo creare flessibilit√† di gestione\n\n\n\n\n\nversione basata sulle porte\n\nun singolo switch viene usato come due switch differenti per mantenere la sicurezza\nuno switch viene diviso a met√† virtualmente\n\n\n\n\nversione con pi√π switch\n\nviene usata una porta trunk per collegare in serie pi√π switch\nuna volta collegato il tutto possono comunicare tra loro gli switch\n\n\n\nEVPN\n\ntecnologia di tunneling che consente di creare una rete locale anche se si hanno due reti di livello 2 quindi con switch su luoghi differenti\n\nviene collegato il router allo switch e viene incapsulato il frame ethernet che poi verr√† passato dall‚Äôaltra parte con un altro router e switch\n\n\n\n\n\nle VLAN hanno un loro ID per comunicare tra loro e riconoscersi\n\nquest‚Äôultimo √© definito dallo standard 802.1Q\n\n\n\nLE RETI WIRELESS\n\nsignificato di wireless\n\nTecnologia di collegamento senza l‚Äôuso di fili ma attraverso frequenze\n\n\nsignificato di mobilit√†\n\npropriet√† dell‚Äôinfrastruttura di rete che consente al client di muoversi cambiando punti di accesso\n\n\nHandover\n\nProcesso che consente a un dispositivo mobile di cambiare collegamento wireless senza problemi\n\n\nComponenti che compongono una rete wireless\n\nHost wireless\n\ndispositivi che eseguono operazioni e hanno un collegamento wireless\nsi dividono in fissi o stazionari\n\n\nCollegamento wireless\n\nUtilizzato per collegare un host wireless alla stazione base oppure un altro host wireless\n\n\nStazione base\n\nelemento che funge da ripetitore\ndi solito connessa a una rete cablata\ndispositivo di relay al livello di collegamento\n\n\n\n\na una determinata velocit√† di banda varia il raggio di copertura\n\n2 Tipi di infrastrutture\n\n\ncon infrastruttura\n\nSono presenti stazioni base che hanno il compito di offrire servizi di rete\navvengono operazioni di handoff, quando un dispositivo si sposta dall‚Äôarea di copertura e cambia punto di accesso\n\n\n\n\nsenza infrastruttura\n\nreti senza stazione base con host che comunicano tra di loro\ndevono provvedere da se per fornire servizi di instradamento\n\n\n\n\nCaratteristiche dei collegamenti wireless\nConcetto di attenuazione\n\nil segnale pu√≤ essere assorbito o attenuato a seconda della presenza di determinati ostacoli o anche solo dalla distanza\nl‚Äôattenuazione con spazio libero si calcola con\n\n(frequenza‚ãÖdistanza)^2=(fd)^2\nPi√π alta √® la frequenza o pi√π lontano √® il ricevitore, pi√π rapidamente si perde il segnale.\n\n\n\n\nTempo di coerenza\n\nTempo che ci indica se all‚Äôarrivo di un segnale ne possono arrivare degli altri uguali a causa di possibili riflessioni a distanza di un determinato tempo\n\nquesto tempo √® detto di coerenza\n\n\n\ninterferenze da altre sorgenti\n\nIl fenomeno fisico di interferenza pu√≤ anche verificarsi a causa di altri dispositivi che lavorano su frequenze simili\n\nper definire il segnale e la frequenza su cui lavoriamo usiamo il SNR(Signal-To-Noise-Ratio)\n\nrappresenta un rapporto tra il segnale e il rumore di fondo\nun SNR alto consente di estrarre le informazioni facilmente\n\n\nIl BER  (Bit error rate) rappresenta la probabilit√† che un bit sia ricevuto in errore\n\n\nBilanciamento di rete\n\naumentare la potenza del segnale aumenta la SNR e riduce i BER\n\nma non √® proprio facile da attuare dovuto a consumi eccessivi\ni dispositivi wireless si adattano automaticamente modulando la frequenza e la velocit√† di trasmissione\ncos√¨ da avere maggiore stabilit√†\n\n\n\n\nTerminali nascosti\n\nI terminali nascosti sono nodi che non possono vedere altri nodi perch√© sono fuori dalla loro portata ma possono comunque causare collisioni che li riguardano\n\nad esempio con un nodo intermedio che vede entrambi\n\n\n\n\nAccesso multiplo\n\nCDMA\n\nprotocollo che permette di condividere stessa frequenza di comunicazione con pi√π utenti\nogni utente ha un suo codice unico chiamato chipping sequence per identificarli\nil loro segnale √® codificato su questo\n\n\n\n\n\nStandard Reti Wi-Fi 802.11\n\n\nrappresenta un insieme di protocolli che consentono la comunicazione wireless tra pi√π dispositivi\n\n\nArchitettura delle LAN 802.11\n\ngli host wireless comunicano con una stazione base detta anche Access Point\nle singole infrastrutture wireless sono dette BSS e hanno vari host punto di accesso ecc‚Ä¶\n\n\n\n\nDivisione dei canali\n\ntecnica che consente la modulazione di frequenze per creare una divisione dei canali di comunicazione\nci√≤ comunque non riduce a zero le interferenze\nquesti canali vengono scelti dal AP admin\n\n\n\n\ningresso di un dispositivo nella rete\n\nun host in arrivo su una BSS deve essere associato a un AP e per farlo si hanno due modalit√†\n\nscansione attiva\n\nil dispositivo che si collega deve mandare un frame sonda in broadcast per trovare l‚ÄôAP corretto\n\n\npassiva\n\ngli AP a intervalli regolari inviano questi frame beacon per essere rilevati dai dispositivi che vogliono accedervi\n\nal loro interno hanno un MAC e un identificativo dell‚ÄôAP il SSID\n\n\n\n\n\n\ndopo aver instaurato questo collegamento con accessi sicuri attraverso ad esempio WPA2\nl‚Äôhost pu√≤ inviare un DHCP discover che sar√† passato all‚ÄôAP e poi al server DHCP\n\n\n\n\ncollisioni nelle reti wireless\n\nCSMA/CA\n\nper gestire accesso multiplo nelle reti WiFi non si possono usare CD ovvero collision Detection perch√© con le reti wireless √® complesso e inutilizzabile vengono usate variabili\nDIFS\n\nvariabile che indica l‚Äôintervallo di tempo che bisogna aspettare per vedere se un canale √® libero\nse lo √® il mittente trasmette\nsenn√≤ aspetta un tempo backoff casuale\n\n\nSIFS\n\nvariabile che indica un intervallo di tempo che deve aspettare il destinatario prima di inviare un ACK di ricevuta dei dati\n\n\n\n\nMeccanismo di prenotazione\n\nvengono usati segnali RTS(Request to Send)\n\nper prenotare il canale di comunicazione\n\nvengono inviati ai vari AP\n\n\npossono avvenire collisioni di prenotazione\n\n\n\n\n\n\n\nquando un frame viene passato a un AP ha come destinazione l‚Äôindirizzo MAC dell‚ÄôAP\n\nquando un frame deve passare per un router viene incapsulato in un altro frame che avr√† come mittente il MAC dell‚ÄôAP e come destinatario il MAC del router\n\n\n\nTecnologie wireless\n\n\nBluetooth\n\ndefinizione\n\nTecnologia wireless che consente un collegamento di tipo PAN(Personal Area Network)\n\n\npiconet\n\nnome che prende una singola rete Bluetooth che consente fino a 8 dispositivi compreso 1 master controller\n\n\nbootstrapping\n\nprocesso di accesso a una piconet di un dispositivo client\nsi divide in 2 modalit√† possibili\n\nNeighbor discovery\n\nil master invia dei messaggi in broadcast detti inquiry\nil dispositivo in ascolto lo rileva e instaura cos√¨ una connessione\n\n\nPaging\n\nil master invita un dispositivo specifico a entrare quando lo conosce\n\nviene successivamente comunicato l‚Äôindirizzo di partecipazione e altre informazioni utili\n\n\n\n\n\n\n\n\n\n\n\n\nReti 4G/5G\n\ndefinizione\n\nTecnologia funzionale che consente il collegamento wireless su WAN\nattraverso Access Point\n\n\nsimilarit√† e differenze con internet cablato\n\nUsano stessi protocolli e sono reti globali\ntecnologie radio da parte delle reti 4G\nsupporto alla mobilit√† nativa da parte delle reti 4G/5G\n\n\narchitettura 4G\n\ncomposta da\n\nMobile device(UE)User Equipment\n\ndispositivi mobili connessi alle base station\nha un IMSI ovvero un suo identificativo\n\n\nBase station(eNode-B)\n\ndispositivo che condivide le informazioni ai mobile Device\n\ncoordinandoli tra loro e gestendo le varie celle di collegamento\n\n\ngestione di handover per mobilit√† dei device\n\n\nMME(Mobility Management Entity)\n\nServizio che\nconosce la posizione dei vari dispositivi\nfa da intermediario con i dispositivi e i P-GW\nidentifica i dispositivi usando l‚ÄôHSS\n\n\nHSS(Home Subscriber Server)\n\nmemorizza le informazioni degli utenti con le varie chiavi di autenticazione\nServe per identificare i dispositivi con ad esempio il loro piano dati\n\n\nS-GW\n\nrouter gateway interno alla rete che instrada i dati da parte delle UE verso i P-GW\n\n\nP-GW\n\nrouter gateway che porta a internet i dati che vengono dalle S-GW attraverso il tunneling\nrouter connesso alla vera e propria rete globale\n\n\n\n\n\n\nmigliorie del 5G\n\nmaggiore velocit√†\npotrebbero esserci problemi di distanza di banda\n\n\n\n\n\n\nRete LTE\n\ndefinizione\n\nStandard di comunicazione wireless con delle modifiche alle reti 4G soprattutto nella fase di tunneling dei dati √® diviso in 2\n\n\npiano di controllo\n\ngestisce la mobilit√† e la sicurezza\n\nnon trasporta i dati effettivi\n\n\n\n\npiano di dati\n\ntrasportare il vero e proprio traffico dati\n\n\npila protocollare LTE\n\nogni comunicazione LTE ha una sua pila protocollare che si differisce in 2 punti\n\n\n\nquando avviene lo scambio dal UE al first hop nella base station abbiamo un incapsulamento complesso che vuole garantire sicurezza e affidabilit√† nella gestione dei segnali radio\n\n\n\n\nuna volta raggiunto invece il passaggio di tunneling dove i dati passano tra i vari Gateway attraverso un tunnel\n\n\nla comunicazione avviene attraverso u n protocollo GTP-U\nche impacchetta i dati in un pacchetto UDP per poi spedire i dati al P-GW passando per l‚ÄôS-GW\n\n\n\n\n\n\n\n\n\n\nproblema della mobilit√†\n\ndefinizione\n\nquando un dispositivo si muove bisogna rinstaurare una connessione a una base station con la copertura adatta e che magari √® collegata a un router differente\n\n\nHome agent\n\ndefinizione\n\nNodo nella rete che rappresenta il riferimento per la ricezione dei dati del dispositivo UE\n\n\n\n\napprocci di routing\n\n1.il router della base station differente annuncia agli altri che il dispositivo ha effettuato questo cambiamento e viene aggiornata la tabella di routing\n\ncon troppi dispositivi non funziona\n\n\n2.viene sfruttato il concetto di Home agent,\nsi divide in 2 altri sottopunti\n\n1.ROUTING INDIRETTO\n\nl‚Äôhome Agent invia i dati che riceve per quel determinato UE al nuovo router della nuova base station\n\n√® lento e vengono fatti giri troppo lunghi\n\n\n\n\n2.ROUTING DIRETTO\n\ni mittenti che vogliono mandare i messaggi all‚ÄôUE non inviano pi√π le informazioni all‚ÄôHome agent ma al nuovo router della base station\n\nveloce ed efficiente ma i mittenti devono capire il tutto\n\n\n\n\n\n\n\n\n\n\n\n\n\nLe reti si dividono in\n\nhome network\n\nrete gestita dall‚Äôoperatore con cui si ha un contratto\n\n\nvisited network\n\nrete gestita da altri operatori\nviene concessa attraverso il roaming\n\n\n\n\n\n"},"UNI/ANNO-2/RETI/ESERCIZI/APPLICAZIONE/CALCOLO-RITARDI":{"slug":"UNI/ANNO-2/RETI/ESERCIZI/APPLICAZIONE/CALCOLO-RITARDI","filePath":"UNI/ANNO 2/RETI/ESERCIZI/APPLICAZIONE/CALCOLO RITARDI.md","title":"CALCOLO RITARDI","links":[],"tags":[],"content":"Ritardo end-to-end\nRitardo_{e2e‚Äã}=T_{tx}‚Äã+T_{prop‚Äã}+T_{queue}‚Äã+T_{proc}‚Äã\n\n\nRitardo di trasmissione\n\nTempo per inviare tutti i bit di un pacchetto sul canale.\nT_{trasm}‚Äã=L/C‚Äã\nDimensione/velocit√† del collegamento\n\n\n\nRitardo di propagazione\n\nTempo per il primo bit a viaggiare da mittente a destinatario.\nT_{prop}‚Äã=d/v‚Äã\ndistanza/velocit√†\n\n\n\nRitardo di elaborazione\n\nTempo che un nodo (es. router) impiega per analizzare, controllare e instradare il pacchetto.\nfornito dal prof\n\n\n\nRitardo di accodamento (se presente)\n\nTempo che un pacchetto aspetta in coda nel router o nodo, in attesa che il link si liberi.\nT_{queue‚Äã}=inizio¬†\\ trasmissione¬†\\ effettiva‚àítempo¬†\\ di¬†\\ arrivo¬†\\ al¬†\\ nodo\n\n\n\nRouter\nse un router ha politica FIFO con store and forward semplicemente pu√≤ salvare nel buffer tutti i pacchetti che vuole e li invia con logistica FIFO, ovviamente rispettando sempre il fatto che pu√≤ inviare su un link un pacchetto per volta o anche ricevere\nConversioni\nSi usa il prefisso decimale:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSimboloNomeValorekkilo10¬≥ = 1.000Mmega10‚Å∂ = 1.000.000Ggiga10‚Åπ = 1.000.000.000\nstimare il ritardo con tanti pacchetti\nRitardo¬†totale‚âàœÑ1‚Äã+œÑ2‚Äã+œÑ3‚Äã+\\frac{D}{\\min_i(C_i)}\ndove rispettivamente abbiamo\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTermineSignificato\\tau_1 + \\tau_2 + \\tau_3œÑ1‚Äã+œÑ2‚Äã+œÑ3‚ÄãSomma dei ritardi di propagazione su ogni tratto\\frac{D}{\\min(C_i)}‚ÄãTempo necessario a trasmettere tutto il file D bit, limitato dalla banda pi√π lentaInsomma quando si hanno tanti pacchetti si pu√≤ fare sta roba\nTroughput end-end con un singolo tunnel\n MIN\\{R_C,R_S,R/LINK\\}\n\nCalcolare il tempo di utilizzo di un collegamento\n R_S/R_C se R_S\\leq R_C o viceversa per il collegamento di R_S fare R_S/R_S\nal num metti il collo di bottiglia\nse per un collegamento passano pi√π collegamenti, moltiplica per il numero di collegamenti"},"UNI/ANNO-2/RETI/ESERCIZI/COLLEGAMENTO/Correzione-Bit":{"slug":"UNI/ANNO-2/RETI/ESERCIZI/COLLEGAMENTO/Correzione-Bit","filePath":"UNI/ANNO 2/RETI/ESERCIZI/COLLEGAMENTO/Correzione Bit.md","title":"Correzione Bit","links":[],"tags":[],"content":"ESERCIZIO 1\nSi vuole inviare la seguente sequenza di bit proteggendola\nattraverso l‚Äôaggiunta di un bit di parit√† (pari), posto alla fine della\nsequenza.\n1101 1010 1001 0110\nQuali bit saranno effettivamente trasmessi?\n\naggiungi bit parit√† alla fine\n\nESERCIZIO 3\nSi supponga di aver ricevuto il seguente frame protetto da singolo\nbit di parit√† (pari):\n1101 1010 1001 0110\nRispondere alle seguenti domande:\n\nIl ricevente rileva un errore?\nIn caso affermativo, il ricevente pu√≤ correggere l‚Äôerrore?\n\nconta i bit 1 se sono dispari errore\nnon si pu√≤ correggere perch√© il sistema di bit di parit√† non permette correzioni\n\n\n\nESERCIZIO 4\nSi considerino i dati forniti di seguito in formato binario\n1101 1010 1001 0110\nSi calcolino i bit di EDC (error detection and correction) secondo lo\nschema di controllo di parit√† (pari) bidimensionale.\nQuali sono i bit EDC da aggiungere (fornire la soluzione minima)?\n\ndividi i bit 4 a 4 mettili in riga e colonna\naggiungi bit di parit√† per ogni riga e colonna\n\naggiungi all‚Äôangolo il bit di parit√† globale che si trova vedendo il numero di 1 totali compresi i bit di parit√†\nscrivi la soluzione prendendo bit di parit√† delle colonne e poi della riga e poi quello globale\n\n\n\nESERCIZIO 5\nSono stati ricevuti i seguenti dati\n10110010 01101100 11001110\nI dati sono stati trasmessi in modo tale che:\n‚Ä¢ Il bit pi√π significativo (il primo a sinistra) di ciascuno dei primi due byte √® un\nbit di parit√† pari calcolato sui restanti 7 bit dello stesso byte.\n‚Ä¢ Il terzo byte contiene, in ciascuna posizione, la parit√† pari dei bit nella stessa\nposizione dei primi due byte\nRispondere alle seguenti domande:\n\nIl ricevente rileva un errore?\nIn caso affermativo, pu√≤ correggerlo?\n\n\ncontrolla gli 1 per vedere se ci sono errori\nper correggerlo prendi errori nelle righe e nella colonna e inverti il bit\ndisponi prima i primi 8 bit su una riga e gli altri 8 bit in una seconda riga\npoi prendi i primi 2 bit come bit di parit√† della riga\nusa il 3 byte come bit di parit√† della riga e quello globale a sx\n\n\nESERCIZIO 6\nSi considerino i dati forniti di seguito in formato binario\n1101 1010 1001 0110 1011 1100 0011 0101 1011 1100 0011 0101\nSi calcolino i bit di EDC (error detection and correction) secondo la\nchecksum di Internet.\n\nprendi i primi 16 bit\nprendi i secondi 16 bit\nsommali tra loro in colonna\nse alla fine hai un riporto di 1 sommalo a partire dai bit meno significativi e cancella il riporto\npoi somma al risultato i successivi 16 bit della fine\ncompl a 1\n\n\nESERCIZIO 6b\nricordati la conversione da esadecimale a decimale e poi da decimale a binario\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA10B11C12D13E14F15\nESERCIZIO 7\nData la sequenza D di bit fornita di seguito in formato binario\n1101 1010 1001 0110\nSi calcolino i bit di EDC (error detection and correction) secondo lo\nschema di CRC usando il generatore CRC-8-CCITT (1 0000 0111).\nQuali sono i bit EDC da aggiungere?\n\n\naggiungo alla fine quanti zeri quanto il grado della CRC\ninizio da sx a fare lo XOR con il generatore\n\nogni volta che ho uno o pi√π 0 a sx procedo a portare gi√π le successive cifre da destra\nse ho 2 0 a sx abbasso 2 a dx\n\n\nesercizio termina quando non ho pi√π cifre da abbassare\nEDC=risultato dello XOR\ncome verificare poi se il messaggio √® arrivato correttamente\n\nPrendi il messaggio ricevuto (dati + CRC)\nFai la divisione binaria con lo stesso generatore\nGuarda il resto finale\nSe √® 00000000, OK!\nAltrimenti, errore\n\n\n\nESERCIZIO 9\nUn frame di N bit viene trasmesso attraverso un collegamento\nsoggetto a errori su bit indipendenti con probabilit√† N.\nQual √® la probabilit√† che:\n\nIl frame sia ricevuto senza errori\nIl frame sia ricevuto con un errore\nIl frame sia ricevuto con errori multipli (2 o pi√π)\nApplicare queste probabilit√† alla discussione dell‚Äôefficacia del bit di\nparit√†.\n\n1. Probabilit√† che il frame sia ricevuto senza errori\nP(S = 0) = (1 - p)^N\nüëâ Dipende fortemente da N e p. Per p \\ll 1 e N piccolo, questa probabilit√† √® vicina a 1.\n2. Probabilit√† che il frame sia ricevuto con esattamente un errore\nP(S = 1) = \\binom{N}{1} \\cdot p \\cdot (1 - p)^{N - 1} = Np(1 - p)^{N - 1}\nüëâ Cresce linearmente con N, ma solo se p √® sufficientemente piccolo.\n3. Probabilit√† che il frame sia ricevuto con errori multipli (2 o pi√π)\nP(S \\geq 2) = 1 - P(S = 0) - P(S = 1)\nüëâ Questa √® la parte pi√π pericolosa per il bit di parit√†, come vediamo sotto."},"UNI/ANNO-2/RETI/ESERCIZI/COLLEGAMENTO/ESERCITAZIONE-ARP":{"slug":"UNI/ANNO-2/RETI/ESERCIZI/COLLEGAMENTO/ESERCITAZIONE-ARP","filePath":"UNI/ANNO 2/RETI/ESERCIZI/COLLEGAMENTO/ESERCITAZIONE ARP.md","title":"ESERCITAZIONE ARP","links":[],"tags":[],"content":"\n\nper identificarle raccogli i vari dispositivi di rete tranne gli host e raccogli nello stesso insieme se non ci sono router\nda H1 viene inviato un messaggio broadcast che raggiunge H2 e S1\n\nda S1 viene rifatta la stessa cosa e arriva a S2\nda S2 la stessa cosa e raggiunge H3 e R1\n\nR1 √® di terzo livello e non pu√≤ continuare l‚Äôoperazione\nH3 risponde con il suo indirizzo MAC con ARP reply\n\ne viene ripercorso il tutto fino a raggiungere H1\n\n\n\n\n\n\nnon pu√≤ perch√© appartiene a un‚Äôaltra sottorete e c‚Äô√® un router di livello 3\n"},"UNI/ANNO-2/RETI/ESERCIZI/RETE/COMANDO-PING":{"slug":"UNI/ANNO-2/RETI/ESERCIZI/RETE/COMANDO-PING","filePath":"UNI/ANNO 2/RETI/ESERCIZI/RETE/COMANDO PING.md","title":"COMANDO PING","links":[],"tags":[],"content":"üß™ Obiettivo generale\n\nImparare a usare ping in modo avanzato per:\n\n\n\nVerificare la raggiungibilit√† di un host\n\n\nCalcolare l‚ÄôRTT (Round Trip Time)\n\n\nStudiare pacchetti ICMP e opzioni di invio\n\n\nCapire l‚Äôeffetto del TTL, del timeout e della dimensione del pacchetto\n\n\n‚úÖ Esercizio 1 ‚Äì ping base + Wireshark\n\nSi esegue ping www.google.it, si interrompe con CTRL+C.\nViene inviato ogni secondo un pacchetto ICMP Echo Request.\n\nserve per capire se un host √® raggiungibile\n\n\nOgni risposta √® un Echo Reply, che include:\n\nNumero sequenza (icmp_seq)\nTempo di ritorno (time)\nTTL (dal pacchetto IP)\n\n\nIn Wireshark si filtra con icmp per vedere i pacchetti.\n\n‚úÖ Esercizio 2 ‚Äì Opzione -c (count)\n\nping -c 1 www.google.it\nInvia n pacchetti in questo caso 1.\n\n‚úÖ Esercizio 3 ‚Äì Opzione -w (deadline)\n\nping -w 3 www.google.it\nEsegue ping per al massimo 3 secondi, indipendentemente dal numero di pacchetti.\nPing invia un pacchetto ogni secondo ‚Üí si ricevono 3 pacchetti prima dello stop.\n\n‚úÖ Esercizio 4 ‚Äì Opzione -i (intervallo)\n\nping -i 1.495 -w 3 www.google.it\nCambia l‚Äôintervallo tra un pacchetto e il successivo.\nServe a simulare invii pi√π frequenti o pi√π lenti.\nSe combinato con -w, pu√≤ causare perdita di pacchetti perch√© non si lascia tempo sufficiente alla risposta.\ncambia la frequenza\n\n‚úÖ Esercizio 5 ‚Äì Combinazione -i -c -w\n\nping -i 1.495 -c 3 -w 3 www.google.it\nInvia 3 pacchetti ma scade a 3 secondi ‚Üí non fa in tempo a ricevere l‚Äôultimo ACK.\nMostra che il timeout √® importante anche se i pacchetti sono stati inviati correttamente.\n\n‚úÖ Esercizio 6 ‚Äì Opzione -W (timeout risposta)\n\nping -W 1 -c 1 www.google.it: aspetta 1 secondo per la risposta.\nping -W 0.01 -c 1 www.google.it: timeout troppo basso ‚Üí perdita pacchetto.\nMostra come un RTT alto pu√≤ portare a false perdite se il timeout √® troppo breve.\n\n‚úÖ Esercizio 7 ‚Äì Opzione -s (dimensione dati ICMP)\n\nping -s 10 www.google.it\nCambia la dimensione del payload ICMP (non del pacchetto IP totale).\nSotto i 16 byte, ping non pu√≤ calcolare l‚ÄôRTT perch√© manca il timestamp.\nUtile per testare quanto i dati influenzano la risposta.\n\n‚úÖ Esercizio 8 ‚Äì Opzione -t (TTL - Time To Live)\n\nping -t 11: limita il TTL ‚Üí pacchetto viene fermato da un router intermedio.\nIl router invia un messaggio ICMP ‚ÄúTime Exceeded‚Äù.\nping -t 12: pacchetto raggiunge la destinazione.\nServe a determinare quanti hop ci sono tra sorgente e destinazione (come fa traceroute).\n"},"UNI/ANNO-2/RETI/ESERCIZI/RETE/ESERCIZI-PIANO-DATI":{"slug":"UNI/ANNO-2/RETI/ESERCIZI/RETE/ESERCIZI-PIANO-DATI","filePath":"UNI/ANNO 2/RETI/ESERCIZI/RETE/ESERCIZI PIANO DATI.md","title":"ESERCIZI PIANO DATI","links":[],"tags":[],"content":"Esercizio 1\n\nQual √® la sua rappresentazione in formato binario?\n\nconversione in binario di ogni punto\n\n\nConsiderando il sistema di indirizzamento a classi (ora non pi√π in uso), dire:\n\na qual √® la maschera di sottorete (in notazione decimale puntata)\n\nper definirla prendi i primi bit dell‚Äôindirizzo\nse 0 maschera /8\nse 10 maschera /16\nse 110 maschera /24\n\n\nb qual √® il prefisso di rete in formato CIDR\n\nbyte del prefisso messi normali poi 0 0 +/x\n\n\nc quali sono la parte di sottorete e la parte di host nell‚Äôindirizzo\n\nsottorete primi /x bit il resto la parte di host\n\n\nd quante interfacce potrebbe supportare la sottorete\n\n2^{32-x}-2\nx rappresenta i bit della sottorete -2 perch√© bisogna escludere broadcast e sottorete\n\n\ne indirizzo di broadcast diretto della sottorete\n\nprendi l‚Äôindirizzo della sottorete e a tutti gli altri metti 255\n\n\n\n\n\nEsercizio 2\n\n\nordina in base al numero di bit della sottorete pi√π grande\nconfronta i byte della parte di host e vedi se sono simili\n\nnel primo caso hai /24 quindi 8-16-24 3 byte, devi vedere corrispondenza tra primi 3 byte\nnel secondo caso /18 sono 8-16 e poi 2 bit del 3 byte, ti converti 192 in binario e prendi i primi 2 bit e li confronti con il 3 byte dell‚Äôindirizzo\ne cos√¨ via‚Ä¶\nse trovi corrispondenza con uno allora hai trovato la soluzione corretta perch√© prendi il numero di bit della sottorete pi√π grande\n\n\n\nEsercizio 3\n\n\nper trovare il piano di partizionamento prendi tutte le sottoreti che sono collegate senza router\n\nanche un router che √® collegato a un altro router √® una sottorete\nper calcolare le interfacce devi fare numero host+ numero di router della singola sottorete\nper definire quanti bit di host sono necessari e quindi quale prefisso corrisponde\n\ndevi fare 2^x-2\\geq \\ interfacce\nper capire il numero di bit della parte della sottorete fai 32-x\n\n\n\n\n\nESERCIZIO 4\n\n\ndata la subnet mask puoi dedurre il numero di bit della parte della sottorete\n\nad esempio alla prima sono 3 byte ovvero 8-16-24 allora avremo indirizzo/24\nall‚Äôultima abbiamo 8-16-23 perch√© abbiamo 255-1 quindi indirizzo/23\n\n\nconvertiamo in binario gli unici byte che cambiano in tutti gli indirizzi\nraggruppiamo per next hop simili e anche per /x uguale\n\nogni destinazione con next hop uguale e /x pu√≤ essere raggruppato modificando lo /x\nmetteremo lo /x della subnet- quanti bit meno significativi cambiano\n\n\n\nESERCIZIO 5\n\n\ncalcola numero di bit minimi per poi fare 2^x-2\\geq interfacce\n\npoi 32-2^x\n\n\nparti da /25 fai 8-16-24 e poi prendi il primo bit di 128\n\ndivide in\n\n\na) 2^{32-x}\nb) calcoli intervallo di indirizzi prendendo dal prefisso di rete al prefisso di broadcast, senza contarli\nc) 2^{32-x}-2\n\n-2 pk hai prefisso di rete e di broadcast\n\n\n"},"UNI/ANNO-2/RETI/ESERCIZI/RETE/ESERCIZI-PIANO-DI-CONTROLLO":{"slug":"UNI/ANNO-2/RETI/ESERCIZI/RETE/ESERCIZI-PIANO-DI-CONTROLLO","filePath":"UNI/ANNO 2/RETI/ESERCIZI/RETE/ESERCIZI PIANO DI CONTROLLO.md","title":"ESERCIZI PIANO DI CONTROLLO","links":[],"tags":[],"content":"Dijkstra\n\nDijkstra viene usato per fare il calcolo dei percorsi\ninizia da un determinato nodo e poi continua la ricerca al successivo nodo con distanza minore\n\ncreare una tabella con i passi\nN‚Äô che rappresenta i nodi usati per la ricerca\nle distanze dai vari nodi rispetto alla sorgente\nse non sono raggiungibili si mette infinito\nsi trascrive la distanza se il nodo non √® ancora stato usato per la ricerca infatti tipo D(C),p(C) non √® stato aggiornato fino all‚Äôultimo\nse un nodo effettua la visita significa che √® stato gi√† trovato il percorso migliore per lui\n\n\n\n\nDistance Vector"},"UNI/ANNO-2/RETI/ESERCIZI/TRASPORTO/CSMACD-e-TCP":{"slug":"UNI/ANNO-2/RETI/ESERCIZI/TRASPORTO/CSMACD-e-TCP","filePath":"UNI/ANNO 2/RETI/ESERCIZI/TRASPORTO/CSMACD e TCP.md","title":"CSMACD e TCP","links":[],"tags":[],"content":"ESERCIZIO 1\nFacendo riferimento allo schema CSMA/CD, determinare che\nvincolo c‚Äô√® tra lunghezza minima dei pacchetti e distanza massima\ntra due interfacce.\n\nil vincolo √®\n\nT_{trasmissione} \\geq 2*T_{propagazione}\nT_{trasm}‚Äã=L/R\n\nDimensione/velocit√† del collegamento\n\n\nT_{prop}‚Äã=d/v‚Äã\n\ndistanza/velocit√†\n\n\n\n\n\nESERCIZIO 2\n\n\nCapire che gli ACK sono cumulativi\nqui viene inviato un ACK corretto per il secondo segmento quindi si implica che anche il primo √® stato inviato correttamente\ndisegna le finestre di ricezione cos√¨\n\n\nESERCIZIO 3\n\n\nAnalizza i casi\n\nse si ha una crescita esponenziale\n\nSlow Start\n\n\nse si ha una piccola ricaduta\n\nTriplo ACK duplicato\nfast recovery e poi congestion avoidance\n\n\nse si ha una caduta a 1\n\ntimeout degli ACK\ncon cwnd=1\ne poi va in slow start\n\n\n\n\n\nESERCIZIO 5\nSi consideri che una singola connessione TCP Reno utilizzi un collegamento da R =\n10 Mbps e si supponga che esso sia l‚Äôunico collegamento congestionato lungo il\npercorso tra il mittente e il destinatario.\nSi assuma che:\n‚Ä¢ la connessione sia sempre in congestion avoidance (andamento a dente di sega)\n‚Ä¢ RTT = 150 ms\n‚Ä¢ tutti i segmenti abbiamo dimensione 1500 byte\n‚Ä¢ il mittente abbia sempre dati da trasmettere\n‚Ä¢ la finestra di ricezione sia molto pi√π grande della finestra di congestione del mittente\nDeterminare:\n‚Ä¢ dimensione massima della finestra, espressa in segmenti\n‚Ä¢ throughput medio, espresso in Mbps\n‚Ä¢ tempo impiegato per raggiungere nuovamente la dimensione massima della finestra\ndopo il dimezzamento dovuto alla perdita di un pacchetto\n\nserve sapere il tasso di trasmissione al TCP reno si calcola facendo\nT_{trasmissione}=\\frac{W*MSS}{RTT}\n\nR\\geq \\frac{W*MSS}{RTT}\nda questa considerazione  sopra si pu√≤ ritrovare W facendo la formula inversa\n\n\nPoi trovi il troughput medio\n\ntroughput \\ medio = \\frac{3}{4}*\\frac{W_{max}*MSS}{RTT}\n\n\nPer trovare il tempo impiegato per raggiungere la dimensione massima\n\n(W_{max}-\\frac{W_{max}}{2} )*RTT\n\n\n"},"UNI/ANNO-2/RETI/ESERCIZI/TRASPORTO/LISTA-COMANDI-diagnostica":{"slug":"UNI/ANNO-2/RETI/ESERCIZI/TRASPORTO/LISTA-COMANDI-diagnostica","filePath":"UNI/ANNO 2/RETI/ESERCIZI/TRASPORTO/LISTA COMANDI diagnostica.md","title":"LISTA COMANDI diagnostica","links":[],"tags":[],"content":"ss -s statistiche sulle socket\n\nmostra quali socket sono all‚Äôattivo per determinati protocolli\n\n\nss-u -ua\n\nu specifica socket UDP\nua specifica anche le socket che non hanno connessioni all‚Äôattivo\n\n\naltri comandi di ss\n\n\n\nn toglie le traduzioni automatiche delle porte\nquindi indirizzo:http  ora si vedr√† come indirizzo:80\n\n\n\n\np informazioni sul processo\n\n\n\n\nE socket distrutte\n\n\n\ndig\neffettua richiestaa un server DNS\n\nWireshark\nanalizza i pacchetti inviati e ricevuti nella rete\n\nha dei filtri che consentono di vedere determinati pacchetti\n\nip addr\nmostra indirizzi IP delle varie interfacce di rete del dispositivo"},"UNI/ANNO-2/RETI/ESERCIZI/VARI-COMANDI-MISTI":{"slug":"UNI/ANNO-2/RETI/ESERCIZI/VARI-COMANDI-MISTI","filePath":"UNI/ANNO 2/RETI/ESERCIZI/VARI COMANDI MISTI.md","title":"VARI COMANDI MISTI","links":[],"tags":[],"content":"COMANDI LIVELLO DI TRASPORTO\nss -s statistiche sulle socket\n\nmostra quali socket sono all‚Äôattivo per determinati protocolli\n\n\nss-u -ua\n\nu specifica socket UDP\nua specifica anche le socket che non hanno connessioni all‚Äôattivo\n\n\naltri comandi di ss\n\n\n\nn toglie le traduzioni automatiche delle porte\nquindi indirizzo:http  ora si vedr√† come indirizzo:80\n\n\n\n\np informazioni sul processo\n\n\n\n\nE socket distrutte\n\n\n\ndig\neffettua richiesta un server DNS\n\nWireshark\nanalizza i pacchetti inviati e ricevuti nella rete\n\nha dei filtri che consentono di vedere determinati pacchetti\n\nip addr\nmostra indirizzi IP delle varie interfacce di rete del dispositivo\nCOMANDI LIVELLO DI RETE\nüß™ Obiettivo generale\n\nImparare a usare ping in modo avanzato per:\n\n\n\nVerificare la raggiungibilit√† di un host\n\n\nCalcolare l‚ÄôRTT (Round Trip Time)\n\n\nStudiare pacchetti ICMP e opzioni di invio\n\n\nCapire l‚Äôeffetto del TTL, del timeout e della dimensione del pacchetto\n\n\n‚úÖ Esercizio 1 ‚Äì ping base + Wireshark\n\nSi esegue ping www.google.it, si interrompe con CTRL+C.\nViene inviato ogni secondo un pacchetto ICMP Echo Request.\n\nserve per capire se un host √® raggiungibile\n\n\nOgni risposta √® un Echo Reply, che include:\n\nNumero sequenza (icmp_seq)\nTempo di ritorno (time)\nTTL (dal pacchetto IP)\n\n\nIn Wireshark si filtra con icmp per vedere i pacchetti.\n\n‚úÖ Esercizio 2 ‚Äì Opzione -c (count)\n\nping -c 1 www.google.it\nInvia n pacchetti in questo caso 1.\n\n‚úÖ Esercizio 3 ‚Äì Opzione -w (deadline)\n\nping -w 3 www.google.it\nEsegue ping per al massimo 3 secondi, indipendentemente dal numero di pacchetti.\nPing invia un pacchetto ogni secondo ‚Üí si ricevono 3 pacchetti prima dello stop.\n\n‚úÖ Esercizio 4 ‚Äì Opzione -i (intervallo)\n\nping -i 1.495 -w 3 www.google.it\nCambia l‚Äôintervallo tra un pacchetto e il successivo.\nServe a simulare invii pi√π frequenti o pi√π lenti.\nSe combinato con -w, pu√≤ causare perdita di pacchetti perch√© non si lascia tempo sufficiente alla risposta.\ncambia la frequenza\n\n‚úÖ Esercizio 5 ‚Äì Combinazione -i -c -w\n\nping -i 1.495 -c 3 -w 3 www.google.it\nInvia 3 pacchetti ma scade a 3 secondi ‚Üí non fa in tempo a ricevere l‚Äôultimo ACK.\nMostra che il timeout √® importante anche se i pacchetti sono stati inviati correttamente.\n\n‚úÖ Esercizio 6 ‚Äì Opzione -W (timeout risposta)\n\nping -W 1 -c 1 www.google.it: aspetta 1 secondo per la risposta.\nping -W 0.01 -c 1 www.google.it: timeout troppo basso ‚Üí perdita pacchetto.\nMostra come un RTT alto pu√≤ portare a false perdite se il timeout √® troppo breve.\n\n‚úÖ Esercizio 7 ‚Äì Opzione -s (dimensione dati ICMP)\n\nping -s 10 www.google.it\nCambia la dimensione del payload ICMP (non del pacchetto IP totale).\nSotto i 16 byte, ping non pu√≤ calcolare l‚ÄôRTT perch√© manca il timestamp.\nUtile per testare quanto i dati influenzano la risposta.\n\n‚úÖ Esercizio 8 ‚Äì Opzione -t (TTL - Time To Live)\n\nping -t 11: limita il TTL ‚Üí pacchetto viene fermato da un router intermedio.\nIl router invia un messaggio ICMP ‚ÄúTime Exceeded‚Äù.\nping -t 12: pacchetto raggiunge la destinazione.\nServe a determinare quanti hop ci sono tra sorgente e destinazione (come fa traceroute).\n\nCOMANDI LIVELLO DI COLLEGAMENTO\nCOMANDI IP\nüîπ ip link\nGestisce le interfacce di rete\n\nüîç Mostra interfacce\nip link (o ip link show)\n‚Üí Elenca tutte le interfacce di rete\nüìä Mostra statistiche\nip -s link show dev eth0\n‚Üí Statistiche RX/TX (byte, pacchetti, errori, ecc.)\n‚õî Disattiva interfaccia\nsudo ip link set eth0 down\n‚úÖ Riattiva interfaccia\nsudo ip link set eth0 up\n\nüîπ ip address\nMostra o gestisce indirizzi IP associati alle interfacce\n\nüîç Mostra indirizzi IP\nip address (o ip addr show)\n‚Üí Elenca indirizzi IPv4/IPv6 di tutte le interfacce\nüîé Filtri utili\n\nip address show up ‚Üí Solo interfacce attive\nip address show dev eth0 ‚Üí Solo eth0\nip address show scope global ‚Üí Solo globali\nip address show to 172.0.0.0/8 ‚Üí Solo questo range\n\n\n\nüîπ ip route\nGestisce la tabella di routing (instradamento)\n\nüîç Mostra tabella di routing\nip route\n‚Üí Mostra le rotte (es. default, reti locali)\nüìÅ Salva e ripristina la tabella di routing\nip route save &gt; route.txt sudo ip route flush table main sudo ip route restore &lt; route.txt\nüîé Filtri utili\n\nip route show dev eth0 ‚Üí Solo rotte per eth0\nip route show via 172.0.0.0/8 ‚Üí Next hop nel range\nip route show to root 0/0 ‚Üí Tutte le rotte (default + locali)\n\n\nüì¶ Trova la rotta per una destinazione\nip route get 8.8.8.8\n‚Üí Mostra via quale interfaccia/gateway va un pacchetto\n\nüîπ ip neighbour\nGestisce la tabella ARP (associazioni IP-MAC)\n\nüîç Mostra tabella ARP\nip neigh (o ip neigh show)\n‚Üí Mostra IP, MAC e stato (es. REACHABLE)\nüîé Filtri utili\n\nip neigh show dev eth0 ‚Üí Solo eth0\nip neigh show to 172.0.0.0/8\nip neigh show nud reachable ‚Üí Solo MAC raggiungibili\n\n\nüîé Consulta una specifica entry ARP\nip neigh get 172.21.240.1 dev eth0\n‚Üí Mostra il MAC per un IP noto\nüßπ Svuota la tabella ARP\n\nTutto: sudo ip neigh flush dev eth0\nSolo voci ‚Äúvecchie‚Äù: sudo ip neigh flush nud stale dev eth0\n\n\n\nComandi per il networking virtuale\nüî∏ 1. Network Namespace (netns)\nUno stack di rete isolato: ogni host virtuale avr√† il suo.\n\n‚ûï Creazione:\nsudo ip netns add hostA\nüîç Lista dei namespace:\nip netns list\n‚ùå Eliminazione:\nsudo ip netns del hostA\nüñ•Ô∏è Avviare una shell in un namespace:\nsudo ip netns exec hostA /bin/bash\n‚ñ∂Ô∏è Eseguire comandi in un namespace:\nsudo ip netns exec hostA &lt;comando&gt;\n\nüî∏ 2. Interfacce Virtuali (veth)\nSimulano un cavo Ethernet tra due dispositivi/namespace.\n\n\n‚ûï Creazione di una coppia veth:\nsudo ip link add vethA type veth peer name vethA-switch1\n\n\n‚ùå Eliminazione di un veth:\nsudo ip link del vethA\n\n\nüîÅ Spostare una veth in un namespace:\nsudo ip link set vethA netns hostA\n\n\nüî∏ 3. Bridge di rete (switch virtuale)\nSimula uno switch Ethernet.\n\n\n‚ûï Creazione del bridge:\nsudo ip link add name switch1 type bridge\n\n\nüîó Collegare le veth al bridge:\nsudo ip link set vethA-switch1 master switch1\n\n\n‚úÖ Attivare bridge e interfacce:\nsudo ip link set switch1 up sudo ip link set vethA-switch1 up\n\n\nüî∏ 4. Configurazione rete nel namespace\n\n\nüñ•Ô∏è Rinominare vethA in eth0 nel netns hostA:\nip netns exec hostA ip link set vethA name eth0\n\n\nüåê Assegnare indirizzo IP e attivare interfacce:\nip netns exec hostA ip addr add 10.0.1.10/24 br+ dev eth0 ip netns exec hostA ip link set eth0 up ip netns exec hostA ip link set lo up\n\n\nüî∏ 5. Router virtuali\n\n\n‚ûï Creazione namespace del router:\nsudo ip netns add router2\n\n\nüåê Assegnare IP e attivare interfacce del router:\nip netns exec router2 ip addr add 10.0.2.1/24 dev vethR2S2 ip netns exec router2 ip link set vethR2S2 up ip netns exec router2 ip link set lo up\n\n\nüîÅ IP forwarding nel router:\nip netns exec router2 sysctl -w net.ipv4.ip_forward=1\n\n\nüìç Aggiungere rotte statiche nel router:\nip netns exec router2 ip route add 10.0.1.0/24 via 10.0.4.1 ip netns exec router2 ip route add 10.0.3.0/24 via 10.0.4.6\n\n\nüî∏ 6. Instradamento degli host\n\n\n‚û°Ô∏è Aggiunta della rotta di default:\nip route replace default via 10.0.1.1\n\n\nTRACEROUTE\nüìå COSA FA traceroute\n\nMostra il percorso (hop per hop) che i pacchetti fanno da te verso una destinazione (es. www.google.it)\nOgni riga = un router attraversato\nViene usato il TTL (Time To Live) per forzare la risposta dei router intermedi\n\nüîß COMANDI PRINCIPALI\nüîπ 1. Installazione (se serve)\nsudo apt install inetutils-traceroute\nüîπ 2. Uso base\ntraceroute www.google.it\n\nMostra fino a 64 hop\nPer ogni hop: 3 tentativi (RTT - round trip time)\n* = nessuna risposta (pu√≤ essere firewall o perdita)\n\nüîπ 3. Protocollo alternativo: ICMP\ntraceroute -M icmp www.google.it\n\nUsa pacchetti ICMP Echo Request (come ping)\nPermette di confrontare i percorsi ICMP vs UDP\nPercorsi diversi ‚áí routing diverso per tipo di pacchetto\n\nüîπ 4. Limitare numero massimo di hop\ntraceroute -m 2 www.google.it\n\nMostra solo i primi 2 hop\nUtile per debug dei primi passaggi di rete\nSe non arriva a destinazione, lo vedi dal codice di uscita:\necho &quot;$?&quot;  # 0 = successo, 1 = fallito\n\nüîπ 5. Ping con TTL personalizzato\nping -t 13 -c 1 142.250.180.131\n\nLimita TTL a 13\nSe TTL √® troppo basso, ricevi errore Time to live exceeded\nVerifica con:\nbash\nCopiaModifica\necho &quot;$?&quot;  # 0 = ricevuto, 1 = fallito\n\nüïµÔ∏è‚Äç‚ôÇÔ∏è Con Wireshark\n\nCattura i pacchetti durante il traceroute\nVedrai:\n\nUDP con TTL crescente (1, 2, 3‚Ä¶)\nICMP ‚ÄúTTL Exceeded‚Äù dai router intermedi\nICMP ‚ÄúPort Unreachable‚Äù dal server finale (perch√© la porta √® casuale, tipo 33434)\n\n\n\nROUTING\nüß† TEMA: Tabella di instradamento e invio pacchetti\nüîπ 1. COMANDO ip route\nVisualizza la tabella di instradamento, cio√® l‚Äôelenco delle reti raggiungibili e come raggiungerle.\nEsempio:\n$ ip route default via 172.20.0.1 dev eth0 172.20.0.0/20 dev eth0 src 172.20.4.226 172.30.0.0/20 dev eth1 src 172.30.1.5 172.50.0.0/20 via 172.30.0.1 dev eth1 172.50.8.0/24 via 172.20.0.10 dev eth0\nüìå Tipi di rotta:\n\n\nDiretta (scope link) ‚Üí la rete √® sulla stessa interfaccia\n\n\nIndiretta (via ‚Ä¶) ‚Üí serve un router\n\n\nDefault route ‚Üí usata se nessuna altra corrisponde\n\n\nüìå Regola importante:\nüëâ Viene scelta la rotta con il prefisso pi√π lungo (longest prefix match).\nüîπ 2. COMANDO ip route get &lt;IP&gt;\nMostra la rotta selezionata per un indirizzo specifico, es:\nip route get 172.20.5.10\n\n\nMostra interfaccia (dev)\n\n\nIndirizzo sorgente (src)\n\n\nRouter (via, se presente)\n\n\n\nüîπ 3. CASI PRATICI (semplificati)\nüÖ∞Ô∏è 172.20.5.10\n\n\nAppartiene alla rete 172.20.0.0/20\n\n\nRotta diretta ‚Üí dev eth0, src 172.20.4.226\n\n\nInvio diretto senza router\n\n\nüÖ±Ô∏è 172.20.26.10\n\n\nNon appartiene a 172.20.0.0/20\n\n\nUsata la default route ‚Üí via 172.20.0.1 su eth0\n\n\nRotta indiretta (passa da router)\n\n\nüÖæÔ∏è 172.50.0.7\n\n\nAppartiene a 172.50.0.0/20\n\n\nRotta via 172.30.0.1 ‚Üí dev eth1, src 172.30.1.5\n\n\nRotta indiretta (passa da router)\n\n\n\nüîπ 4. INDIRIZZI A LIVELLO IP E MAC\nQuando un host manda un pacchetto:\n‚úÖ Livello IP (rete):\n\n\nsorgente: scelto da src nella rotta\n\n\ndestinazione: IP finale, non cambia durante l‚Äôinstradamento\n\n\n‚úÖ Livello MAC (collegamento):\n\n\nsorgente: MAC dell‚Äôinterfaccia usata (ip link)\n\n\ndestinazione:\n\n\nse rotta diretta ‚Üí MAC del destinatario\n\n\nse rotta indiretta ‚Üí MAC del router (next hop)\n\n\n\n\nüõ†Ô∏è Se MAC non noto ‚Üí cercato in tabella ARP oppure inviando richiesta ARP\nüìå RICORDA\n\n\nRouter cambiano solo gli indirizzi MAC, non quelli IP\n\n\nLa scelta del src dipende sempre dalla rete associata all‚Äôinterfaccia\n\n\nSe pi√π rotte corrispondono, vince quella con prefisso pi√π lungo\n\n\nüß† ARGOMENTO: Virtual networking (parte 2), ARP, ping, traceroute\n\nüß∞ 1. Network namespace: shell dedicata\n\n\nPer entrare in una shell nel namespace hostA:\nbash\nCopiaModifica\nsudo ip netns exec hostA /bin/bash\n\n\nPer farlo con l‚Äôutente corrente e prompt personalizzato:\nbash\nCopiaModifica\nPS1=&#039;\\u@$(ip netns identify $$):\\W] &#039; sudo ip netns exec hostA sudo -u $USER /bin/bash --noprofile --norc\n\n\n\nüß≠ 2. Routing base: Host A\nbash\nCopiaModifica\nip route\n\n\n10.0.1.0/24 ‚Üí diretto via eth0\n\n\ndefault via 10.0.1.1 ‚Üí gateway per tutte le reti esterne\n\n\n\nüßπ 3. Tabella ARP\n\n\nVisualizza ARP:\nbash\nCopiaModifica\nip neigh\n\n\nSvuota tabella:\nbash\nCopiaModifica\nsudo ip neigh flush dev eth0\n\n\n\nüß™ ESEMPIO 1: Ping da Host A a Host B (stessa sottorete)\nüì¶ Pacchetti scambiati:\n\n\nRichiesta ARP per trovare MAC di 10.0.1.20\n\n\nRisposta ARP ‚Üí IP 10.0.1.20 = MAC 42:3e:e5:36:27:f9\n\n\nICMP Echo Request\n\n\nICMP Echo Reply\n\n\nüìå IP: da 10.0.1.10 a 10.0.1.20\nüìå MAC: da Host A ‚Üí Host B\nüëâ Instradamento diretto\n\nüß™ ESEMPIO 2: Ping da Host A a Host F (rete diversa)\nüì¶ Pacchetti scambiati:\n\n\nARP per trovare MAC di 10.0.1.1 (il router)\n\n\nRisposta ARP\n\n\nICMP Echo Request\n\n\nICMP Echo Reply\n\n\nüìå IP: da 10.0.1.10 a 10.0.3.20\nüìå MAC (primo tratto): da Host A a Router 1\nüëâ Instradamento indiretto via router\n\nüõ∞Ô∏è Router 1: inoltro pacchetti\n\n\nInoltra l‚ÄôEcho request a 10.0.3.20 passando per 10.0.4.2\n\n\nVerifica e aggiorna MAC via ARP\n\n\nICMP non cambia IP, ma cambia MAC a ogni hop\n\n\n\nüîé Traceroute da Host A a Host F\nbash\nCopiaModifica\ntraceroute 10.0.3.20\nEsempio output:\nCopiaModifica\n1  10.0.1.1 2  10.0.4.2 3  10.0.4.6 4  10.0.3.20\n\nüì° arping ‚Äì Test ARP manuali\n‚úÖ Richiesta ARP (manuale)\nbash\nCopiaModifica\nsudo arping -c 1 10.0.1.20\n‚úÖ Probe ARP (controlla se un IP √® gi√† usato)\nbash\nCopiaModifica\nsudo arping -I eth0 -c 1 -S 0.0.0.0 10.0.1.10\n‚úÖ Announcement ARP (annuncia IP con MAC aggiornato)\nbash\nCopiaModifica\nsudo arping -I eth0 -c 1 -A 10.0.1.10\nüìå Serve per aggiornare la tabella ARP degli altri host se qualcuno ha una voce vecchia.\n\nüß™ Caso avanzato: sostituzione entry ARP\nForzare entry nella tabella ARP:\nbash\nCopiaModifica\nip neigh replace 10.0.1.10 lladdr 11:11:11:11:11:11 nud reachable dev eth0\nReset comportamento ARP:\nbash\nCopiaModifica\nsudo sysctl -w net.ipv4.conf.eth0.arp_accept=1"},"UNI/ANNO-2/RETI/INDICE-RETI":{"slug":"UNI/ANNO-2/RETI/INDICE-RETI","filePath":"UNI/ANNO 2/RETI/INDICE RETI.md","title":"INDICE RETI","links":["UNI/ANNO-2/RETI/1.LIVELLO-DI-APPLICAZIONE","UNI/ANNO-2/RETI/2.LIVELLO-DI-TRASPORTO","UNI/ANNO-2/RETI/3.LIVELLO-DI-RETE","UNI/ANNO-2/RETI/4.LIVELLO-DI-COLLEGAMENTO","UNI/ANNO-2/RETI/RETI-LEZ.1","UNI/ANNO-2/RETI/RETI-LEZ.2","UNI/ANNO-2/RETI/RETI-LEZ.3","UNI/ANNO-2/RETI/RETI-LEZ.4","UNI/ANNO-2/RETI/RETI-LEZ.5","UNI/ANNO-2/RETI/RETI-LEZ.6","UNI/ANNO-2/RETI/RETI-LEZ.7","UNI/ANNO-2/RETI/RETI-LEZ.8","UNI/ANNO-2/RETI/RETI-LEZ.9","UNI/ANNO-2/RETI/RETI-LEZ.10","UNI/ANNO-2/RETI/RETI-LEZ.11","UNI/ANNO-2/RETI/RETI-LEZ.12","UNI/ANNO-2/RETI/RETI-LEZ.13","UNI/ANNO-2/RETI/RETI-LEZ.14","UNI/ANNO-2/RETI/RETI-LEZ.15","UNI/ANNO-2/RETI/RETI-LEZ.16","UNI/ANNO-2/RETI/RETI-LEZ.17","UNI/ANNO-2/RETI/RETI-LEZ.18","UNI/ANNO-2/RETI/RETI-LEZ.19","UNI/ANNO-2/RETI/RETI-LEZ.20","UNI/ANNO-2/RETI/RETI-LEZ.21","UNI/ANNO-2/RETI/RETI-LEZ.22","UNI/ANNO-2/RETI/RIPASSO","UNI/ANNO-2/RETI/ESERCIZI/APPLICAZIONE/CALCOLO-RITARDI","Convertire-unit√†-di-misura","UNI/ANNO-2/RETI/ESERCIZI/TRASPORTO/LISTA-COMANDI-diagnostica","UNI/ANNO-2/RETI/ESERCIZI/RETE/ESERCIZI-PIANO-DATI","UNI/ANNO-2/RETI/ESERCIZI/RETE/ESERCIZI-PIANO-DI-CONTROLLO","UNI/ANNO-2/RETI/ESERCIZI/RETE/COMANDO-PING"],"tags":[],"content":"1.LIVELLO DI APPLICAZIONE\n2.LIVELLO DI TRASPORTO\n3.LIVELLO DI RETE\n4.LIVELLO DI COLLEGAMENTO\nRETI LEZ.1\nRETI LEZ.2\nRETI LEZ.3\nRETI LEZ.4\nRETI LEZ.5\nRETI LEZ.6\nRETI LEZ.7\nRETI LEZ.8\nRETI LEZ.9\nRETI LEZ.10\nRETI LEZ.11\nRETI LEZ.12\nRETI LEZ.13\nRETI LEZ.14\nRETI LEZ.15\nRETI LEZ.16\nRETI LEZ.17\nRETI LEZ.18\nRETI LEZ.19\nRETI LEZ.20\nRETI LEZ.21\nRETI LEZ.22\nRIPASSO\nEsercizi\nApplicazione\nCALCOLO RITARDI\nConvertire unit√† di misura\nTrasporto\nLISTA COMANDI diagnostica\nRete\nESERCIZI PIANO DATI\nESERCIZI PIANO DI CONTROLLO\nCOMANDO PING"},"UNI/ANNO-2/RETI/RETI-LEZ.1":{"slug":"UNI/ANNO-2/RETI/RETI-LEZ.1","filePath":"UNI/ANNO 2/RETI/RETI LEZ.1.md","title":"RETI LEZ.1","links":[],"tags":[],"content":"parti fondamentali di internet\ngli host ospitano le applicazioni di rete, vengono anche chiamati end system si dividono in:\n\nclient, chiedono servizi\nserver, forniscono servizi\nil browser √® lo user-agent che consente la comunicazione all‚Äôinterno della rete\nall‚Äôinterno della rete non abbiamo gli host, essi sono parte esterna di esso come anche i client\nall‚Äôinterno della rete abbiamo i vari router e switch e ci consentono di commutare i vari pacchetti\n\n\n\n                  \n                  per commutare si intende l&#039;instradamento e la gestione dei vari pacchetti all&#039;interno di una rete \n                  \n                \n\n\nper far comunicare tra loro i vari router switch host ecc‚Ä¶ abbiamo bisogno di\nreti di collegamento\ncome rame fibra ecc‚Ä¶ che hanno un loro tasso di trasmissione(pratico) e una loro ampiezza di banda(teorico)\nInternet non √® uniforme bens√¨ √® una serie di reti composte a loro volta da\n\ndispositivi, router, collegamenti ecc‚Ä¶\n\nChi ci fornisce internet?\ngli ISP(Internet Service Provider)\nInternet √® un insieme di ISP connessi tra loro\nConcetto di IoT\ninternet delle cose, dove per ‚Äúcose‚Äù si intendono tutti quegli oggetti che un tempo non erano connessi a internet ma ora lo sono\nI dispositivi devono comunicare attraverso dei protocolli\ni protocolli sono un insieme di regole che consentono e gestiscono l‚Äôinvio e la ricezione di messaggi\n\nhttp,streaming video, skype, tcp, ip, ethernet, wifi 4-5g ecc‚Ä¶\nil protocollo di un messaggio indica esattamente\nil loro formato\nl‚Äôordine di invio\nazioni intraprese in fase di trasmissione o ricezione di un messaggio o un evento\n\n\nStandard che danno delle garanzie sulle varie compatibilit√† di internet\n\nRFC\nIETF\naltri standard che lavorano su reti metropolitane oppure ethernet e Wi-Fi\nprotocolli Wi-Fi definiti da IEE come 802.11\n\ninternet cosa √®\ninternet √® una infrastruttura globale di reti che fornisce un servizio di comunicazione alle varie applicazioni e dispositivi\nInternet √® un po come le poste, ci da la possibilit√† di avere pi√π servizi di comunicazione\nl‚Äôinterfaccia socket ci serve per usare e definire una connessione a internet tra processi e applicazioni\nle reti di accesso\nil primo router usato per uscire da una rete LAN a una WAN si chiama router edge\ncosa importa?\n\nvelocit√† di trasmissione\nuna forma primitiva di rete di accesso internet √® sicuramente quella con il modem 56k\npoi ci fu una evoluzione con la DSL\n\nIl provider dar√† un DSLAM un dispositivo che collega pi√π linee da parte del provider\nviene usato quindi un doppino per le basse frequenze le chiamate per le alte frequenze internet chiamato multiplexing a divisione di frequenza\nnoi abbiamo un collegamento dedicato con la centrale operativa\n√® normale ci sia differenza tra download e upload dovuto a un limite fisico\n\nDifferenza tra i vari punti di accesso FTTx\n\nFTTH di tipo PON\nsistemi non alimentati passivi\n\nsono composti dai seguenti dispositivi OLT e ONT\n\nOLT: √® da parte del provider e viene usato per fare da intermediario tra internet della centrale locale e i vari ONT\nViene usato uno splitter ottico per indirizzare i pacchetti ad ogni ONT, essendo passivo lo invia ad ogni ONT\nONT: rappresentano un terminatore di fibra che viene condiviso nelle singole abitazioni\nla potenza viene suddivisa quindi per ogni ONT\nper l‚Äôupload viene usato il TDM Time division multiplexing per dividere il tempo di uso di upload dal ONT al OLT\nFWA(Fixed Wireless Access)\nwireless != mobile\n\n\nReti locali wireless o Accesso wireless su scala geografica\nLocali centinaia di metri di copertura\n\nGeografica kilometri di copertura\n\nINVIO DEI PACCHETTI DI DATI\nIl tutto viene suddiviso in sotto pacchetti con un tempo di trasmissione R e una lunghezza dei pacchetti L quindi abbiamo un ritardo di trasmissione dato da \\frac{L}{R}\nMezzi vincolati e mezzi non vincolati\n\nmezzi vincolati sono obbligati a propagarsi su mezzi solidi\nmezzi non vincolati tipo wireless o radio\n\nTipi di cavi\n\ncavo ethernet\n\ncategoria 5-6\n\ncambia la velocit√† e la distanza\n\n\n\n\ncavo coassiale\n\nconnettori di rami a banda larga\n\n\ncavo in fibra ottica\n\nsi attenua poco alle distanze e alle interferenze elettromagnetiche\n\n\n\nsegnali wireless\n\ncanali radio\n\nsegnale elettromagnetico\nbroadcast quindi non si pu√≤ parlare contemporaneamente\nriflessione dell‚Äôonda ostruzione ecc‚Ä¶\n\n\nBluetooth\n\nbrevi distanze con PAN Personal area network\n\n\nWireless LAN\nmicroonde terrestri\n\npunto punto\n\n\nsatellitari\n\ntipo star-link\n3 tipi di orbite\n\nLEO\n\norbita bassa\n\n\nMEO\n\norbita media\n\n\nGEO\n\norbita geostazionaria ad alta distanza quindi rimane sempre nello stesso punto\n\n\n\n\n\n\n\n"},"UNI/ANNO-2/RETI/RETI-LEZ.10":{"slug":"UNI/ANNO-2/RETI/RETI-LEZ.10","filePath":"UNI/ANNO 2/RETI/RETI LEZ.10.md","title":"RETI LEZ.10","links":[],"tags":[],"content":"TCP\n\n√à un protocollo di trasporto punto a punto\n\ncrea una connessione diretta (1,1) tra mittente e destinatario\n\n\nI dati sono trasmessi come un unico flusso di byte sicuri, i byte devono arrivare correttamente e senza perdite\nFull duplex, ovvero connessione bidirezionale simultanea\nMSS √® un dato che rappresenta la grandezza massima di dati di un singolo segmento\n\nescludiamo per√≤ l‚Äôintestazione\n\n\nSpesso gli ACK possono essere accumulati cos√¨ posso confermare pi√π segmenti con un singolo ACK\nconcetto di pipelining visto anche in rdt che applica anche\n\nhandshaking tra i due(viene stabilita una connessione sicura)\ncontrollo su cose come flusso e congestione adattando le varie velocit√† di trasmissione e ridurre cos√¨ il traffico\n\n\n\nFoto dettagliata di come funziona\n\nMSS cosa √®\n\nin questa immagine abbiamo un segmento TCP diviso in pi√π strati\n\nil primo arancione √® il segmento gestito dal TCP diviso tra H_t+dati\n\nMSS √® la lunghezza solo dei dati\n\n\nil secondo verde √® quello del protocollo IP che contiene anche quello TCP\npoi il terzo blu √® quello vero e proprio che √® tutto l‚Äôinsieme, i dati sono lunghi quanto una variabile MTU\n\nc‚Äô√® anche un T_i che indica un altra collezione di dati detto trailer per fare tipo controlli o cose varie\nCalcoli vari\n\n\novviamente MTU deve essere &gt;= a MSS+H‚Çú+H‚Çô\n\n\n\n                  \n                  esempio \n                  \n                \n\n\n\nMTU = 1500 byte\n\n\nH‚Çô = 20 B (IPv4),\n\n\nH‚Çú = 20 B (TCP)\n‚áí MSS = 1460 byte\nfa la formula inversa per ricavare MSS\n\n\n\n\nQuando due dispositivi fanno handshake TCP possono anche scambiarsi il valore MSS\n\ncos√¨ sanno quanto possono scambiarsi\nper impostare un determinato valore MSS si scrive su un pacchetto TCP SYN scambiato tra i due\nQuesto permette a entrambi di adattarsi al valore pi√π sicuro e compatibile.\nIl valore MTU pu√≤ variare lungo il percorso in base ai dispositivi che lo intercorrono\nusare Path MTU Discovery ci permette di scoprire automaticamente il min MTU\nevita frammenti o scarti di pacchetti\nSe si supera la MTU\ncon ipv4 viene frammentato il pacchetto\nipv6 li scarta e manda un errore al mittente\n\nSegmento PDU del TCP\npossiamo vedere in questa foto qua sotto come abbiamo una Protocol Data Unit del TCP\n\n\nL‚Äôimmagine rappresenta un vero e proprio segmento TCP, ovvero l‚Äôunit√† di dati del livello di trasporto, che contiene tutte le informazioni necessarie per la comunicazione tra mittente e destinatario ‚Äî come porte, numeri di sequenza, ACK, flag, dati applicativi ‚Äî e che viene effettivamente generato, trasmesso e memorizzato da entrambe le parti per garantire un trasferimento affidabile\n\ndescriviamo tutte le cose in modo migliore:\nüîπ 1. Porta origine (16 bit)\n\n\nNumero della porta TCP del mittente.\n\n\nServe per capire quale applicazione (es. browser, server web) ha generato i dati da inviare.\n\n\nüîπ 2. Porta destinazione (16 bit)\n\nPorta TCP del destinatario, che identifica l‚Äôapplicazione che deve ricevere i dati.\nEs: porta 80 per HTTP, 443 per HTTPS.\n\nüîπ 3. Numero di sequenza (32 bit)\n\nIndica il numero del primo byte inviato in questo segmento.\nTCP lavora a livello di byte, non di pacchetti!\nServe a ricostruire l‚Äôordine corretto dei dati.\n\nüîπ 4. Numero di acknowledgment (32 bit)\n\nCampo valido solo se il flag ACK √® attivo.\nIndica il numero del prossimo byte atteso, cio√®: ‚ÄúHo ricevuto tutto fino a questo punto‚Äù.\n\nüîπ 5. Lunghezza dell‚Äôintestazione (4 bit)\n\nSpecifica quanto √® lunga l‚Äôintestazione TCP, in multipli di 4 byte (32 bit).\nServe per capire dove iniziano i dati dell‚Äôapplicazione.\nLa lunghezza tipica √® 20 byte, se non ci sono opzioni.\n\nüîπ 6. Flag TCP (6 bit principali tra vari):\n\nURG: ci sono dati urgenti\nACK: acknowledgment valido\nPSH: consegna immediata all‚Äôapplicazione\nRST: resetta la connessione (es. errore)\nSYN: inizio connessione (handshake)\nFIN: fine della trasmissione\nüß† RST, SYN, FIN sono usati nella gestione della connessione.\n\nüîπ 7. Finestra di ricezione (16 bit)\n\nUsata per il controllo di flusso: indica quanti byte il destinatario √® pronto a ricevere.\nServe al mittente per non sovraccaricare il buffer del ricevente.\n\nüîπ 8. Checksum (16 bit)\n\nCalcolato su intestazione + dati.\nVerifica l‚Äôintegrit√† dei dati (come in UDP).\nSe il valore non torna, il pacchetto viene considerato danneggiato e scartato.\n\nüîπ 9. Puntatore ai dati urgenti (16 bit)\n\nUsato solo se il flag URG √® attivo.\nIndica dove finisce la parte urgente nei dati.\nOggi √® raramente usato.\n\nüîπ 10. Opzioni TCP (lunghezza variabile)\n\nArea facoltativa con estensioni utili come:\n\nMSS (Maximum Segment Size)\nTimestamp\nWindow Scaling\n\n\nNelle connessioni moderne, opzioni usate frequentemente per ottimizzare le prestazioni (soprattutto in reti ad alta latenza).\n\nüîπ 11. Dati dell‚Äôapplicazione\n\nSono i dati veri e propri generati dall‚Äôapplicazione (es. contenuto HTML, file, email‚Ä¶).\nTCP li riceve dall‚Äôapp tramite la socket TCP.\nLa lunghezza √® variabile, in base alla MSS e allo spazio disponibile.\n\nNumeri di sequenza e ACK di TCP\n\nogni byte ha un suo numero di sequenza che √® sequenziale al primo byte\n\nse il primo byte ha numero 3000 il successivo avr√† 3001 e cos√¨ via\nserve per identificarli\n\n\nil campo ACK number √® un campo che contiene il numero del prossimo byte che deve essere ancora confermato, se invio ACK 5000 significa che ho ricevuto tutto fino a 4999 e quindi attendo che il 5000 arrivi\n\nesiste quello selettivo che permette di non confermare in sequenza ma a pezzi\n\n\nnon sappiamo definire esattamente cosa succede se i byte vengono inviati non in ordine\n\ndipende dalle implementazioni\n\nin questa foto possiamo vedere come anche qui abbiamo una gestione a finestre che permette di salvare i vari numeri\nScambio tra due host evidenziando i vari Seq e ACK ‚Üí\n\n\n\n\nRound Trip Time RTT\n\nanche qui abbiamo un valore di timeout che una volta scaduto pu√≤ ad esempio reinviare un determinato byte\nquesto valore deve essere &gt; di RTT\n\nil tempo trascorso tra invio del segmento e l‚ÄôACK\nil problema √® che esso varia nel tempo\n\n\nse √® troppo piccolo avr√≤ ritrasmissioni non necessarie\nse √® troppo grande aumento la latenza\n\nCome stimarlo\n\nSample RTT √® il tempo che viene misurato della trasmissione di un segmento fino alla ricezione di un ACK, senza contare ritrasmissioni\nvisto che varia abbiamo bisogno di fare una media livellata(pesata) tra pi√π Sample RTT\n\nTutto si pu√≤ tradurre in una sommatoria dove:\n\n\n\nCalcolare il Timeout corretto\nIl timeout serve per capire quando ritrasmettere un segmento se l‚ÄôACK non arriva in tempo.\nTimeoutInterval=EstimatedRTT+4*DevRTT\ndove abbiamo:\n\nEstimatedRTT\n\nche √® il tempo stimato di Trasmissione\n\n\nDevRTT\n\n√® un valore che ci dice quanto siamo vicini alla stima rispetto ai singoli SampleRTT calcolati di volta in volta\n√à moltiplicato per 4 per dare un margine maggiore al singolo DevRTT\nPer trovare DevRTT andiamo ad applicare\n\n\n\n\nEventi di un mittente TCP(semplificato)\n\nricevi i dati dall‚Äôapplicazione(livello superiore)\ncrea un segmento con questi dati\nassegna un numero di sequenza dal primo byte\ninizia a inviare i segmenti e poi\navvia il timer applicando un TimeoutInterval\nSe il timeout scade:\ntimer scade e ACK non arrivato:\n\nritrasmette il segmento di byte scaduto\nriavvia il timer\ndurata del timeout raddoppiata\n\n\ntimer scade e ACK arrivato:\naggiorna il numero di sequenza dei byte inviati(SendBase)\nriavvia il timer per il prossimo segmento in attesa\n\nCasi in cui un ricevente invia gli ACK\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCasoDestinatario (ricevente TCP)Mittente TCP1Riceve segmento ordinato e atteso. Tutti i dati precedenti gi√† ricevuti.  üîπ Attende fino a 500 ms prima di inviare un ACK (ACK ritardato).Attende ACK.  Se non arriva entro il timeout, ritrasmette. Se arriva entro 500 ms, continua normalmente. (continua comunque a inviare le cose)2Riceve altro segmento ordinato mentre il primo √® in attesa di ACK.  üîπ Invia ACK cumulativo immediato.Riceve l‚ÄôACK.  Conferma pi√π dati, avanza la finestra e pu√≤ inviare nuovi segmenti.3Riceve segmento fuori ordine (numero di sequenza superiore).  üîπ Invia ACK duplicato, ripetendo il numero del byte atteso.Riceve ACK duplicato.  Dopo 3 ACK duplicati, attiva la Fast Retransmit e ritrasmette il segmento mancante.4Riceve segmento che colma il buco (tutto o parte).  üîπ Se il segmento inizia esattamente nel punto mancante, invia ACK immediato.Riceve ACK.  Conferma nuovi dati e riprende la trasmissione in modo ordinato.\nFoto esempi\n\n\n\n\nAl terzo ACK invia il segmento subito senza timeout vari\nApprofondimento sui controlli\nIl controllo di flusso\nEsso serve quando il livello di rete fornisce dati pi√π velocemente di quanti ne pu√≤ assimilare il livello applicativo, riempiendo di conseguenza tutto il buffer\n\n\nIl destinatario riesce a controllare il mittente per ridurre quante cose deve inviare andando a definire una receive window adatta\n\nApprofondimento su rwnd\nFa parte dell‚Äôintestazione TCP e appunto serve a indicare quanti byte il destinatario pu√≤ ancora ricevere esso viene calcolato da questa formula:\nrwnd=RcvBuffer‚àí(LastByteRcvd‚àíLastByteRead)\n\nRcvBuffer = dimensione totale del buffer di ricezione (es. 4096 byte)\nLastByteRcvd = ultimo byte ricevuto\nLastByteRead = ultimo byte consegnato all‚Äôapplicazione\n\novviamente abbiamo che\ndati¬†non¬†riscontrati ‚â§ rwnd\ni dati non riscontrati sono quei dati inviati ma che ancora non hanno un ACK di riscontro\n\nStabilire una connessione TCP con handshake\n\nprima di scambiare i dati entrambi\n\naccettano di stabilire una connessione\nconcordano i vari parametri come anche il rcvbuffer\n\n\n\n\n\nScenari possibili con handshake a 2 vie\nin questo caso abbiamo uno scambio perfetto di informazioni\n\nqui la la connessione viene stabilita ESTAB\nma viene inviata una doppia richiesta al server perch√© non viene dato abbastanza tempo per accettarla\n\nQui per sbaglio il client invia una nuova richiesta di connessione poich√© il server non fa in tempo ad inviare l‚ÄôACK\n\nEsempio con 3 way handshake che risolve i problemi sopra\nIn questo caso abbiamo un handshake che avviene in 3 passaggi\n\npassaggio 1:\n\nviene inviata una sincronizzazione attraverso un Synbit e specificando un codice di sequenza del client\nil server risponde con lo stesso Synbit che identifica la sincronizzazione e un suo numero di sequenza, inoltre l‚ÄôACK viene gestito cos√¨\n\nACKbit\n\nidentifica se √® da prendere in considerazione o meno 1 o 0\n\n\nACKnum\n\nidentifica a quale sequenza ci riferiamo\n\n\n\n\nil client rimanda una conferma con ACKnum ovviamente mettendolo anche valido con ACKbit\n\n\n\n\nBit di reset in questo tipo di connessione\nIl bit di reset RST √® un flag presente nell‚Äôintestazione\n\nserve per forzare la chiusura di una connessione\n\nusata tipo in errori critici\n\n\nse un host riceve una richiesta su una porta su cui nessuno √® in ascolto\n\ninvier√† RST=1 a quel client\n\n\nSe una delle due parti riceve un pacchetto sbagliato\n\ninvia RST=1\n\n\n\nUn segmento RST:\n\nRivela all‚Äôattaccante che la porta √® accessibile, anche se nessun servizio √® attivo\nQuindi:\n\n‚ÄúLa porta non √® usata da un processo, ma non √® nascosta da un firewall‚Äù\n\n\n\nFSM\n\nAttacco di tipo SYN FLOOD\n\nha come obiettivo quello di saturare le risorse del server mandando tantissime richieste di connessione senza per√≤ terminare le 3 fasi dell‚Äôhandshake\n\nüîÅ Fasi dell‚Äôattacco :\n\nüßë‚Äçüíª L‚Äôaggressore invia un gran numero di segmenti TCP SYN al server, ma con indirizzi IP fasulli (spoofati).\nüñ• Il server risponde a ognuno con un SYN-ACK e alloca risorse per la connessione (buffer, variabili‚Ä¶).\nüì° La rete prova a inoltrare i SYN-ACK agli IP falsi ‚Üí che non rispondono con l‚ÄôACK\n‚è± Il server rimane nello stato SYN_RCVD per un po‚Äô (anche 60+ secondi) in attesa dell‚ÄôACK ‚Üí connessioni mezze aperte.\nüí• Ripetendo l‚Äôattacco su larga scala, il server esaurisce le risorse (memoria, connessioni, socket) ‚Üí non riesce pi√π a gestire nuove richieste legittime.\n\nüß® Questo √® un classico esempio di DoS (Denial of Service), e se fatto in parallelo da pi√π sorgenti diventa un DDoS.\nUtilizzo di SYN Cookie per proteggere i server\n\nVogliamo evitare che il server allochi risorse per richieste false\nQuando arriva il SYN\nil server non salva nessun dato della connessione\n\ncalcola un cookie con le seguenti info\n\ncookie=hash(IPsrc,¬†IPdst,¬†portsrc,¬†portdst,¬†chiave \\¬†segreta)\n\n\nquest‚Äôultimo viene messo come numero di sequenza nel SYN-ACK\nnon abbiamo ancora allocato nulla\n\n\nse il client √® vero lui risponder√† con un ACKnum che corrisponde al cookie\nüîÑ Pu√≤ includere anche timestamp per evitare attacchi replay, ovvero ogni tot cambia la chiave che consente la generazione dei cookie\n\nChiudere una connessione TCP\nUsano entrambi il segmento TCP con il flag FIN impostato a 1\nognuno di loro deve farlo e si pu√≤ rispondere con un ACK combinato al FIN\n\nlo fa quando una delle due parti vuole sia confermare che l‚Äôaltro ha chiuso ma anche che lui sta chiudendo quindi fa ACK+FIN\n\n\nA manda: FIN\nB riceve e risponde con: ACK + FIN\nA riceve e risponde con: ACK\n\n\nin questa foto non li manda insieme ma fa due cose a s√®"},"UNI/ANNO-2/RETI/RETI-LEZ.11":{"slug":"UNI/ANNO-2/RETI/RETI-LEZ.11","filePath":"UNI/ANNO 2/RETI/RETI LEZ.11.md","title":"RETI LEZ.11","links":[],"tags":[],"content":"Differenza tra congestione üåê e controllo di flusso üåäüì∂\n\nControllo di flusso\n\nesso indica quando abbiamo un mittente che manda troppi pacchetti velocemente\n\n\ncongestione üåê\n\nquando n mittenti trasmettono tutto troppo velocemente\n√® un problema importantissimo del networking perch√© causa:\n\n\nritardi\nperdita di pacchetti\n\nCasistiche di congestione üåê\nScenario 1 üîµ\n\nabbiamo buffer illimitati\ncapacit√† di collegamento R\n\nla massima quantit√† di dati (in bit al secondo) che un collegamento pu√≤ trasportare\n\n\ndue flussi di comunicazione\nnessuna ritrasmissione üîÅ\n\nniente errori\n\n\n\n\nil tutto ovviamente √® cos√¨ perfetto da risultare lineare\n\n\n                  \n                  visto che il router e il collegamento √® condiviso tra due insiemi di host \n                  \n                \n\nappena si supera R/2 il collegamento subisce dei rallentamenti causando congestione üåê\novviamente visto che \\delta_in e \\delta_out escono in modo 1:1\nappena superano R/2 accade quanto detto\n\n\n\nScenario 2 üü¢\nabbiamo sempre\n\nun router\nper√≤ stavolta\nbuffer finiti\nla possibilit√† che alcuni pacchetti debbano essere ritrasmessi\n\nquando il buffer √® pieno\nAggiungiamo inoltre una differenza tra\n\n\ninput del livello di applicazione\n\n\\lambda_{in}\nnon include le ritrasmissioni\n\n\ninput del livello di trasporto\n\n\\lambda&#039;_{in}\ninclude le ritrasmissioni\nviene anche chiamato carico offerto alla rete\ncos√¨ facendo possiamo prendere per ovvio che\n\\lambda&#039;_{in} \\geq \\lambda_{in}\n\nPrendiamo una situazione ancora perfetta:\n\n\nil mittente sa se il buffer del router √® pieno oppure no\n\nprocede a inviare solo quando si pu√≤\nnon viene generata congestione üåê\ninput=troughput fino a R/2\n\nPrendiamo una situazione meno perfetta:\n\n\ni pacchetti possono essere scartati dal router quando il suo buffer √® pieno\nil mittente per√≤ sa quando ci√≤ accade quindi lo ritrasmette\n\nin questo caso si perde un po di troughput üìâ rispetto all‚Äôinput\n\nPrendiamo una situazione realistica\ni pacchetti vengono persi e scartati dal router\n\ncausa: buffer pieni üìõ\n√® richiesta una ritrasmissione üîÅ\nse il mittente invia un pacchetto ma a causa della congestione üåê esso √® rallentato üê¢\n\n\nallora quello che succede √® che l‚ÄôACK üì¨ che il mittente attendeva arriver√† in ritardo\nil mittente pensa che il pacchetto sia perso quindi entra in timeout ‚è±Ô∏èper l‚ÄôACK üì¨ non ricevuto\n\nrimanda il pacchetto\nsostanzialmente invia due copie uguali al destinatario\ntimeout ‚è±Ô∏è (prematuro perch√© non sa della congestione üåê)\n\n\n\n\nil troughput √® ridotto perch√© abbiamo pi√π lavoro inutile\n\nScenario 3 üü£\n\nabbiamo 4 mittenti\npercorsi multi- hop\n\nUn percorso multi-hop √® un tragitto in rete in cui i dati devono attraversare pi√π di un router o nodo intermedio per arrivare a destinazione.\n\n\n√® presente sia timeout ‚è±Ô∏è che ritrasmissione üîÅ\nLeggi la domanda e la risposta sotto:\n\nPerch√© vengono scartati? i pacchetti blu?\n\nsostanzialmente vengono scartati perch√© quelli rossi arrivano prima di quelli blu e quindi si prendono tutta la banda\nquelli rossi subiscono la congestione üåê\n\n\n\nquando abbiamo una congestione üåê i collegamenti upstream sono limitati e quindi stiamo sprecando la loro capacit√† trasmissiva\nin questo grafico si pu√≤ vedere come sia tutto altalenante\n\nRiassunto sui vari grafici üìä\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDescrizioneGrafico a destraüî∏ Il throughput non pu√≤ mai superare la capacit√†.üî∏ Il ritardo aumenta mentre ci si avvicina alla capacit√†.üî∏ La perdita/ritrasmissione üîÅ diminuisce il throughput effettivo.üî∏ I duplicati non necessari üóëÔ∏è diminuiscono ulteriormente il throughput effettivo.üî∏ Capacit√† a monte/buffer sprecati per pacchetti persi a valle.\nCome controllare la congestione üåêüß†üåê\nnetwork assisted\nSenza l‚Äôaiuto della rete(metodo che usa TCP)\n\ni dispositivi che si scambiano le info devono dedurre ci√≤ che accade\n\nattraverso il ritardo e le perdite dei pacchetti\n\nCon l‚Äôaiuto della rete\n\n\nper capirlo fa come il dottore, vede i sintomi\ni router forniscono un feedback diretto all‚Äôhost\n\nattraverso un pacchetto chiamato chokepacket\nlo avvisa dello stato di congestione üåê\n\n\nun router marca i pacchetti dicendo il suo stato di congestione üåê\n\nin modo che poi il destinatario li legga e informi il mittente della situazione\n\n\nservono non solo per indicare cause di congestione üåê ma anche solo impostare dei tassi a cui inviare i pacchetti\nviene usato nei protocolli\nTCP ECN\nATM\nDECbit\n\nRecuppino di trasmissione dati affidabile e controllo della congestione üìäüåê üåê üîÅüì°\n\ntrasmissione dati affidabile\n\nUna trasmissione dati affidabile consente di ridurre la perdita üìâ e la corruzione dei pacchetti\nqueste cose possono essere causate dalla congestione üåê\n\n\ncontrollo congestione üåê\n\nAvere un controllo della congestione üìäüåê üåê ci consente di risolverla o comunque di ridurla notevolmente\n\nevita il ‚Äúcollasso di congestione üåê‚Äú\n\n\n\n\n\nCambiamenti del TCP üîß\n\nin origine aveva un controllo di congestione üåê end-to-end\nora ci sono delle versioni pi√π recenti che consentono\n\ndi avere esplicitamente dalla rete le info sulla congestione üåê\n\n\n\ncome avere controllo sulla congestione end-to-end üåê üìà?\nper farlo si definisce un tasso di invio ovvero:\n\nquanti byte al secondo posso spedire?\n\nper saperlo si utilizza la finestra della congestione üåê\n\n\n\nIn questa foto ci interessa in particolare la cwnd congestion window\n\nche viene regolata dinamicamente in base allo stato di congestione üåê della rete\nil tasso di invio viene calcolato dalla seguente formula\n tasso \\ di \\ invio \\approx \\frac{cwnd}{RTT} \\ byte/s\n\n\nogni volta che vengono inviati i byte della finestra cwnd\n\nsi attende anche l‚ÄôRTT quindi si dimezzano\n\n\novviamente il mittente limita la trasmissione dei dati che saranno\n\nultimo\\_byte\\_inviato-ultimo\\_byte\\_acked\\leq cwnd\ndevono per forza di cosa essere minori uguali perch√©\n\nla differenza tra l‚Äôultimo byte inviato e l‚Äôultimo byte verificato ci porta a sapere quanti sono ancora in volo\novviamente il dato deve essere minore o uguale a quella che √® la nostra finestra di congestione üåê CWND\n\n\n\n\nNon bisogna porre solo attenzione al massimo della finestra della congestione üåê bens√¨ anche ai limiti della finestra del destinatario RWND\n\nquindi il numero di byte in volo deve essere anche \\leq rwnd\nultimo\\_byte\\_inviato-ultimo\\_byte\\_acked\\leq min \\{rwnd,cwnd\\}\n\n\n\n\n\n                  \n                  in realt√† si dovrebbe assumere che la finestra di ricezione rwnd sia comunque pi√π grande di quella di congestione üåê quindi si potrebbe anche trascurare \n                  \n                \n\ncome gestire il tasso di invio üïπÔ∏è\nora che sappiamo calcolarlo come facciamo per√≤ a gestirlo in relazione al fatto che non vogliamo che la congestione üåê peggiori?\n\nper farlo cerchiamo di punire o premiare il mittente in base ad una perdita presente o meno\nse c‚Äô√® una perdita dimezzo la velocit√† di invio\nse non avvengono aumento la velocit√† di 1MSS ad ogni RTT\n\nMSS: invio un segmento dati in pi√π ogni volta\nRTT: invio di un dato + feedback di rientro üì§üì•\nQuesto fenomeno viene chiamato AIMD\n\n\nsta per Additive Increase, Multiplicative Decrease\n\n\nTCP Reno üå™Ô∏è\n\n√à un algoritmo che implementa le idee di AIMD\n\ndimezza quando un triplo ACK üì¨ ha lo stesso numero di ACK üì¨\n\nentra poi nella fase di fast recovery(spiego meglio dopo)\n\n\nTaglio a 1 MSS quando abbiamo invece una perdita dovuta a un ACK üì¨ non ricevuto\n\nil timeout ‚è±Ô∏è √® scaduto\nTCP Tahoe √® una versione pi√π vecchia e semplice\n\n\n\n\nper qualsiasi perdita toglieva 1 MSS e passava a slow start\n\n\n\n                  \n                  attraverso questi algoritmi miglioriamo stabilit√† e congestione üåê generale \n                  \n                \n\nConcetto di slow start üê¢üí®\n\nla partenza √® con una frequenza bassa di invio\n\nma cresce esponenzialmente\nfino a quando non si verifica una perdita\n\n\ninizio:\n\ncwnd=1 MSS\n\n\ndurante:\n\ncwnd raddoppiato ad ogni RTT\n\n\nperdita:\n\nriduco gli MSS\n\n\n\n\nDa esponenziale a lineare üìâ‚û°Ô∏èüìà\n\navviene quando il cwnd assume pi√π della met√† del suo valore prima del timeout ‚è±Ô∏è\nper aggiustare il tiro viene usata la variabile sstresh\ntiene conto delle perdite per ridurle in futuro\n\nquando siamo in slow start cwnd cresce\ninizialmente sstresh=64 KB\nappena cwnd raggiunge in questo caso 64 KB\n\ncresce linearmente\n\n\nappena avviene un fault üö®\n\nsstresh=cwnd/2e\navviene una cosa in base al tipo di fault\nüü• Caso 1: fault tramite timeout ‚è±Ô∏è (grave)\n\n\n\n\ncwnd = 1 MSS ‚Üí si riparte da zero (fase di slow start)\nüîÅ TCP √® super prudente: pensa che la rete sia molto congestionata.\n\nüü¶ Caso 2: fault dovuto a triplo ACK üì¨ duplicato (meno grave, Reno)\n\nssthresh = cwnd / 2\ncwnd = ssthresh o poco sopra\nEntra in fast recovery(vedi tra poco), poi passa alla congestion avoidance\n\nMacchina a stati che chiede all‚Äôesame üßæ\n\n\n\n                  \n                  spiegazione(prova a farla da solo prima di leggere qua sotto) \n                  \n                \n\nspiegazione falla tra poco\n\n\n‚úÖ Riassunto: Controllo della Congestione TCP\nüîµ 1. Quando arriva un nuovo ACK üì¨\n\n\nIl mittente pu√≤ spostare in avanti la sua finestra di invio (scorre verso destra).\n\n\nQuesto significa che pu√≤ inviare nuovi segmenti, perch√© uno √® stato confermato (ACK üì¨ ricevuto) e quindi ‚Äúlibera spazio‚Äù.\n\n\nüü¢ 2. Fase di Congestion Avoidance üõ£Ô∏è\n\nLa finestra cwnd cresce lentamente, in modo lineare.\nPer ogni nuovo ACK üì¨ ricevuto:\n\nincremento=MSS*\\frac{MSS}{cwnd}\n\n\nIn un intero RTT, ci si aspetta un numero di ACK üì¨= \\frac{cwnd}{MSS}\nquindi abbiamo un incremento di 1 MSS ad ogni RTT perch√© si semplificano MSS e cwnd\nüîÅ Questo √® l‚Äôincremento additivo dell‚ÄôAIMD.\n\nüü† 3. Fase di Fast Recovery ‚ö°\n\nScatta dopo un triplo ACK üì¨ duplicato (segnale di perdita).\n\nIl mittente non avanza la finestra finch√© non arriva un ACK üì¨ nuovo.\nPer√≤: per ogni ACK üì¨ duplicato, TCP aumenta temporaneamente cwnd, per poter eventualmente trasmettere un nuovo pacchetto.\nun nuovo pacchetto quindi viene inviato circa ogni mezzo RTT\n\n\nAppena arriva l‚ÄôACK üì¨ del segmento perso, si esce dalla fast recovery.\n\nüî¥ 4. Durata della Fast Recovery ‚ö°\n\ntutta la fast dura circa 1 RTT, cio√® il tempo necessario affinch√© l‚ÄôACK üì¨ del segmento ritrasmesso torni al mittente.\n\nTCP CUBIC üì¶üöÄ\nAlgoritmo che cerca di sfruttare meglio le bande moderne che sono molto veloci\nrispetto a TCP Reno che cresceva linearmente, questo cresce di pi√π\n\ndato un W_{max}\n\nche indica la dimensione della finestra di quando √® avvenuta una perdita\n\n\nquando avviene una perdita si dimezza la velocit√† di trasmissione ma si ritorna pi√π velocemente a W_{max} avvicinandosi pi√π lentamente\n\npossiamo vedere da questa foto qua sopra come sia molto pi√π veloce\nPer capire quanto tempo ci metter√† per raggiungere la dimensione W_{max} si usa una variabile K\nappena si √® lontani da K significa che si pu√≤ andare pi√π veloci\nappena ci si avvicina bisogna essere pi√π cauti perch√© significa che ci si sta avvicinando al limite\ntutto ci√≤ √® calcolato da una funzione cubica che non stiamo a precisare con diversi parametri\nTCP cubic √® di default nei server linux\nil problema di questo TCP √® che si raggiunge ogni volta il collo di bottiglia\nsi intende che ogni volta si cerca di superare W_{max}\n\ninvece non si dovrebbe far straripare il buffer\nfoto che fa vedere che il buffer √® sempre strapieno e poi si creano problemi di congestione ‚ö†Ô∏è üåê\n\n\n\n\n\n\n                  \n                  quindi l&#039;obiettivo √® quello di tenere il buffer quasi pieno ma mai completamente \n                  \n                \n\n\nSoluzione: TCP vegas ‚ô†Ô∏èüéØ\nTCP Vegas √® una evoluzione di CUBIC, cerca sostanzialmente ogni volta di calcolare una stima di quello che pu√≤ essere il limite per non raggiungerlo mai\nSta letteralmente facendo edging\nCome si fa questa stima?\nper calcolarla viene\n\nogni volta calcolato l‚ÄôRTT attuale e lo chiama RTT_{measured}\nconfrontato questo attuale con quello minimo rilevato\n\nnon pensare che minimo sia peggio\n\nminimo significa che ci ha messo poco ritardo\n\n\n\n\nquesta differenza tra i due si calcola perch√© ci serve per capire se stiamo avendo pi√π ritardo del normale (il min indica una situazione ideale senza congestione üåê)\n\nsuccessivamente calcola il troughput ideale con \\frac{cwnd}{RTT_{min}} e lo confronta con quello reale dovuto a \\frac{byte\\_sended}{RTT_{measured}}\n\nSe il throughput reale ‚âà quello ideale\n\nrete libera üü¢\nsi pu√≤ aumentare cwnd\n\n\nSe il throughput reale ‚â™ quello ideale\n\nrete congestionata üî¥\nserve ridurre cwnd\ncon questo metodo\n\n\nle perdite non sono forzate\nsi massimizza il troughput üöÄ\nil ritardo rimane basso\n\n\n\n                  \n                  ci sono dei TCP che adottano un approccio basato su ritardi come \n                  \n                \n\n\nBBR della rete interna di Google üåêüîç\nsono distribuiti ovvero su larga scala\n\n\n\nECN(Explicit Congestion Notification)\nalcune implementazioni di TCP spesso hanno un controllo della congestione üìäüåê üåê aiutato dalla rete stessa\n\nun router di rete imposta due bit ECN che sono nell‚Äôintestazione IP\n\nquesti due bit indicano la congestione üåê\nse li imposto a 10 significa che questi bit sono abilitati\nse un router rileva congestione üåê li mette a 11\n\n\nil destinatario non pu√≤ modificare mai il protocollo TCP per√≤ pu√≤ inviare un ACK üì¨ con un bit speciale chiamato\n\nECE che se √® a 1 significa che c‚Äô√® congestione üåê\n\n\nECN viene negoziato nella fase di handshake iniziale dove:\n\nsia mit che dest devono dire:  üëâ ‚ÄúS√¨, supporto ECN‚Äù\n\n\n\n\nIl TCP √® fair?\n\n\n                  \n                  precisazione su fairness \n                  \n                \n\nse ho k connessioni tutte con la stessa banda\n\nho equit√† tra di loro?\nho un troughput = a \\frac{R}{K}\n\nR √® la capacit√† di rete\nK sono le connessioni\n\n\n\n\n\n\nOra parliamo di questo applicato proprio al TCP:\nnella foto sottostante abbiamo un esempio con due troughput diversi che lavorano sulla stessa banda\nalla fine si riesce a vedere che √® fair se per√≤ le connessioni hanno un equilibrio tipo:\n\nhanno stesso RTT\nnumero di connessioni costante\ntutte le connessioni sono lineari e non sono in slow start(esponenziali)\n\nInvece UDP √® fair?\n\nvisto che abbiamo detto che le app video e audio non usano TCP ma UDP per garantire minore latenza poniamoci il dubbio se anche lui √® fair\n\nUDP pu√≤ essere unfair\nin un caso di banda condivisa pu√≤ inviare di pi√π a un determinato destinatario\n\n\n\nConcetto di TCP paralleli ü™Ñüì∂\nsemplicemente quando apri pi√π schede del browser stai aprendo pi√π connessioni TCP\nquesto trucco pu√≤ quindi bypassare la fairness perch√© ti permette di fare pi√π connessioni quindi avere pi√π banda\nCome calcolare il troughput medio üßÆüìè\nsemplicemente fai troughput\\_med=\\frac{3}{4}*\\frac{W}{RTT}\ndove\n\nW dimensione della finestra poco prima di una perdita\n\n\nEvoluzioni di TCP e UDP üß¨\n\nTCP e UDP dominano il trasporto da oltre 40 anni.\nMa i contesti moderni (cloud, 5G, data center, satellite, ecc.) hanno esigenze molto diverse ‚Üí servono varianti specializzate di TCP.\nüìã Tabella riassuntiva:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nScenarioSfida principaleLong, fat pipesMolti pacchetti ‚Äúin volo‚Äù ‚Üí una perdita interrompe tutto (es. WAN ad alta banda)Reti wirelessPerdita dovuta a rumore/mobilit√†, ma TCP la interpreta come congestione üåêLink ad alto ritardoRTT altissimi (es. satellite) ‚Üí risposta lenta, crescita lenta della finestraData centerReti con latenza bassissima, ma altissima sensibilit√† a ogni millisecondo di ritardoFlussi in backgroundFlussi TCP non prioritari, devono adattarsi senza disturbare gli altriIl TCP ha un problema delle Long, Fat pipes ovvero:\n\npacchetti da inviare lontano (long) (alto RTT)\ne con alta capacit√† di banda (Fat)(tanti Gbps di banda)\nQuesto problema ci riporta a un esempio che scrivo sotto ma che in sostanza ci fa capire che per raggiungere la banda prefissata dovremmo praticamente avere\n1 pacchetto perso ogni 5 miliardi\n\nW viene calcolato da: Throughput\\_¬†desiderato√óRTT\n\n\n\n                  \n                  In questi casi servono varianti di TCP per risolvere il problema: \n                  \n                \n\n\nTCP BIC, TCP HighSpeed, TCP CUBIC (default in Linux),\noppure nuove soluzioni come BBR,\noppure approcci come QUIC sopra UDP.\n\n\n\nQUIC üöÄüîó\n√® un protocollo applicativo che si trova sopra a UDP\n\nserve per aumentare le performance di HTTP\nusato in app di google e in molti server\n\n\nPerch√© QUIC √© meglio?\n\nQUIC usa algoritmi per fare il controllo degli errori simili a quelli di TCP\n\nrileva perdite\nregola il flusso\n\n\ncon un solo handshake(andata-ritorno) stabilisce:\n\naffidabilit√†\ncontrollo della congestione üìäüåê üåê\nutilizza autenticazioni sicure come TLS\n\n\nConsente di fare del multiplexing degli stream\n\npi√π flussi simultanei separati\ncondividono stesso controllo della congestione üìäüåê ü§ùüåê üåê\nTCP fa schifo rispetto a questo perch√© TCP soffre di\n\nhead-of-line blocking üö´üì¶\nil primo pacchetto mancante blocca tutta la fila dietro.\n\nse un merdone blocca il cesso √® tutto intasato e bloccato\n\n\n\n\n\n\n\nTCP VS QUIC ü•ä\n\nsi pu√≤ vedere una notevole differenza\nQUIC con un solo handshake fa tutto e pu√≤ subito iniziare a inviare i dati\nGif che fa vedere che che non c‚Äô√® HOL blocking, se uno si blocca vanno gli altri\n"},"UNI/ANNO-2/RETI/RETI-LEZ.12":{"slug":"UNI/ANNO-2/RETI/RETI-LEZ.12","filePath":"UNI/ANNO 2/RETI/RETI LEZ.12.md","title":"RETI LEZ.12","links":["UNI/ANNO-2/RETI/RETI-LEZ.12"],"tags":[],"content":"üß≠ Cosa fa il livello di rete?\n\nIl livello di rete si occupa di trasportare i segmenti (ossia i dati provenienti dal livello di trasporto, come TCP/UDP) da un host mittente a un host destinatario.\n\n\nüü¢ Mittente\n\nPrende il segmento ricevuto dal livello di trasporto\nLo incapsula nel datagramma IP, che poi lo passa al livello di collegamento (tipo Ethernet, Wifi‚Ä¶)\n\n\n\nüîµ Destinatario\n\nQuando il datagramma arriva, il livello di rete lo estrae e consegna il segmento al livello di trasporto\n\n\n\nüåç Protocollo di rete = IP (Internet Protocol)\n√à il cuore del livello di rete ed √® implementato ovunque\n\nhost (client, server, smartphone)\nrouter\n\n\n\n                  \n                  üõ£Ô∏è Cosa fa un router?\n                  \n                \n\n\nEsamina l‚Äôintestazione IP di ogni pacchetto che gli passa attraverso (ossia, guarda l‚Äôip di destinazione)\nDecide dove mandare il pacchetto e lo instrada dalla posta di ingresso a quella di uscita\n\nQuesto processo avviene hop-by-hop, ossia ogni router prende una decisione fino a raggiungere la destinazione finale\n\n\n\nüö¶ Le due funzioni chiave del livello di rete:\n\n\nüîπInoltro (forwarding)\n√à il lavoro fatto da ogni singolo router per instradare ogni pacchetto (il discorso che facevamo prima dello ‚Äúscegliere la porta corretta‚Äù).\nüß† √à gestito dal piano dei dati(spiegazione dopo)\nüü¢ √à un‚Äôoperazione rapida e locale che riguarda ogni singolo pacchetto.\n\n\nüîπ Instradamento (routing)\n√à il processo globale che decide quale percorso seguire nella rete\n\nvengono utilizzati degli algoritmi (tipo Dijkstra) che creano e aggiornano le tabelle di routing nei router\nqueste tabelle servono per sapere dove inoltrare i pacchetti per ogni possibile destinazione.\nüß† √à gestito dal piano di controllo(dopo spiego meglio)\nüü° √à una pianificazione a lungo termine, non si fa per ogni pacchetto.\n\n\n\n\nLe due parti del livello di rete\nüîπ Piano dei dati\n\n√à la parte operativa di ogni singolo router.\n\n√à una funzione locale ‚Üí ossia lavora sul momento, nel router stesso.\nDecide come inoltrare ogni pacchetto in base alla tabella di instradamento\nGuarda l‚Äôintestazione del pacchetto ‚Üí lo manda verso la porta corretta.\nüìå √à quindi il meccanismo che fa fisicamente muovere i pacchetti.\nüî∏ Piano di controllo\n\n√à la parte che si occupa della logica globale della rete\n\nDecide quali percorsi devono esistere tra origine e destinazione, costruendo e aggiornando le tabelle di instradamento (usate poi nel piano dei dati).\nFunziona con algoritmi di routing che possono essere gestiti in due modi:\n\n\nAlgoritmi tradizionali (es. RIP, OSPF):\n\nimplementati nei router stessi\n\n\n\nSDN ‚Äì Software Defined Networking:\n\nla logica dell‚Äôinstradamento √® gestita da server esterni/remoti\nin questo modo i router ricevono le regole da un controller centrale\n\n\n\n\n\nSoftware-Defined Networking (SDN)\nüß† Cos‚Äô√® SDN?\nUn‚Äôarchitettura in cui il piano di controllo non √® pi√π nei router ma viene centralizzato in un unico server remoto\n\nüîß Come funziona?\n\nI router diventano semplici dispositivi ‚Äúesecutori‚Äù (solo inoltro)\nNon calcolano nulla da soli\nIl controller remoto\n\nriceve le informazioni della rete\ncalcola le tabelle di instradamento per tutti i router\ne le installa nei router (frecce rosse verso il basso)\n\n\n\nüß© Che tipo di servizio offre la rete al trasporto dei datagrammi?\nModello di servizio\n√à come dire:\n\n‚ÄúQuando mando un datagramma, la rete mi garantisce qualcosa oppure no?‚Äù\nLe risposte possono variare in base al tipo di servizio offerto.\n\nüì¶ Servizi per un singolo datagramma\nQuesti si riferiscono a una singola unit√† dati\n\nüîµ Consegna garantita: il pacchetto arriva sicuramente a destinazione\nüîµ Consegna con ritardo limitato: tipo dice ‚Äúil pacchetto deve arrivare entro 40ms‚Äù (serve per applicazioni sensibili al ritardo, tipo audio/video)\n\nüîÑ Servizi per un flusso di datagrammi\nQui si fa riferimento a pi√π pacchetti consecutivi (es. una videochiamata)\n\nüîµ Consegna in ordine: i pacchetti arrivano nell‚Äôordine corretto\nüîµ Banda minima garantita: la rete assicura una velocit√† certa (es. 2 Mbps)\nüîµ Controllo della spaziatura: i pacchetti non arrivano troppo distanziati\n\n\n\n\n                  \n                  üìå Nota importante: \n                  \n                \n\nIl protocollo IP non garantisce nulla di tutto questo.\n√à un servizio ‚Äúbest effort‚Äù ‚Üí ci prova, ma non promette niente.\n\n\nTutti questi modelli sono esempi di servizi che una rete potrebbe offrire,\nma non sono presenti nel modello IP base di Internet.\nPerch√© il modello ‚Äúbest-effort‚Äù, per quanto non garantisca al 100%, funziona ed √® diffuso?\n\n\nRouter\nüß± Struttura del router: due piani\n\nüîπ 1. Piano di controllo\n√à gestito via software.\nSi occupa di\n\ncalcolare i percorsi\nrispondere a malfunzionamenti\ngestire configurazioni\n\nFunziona a una scala lenta (millisecondi o secondi) perch√© non √® coinvolto nel trattamento di ogni pacchetto.\nüî∏ 2. Piano dei dati\nFatto in hardware, perch√© deve essere molto veloce.\nSi occupa dell‚Äôinoltro dei pacchetti, ossia\n\nprende un pacchetto da una porta di ingresso\nlo sposta verso la porta di uscita giusta, passando per la struttura di commutazione\n\nFunziona su scala molto rapida: nanosecondi.\nüîÅ Struttura di commutazione\n\n√à il ‚Äúcuore‚Äù del router,\nServe per instradare velocemente i pacchetti dall‚Äôingresso all‚Äôuscita.\n\nANALOGIA AUTOMOBILISTICA\n\nPorte di ingresso\nüéØ Obiettivo generale\nL‚Äôidea √® quella far s√¨ che ogni porta di ingresso possa ricevere e processare i pacchetti il pi√π velocemente possibile, idealmente alla velocit√† di linea (senza la conseguente perdita di pacchetti).\n\nPassi in sequenza\n1Ô∏è‚É£ Terminazione di linea (verde)\n\nriceve i bit ‚Äúgrezzi‚Äù che arrivano sul cavo o sul collegamento (LIVELLO FISICO)\n\n2Ô∏è‚É£ Elaborazione a livello di collegamento (blu)\n\nInterpreta il frame\nrimuove l‚Äôintestazione di livello 2 ‚Üí si dice che ‚Äúdecapsula‚Äù il datagramma IP\n\nIn pratica (matrioska): rimuovi il guscio esterno (frame) ‚Üí arrivi al datagramma\n3Ô∏è‚É£ Ricerca e inoltro (rosso)\n\nGuarda i campi del datagramma\nconsulta la tabella di inoltro locale\ndecide la porta di uscita corretta\n\n\nProcesso che si chiama ‚ÄúMatch Plus Action‚Äù\n\n\n\nüü¶ Match ‚Üí confronta l‚Äôintestazione del pacchetto (soprattutto l‚Äôindirizzo IP di destinazione) con le voci nella tabella di inoltro\n\n\nüü© Action ‚Üí decide l‚Äôazione da eseguire, cio√® a quale porta mandare il pacchetto\n\n\n4Ô∏è‚É£ Accodamento (buffer)\n\nServe per mettere in coda i pacchetti se questi arrivano troppo in fretta o se la struttura di commutazione √® occupata/lenta\n\n\nAbbiamo i soliti problemi di congestione se il buffer si riempie\n\nüß† Commutazione decentralizzata\nQuesto vuol dire che questa struttura √® progettata per far s√¨ che le porte di ingresso eseguano le loro elaborazioni da sole, senza aspettare il processore centrale.\nCos√¨ il tutto √® molto pi√π veloce.\n\n\n                  \n                  üîÅ Cosa succede con commutazione centralizzata (vecchio metodo)\n                  \n                \n\n\n\nTutti i pacchetti devono passare per la CPU centrale del router\n\n\nLa CPU guarda l‚Äôintestazione IP, consulta la tabella e decide dove mandare il pacchetto\n\n\nPoi lo inoltra alla porta di uscita\n\n\nüõë Problema: se arrivano troppi pacchetti ‚Üí la CPU si intasa ‚Üí ritardi\nüöÄ Cosa succede con commutazione decentralizzata\n\nOgni porta di ingresso ha:\n\nun piccolo processore locale\naccesso alla tabella di inoltro\n\n\n\n\n\nüìå Due tipi di inoltro\nüî¥ Inoltro basato sulla destinazione\nIl metodo tradizionale usato in internet, in cui\n\nil router guarda l‚Äôindirizzo IP di destinazione\ne usa la tabella per decidere la porta di uscita\n\nüü† Inoltro generalizzato\nQui il router guarda altre informazione, i campi dell‚Äôintestazione\n\nes. tipo di servizio, protocollo, ecc‚Ä¶\n\nQuesto √® utile in reti pi√π complesse.\nDestinazione basata sull‚Äôindirizzo di destinazione\nCIDR (Classless Inter-Domain Routing).\nüîÅ Contesto un po‚Äô pi√π generale\nCome abbiamo detto prima, quando un router riceve un pacchetto, deve decidere da quale interfaccia farlo uscire, in base all‚ÄôIP di destinazione.\nPer farlo confronta l‚ÄôIP con le voci nella tabella di inoltro.\nQui abbiamo due casi\n\n\ngli indirizzi IP si dividono bene in blocchi ‚Üí la tabella √® semplice da leggere e sfruttare, hanno un intervallo ben definito\n\n192.168.0.0/16\nSignifica che tutti gli IP da 192.168.0.0 a 192.168.255.255 sono coperti da una sola riga nella tabella.\n‚û°Ô∏è In questo caso: una riga = copertura perfetta\nSemplice da gestire.\n\n\npu√≤ succedere per√≤ che gli indirizzi non si allineino perfettamente, non hanno un intervallo eccezionale\n\nQui √® necessario spezzare l‚Äôintervallo e inserire pi√π righe nella tabella per coprire tutte le possibilit√†\nSupponiamo ora che tu debba coprire solo un intervallo ‚Äústrano‚Äù, tipo:\nda 192.168.0.0 a 192.168.2.255\nQuesto non corrisponde a un singolo blocco CIDR pulito, quindi non puoi scrivere una sola riga come:\n192.168.0.0/22\nPerch√© /22 coprirebbe anche 192.168.3.x, che non vuoi includere.\nüëâ Quindi sei costretto a spezzare l‚Äôintervallo in pi√π sottoblocchi, tipo:\n\n\n192.168.0.0/23   ‚Üí copre da 192.168.0.0 a 192.168.1.255\n192.168.2.0/24   ‚Üí copre da 192.168.2.0 a 192.168.2.255\nOra hai due righe nella tabella per coprire quello che prima speravi di scrivere in una.\n\n\n                  \n                  cosa significa quello /x? \n                  \n                \n\nLa /x indica quanti bit iniziali dell‚Äôindirizzo IP rappresentano la parte di rete (sottorete).\nUn indirizzo IPv4 √® lungo 32 bit\n\nSe scrivi 192.168.0.0/16, stai dicendo:\n‚ÄúI primi 16 bit identificano la rete, gli altri 16 bit identificano gli host in quella rete‚Äù\n\n\n\nlo spiego meglio qui\n\n\n                  \n                  Come si gestisce il secondo caso? \n                  \n                \n\nQuando un router trova pi√π voci che ‚Äúmatchano‚Äù un IP si sceglie sempre quella con il prefisso pi√π lungo (ossia quella che ha pi√π bit uguali).\nESEMPIO\n\n\n\nProviamo la prima\n\n\n\nProviamo la terza\n\n\n\nProviamo la seconda\n\n\n\n\n\n                  \n                  La seconda ha pi√π bit uguali ‚Üí viene scelta\n                  \n                \n\nTCAM + Priority Encoder\nPer poter eseguire la ricerca dell‚ÄôIP corretto (o comunque quello pi√π papabile) viene utilizzata un‚Äôarchitettura particolare.\nüì¶ 1. TCAM (Ternary Content Addressable Memory)\n√à una memoria speciale content addressable in cui\n\nviene passato un indirizzo IP a 32 bit come input\ne la TCAM dice quale riga corrisponde in un tempo essenzialmente costante\n\nNel dettaglio, ogni riga TCAM ha\n\nun prefisso da confrontare\nalcuni bit marcati come * (definiti ‚Äúdon‚Äôt care‚Äù), ossia non vengono considerati\nun comparatore che restituisce ‚Äú1‚Äù se c‚Äô√® una corrispondenza\n\nüìä 2. Priority Encoder\nQuando la TCAM trova pi√π righe valide (quindi a ‚Äú1‚Äù) entra in gioco il Priority Encoder, il quale\n\nsceglie la riga con la priorit√† pi√π alta, ossia quella pi√π in alto (foto).\n\nüëâ Nota: Le righe con prefissi pi√π lunghi stanno in alto per primeggiare nella selezione.\nüì• 3. RAM\nDopo aver scelto la porta giusta, il Priority Encoder restituisce il numero di quella riga in binario e lo passa al Decoder della RAM, che mappa quella riga a un‚Äôinterfaccia di uscita (porta).\n\nüèóÔ∏è Struttura di commutazione (switching fabric)\nLA struttura di comunicazione √® il cuore del router: serve a trasferire i pacchetti dalle porte di ingresso a quelle di uscita.\nüéØ Obiettivo\nMuovere i pacchetti il pi√π velocemente possibile tra input e output.\nL‚Äôideale sarebbe avere un tasso di trasferimento della struttura pari a N \\times R, dove\n\nN = numero di porte\nR = velocit√† di ogni singola linea\n\nüîß Le 3 tipologie di strutture di commutazione\n\n1. Commutazione in memoria üß†\n√à il metodo pi√π semplice e vecchio.\n\nUn router tradizionale usa la CPU per spostare i pacchetti da una parte all‚Äôaltra\nogni pacchetto viene copiato in memoria, poi letto e infine inoltrato\n\n\nPROBLEMI\n\n‚ùå Limite: la velocit√† dipende dalla memoria del sistema ‚Üí non scala bene.\n‚ö†Ô∏è Richiede 2 accessi alla memoria per ogni pacchetto (scrittura e lettura).\n\n\nüó®Ô∏è Va bene per router lenti o di piccole dimensioni, ma non √® adatto ad ambienti ad alta velocit√†.\n\n\n2. Commutazione tramite bus üöå\nTutte le porte usano un bus condiviso per mandare pacchetti da input a output.\n\n‚úÖ √à pi√π veloce della commutazione di memoria perch√© la CPU non viene coinvolta direttamente\n‚ùåMa c‚Äô√® bus contention: solo una trasmissione per volta ‚Üí colli di bottiglia\n\n\n\nüó®Ô∏è √à pi√π efficiente della memoria, ma scala poco: quando il traffico aumenta, il bus si satura.\n\n3. Commutazione tramite rete di interconnessione üï∏Ô∏è\nQui entra in gioco il parallelismo: vengono usati switch multipli collegati in modo strutturato\nAbbiamo due approcci\na. Crossbar (matrice di commutazione)\n√à una griglia N \\times N: ogni input pu√≤ essere connesso a ogni output, se non c‚Äô√® conflitto.\n\n\n‚úÖ Veloce e parallela.\n‚ùå Ma costosa e complessa per grandi N.\n\nb. Multistage (reti Clos)\nSi usano pi√π stadi di switch piccoli, tipo 2x2 o 4x4, in cascata.\n\n\n‚úÖ Molto scalabile e sfrutta meglio il parallelismo.\n‚úÖ Permette la commutazione di celle (pacchetti frammentati) ‚Üí pi√π efficienza.\n\n\nAccodamento sulle porte di ingresso\nCome abbiamo visto prima i pacchetti, in un router, entrano in una porta di ingresso e vengono indirizzati verso una porta di uscita.\nPu√≤ capitare per√≤ che si formino code in ingresso quando\n\nuna commutazione √® lenta\no ci sono conflitti tra pi√π pacchetti destinati alla stessa uscita\n\n‚ùå Problema: HOL blocking\n√à una situazione in cui il primo pacchetto nella coda (in testa) non pu√≤ essere trasferito, e impedisce anche agli altri dietro di avanzare, anche se andrebbero verso porte libere.\n\nüîΩ A sinistra:\n\ndue pacchetti (datagrammi) rossi vogliono uscire dalla stessa porta di uscita\nMA solo uno pu√≤ passare, l‚Äôaltro rimane bloccato\nIl pacchetto verde, che potrebbe tranquillamente uscire da un porta di uscita LIBERA, rimane bloccato inutilmente.\nüëâ √à questo il blocco in testa alla coda: chi √® davanti blocca tutti.\n\nüîº A destra:\n\nuna volta che i pacchetti rossi sono usciti, il pacchetto verde pu√≤ avanzare\nMA √® avvenuto un ritardo completamente inutile per colpa del pacchetto in testa\n\nAccodamento in uscita (IMPORTANTE)\nQuando i pacchetti passano attraverso la struttura di commutazione, possono arrivare pi√π velocemente di quanto il collegamento di uscita sia in grado di trasmetterli.\nQuesto crea un collo di bottiglia e richiede un meccanismo di buffering, cio√® accodamento in attesa della trasmissione.\nüéØ Concetti chiave\n\n\nBuffering:\n\nServe per mettere in attesa i pacchetti quando la porta di uscita √® occupata.\nSe arrivano troppi pacchetti e il buffer √® pieno ‚Üí si perdono pacchetti (overflow).\nQuesto porta a ritardi e perdite.\n\n\n\nDrop policy (politica di scarto):\n\nQuando il buffer √® pieno, quale pacchetto scartare?\nEsistono varie politiche (vedremo tra poco).\n\n\n\nDisciplina di scheduling (o schedulazione):\n\nQuando ci sono pi√π pacchetti in coda, quale viene trasmesso per primo?\nAnche qui si possono applicare criteri diversi (vedremo sempre tra poco)\n\n\n\n\nüìâ Cosa pu√≤ succedere se il buffer non √® ben gestito?\n\nCongestione: troppi pacchetti si accumulano.\nPerdita di pacchetti: il buffer si riempie e inizia a scartarli.\nDelay: i pacchetti aspettano pi√π tempo prima di uscire ‚Üí aumenta la latenza.\n\n\nQui se vedi i pacchetti rossi (a sinistra) entrano tutti dentro la stessa porta e se non viene gestita bene la situazione (a destra) sono cavoli!!\nQuanta memoria di buffer √® necessaria?\nüìå 1. Regola empirica (RFC 3439):\n\nBuffer = RTT √ó C\n\n\n\nDove:\n\nRTT √® il round-trip time tipico (es. 250 ms),\nC √® la capacit√† del collegamento (es. 10 Gbps),\n\n\n\nEsempio:\n\nSe C = 10 Gbps ‚Üí buffer ‚âà 2.5 Gbit.\n\n\n\n‚ùó √à una regola empirica, detta anche rule of thumb (cio√® una stima pratica, non una legge assoluta).\n\n\nüìå 2. Raccomandazione pi√π recente:\n\nCon N flussi TCP contemporanei, il buffer richiesto pu√≤ essere ridotto:\n\n\\text{Buffer} = \\frac{RTT \\cdot C}{\\sqrt{N}}\n\nPi√π flussi ‚Üí pi√π il carico si ‚Äúdistribuisce‚Äù ‚Üí serve meno buffer.\n\n‚ö†Ô∏è Attenzione: troppo buffering pu√≤ essere un problema!\nBufferbloat:\nSe c‚Äô√® troppa memoria, i pacchetti si accumulano ‚Üí aumenta l‚ÄôRTT.\nQuesto √® dannoso soprattutto:\n\nNei router domestici,\nPer le app real-time (come videochiamate, giochi online),\nPer TCP, che diventa meno reattivo alla congestione.\n\nL‚Äôobiettivo moderno √®\n\nMantenere il collo di bottiglia pieno, ma non troppo pieno.\n\nGestione del buffer\n\nVisto in modo astratto\n\nüö® Cosa succede se √® pieno?\nüü• Politica di scarto (drop policy):\n\n\nTail drop (classico):\n\nSe il buffer √® pieno ‚Üí si scarta il pacchetto appena arrivato.\n√à semplice, ma pu√≤ causare problemi a TCP (es. molte perdite improvvise).\n\n\n\nPriorit√†:\n\nAlcuni pacchetti hanno pi√π ‚Äúimportanza‚Äù (es. voce, controllo) ‚Üí si scarta il meno prioritario.\n\n\n\nMarcatura:\n\nInvece di scartare subito, il router segna i pacchetti per avvisare il mittente di rallentare.\nPer fare ci√≤ vengono utilizzati protocolli come:\n\nECN (Explicit Congestion Notification)\nRED (Random Early Detection)\n\n\n\n\n\nAlgoritmi di schedulazione\nalgoritmi che decidono come gestire i pacchetti da trasmettere\nüîµ 1. FCFS ‚Äì First Come, First Served (o FIFO)\nüìå Cosa fa:\n\nTrasmette i pacchetti nell‚Äôordine in cui arrivano alla coda.\nIl primo pacchetto che entra √® anche il primo che esce.\n\n√à molto semplice MA inutilizzabile in contesti in cui i pacchetti hanno priorit√† diverse.\nüî¥ 2. Scheduling con Priorit√†\nüìå Cosa fa:\n\nI pacchetti vengono classificati per classi di priorit√† (es. alta e bassa).\nLa coda con priorit√† pi√π alta viene sempre servita prima.\n\n‚öôÔ∏è Come funziona:\n\nOgni pacchetto in arrivo viene inserito nella coda corrispondente alla sua priorit√†.\nIl router cerca la prima coda non vuota (partendo da quella a priorit√† massima) e serve un pacchetto da l√¨.\n\nüö´ Limiti:\n\nStarvation: se arrivano sempre pacchetti ad alta priorit√†, quelli a bassa potrebbero non uscire mai.\n\n\nüìå Nota: All‚Äôinterno di ogni coda si usa FCFS.\nüîÅ 3. Round Robin (RR)\nüìå Cosa fa:\n\nIl traffico √® sempre classificato per classi, come nella priorit√†.\nInvece di servire sempre la classe pi√π importante, il server serve a turno ciascuna coda (una alla volta).\n\n‚öôÔ∏è Come funziona:\n\nScorre ciclicamente tra le code.\nSe una coda ha pacchetti, ne trasmette uno intero e poi passa alla successiva.\n\n‚úÖ Vantaggi:\n\nEquo: ogni classe riceve attenzione.\nEvita il problema dello starvation.\n\nüö´ Limiti:\n\nSe una classe ha pi√π pacchetti e altre ne hanno pochi, non riesce a sfruttare bene la banda.\n\n\n‚öñÔ∏è 4. Weighted Fair Queuing (WFQ)\nüìå Cosa fa:\n\n√à una versione avanzata del Round Robin.\nOgni coda (classe) riceve una quantit√† di banda proporzionale a un peso assegnato\n\n‚öôÔ∏è Formula:\n\\text{Quota per classe } i = \\frac{w_i}{\\sum_j w_j}\ndove w_i √® il peso della classe i.\n‚úÖ Vantaggi:\n\nPi√π flessibile: si possono garantire quote minime di banda.\nSupporta QoS (Quality of Service) per servizi critici.\n\n\nüìå Esempio:\n\nSe hai 3 code con pesi 5, 3 e 2, allora riceveranno rispettivamente il 50%, 30% e 20% della banda (pi√π o meno).\n\n\n\n                  \n                  Riassunto delle ultime tre slide \n                  \n                \n\n\nNet neutrality: principio secondo cui gli ISP devono trattare tutto il traffico Internet in modo equo, senza blocchi, rallentamenti o priorit√† a pagamento.\nUSA: nel 2015 la FCC impone regole rigide; nel 2017 vengono annullate, puntando solo sulla trasparenza degli ISP.\nAspetto legale: classificare un ISP come servizio di telecomunicazione o informazione cambia il tipo di regolamentazione applicabile.\n\n\n\n\nINTERNET AL LIVELLO DI RETE\n\nüîß Formato dei datagrammi IP\n\nüß© Frammentazione dei datagrammi IP\nüß± Cos‚Äô√® la frammentazione?\nQuando un datagramma IP √® troppo grande per essere trasportato su un collegamento di rete (ossia supere l‚ÄôMTU del link) viene suddiviso in pezzi pi√π piccoli chiamati frammenti.\n‚úÇÔ∏è Come funziona la frammentazione\n\n\nUn datagramma IP (es. da 4000 byte) deve attraversare un link con MTU da 1500 byte.\n\n\nViene diviso in frammenti sufficientemente piccoli per entrare in un frame (tipicamente in blocchi da 1480 byte di dati + header IP).\n\n\nOgni frammento riceve un‚Äôintestazione quasi identica all‚Äôoriginale, ma con:\n\nlo stesso identificatore\nflag per indicare se √® l‚Äôultimo frammento\noffset per indicare dove si inserisce nel datagramma completo\n\n\n\nüß© Riassociazione (riassemblaggio)\n\nI frammenti non vengono ricomposti nei router, ma solo dal destinatario finale.\nQuesto √® importante perch√© consente trattamento indipendente dei frammenti nei router intermedi.\n\nESEMPIO\n\nSpiegazione CHATGPT\n\n\nüîö Frammentazione e Riassemblaggio IP ‚Äì oggi\nüóëÔ∏è Deprecato in IPv6\n\nLa frammentazione nei router √® stata eliminata con IPv6.\nSolo l‚Äôhost mittente pu√≤ frammentare, non pi√π i router intermedi.\nMotivo: evitare complessit√†, overhead e vulnerabilit√† nei router.\n\nüß≠ Path MTU Discovery (PMTUD)\nüéØ Obiettivo\nTrovare la MTU massima lungo il percorso dal mittente al destinatario senza frammentare.\n‚öôÔ∏è Come funziona\n\n\nIl mittente invia pacchetti con il bit DF (Don‚Äôt Fragment) impostato a 1.\n\n\nSe un router incontra un collegamento con MTU troppo grande:\n\nnon frammenta, ma scarta il pacchetto.\ninvia un messaggio ICMP ‚ÄúDestination Unreachable: Fragmentation Required‚Äù al mittente.\n\n\n\nIl mittente riduce la dimensione del pacchetto e riprova.\n\n\n\n\n                  \n                  ICMP bloccato \n                  \n                \n\nMolti firewall o router bloccano i messaggi ICMP per motivi di sicurezza.\n\nQuesto rende il PMTUD inaffidabile:\n\nIl mittente non riceve l‚Äôavviso e continua a inviare pacchetti troppo grandi.\nSi verificano ritrasmissioni inutili e perdita di performance.\n\n\n\n\n\nüîÑ Alternative pi√π robuste (mitigazioni):\n\nDurante l‚Äôhandshake TCP, i dispositivi possono negoziare il valore MSS (Maximum Segment Size) per evitare l‚Äôinvio di pacchetti troppo grandi.\n\nSi agisce all‚Äôinizio della connessione, rendendo la comunicazione pi√π stabile.\n\n\n\nüìç Indirizzamento IP ‚Äì Introduzione\nCome gi√† sappiamo, un indirizzo IP √® un identificatore univoco a 32 bit, assegnato a ogni interfaccia di rete.\nUn‚Äôinterfaccia invece, √® un punto di connessione fisico o logico attraverso cui un dispositivo (host o router) si collega a una rete.\n\nOgni interfaccia ha un indirizzo IP.\n\n\n\n\n                  \n                  Come si collegano effettivamente le interfacce IP? \n                  \n                \n\n\n\n\nPer√≤, per ora, non c‚Äô√® bisogno di preoccuparsi di come sono fisicamente collegate le interfacce (lo vedremo a livello di collegamento).\nSottoreti (subnet)\nü•Ö Cos‚Äô√® una sottorete (subnet)?\nUna sottorete √® un gruppo di dispositivi (host e router) che possono comunicare tra loro direttamente, senza dover passare attraverso un router. Questo √® importante per ridurre traffico e latenza, e per gestire meglio le risorse.\n\nquesta rete √® composta da 3 sottoreti\nüìå In pratica: tutti i dispositivi collegati allo stesso switch (fisico o virtuale) e con indirizzi IP simili fanno parte della stessa sottorete.\nüîßStruttura di un indirizzo IP\nUn indirizzo IP √® lungo 32 bit ed √® composto da due parti:\n\nParte di rete (sottorete): identifica a quale rete appartiene il dispositivo.\nParte dell‚Äôhost: identifica il singolo dispositivo dentro quella rete.\n\nüèóÔ∏è Come si creano le sottoreti?\nLa procedura consiste nello ‚Äúspezzare‚Äù una rete pi√π grande in reti pi√π piccole.\nSi fa ‚Äúscollegando‚Äù logicamente le interfacce, cos√¨ da creare ‚Äúisole‚Äù di dispositivi separati tra loro dai router.\n\nüìå Le reti cos√¨ ottenute:\n\nhanno indirizzi IP simili (es. 223.1.1.1, 223.1.1.2‚Ä¶ ‚Üí stessa subnet),\nsono isolate l‚Äôuna dall‚Äôaltra,\ncomunicano tramite router.\n\nEsempio con una rete molto pi√π grande\n\nIndirizzamento IP con CIDR\nIl CIDR √® un metodo moderno per rappresentare indirizzi IP e sottoreti senza basarsi sulle classi tradizionali (A, B, C). √à molto pi√π flessibile, perch√© permette di scegliere una lunghezza arbitraria per la parte di rete dell‚Äôindirizzo.\nüìå Formato CIDR\nL‚Äôindirizzo √® scritto cos√¨:\na.b.c.d/x\n\ndove\n\na.b.c.d ‚Üí indirizzo IP.\n/x ‚Üí indica quanti bit iniziali appartengono alla parte di rete (sottorete).\n\nEsempio:\n200.23.16.0/23 ‚Üí i primi 23 bit identificano la sottorete, i restanti bit sono per l‚Äôhost.\n\nMetodo vecchio\n\n"},"UNI/ANNO-2/RETI/RETI-LEZ.13":{"slug":"UNI/ANNO-2/RETI/RETI-LEZ.13","filePath":"UNI/ANNO 2/RETI/RETI LEZ.13.md","title":"RETI LEZ.13","links":[],"tags":[],"content":"Come si ottiene un indirizzo IP?\nquesta domanda essendo troppo generica si divide in 2 sotto-domande:\n\ncome fa un host a ottenere un suo recapito IP?\n\ncome fa a sapere il suo identificativo all‚Äôinterno di una rete?\n\n\nCome fa una rete a ottenere l‚Äôindirizzo IP (la parte dell‚Äôindirizzo relativa alla rete)?\n\nRispondiamo alla prima\nl‚Äôhost pu√≤ ottenerlo:\n\nmanualmente\n\nviene messo nel file di configurazione sysadmin in modo statico\n\n√® ormai inutilizzata questa cosa perch√© ogni nuovo dispositivo dovrebbe essere configurato manualmente\n\n\n\n\ndinamicamente\n\ncon il DHCP(Dynamic Host Configuration Protocol)\n\npermette a un host di ottenere un indirizzo IP in modo automatico\n√® decisamente pi√π facile usarlo ‚Äúplug-and-play‚Äù\n\n\n\n\n\nspiegazione migliore sul DHCP\n\nappena l‚Äôhost si unisce alla rete deve ottenere un indirizzo IP dinamico\n\ndinamico perch√© ogni volta che si collega varia\nL‚Äôindirizzo non √® assegnato per sempre: pu√≤ essere rinnovato o rilasciato, cos√¨ da riutilizzare gli IP in modo efficiente.\nQuesto sistema √® ideale per utenti mobili che entrano ed escono spesso dalla rete, come smartphone e portatili.\n\n\n\n\n\n                  \n                  Tuttavia, poich√© ogni accesso pu√≤ dare un IP diverso, non garantisce la stabilit√† di una connessione TCP attiva (che dipende dall‚Äôindirizzo IP).\n                  \n                \n\nDove √® posizionato?\n\nIl DHCP in 4 passi\n\nDHCP Discover (opzionale):\nL‚Äôhost invia un messaggio broadcast sulla rete per scoprire se ci sono server DHCP disponibili.\nDHCP Offer (opzionale):\nUn server DHCP risponde, proponendo un indirizzo IP disponibile da assegnare.\nDHCP Request:\nL‚Äôhost richiede formalmente quell‚Äôindirizzo IP, indicando che accetta l‚Äôofferta.\nDHCP Ack:\nIl server DHCP conferma l‚Äôassegnazione, e l‚Äôhost pu√≤ iniziare a usare quell‚ÄôIP.\n\nle chiamate vengono fatte in broadcast perch√© il client appena entrato non sa con chi sta parlando e il server DHCP non sa con chi sta parlando perch√© non ha ancora un IP\n\n\n\nsrc: indica l‚Äôindirizzo IP e la porta UDP del mittente del messaggio.\n\n\ndest: indica l‚Äôindirizzo IP e la porta UDP del destinatario del messaggio.\n\n\nyiaddr: specifica l‚Äôindirizzo IP che il server DHCP assegna al client.\n\n\ntransaction ID: identifica in modo univoco una sessione DHCP tra client e server.\n\n\nlifetime: definisce il tempo per cui il client pu√≤ utilizzare l‚Äôindirizzo IP assegnato.\n\n\nDHCP ‚Üí IP e non solo\nil DHCP non fornisce solo IP ma anche:\n\n\nIndirizzo del router first-hop: specifica il gateway predefinito che il client user√† per raggiungere altre reti.\n\ndice quale router usare per comunicare con altre reti esterne(gateway)\nUn gateway (in italiano: porta di accesso) √® un dispositivo di rete che collega due reti diverse tra loro e instrada i dati da una rete all‚Äôaltra.\n\n\n\n\nNome e indirizzo IP del server DNS: indica al client quali server DNS usare per risolvere i nomi di dominio.\n\n\nMaschera di rete(subnet): definisce la parte dell‚Äôindirizzo IP che identifica la rete e quella che identifica l‚Äôhost.\n\n\nAltri esempi di DHCP\n\n\nRispondiamo alla seconda domanda\nCome fa una rete a ottenere l‚Äôindirizzo IP (la parte dell‚Äôindirizzo relativa alla rete)?\nQui parleremo di indirizzi pubblici su una rete ma diciamo che si applica la medesima cosa su indirizzi privati\n\nquesti indirizzi sono forniti dagli ISP per identificare una rete( che altrimenti sarebbe privata) dall‚Äôesterno\nDobbiamo immaginare come se l‚ÄôISP ha un grande blocco di indirizzi che divider√† per ogni rete che ne richiede un po‚Äô\n\n‚úÖ Esempio\nL‚ÄôISP possiede un blocco grande di indirizzi:\n\n200.23.16.0/20\nQuesto significa che:\nI primi 20 bit dell‚Äôindirizzo sono fissi ‚Üí √® la parte di rete.\nI restanti bit sono disponibili per la suddivisione:\n\n32 - 20 = 12 bit per la parte variabile.\nQuindi il blocco contiene 2^{12} = 4096 indirizzi IP.\n\n\n\n[     parte di rete     ][     parte di host     ]\n         /20                      /12\nüîπ In quante sottoreti posso dividere questo blocco?\nSe scelgo di suddividere in blocchi pi√π piccoli:\n\nPasso da /20 a /23 ‚Üí significa che tengo fissi 23 bit invece di 20.\nQuindi aggiungo 3 bit alla parte di rete.\nüëâ Con 3 bit in pi√π, posso rappresentare 2^3 = 8 combinazioni distinte.\n\nüü¢ Risultato:\n\nIl blocco 200.23.16.0/20 pu√≤ essere suddiviso in 8 sotto-blocchi da /23\nOgnuno con 512 indirizzi (2^{9}, perch√© 32 ‚àí 23 = 9)\n\n\nroute aggregation\nOgni ISP o grande router su Internet deve pubblicizzare agli altri router quali indirizzi IP √® in grado di raggiungere.\nQuesto lo fa con le tabelle di routing e i protocolli come BGP.\nSupponiamo che Fly-By-Night-ISP(nome a caso di un ISP) abbia assegnato questi 8 blocchi a 8 clienti:\n\n200.23.16.0/23\n200.23.18.0/23\n200.23.20.0/23\n‚Ä¶\n200.23.30.0/23\nSe volesse pubblicizzare ognuno singolarmente, dovrebbe inserire 8 righe distinte nella tabella di routing di Internet. Questo aumenta la dimensione e la complessit√† della tabella.\nInvece di pubblicare ogni singolo blocco su Internet, Fly-By-Night-ISP dice:\n‚ÄúInviatemi tutto ci√≤ che ha un indirizzo che inizia con 200.23.16.0/20‚Äù\nüëâ Questo √® indirizzamento gerarchico:\nTanti blocchi vicini (stessa radice binaria) sono aggregati in uno solo.\n\n‚úÖ Vantaggio:\n\nRiduzione della complessit√† nelle tabelle di routing a livello globale.\nPi√π efficienza nella gestione dei percorsi Internet.\n\n√® sufficiente dire 200.23.16.0/20 perch√© saranno i sistemi di rete con cui comunico a calcolare che il CIDR arriva fino a 200.23.31.255\nüëá Facciamo il calcolo passo per passo:\n\nInizio: 200.23.16.0\n\n\n√à l‚Äôindirizzo di rete (tutti gli ultimi 12 bit a 0)\n\n\nFine: si aggiungono 2^{12} - 1 = 4095 indirizzi\n\n\nUltimo indirizzo: 200.23.31.255 (tutti gli ultimi 12 bit a 1)\n\n\nCambio di percorsi\nüîÅ Scenario:\n\nOrganizzazione 1 si sposta da Fly-By-Night-ISP a un altro ISP: ISPs-R-Us\nL‚Äôindirizzo IP di Organizzazione 1 rimane lo stesso: 200.23.18.0/23\nüß≠ Cosa succede:\nISPs-R-Us ora deve pubblicizzare un percorso specifico per quell‚Äôindirizzo.\nDice a Internet:\n\n‚ÄúInviatemi tutto ci√≤ che inizia con 199.31.0.0/16\noppure con 200.23.18.0/23‚Äù ‚Üê (questo √® pi√π specifico!)\n\n\n\n\nricordiamo che se avviene una richiesta su un indirizzo pi√π specifico\n\nessa viene soddisfatta da quello che ci assomiglia di pi√π\nAnche se Fly-By-Night-ISP pubblicizza il blocco aggregato 200.23.16.0/20,\nla rotta pi√π specifica pubblicata da ISPs-R-Us viene preferita.\nüìç Perch√©?\nI router Internet scelgono sempre il percorso pi√π specifico, se esiste.\nQuindi il traffico per 200.23.18.0/23 andr√† verso ISPs-R-Us,\nnonostante Fly-By-Night-ISP continui a pubblicare il blocco /20.\n\n\nUltime parole su questo argomenti degli indirizzi IP\nrispondendo a delle domande\n\n\n                  \n                  come fa un ISP a ottenere un blocco di indirizzi? \n                  \n                \n\ntramite ICANN\n\nICANN (Internet Corporation for Assigned Names and Numbers) √® l‚Äôorganizzazione che gestisce l‚Äôassegnazione globale degli indirizzi IP.\nNon assegna direttamente agli ISP, ma lo fa tramite 5 Registri Regionali (RR):\n\nEsempi: RIPE (Europa), ARIN (Nord America), APNIC (Asia-Pacifico), ecc.\n\n\nI RR poi possono assegnare blocchi a registri locali o direttamente agli ISP.\n\nüß† Nota: ICANN gestisce anche il sistema DNS, inclusi i domini di primo livello (TLD) come .com, .edu, ecc.\n\n\n\n\n                  \n                  ci sono abbastanza indirizzi con IPv4? \n                  \n                \n\nno 32 bit sono pochi e sono gi√† finiti nel 2011\n\nPer mitigare il problema, √® stato introdotto il NAT (Network Address Translation), che permette a molte macchine private di condividere un solo IP pubblico.\n\nlo vedremo tra poco\n\n\nMa la vera soluzione √® il passaggio a IPv6, che usa indirizzi a 128 bit ‚Üí tantissimi indirizzi disponibili (2¬π¬≤‚Å∏).\n\n\n\nNAT\nsta per network address translation\n\nServe per ridurre il numero di dispositivi che usano l‚ÄôIPv4 pubblico(per l‚Äôesterno)\n\nogni dispositivo ha un suo indirizzo privato\n\ntipo 10.0.0.1\nsolo il router ha un indirizzo pubblico\n\ngli viene dato dall‚ÄôISP\n\n\ntutti i dispositivi quando si interfacciano con l‚Äôesterno usano lo stesso ip pubblico\ntutti i dispositivi non sono visibili dall‚Äôesterno(solo il router lo √®)\npuoi cambiare ISP pi√π facilmente\n\n\n\nRouter di tipo NAT\nIl Router di tipo NAT deve gestire meticolosamente la traduzione degli indirizzi IP per instradare i pacchetti correttamente\nQuindi cosa deve fare esattamente il router quando un pacchetto esce dalla rete locale?\n\nsostituire l‚Äôindirizzo IP sorgente e il n. di porta sorgente di ogni datagramma in uscita con l‚Äôindirizzo IP pubblico del router NAT e il nuovo numero di porta che si affaccia all‚Äôesterno\nutilizzare una tabella di traduzione NAT per ricordare ogni coppia di traduzioni fatta\nQuando arriva una risposta da internet\n\nun pacchetto in entrata\ndeve sostituire ad ogni pacchetto in entrata il datagramma corretto\n\nscambiando i vari indirizzi ip pubblici e la porta pubblica con i rispettivi privati\n\n\n\n\n\nEsempio di router NAT\n\nI vari step:\n\nAbbiamo un PC 10.0.0.1  che vuole accedere ad un sito web 128.119.40.186 sulla porta 80 (HTTP)\n\n\nLa rete locale ha IP privati come quello sopra\n\n\nIl router ha UN SOLO IP pubblico\n\n\nServe il NAT per andare ‚Äúsu internet‚Äù\n\n\n\n\n\n\nIl dispositivo 10.0.0.1:3345 (3345 √® il numero di porta) invia un datagramma a 128.119.40.186, porta 80 (richiesta a server web)\n\n\nIl router NAT traduce  Da: 10.0.0.1:3345   A: 138.76.29.7:5001  Internet (tutto ci√≤ che √® esterno) penser√† che il pacchetto venga da quest‚Äôultimo\n\n\nArriva la risposta dal server server destinazione: 138.76.29.7:5001 (l‚Äôindirizzo IP pubblico visto prima)\n\n\nIl router riconverte guarda nella tabella NAT e trova 138.76.29.7:5001 ‚Üí 10.0.0.1:3345  Allora cambia l‚Äôindirizzo di destinazione e invia il pacchetto a  10.0.0.1:3345 che √® PC giusto.\n\n\n\n\n                  \n                  in poche parole traduce indirizzzi e porte e tiene traccia di tutti i movimenti di indirizzi attraverso quella tabella, facendo sembrare che sia tutto pubblico \n                  \n                \n\nIl router NAT in realt√†\n\ndovrebbe arrivare fino al livello 3 IP di rete\n\ninvece usa anche il livello 4 di trasporto TCP/UDP\n\n\nIl NAT √® nato per ridurre l‚Äôuso di indirizzi IPv4\n\nma ora esiste il 6\n\n\nrende le connessioni pi√π complicate per questi scambi di indirizzzi\ndifficile comunicare direttamente con chi √® dietro il NAT\n√® molto economico quindi ancora in uso\n\nIPv6\nnasce per i motivi detti prima:\n\nIPv4 insufficienti, avevano solo 32 bit\npi√π veloce da gestire\nquesti 64\n\nDatagramma IPv6\n\nCampi principali:\n\nVersione (ver): sempre 6\nClasse di traffico: d√† priorit√† ai datagrammi importanti\nEtichetta di flusso: per raggruppare datagrammi che fanno parte dello stesso ‚Äúflusso‚Äù\nIndirizzo sorgente e destinazione: sono lunghi 128 bit (IPv4 era 32 bit)\nCarico utile (payload):pi dati veri e propri\n\n\n\n                  \n                  Cosa manca in IPv6 rispetto a IPv4? \n                  \n                \n\n\nNo checksum, meno controllo ma router pi√π veloci\nNo frammentazione/riassemblaggio, se il pacchetto √® troppo grande, il mittente viene avvisato e lo rimanda pi√π piccolo\nNo opzioni stanno da un‚Äôaltra parte\n\n\n\nPacchetti destinati ad esempio lo streaming sono spesso etichettati con stesso ‚Äúflusso‚Äù\n\n\n                  \n                  aggiornare da IPv4 a IPv6 non √® cos√¨ semplice quindi ci sono router misti che sono degli ibridi tra le due cose \n                  \n                \n\nTunneling e incapsulamento\nPer comunicare in una rete mista si usa il tunneling dove:\n\nun pacchetto IPv6 viene inserito in un pacchetto IPv4(payload)\ncos√¨ pu√≤ viaggiare in IPv4\npoi un router IPv6 pu√≤ spacchettarlo senza problemi\n\n\nEsempio\n\n\nA ed E sono i router misti\nloro hanno il compito di impacchettare e spacchettare nei formati corretti\n\nvisione fisica del tunneling\n\nnella visione logica sembra che il pacchetto vada senza problemi da B a E\nInvece nella versione fisica fa vedere anche i vari router intermedi con i vari cambiamenti di indirizzo\nUtilizzo di IPv6\n\nfa vedere quanto viene adottato IPv6 nel tempo\nMatch Plus Action(inoltro generalizzato)\nuna tabella di inoltro o dei flussi\n\nogni router ne ha una, serve per capire a chi inoltrare il pacchetto\n\ncon match plus action fa due tipi di inoltro:\n\nnormale:\n\nfa un inoltro basato sulla destinazione guardando l‚Äôip di destinazione e fa un inoltro verso il router giusto\n\n\ngeneralizzato: quando guarda anche altri campi dell‚Äôintestazione e pu√≤ fare oltre all‚Äôinoltro anche ulteriori azioni\n\nin questo esempio inoltra al router numero 3 perch√© abbiamo 0111\n\n\n\n\n\nTabella di inoltro o dei flussi\nUn flusso √® definito dai valori dei campi dell‚Äôintestazione nei pacchetti (a livello di collegamento, rete o trasporto), la tabella dei flussi contiene regole tipo ‚ÄúSE un pacchetto ha questi valori ‚Üí ALLORA fai questa azione‚Äù.\nOgni router pu√≤ prendere decisioni ‚Äúsemplici‚Äù per la gestione dei pacchetti seguendo quello che c‚Äô√® scritto nella tabella dei flussi:\n\n\nMatch = ‚Äúse il pacchetto ha questi valori‚Ä¶‚Äù\n\n\nAction = allora puoi fare queste cose:\n\n\ninoltrare (forward) il pacchetto su una certa porta;\n\nscartare (drop) il pacchetto;\nmodificare (modify) l‚Äôintestazione;\nmandarlo al controller (se usi una rete SDN);\ncopiarlo, loggarlo, contarne i byte, ecc‚Ä¶\nEsempio\n\n\n\n\nSe due tabelle si sovrappongono vince quella con priorit√† pi√π alta\n\n\npresenza di contatori che tengono conto di quanti inoltri hanno usato quella determinata regola, con anche timestamp\n\npraticamente sai anche a che ora √® successo\n\n\n\n\nVoci tabella dei flussi(Open Flow)\n\nOpenFlow rappresenta uno standard usato nelle reti SDN(Software Defined Networking)\nLa logica di controllo √® separata dall‚Äôhardware invece di avere ogni router che decide da solo come inoltrare i vari pacchetti\n\nc‚Äô√® un grande controller centrale che decide per tutti\nOpen Flow √® anche il nome del protocollo usato per far comunicare questo grande controller con i router\nOgni riga √® fatta da 4 parti principali:\n\n\nMatch ‚Üí cosa cercare nel pacchetto\nActions ‚Üí cosa fare se c‚Äô√® corrispondenza\nContatori ‚Üí contano pacchetti e byte\nPriorit√† ‚Üí serve se pi√π regole combaciano con lo stesso pacchetto\nContinuo domani\n\n1)Match¬†\nIn pratica il router guarda l‚Äôintestazione del pacchetto alla ricerca di valori specifici. Questi campi che controlla sono divisi per livello (diversi strati del pacchetti):¬†\n(Li riporto solo per dare un contesto a quello che vedo, li copio e incollo)¬†\nLivello 2 ‚Äì Collegamento\nServe per decidere cosa fare dentro una rete locale (LAN)\n\nIngress Port: Porta fisica dove √® entrato il pacchetto\nSrc MAC: MAC address sorgente\nDst MAC: MAC address destinazione\nEth Type: Tipo di protocollo (es. IPv4, IPv6, ARP‚Ä¶)\nVLAN ID: ID della VLAN\nVLAN Pri: Priorit√† della VLAN\n\nLivello 3 ‚Äì Rete\nCampi per muoversi da una rete all‚Äôaltra, serve ai router per inoltrare verso la destinazione corretta:\n\nIP Src: Indirizzo IP sorgente\nIP Dst: Indirizzo IP destinazione\nIP Proto: Protocollo IP (es. TCP, UDP, ICMP)\nIP ToS: Tipo di servizio (priorit√† pacchetto)\n\nLivello 4 ‚Äì Trasporto\nCampi che servono per capire quale applicazione ha generato il pacchetto, distinguere tipo di traffico:\n\nTCP/UDP Src Port: Porta sorgente (es. 443)\nTCP/UDP Dst Port: Porta di destinazione (es. 80)\n\nAltri esempi\nEsempio 1\n\nüîÅ Inoltro basato sulla destinazione\nDescrizione:\nSe un pacchetto ha come IP di destinazione 51.6.0.8, allora deve essere inoltrato sulla porta 6 del router.\nRegola:\n\nIP Dest = 51.6.0.8\nTutti gli altri campi = * (qualsiasi valore)\nAzione:\nport6 ‚Üí inoltra sulla porta 6\n\nüîí Bloccare SSH\nDescrizione:\nBlocca tutti i pacchetti destinati alla porta TCP 22 (usata per SSH).\nRegola:\n\nTCP Dst Port = 22\nTutti gli altri campi = *\nAzione:\ndrop (scarta)\n\nüö´ Bloccare un host specifico\nDescrizione:\nBlocca tutti i pacchetti inviati da 128.119.1.1.\nRegola:\n\nIP Src = 128.119.1.1\nTutti gli altri campi = *\n\nAzione:\ndrop\nESEMPIO 2\n\nüéØ Inoltro basato su MAC di destinazione\nDescrizione:\nSe un pacchetto ha MAC di destinazione = 22:A7:23:11:E1:02, allora viene inoltrato sulla porta 3.\nRegola:\n\nMAC Dst = 22:A7:23:11:E1:02\nTutti gli altri campi = *\n\nAzione:\nport3 ‚Üí inoltra sulla porta 3\n‚öñÔ∏è Load Balancing\nDescrizione:\nCon il load balancing si distribuiscono i pacchetti destinati a 10.1.*.* e provenienti da porta 3 e 4 su porta 2 e 1.\n\n\nQuesta cosa non si pu√≤ fare con l‚Äôinoltro basato solo sulla destinazione IP (IP DST), perch√© andrebbero tutti sulla stessa porta.\n\nAstrazione di Open Flow¬†\nOpen Flow pu√≤ comportarsi come diversi dispositivi (router, switch, firewall, NAT) in base al match + action\n\n\nEsempio di rete Open Flow\n\nQuesta rete ha\n\n6 host (da h1 a h6)\n3 switch (s1,s2,s3)\n1 controller OF che controlla il tutto.¬†\n\nIl controller crea delle regole affinch√©:¬†\n\nI pacchetti da h5 e h6¬†arrivino a h3 o h4¬†\nIl traffico¬†passi attraverso s1 e poi s2¬†\n\nQuello che succede √® questo:\n\nSpiegazione con i relativi match + action:\n\n\n\n\n\n                  \n                  In sintesi, inoltro generalizzato¬†perle \n                  \n                \n\n\nMatch + action?¬†\n\nControlla certi campi del pacchetto (match)¬†\nFai qualcosa se c‚Äô√® corrispondenza (action)¬†\n\n\nCosa pu√≤ fare un dispositivo OpenFlow?¬†\n\nGuardare tutti i campi dell‚Äôintestazione di prima¬†\nDecidere cosa fare (scarto, inoltro‚Ä¶)¬†\n\n\n√à utile perch√© pu√≤ programmare il comportamento della rete, come fossero tanti dispositivi diversi\n\n\n\nMIDDLEBOX\nCosa √® e dove si trova?¬†\n‚ÄúQualsiasi dispositivo intermedio nella rete che svolge¬†funzioni diverse¬†da quelle¬†normali¬†di¬†un router IP‚Äù\n\nNon si limita ad inoltrare i pacchetti in base all‚ÄôIP di destinazione (come un semplice router) ma fa anche altro.\nEsempi di MB:\n\n\nEvoluzione delle reti moderne (skip?)\nAll‚Äôinizio: hardware chiuso\nLe reti usavano:\n\nHardware proprietario (es. router Cisco, firewall Fortinet, ecc.)\nTutto era bloccato: non si poteva modificare o programmare niente\nLe funzioni erano fisse e legate al dispositivo fisico\n\n\nPassaggio a whitebox + API aperte\n\nWhitebox = hardware generico\nCon API (interfacce standard pubbliche) aperte tipo OpenFlow\nSi abbandona l‚Äôhardware proprietario\nLe azioni locali diventano programmabili con match + action\nL‚Äôintelligenza si sposta nel software (√® l√¨ che innovi)\nIl controller SDN √® centrale e dice a tutti cosa fare\n\n\nNFV ‚Äì Network Functions Virtualization\n\nPorta le funzioni di rete nel software che non sono pi√π legate all‚Äôhardware\nInvece di avere un firewall fisico si usa un software firewall su un server\nFunziona su hardware generico (COTS = ‚Äúcommerciale standard‚Äù)\n\nPu√≤ girare su:\n\nuna macchina virtuale (VM)\nun container\nanche nel cloud\n\nLe funzioni virtualizzate:\n\nrouter\nfirewall\nswitch\nNAT\nload balancer\necc.\n\n\nCosa cambia tra le due?\n\n\nLa clessidra IP\nIn passato:\n\nTanti protocolli di applicazione, trasporto, collegamento e fisico\nSolo uno a livello di rete ‚Üí tutti i dispositivi in Internet lo devono supportare\n\n\n\nCon il passare degli anni:\n\nSono spuntati nuovi elementi dentro il livello IP (middlebox)\nPi√π complicata ma molto pi√π scalabile\n\n\n\nPrincipi architetturali di Internet\n\n\nLa rete centrale (router, switch) fa solo passaggio pacchetti\nLa logica e la complessit√† (es. controllo errori, sicurezza, affidabilit√†) sono fatte dai dispositivi agli estremi (host di partenza e di arrivo)\n\n\nTre idee chiave della filosofia Internet:\n\nConnettivit√† semplice, trasferimento grezzo di pacchetti da A a B\nProtocollo IP come base, il ‚Äúcollo stretto‚Äù della clessidra, maschera la complessit√† dei livelli sotto\nL‚Äôintelligenza √® ai bordi della rete, √® l√¨ che si fanno cose complesse: app, sicurezza, controlli, logiche\n\n\nEnd to End\n\n‚ÄúAlcune funzioni (come affidabilit√† o controllo errori) √® meglio metterle negli host, non dentro la rete‚Äù\nSolo host A e B gestiscono cose complesse\nI router trasportano e basta\nEs: TCP fa il controllo errori tra gli host\n\n\nHop-by-hop\n\nOgni nodo intermedio (router) si occupa di garantire il trasferimento\nOgni tratto della rete deve essere ‚Äúintelligente‚Äù\n\n\n\nPerch√© Internet ha scelto end-to-end?\n\nPi√π semplice: la rete √® pi√π stupida = pi√π economica, pi√π scalabile\nPi√π robusta: se un nodo inter\n\n"},"UNI/ANNO-2/RETI/RETI-LEZ.14":{"slug":"UNI/ANNO-2/RETI/RETI-LEZ.14","filePath":"UNI/ANNO 2/RETI/RETI LEZ.14.md","title":"RETI LEZ.14","links":[],"tags":[],"content":"piano di dati e di controllo di una rete\nprincipalmente una rete fa 2 cose:\n\ninoltro(forwarding)\n\nsposta i pacchetti dall‚Äôingresso del router alla sua appropriata uscita\n\nfa parte del PIANO DEI DATI\n\n\n\n\ninstradamento(routing)\n\ndetermina il percorso migliore che i pacchetti devono eseguire dalla sorgente alla destinazione\n\nfa parte del PIANO DI CONTROLLO\n\n\n\n\n\nPIANO DI CONTROLLO su un router tradizionale\nOgni router:\n\nCalcola autonomamente la propria tabella di instradamento.\nComunica con gli altri router (scambio di informazioni di routing).\nQuando riceve un pacchetto, consulta la tabella e decide dove inoltrarlo.\n\nüí° In questo modello, ogni router partecipa attivamente all‚Äôelaborazione delle decisioni di instradamento.\n\nPIANO DI CONTROLLO di tipo SDN\nCon SDN (Software Defined Networking):\n\nIl controllo √® centralizzato: un controller remoto (software) calcola le tabelle di instradamento.\nI router non prendono decisioni: ricevono le tabelle gi√† pronte e si limitano all‚Äôinoltro.\nüí° Questo approccio separa completamente il piano di controllo (gestito dal controller centrale) dal piano dei dati (nei router/switch).\n\n\nAlgoritmi di instradamento\nservono per trovare il percorso migliore da far fare al pacchetto\n\nPercorso:¬†sequenza di router che i pacchetti attraversano dall‚Äôorigine alla destinazione¬†\nMigliore:¬†con meno costo\n\n\nUso dei grafi per rappresentare il tutto\nPer rappresentare una rete si usano i grafi dove:\n\ni nodi\n\nsono i router\n\n\ngli archi\n\nsono il collegamento con un peso\npossono avere una direzione\n\n\n\n\nCollegamento diretto\nper collegamento diretto si intende un collegamento che non ha nodi intermezzi\n\nClassificazione degli algoritmi di instradamento\nSi basa su due criteri fondamentali\n\n1. Tipo di informazione usata\n\nGlobali (link state):\n\nOgni router conosce l‚Äôintera mappa della rete.\nIl calcolo del percorso ottimale √® centralizzato.\n\n\nDecentralizzati (distance vector):\n\nOgni router conosce inizialmente solo i costi verso i suoi vicini.\nCon successive iterazioni, apprende gradualmente i costi verso tutti gli altri router.\n\n\n\n\n2. Frequenza di aggiornamento dei percorsi\n\nStatici:\n\nCambiano raramente.\nRichiedono intervento umano.\n\n\nDinamici:\n\nSi aggiornano automaticamente al variare dei costi dei link.\n\n\n\n\n\n\nAdattamento in base ai costi\n\n\nalcuni algoritmi adattano il percorso in base a eventuali congestioni o altro\n\n\n\n2 tipi di algoritmi\nin questa lezione vedremo due tipi di algoritmi\n\nDijkstra\nDistance Vector\n\nAlgoritmo link-state: Dijkstra\n√® un algoritmo GLOBALE che consente di trovare il percorso migliore(con costo minimo) a partire da un nodo u verso tutti gli altri nodi\n\n√à globale perch√© ogni router condivide le informazioni dei suoi collegamenti vicini a tutti gli altri router\n\nlo fa in broadcast\n\n\nquindi tutti i router conoscono la rete completa e possono calcolare il percorso migliore\nüîÅ Funzionamento iterativo\nL‚Äôalgoritmo mantiene un insieme N&#039; di nodi per cui ha gi√† trovato il cammino minimo.\nAd ogni passo aggiunge un nuovo nodo a N&#039;, quello raggiungibile con il minimo costo attuale.\nDopo k passi, avr√† trovato i cammini migliori verso k nodi.\nNotazioni utilizzate:\n\n\nPseudocodice dell‚Äôalgoritmo\n\n\ninizializzazione\n\nparte da u\nmette il costo di quelli vicini ad u\ntutti gli altri a \\infty\n\n\nciclo\n\nprende tutti i nodi che non sono in N&#039;\ntipo si prende un nodo w con distanza minima da u a w\n\ninizialmente questo nodo w √® tra quelli conosciuti quindi adiacente a u\n\n\naggiungiamo w a N&#039; che inizialmente aveva solo u\nprende i nodi adiacenti a w e trova la loro distanza minima\n\nripeto il ciclo finch√© N&#039; √® pieno\n\n\n\n\n\nEsempio\npasso 0\n\naggiorno le distanze da u per ogni nodo adiacente\n\n\npasso 1.1\n\nprendo la distanza minima da u\n\nquindi x\n\n\n\n\npasso 1.2\n\nvedo se a partire da x ho un costo inferiore\n\ntipo da v mi conviene rimanere con u\ncon w no\ncon y no\n\n\n\n\npasso 2.1\n\nora prende la distanza minima da x e rif√† i calcoli\n\ntocca a y\n\n\n\n\npasso 2.2\n\ncalcolo nuovi possibili distanze migliori\n\n\npasso 3.1\n\nprendo le distanze adiacenti a v e vedo se sono migliori\n\n\npasso 3.2\n\nnotiamo che sono tutte uguali o peggiori\n\n\npasso 4.1\n\nprendo il nodo minore adiacente a v\nin questo caso w\n\n\npasso 4.2\n\nmi accorgo che sono tutti uguali o peggiori\n\n\npasso 5.1\n\ncerco nodo minimo adiacente\nin questo caso z\n\n\npasso 5.2\n\nmi accorgo che non posso migliorare nulla da z\nil risultato finale sar√†:\n\n\n\nAltro esempio\n\nCosti di questo algoritmo\n\nogni volta vado a visitare n-1 nodi quindi costo O(n^2)\n\nla prima volta n\npoi n-1\npoi n-2\ne cos√¨ via\n\n\nse usassi un heap come struttura dati avrei O(nlogn)\nper il costo dei messaggi\n\nad ogni iterazione faccio un broadcast che costa O(n)\n\nperch√© deve arrivare a tutti gli n nodi(router)\n\n\nvisto che abbiamo n router costa O(n^2)\n\n\n\nAlgoritmo distance vector (decentralizzato)\nsi basa su un‚Äôequazione ideata da Bellman-Ford\n\nDove:¬†\n\nd‚Çì(y) ‚Üí costo del percorso minimo da x a y¬†\nC‚Çì,·µ• ‚Üí costo collegamento diretto da x a v¬†\nd·µ•(y) ‚Üí costo cammino minimo da v a y\n\nEsempio\nNodo x vuole raggiungere y.\n\nHa tre vicini diretti:\n\nVia v‚ÇÅ:\n\nc(x,v‚ÇÅ) = 4\nd(v‚ÇÅ,y) = 8\nTotale: 4 + 8 = 12\n\n\nVia v‚ÇÇ:\n\nc(x,v‚ÇÇ) = 3\nd(v‚ÇÇ,y) = 10\nTotale: 3 + 10 = 13\n\n\nVia v‚Çô:\n\nc(x,v‚Çô) = 9\nd(v‚Çô,y) = 7\nTotale: 9 + 7 = 16\nüîç Quindi x sceglie il percorso con costo minimo, cio√® 12 passando per v‚ÇÅ.\n\n\n\nüìã Come funziona il Distance Vector nella rete\n\nOgni router mantiene una tabella delle distanze (distance vector) verso tutte le destinazioni.\nInizialmente conosce solo i costi verso i vicini diretti.\nI router si scambiano le tabelle con i loro vicini.\nQuando un router riceve la tabella di un vicino, aggiorna la propria con la formula di Bellman-Ford.\nSe ci sono cambiamenti nei costi, inviano di nuovo la tabella.\nIl processo si ferma quando nessuna tabella cambia pi√π ‚Üí la rete ha convergenza.\n\nEsempio specifico ma astratto\nT=0 inizializzazione\n\n\nLa tabella in alto a sx mostra il¬†distance vector¬†di a cio√® quanto a stima che costi raggiungere ogni altro nodo.¬†\nOvviamente come per prima per raggiungere s√© stesso √® 0, per raggiungere i suoi vicini √® 8 e 1. Gi altri li mette a inf perch√© non sa chi sono\nCosa succede:¬†\nA invia la sua tabella a¬†b¬†e¬†d¬†\nD¬†la invia a¬†a, e, g¬†\nEcc‚Ä¶\n\nT=1 Ascolto e aggiornamento e invio dei nuovi vettori\n\ni nodi ricevono le tabelle dai loro vicini\n\nstep successivo ‚Üí aggiornamento delle varie tabelle dopo il ricalcolo con la formula detta prima\n\nora avviene un reinvio con i calcoli aggiornati\n\nquesta cosa andr√† in loop con T=1‚Üí 2 ‚Üí 3 ecc‚Ä¶ finch√© non ci saranno pi√π aggiornamenti da fare\nEsempio decente fatto da chat gpt\nüß™ Esempio di aggiornamento del Distance Vector ‚Äì Nodo d\nüîπ Situazione iniziale:\nIl nodo d ha come vicini diretti:\n\na, e, g, tutti con costo diretto = 1.\nRiceve i rispettivi distance vector:\nDa a: sa che a ‚Üí b = 8\nDa e: sa che e ‚Üí b = 1\nDa g: non ha informazioni su b ‚Üí considera ‚àû\n\n‚úèÔ∏è Applicazione della formula Bellman-Ford:\n\nüîç Valutiamo le opzioni:\n\nVia a:\n\nc(d,a) = 1, d‚Çê(b) = 8 ‚Üí totale = 9\n\n\nVia e:\n\nc(d,e) = 1, d‚Çë(b) = 1 ‚Üí totale = 2 ‚úÖ\n\n\nVia g:\n\nd_g(b) non √® noto ‚Üí costo = ‚àû\n\n\n\nüîß Il percorso migliore √® tramite e, con costo totale = 2.\n‚úÖ Risultato:\nD_d(b) = 2\nIl nodo d ora conosce una nuova stima pi√π efficiente per raggiungere b, passando da e.\nPrendiamo l‚Äôesempio di prima delle slide e vediamo nello specifico cosa succede\ncosa avviene esattamente al livello di calcoli?\n\nqui sotto b riceve i distance vector dai suoi vicini\n\nper poi fare un ricalcolo adeguato alla sua tabella\n\n\n\neffettua i calcoli\npossiamo vedere come dopo i ricalcoli la tabella cambi(quella sotto)\n\nvisto che siamo ancora in t=1\nse c riceve il DV da b non otterr√† la tabella aggiornata\n\nc effettua i calcoli e cambia la tabella\n\npoi tocca ad e che si chieder√†‚Ä¶\n\ne cos√¨ va avanti‚Ä¶\n\nComunicazione iterativa sullo stato\n\npossiamo vedere che ad ogni t\n\nle informazioni di un singolo router vengono diffuse a pi√π router\n\nAggiornamento costi dei collegamenti\nogni nodo ha una tabella con i vari costi degli altri nodi\n\nse un nodo cambia il suo costo\nil nodo deve aggiornare la sua tabella delle distanze e rinviarla a tutti gli altri\n\nle buone notizie viaggiano in fretta\n\nora vediamo cosa succede se il collegamento da x-y passa da 4 a 1:\n\na tempo 0\n\ny si accorge che il collegamento x-y √® cambiato\n\naggiorna il suo DV e lo manda a tutti i vicini\nsia x che z\n\n\n\n\na tempo 1\n\nz si accorge che pu√≤ passare per y per pagare meno\naggiorna il suo DV e lo invia ai vicini\n\n\na tempo 2\n\ny riceve il nuovo DV ma si accorge che per lui non fa differenza\nnon aggiorna nulla\nnon invia nulla\nsi dice che:\n\n\nIl Distance Vector reagisce solo quando qualcosa cambia.\nLe buone notizie (cio√® percorsi migliori) si propagano in fretta perch√© ogni aggiornamento genera altri aggiornamenti solo se migliorativi.\n\nle cattive notizie viaggiano piano\n\nqui il percorso x-y peggiora da 4‚Üí 60\n\na tempo 0\n\ny deve cercare una soluzione migliore per arrivare a x\npensa di passare per z pagando 1+4\n\nperch√© z arriva a x passando per y(non aggiornato a 60)\n\n\naggiorna il DV e lo invia ai vicini\n\n\na tempo 1\n\nz riceve il DV di y\ny dice di passare a x con costo 5\nz allora calcola che gli ci vuole 6 per raggiungere x\n\n\na tempo 2\n\ny riceve il DV di z\npensa che z impiega 6 per passare a x\nquindi pensa di metterci 6+1=7\nin poche parole si crea un loop infinito chiamato\n‚Äúproblema del conteggio infinito‚Äù\n\n\n\nAltro problema\n\nin questo caso viene rotto il collegamento x-y\nsia y che z non capiscono cosa stia succedendo perch√© ognuno pende dall‚Äôaltro nell‚Äôaggiornamento del DV\ny prova a raggiungere x passando per z, che a sua volta si basa su y.\nSoluzione parziale al problema(inversione avvelenata)\n\nSe z instrada verso x tramite y, allora non deve mai dire a y che ha una via verso x.\nInvece, dice a y:\n\nD_z(x)=+‚àû\n\n\nCos√¨ y non viene ingannato nel momento in cui perde il collegamento diretto con x.\nüëâ Questo blocca il ciclo prima che inizi.\nMa funziona solo se il ciclo √® tra due nodi adiacenti.\n\n\n\nQuando invece non funziona(fail)\n\nCon topologie pi√π complesse (pi√π di due nodi nel ciclo), l‚Äôinversione avvelenata non riesce a bloccare tutto.\nL‚Äôesempio mostra un ciclo tra x, y, z, w.\n\nAnche con poisoned reverse, si forma un loop a tre nodi, e i costi continuano a salire\n\nüõë Per reti pi√π grandi si usano altri meccanismi: limite di costo massimo, split horizon, ecc.\n\n\n\nconfronto\n"},"UNI/ANNO-2/RETI/RETI-LEZ.15":{"slug":"UNI/ANNO-2/RETI/RETI-LEZ.15","filePath":"UNI/ANNO 2/RETI/RETI LEZ.15.md","title":"RETI LEZ.15","links":[],"tags":[],"content":"Piano di controllo parte 2\nFino ad ora abbiamo visto che i router erano tutti uguali e generici\n\n\n                  \n                  la realt√† per√≤ non √® questa \n                  \n                \n\n\nNon si possono salvare tutte le destinazioni nelle tabelle di routing;¬†\nGli scambi tra le tabelle di routing occuperebbero un tempo enorme intasando la rete;¬†\nGli algoritmi studiati sono troppo lenti per reti cos√¨ grandi;¬†\nInternet √® una rete di reti;¬†\nOgni amministratore ISP vuole gestire il routing nella sua parte di rete.\n\n\n\nObiettivo: gestire router sotto la stessa amministrazione\nRouting ‚Äúscalabile‚Äù\nPresenta il concetto di aggregare router in forme scalabili che si scambiano info tra loro\nora parleremo di Sistemi autonomi AS\n\ninsiemi di router che sono nella stessa ISP\npossono essere pi√π di uno\n\nPresentano 2 tipi di instradamento\n\nintra AS tutti i router usano stesso protocollo\ninter AS routing tra AS diversi, per comunicare ci sono i gateway router che gestiscono quello interno e esterno\n\nesempi di AS interconnessi tra loro\n\nCi sono 3 AS, ogni AS ha pi√π router.\n\nI router dentro un AS comunicano tra solo tramite¬†intra-AS\n\nI gateway router sono quelli che collegano i vari AS tra loro (connessioni Inter-AS)\n\n\nqui ogni router ha una sua tabella di inoltro riempita utilizzando degli algoritmi che dicono ‚Üí\ncome raggiungere un router in intra-AS\nse vuoi mandare fuori da AS devi usare sia intra-As che inter-As\n\nEsempio\n\n\nL‚Äôinstradamento inter-AS in¬†AS1 deve imparare quali destinazioni sono raggiungibili attraverso AS2 e quali attraverso AS3 e¬†dare queste informazioni a tutti i router in AS1\n\ntipi di protocolli di instradamento intra-AS\n\nquelli intra sono quelli dentro il sistema\n\n\nRIP- routing information protocol¬†\n\n√à di tipo distance vector (DV), i router scambiano tabelle ogni 30 secondi.¬†NON SI USA PI√ô\n\n\nEIGRP¬†‚Äì¬†Enhanced Interior Gateway Routing Protocol¬†\n\nBasato su DV, usato nelle reti Cisco¬†¬†\n\n\nOSPF ‚Äì Open Shortest Path First¬†\n\nDi tipo Link State, ogni router costruisce una mappa della rete e scambia informazioni solo se ci sono modifiche nella rete.¬†Usato nelle reti moderne.¬†Questo protocollo √® identico a IS-IS (√® una nota nelle slide)\n\n\n\nPrecisazioni su OSPF\n√® di tipo link-state\n\nogni router invia lo stato dei suoi collegamenti agli altri router in broadcast\n\nviene chiamato flooding\nusa il protocollo IP e non TCP o UDP\n\n\ncome criteri per capire se conviene o meno usare un determinato router vengono usate informazioni importanti come la larghezza di banda\nper effettuare i calcoli viene usato l‚Äôalgoritmo di Dijkstra con tutti i messaggi autenticati per fornire una sicurezza maggiore\nOSPF √® divisa in due livelli\n\n\nArea locale: un sottoinsieme della rete\nBackbone: la dorsale che collega tutte le varie aree tra di loro\nQueste aree OSPF sono comunque tutte intra-AS, ma suddivise internamente in sottosezioni chiamate aree.\n\n\nogni router ha solo conoscenza della sua area e come raggiungere le altre aree, ma senza troppe informazioni\n\nqueste aree sono tutte collegate dalla rete dorsale quella in azzurro\n\ncome avviene nello specifico l‚Äôinstradamento inter-AS con BGP\n√à il protocollo standard per l‚Äôinstradamento inter-domain, permette ai vari AS di comunicare tra loro (la colla di internet).\n\nPermette ad un AS di comunicare la sua esistenza e tutte le destinazioni che pu√≤ raggiungere al resto di Internet.\n\nüîÑ Tipi di BGP\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTipoSignificatoDove operaA cosa serveeBGPExternal BGPTra AS diversiRiceve annunci da AS vicini (es: ‚Äúper andare in rete X, passa da me‚Äù)iBGPInternal BGPDentro un ASPropaga internamente le informazioni ricevute da eBGP\n\nUn router di confine riceve annunci BGP da AS esterni tramite eBGP.\nPoi distribuisce l‚Äôinformazione a tutti gli altri router del suo AS tramite iBGP.\n\n\nUna sessione BGP\n√à una connessione TCP semi permanente tra due router BGP che sono detti peer\nquesto tipo di sessione rappresenta il vero e proprio scambio di info sui percorsi\n\nIl path vector √® la lista degli AS attraversati per arrivare a una rete\nCome sono fatti i messaggi BGP\nSono tutti scambiati tramite connessione¬†TCP¬†tra peer:\n\nI messaggi servono a stabilire, mantenere e aggiornare la relazione tra peer.\n\nüßæ Tipi di messaggi principali:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMessaggioFunzioneOPENAvvia la connessione tra due peer BGP, include anche dati per l‚ÄôautenticazioneUPDATEServe per annunciare nuovi percorsi o ritirare rotte vecchieKEEPALIVEMantiene la connessione attiva, anche se non ci sono UPDATE (funziona anche come ACK di OPEN)NOTIFICATIONSegnala errori o anomalie e pu√≤ chiudere la connessione TCP\nUna rotta BGP\n√® un tipo di informazione inviata da un certo AS che dice:\n\n\n                  \n                  per raggiungere la rete X passa per questo determinato percorso composto da vari AS \n                  \n                \n\nLa rotta √® composta da:\nüîπ 1. Prefisso\n\nIndica la rete di destinazione (es. 10.0.0.0/16)\nüîπ 2. Attributi\nDanno informazioni sul percorso\nI pi√π importanti:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAttributoSignificatoAS-PATHElenco degli AS da attraversare per raggiungere il prefisso. Aiuta ad evitare loop.NEXT-HOPIP del router che conosce il percorso verso il prefisso. √à il primo ‚Äúsalto‚Äù dell‚ÄôAS-PATH.\n\n\n                  \n                  Non basta comunque il percorso pi√π corto, BGP segue precise regole decise dagli amministratori \n                  \n                \n\nEsempio\n\n1Ô∏è‚É£ AS3 ‚Üí AS2 (eBGP)\n\nIl router 3a in AS3 annuncia al router 2c in AS2 la rotta verso la rete X, usando eBGP.\nIl messaggio contiene:\n\nPrefisso: rete X\nAS-PATH: AS3\nNEXT-HOP: IP del router 3a\n2Ô∏è‚É£ Dentro AS2: propagazione con iBGP\n\n\nIl router 2c accetta il percorso AS3, X (se le politiche di AS2 lo permettono).\nPoi invia lo stesso annuncio tramite iBGP a tutti gli altri router in AS2: 2a, 2b, 2d.\nIl NEXT-HOP rimane 3a (non cambia nei messaggi iBGP).\n3Ô∏è‚É£ AS2 ‚Üí AS1 (eBGP)\nOra il router 2a (AS2) annuncia al router 1c (AS1) la rotta verso X:\n\nIl messaggio eBGP dice:\n\nPrefisso: X\nAS-PATH: AS2, AS3 ‚Üí si aggiunge AS2 in testa\nNEXT-HOP: IP del router 2a (perch√© √® chi sta facendo l‚Äôannuncio)\n\n\n\n\n\n\n\n                  \n                  cosa ricordare di questo esempio \n                  \n                \n\n\nIl NEXT-HOP cambia solo nei messaggi eBGP (ogni AS annuncia se stesso come nuovo punto di accesso).\nI messaggi iBGP non modificano il NEXT-HOP.\nGli AS-PATH vengono aggiornati solo nei passaggi tra AS (eBGP).\n\n\n\nEsempio con percorsi multipli\n\nüìå Riepilogo:\nabbiamo pi√π percorsi e li sceglie secondo le policy\n\n(tipo preferire meno AS nel cammino o evitare certi AS, costi ecc‚Ä¶)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFaseCosa succede1Ô∏è‚É£1c riceve due percorsi per la rete X (via 2a e 3a)2Ô∏è‚É£Applica le politiche di selezione BGP3Ô∏è‚É£Sceglie il percorso AS3, X4Ô∏è‚É£Diffonde internamente quel percorso via iBGP\nEsempi di come vengono popolate le tabelle di inoltro\n‚úÖ Obiettivo comune\nI router 1a, 1b e 1d devono sapere come raggiungere la rete X (situata in AS3), usando le informazioni BGP ricevute da 1c, che √® il router gateway del loro AS (AS1).\nCaso 1 ‚Äì Next-Hop modificato (next-hop-self)\n\nIl router 1c modifica il NEXT-HOP e lo imposta su s√© stesso quando inoltra l‚Äôannuncio BGP agli altri router interni (via iBGP).\nQuesto semplifica il routing interno: gli altri router (1a, 1b, 1d) devono solo sapere come raggiungere 1c.\nüß† Comportamento attivo di BGP: modifica il NEXT-HOP\n\n\nCaso 2 ‚Äì Next-Hop NON modificato (default)\n\nIl router 1c NON modifica il NEXT-HOP, quindi lo lascia impostato su 3a (router esterno).\nI router interni devono sapere come raggiungere 3a (indirizzo esterno) ‚Üí pi√π complesso.\nüß† Comportamento passivo di BGP: non tocca il NEXT-HOP\n\n\nCaso 3 ‚Äì Dettaglio sul forwarding OSPF\n\nStesso comportamento di caso 1 (cio√® next-hop-self attivo), ma focalizzato sull‚Äôeffetto pratico:\n\nMostra come router diversi usano interfacce diverse per arrivare a 1c ‚Üí e quindi a X.\nEvidenzia il ruolo dell‚ÄôOSPF intra-AS nel determinare i percorsi effettivi per inoltrare i pacchetti.\n\n\nüß† Focus sul calcolo della tabella di inoltro (dati forwarding), non su un comportamento diverso di BGP.\n\n\nCaso 4 ‚Äì Instradamento a patata bollente (hot potato routing)\n\nQuando un AS ha pi√π possibili NEXT-HOP esterni per raggiungere una rete (es. X), e i percorsi sono equivalenti dal punto di vista BGP (AS-PATH ecc.), allora:\nL‚Äôinstradamento **sceglie il NEXT-HOP con il minimo costo intra-AS.\nOvvero: ‚Äúbutta fuori il traffico il prima possibile‚Äù, senza preoccuparsi del percorso esterno.\n\nImplementare determinate politiche attraverso gli annunci\n\nGli ISP possono voler ‚Äúforzare‚Äù determinati percorsi\n\nper farlo vengono privati determinati annunci cos√¨ da evitare instradamenti per determinati AS\nL‚ÄôAS A annuncia a B e C che pu√≤ raggiungere Aw (cio√® la rete w del suo cliente).\nIl router B riceve l‚Äôannuncio da A, ma decide volontariamente di NON annunciarlo a C.\n\n√à una scelta politica, non tecnica.\n\n\n\naltro esempio\n\n\n\nx √® una rete cliente collegata sia a B che a C (quindi √® dual-homed).\n\n\nA, B, C sono provider (reti di ISP).\n\n\nx vuole controllare come viene usata come punto di transito.\n\n\nx riceve da C un annuncio BGP (es. ‚Äúper raggiungere y passa da C‚Äù).\n\n\nx decide di NON annunciare a B questo percorso verso C/y.\n\n\nRisultato: B non sa che pu√≤ raggiungere y passando da x ‚Üí C ‚Üí y.\n\n\nQuindi B non user√† x come transito per parlare con C.\n\n\nconclusione\nquali criteri usano i router BGP per scegliere le rotte da seguire?\n\nLocal Preference (Pref Local)\n‚û§ Valore impostato manualmente per definire preferenze politiche.\n\n‚ÄúPreferisco uscire da questa interfaccia per motivi di politica aziendale.‚Äù\n\n\nAS-PATH pi√π corto\n‚û§ Percorso con meno AS da attraversare.\n\n‚ÄúMeno passaggi, meno complicazioni.‚Äù\n\n\nNEXT-HOP pi√π vicino\n‚û§ Criterio detto ‚ÄúHot Potato Routing‚Äù:\n\n‚ÄúUscire il prima possibile dal mio AS, anche se il percorso esterno √® peggiore.‚Äù\n\n\nBGP ID pi√π basso (tie-break)\n‚û§ Se tutto il resto √® uguale, si usa l‚ÄôID BGP (tipicamente l‚Äôindirizzo IP pi√π basso tra i peer).\nüîÑ üìå Differenze tra intra-AS e inter-AS\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAspettoIntra-ASInter-ASPoliticheUn solo amministratore ‚Üí decisioni localiOgni AS vuole controllo totale sul proprio trafficoScalabilit√†Reti gerarchiche (es. OSPF aree) riducono aggiornamentiBGP non scala per tabelle grandi internePrestazioniOttimizzabili (si pu√≤ scegliere percorsi pi√π rapidi)Le performance sono secondarie alle politiche\nIP ANYCAST\nAnycast √® una tecnica di instradamento IP in cui pi√π server condividono lo stesso indirizzo IP pubblico (es. 8.8.8.8) e:\n\nil traffico viene inviato automaticamente al server ‚Äúpi√π vicino‚Äù secondo la metrica di routing (es. minor numero di AS da attraversare).\nil client non sa quale server ricever√† il traffico: usa semplicemente quell‚ÄôIP.\n\n\nControllo distribuito prima degli SDN\n(Software-Defined-Networking)\n\nPrima degli SDN avevamo sistemi dove i router erano autonomi\n\nprendono decisioni per conto proprio\n\n\nerano router di tipo monolitico\n\nhanno tutto proprietario hardware + software per calcolare in autonomia le rotte e gestire tutti i protocolli\n\nIP, OSPF, BGP\n\n\n\n\n\nDal 2005 si pensa che i router devono essere flessibili e programmabili e che non siano totalmente autonomi\nmodello classico non SDN\nOgni router ha il proprio algoritmo di instradamento e fa i calcoli in autonomia\n\nha anche una tabella di forwarding locale\n\n\nmodello con SDN\n\nI router (o switch) non hanno intelligenza interna: eseguono solo le regole ricevute.\nIl piano di controllo √® centralizzato: esiste un controller remoto che:\n\nmantiene la visione globale della rete\nprende decisioni\ninstalla direttamente le regole negli switch\n\n\nGli switch guardano i pacchetti e, se non sanno cosa fare, chiedono al controller remoto.\n\n\nVantaggi di averlo logicamente centralizzato\nCentralizzando il controllo:\n\n√à pi√π facile evitare errori di configurazione.\nSi ottiene maggiore flessibilit√† nel gestire i flussi (es. per priorit√†, QoS, sicurezza).\nL‚Äôoperatore ha una visione globale della rete.\nCentralizzata = pi√π semplice, uniforme, meno errori\nLe reti non sono pi√π chiuse nei sistemi di un singolo produttore\n\npossono esserci standard pi√π aperti come OPENFlow(vedrai tra poco)\n\n\n\nAnalogia per spiegare SDN\n\nConcetto di ingegneria del traffico\n√® l‚Äôinsieme delle tecniche e conoscenze per:\n\nOttimizzare le prestazioni della rete\nMisurare, modellare e controllare il flusso del traffico\nRaggiungere obiettivi specifici, come:\n\nevitare congestioni,\nbilanciare il carico,\nusare al meglio le risorse.\nIl routing tradizionale √® limitato e poco flessibile per ottimizzare il traffico.\nCon gli SDN √® pi√π facile creare tecniche efficaci per gestire il traffico!\n\n\n\nEstensione di OSPF\nsostanzialmente viene detto che:\n\nse non lavoriamo con le SDN\npossiamo usare una estensione delle OSPF che aggiungono dettagli per scegliere i percorsi\nLe estensioni permettono a OSPF di annunciare parametri utili alla gestione avanzata del traffico:\n\nbanda disponibile\nritardo\njitter\nperdita di pacchetti\n\n\nQuesti dati aiutano a modellare meglio la rete, ma OSPF da solo non pu√≤ usarli\nviene usato MPLS-TE\n\n(Multiprotocol Label Switching ‚Äì Traffic Engineering)\npermette di indirizzare i flussi correttamente e evitare zone di congestione\nFunziona senza SDN, ma con logica simile ma resta comunque distribuito\n\n\n\nTorniamo a parlare di SDN\n\n√® centralizzato e formato cos√¨\n\nInoltro generalizzato ‚Äúbasato sui flussi‚Äù¬†\n\nEs. OpenFlow: il controller decide come gestire ogni flusso di pacchetti, non solo in base alla destinazione.¬†\n\n\nSeparazione tra piano di controllo e piano dei dati¬†\n\nGli switch/router si occupano solo di inoltrare.¬†\nLe decisioni vengono prese da un controller centrale.¬†\n\n\nFunzioni di controllo esterne¬†\n\nRouting, access control, bilanciamento del carico‚Ä¶ sono gestiti fuori dagli switch.¬†\n\n\nApplicazioni programmabili¬†\n\nSi possono scrivere app che controllano la rete (es. per routing dinamico, sicurezza, ottimizzazione).\n\n\n\nCome √® suddiviso correttamente SDN\n\n\nNel piano dei dati abbiamo semplicemente gli switch che eseguono ci√≤ che gli viene ordinato dall‚Äôalto\n\nLa comunicazione tra controller e switch usa API standard tipo¬†Open Flow\n\n\nPoi abbiamo un controller che fa da intermediario e comunica con i due livelli attraverso delle API\n\n√à¬†distribuito, per migliorare le prestazioni, garantire scalabilit√† e gestire guasti/sicurezza.\nMantiene lo stato della rete: conosce topologia, traffico, link attivi‚Ä¶\n\n\nPoi ci sono le vere e proprie applicazioni che effettuano ‚Äúi calcoli‚Äù\n\nCome √® fatto un controller SDN dentro\n\nPresenta tre livelli principali\n\nLivello di interfaccia con le applicazioni\n\nFornisce API e astrazioni per le app di rete (routing, access control, ecc‚Ä¶)¬†\n\nnetwork graph: mappa della rete.¬†\nRESTful API: interfacce web per le app.¬†\nintent: specifica cosa si vuole ottenere, non come.\n\n\n\n\nGestione dello stato di rete\n\nTiene¬†informazioni aggiornate¬†su:¬†\n\nlink (stato, costi),¬†\nhost (IP, MAC),¬†\nswitch (chi sono, cosa fanno),¬†\ntabelle di flusso (flow tables).¬†\n\n\n√à un¬†database distribuito¬†per affidabilit√† e aggiornamenti rapidi.\n\n\nComunicazione con i dispositivi che controlla\n\nUsa protocolli come¬†OpenFlow¬†o¬†SNMP¬†per inviare regole agli switch.¬†\n√à la parte che parla direttamente con l‚Äôhardware.\n\n\n\nPrecisazione sul protocollo OpenFlow\n\n√à un protocollo di comunicazione tra controller e switch SDN\nUsa¬†TCP¬†per inviare i messaggi (opzionalmente cifrati), questi si dividono i 3 categorie:¬†\n\nController-to-switch: es. installa o aggiorna una regola.¬†\nAsynchronous: lo switch avvisa il controller (es. nuovo flusso, errore).¬†\nSymmetric: generici, usati da entrambi (es. keepalive).\n\n\n\n                  \n                  Non va confuso con l&#039;API Open Flow perch√© il protocollo scambia messaggi e l&#039;API definisce le azioni di inoltro programmabili tipo &quot;se vedi pacchetto X mandalo sull&#039;interfaccia Y&quot;. \n                  \n                \n\nTipi di messaggi spiegati meglio\nüîª Da Controller a Switch (controller-to-switch)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMessaggioFunzionefeaturesChiede allo switch quali funzionalit√†/supporti haconfigureImposta o legge parametri di configurazione dello switchmodify-stateAggiunge, modifica o elimina regole nella tabella di flusso dello switchpacket-outOrdina allo switch di inoltrare un pacchetto specifico su una porta\n\nüî∫ Da Switch a Controller (switch-to-controller)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMessaggioFunzionepacket-inLo switch invia al controller un pacchetto che non sa gestireflow-removedAvvisa che una regola √® stata rimossa dalla tabella di flussoport statusInforma il controller di cambiamenti su una porta (es. guasti, stato)\ninterazione completa tra il piano dei dati e il piano di controllo in una rete SDN\n\n1Ô∏è‚É£ Guasto segnalato (piano dei dati ‚Üí controller)\n\nLo switch S1 rileva un guasto e invia un messaggio port status (OpenFlow) al controller SDN.\n2Ô∏è‚É£ Aggiornamento del controller\nIl controller SDN riceve il messaggio e aggiorna lo stato della rete\n3Ô∏è‚É£ Attivazione dell‚Äôalgoritmo di routing\nL‚Äôapplicazione di routing (es. Dijkstra) viene avvisata perch√© si era registrata per ricevere eventi di cambiamento di stato dei link.\n4Ô∏è‚É£ Ricalcolo dei percorsi\nL‚Äôapp Dijkstra usa:\n\nla mappa della rete (network graph)\nle informazioni aggiornate sullo stato dei link\n\n\nCalcola nuove rotte per evitare il collegamento guasto.\n\n5Ô∏è‚É£ Creazione delle nuove tabelle\nL‚Äôapplicazione interagisce col modulo flow-table computation del controller per creare le nuove tabelle di inoltro.\n6Ô∏è‚É£ Aggiornamento degli switch\nIl controller SDN invia, tramite OpenFlow, le nuove tabelle agli switch che ne hanno bisogno (es. S2, S3‚Ä¶).\n\nConcetto di Intent-Based Networking(IBN)\n√à un modello in cui l‚Äôutente non definisce pi√π ‚Äúcome‚Äù gestire la rete, ma cosa vuole ottenere. L‚Äôinfrastruttura si occupa del ‚Äúcome‚Äù.\n\n1Ô∏è‚É£ L‚Äôutente esprime un intento\n\nIn forma dichiarativa (cio√® il risultato desiderato, non il metodo).\nEsempi:\n\n‚ÄúGarantire latenza &lt; 5 ms tra A e B‚Äù\n‚ÄúIsolare il traffico VoIP‚Äù\n2Ô∏è‚É£ Il controller SDN interpreta l‚Äôintento\n\n\nTraduce l‚Äôobiettivo in azioni concrete:\n\nConfigura switch\nImposta tabelle di flusso\nAlloca risorse (es. larghezza di banda)\n3Ô∏è‚É£ Il controller monitora e adatta\n\n\nControllo continuo:\n\nSe l‚Äôintento non √® pi√π rispettato (es. latenza &gt; 5 ms), interviene automaticamente per ripristinare l‚Äôobiettivo.\nUsa info da moduli come statistics, link-state, host info.\n\n\n\nSDN: Sfide selezionate\n\nRobustezza e affidabilit√† del piano di controllo: deve essere un sistema distribuito dependable (cio√® prevedibile, sicuro, scalabile, affidabile).\n\nDeve resistere ai guasti sfruttando concetti dei sistemi distribuiti.\nLa sicurezza e l‚Äôaffidabilit√† devono essere integrate fin dall‚Äôinizio.\n\n\nReti e protocolli per missioni critiche: SDN deve supportare reti in tempo reale, con alta affidabilit√† e sicurezza.\nEstensione oltre un singolo AS: le SDN devono evolvere per funzionare su pi√π domini amministrativi.\nFondamentale per il 5G: SDN √® una componente chiave per garantire flessibilit√† e controllo nelle reti cellulari di nuova generazione.\n\nüîÆ SDN e il futuro dei protocolli di rete tradizionali\n\nLe tabelle di inoltro non devono pi√π essere calcolate localmente dai router, ma possono essere calcolate centralmente dal controller SDN ‚Üí maggiore coerenza e programmabilit√†.\nPossibile controllo della congestione centralizzato:\n\nIl controller pu√≤ impostare dinamicamente la velocit√† dei mittenti sulla base dei dati di congestione raccolti dai router.\n\n\nDomanda aperta:\nCome evolveranno le funzionalit√† di rete (oggi affidate ai protocolli) quando saranno gestite dalle SDN?\nüëâ Questo apre la porta a nuove architetture di rete pi√π intelligenti e flessibili.\n"},"UNI/ANNO-2/RETI/RETI-LEZ.16":{"slug":"UNI/ANNO-2/RETI/RETI-LEZ.16","filePath":"UNI/ANNO 2/RETI/RETI LEZ.16.md","title":"RETI LEZ.16","links":[],"tags":[],"content":"Conclusione del Livello di rete\nICMP internet control message protocol\n\nUtilizzato da Host e router per comunicare informazioni a livello di rete\n\ntipo errori o richieste\n√® incapsulato dentro IP, ma non viene considerato un protocollo di trasporto perch√© non ha quello come scopo\n\n\ni messaggi di ICMP sono nello stesso datagramma di IP\nInformazioni su come √® strutturato:\n\nTipo (8 bit): identifica il tipo di messaggio (es. richiesta echo, host non raggiungibile, ecc.)\nCodice (8 bit): specifica il significato dettagliato del tipo.\nChecksum (16 bit): per il controllo degli errori.\nResto dell‚Äôintestazione: varia a seconda del tipo di messaggio.\nDati / intestazione IP originale: include i primi 8 byte dei dati del datagramma IP che ha causato il messaggio, per aiutare a identificare il processo responsabile.\n\nTipi di messaggi ICMP\nQuesti sono tutti i messaggi possibili, se scendi gi√π c‚Äô√® un focus sui pi√π utili\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTipoCodiceDescrizioneUtilizzo / Spiegazione00Echo reply (ping)Risposta a una richiesta ping (tipo 8); il destinatario conferma la ricezione.30Destination unreachableSegnala che il pacchetto non pu√≤ essere consegnato.30Network unreachableNessuna rete di destinazione raggiungibile. Potrebbe essere un router a inviarlo.31Host unreachableL‚Äôhost specifico non √® raggiungibile (es. fallimento ARP).32Protocol unreachableProtocollo IP non supportato dalla destinazione.33Port unreachablePorta della destinazione non aperta (es. nessun servizio in ascolto).34Fragmentation requiredNecessaria frammentazione ma non permessa (usato da Path MTU Discovery).36Network unknownLa rete di destinazione √® sconosciuta (nessuna rotta).37Host unknownL‚Äôhost √® sconosciuto (indirizzo errato o non risolvibile).40Source quench (deprecato)Un router congestionato richiedeva all‚Äôhost mittente di rallentare l‚Äôinvio. Ora non pi√π usato.80Echo request (ping)Richiesta ping. Usata per verificare se un host √® attivo e raggiungibile.110TTL expiredIl pacchetto √® scaduto (TTL=0); usato da traceroute per identificare i router sul percorso.‚úÖ Focus pratico sui messaggi pi√π importanti:\nüîπ Echo Request / Echo Reply (Tipo 8/0 e 0/0)\n\nUsati da ping.\nPermettono di sapere se un host √® raggiungibile e misurare il tempo di risposta (RTT).\nLa risposta (tipo 0) contiene gli stessi dati della richiesta (tipo 8), utile per calcoli.\n\nüîπ Destination Unreachable (Tipo 3)\n\nMolto usato dai router o dagli host di destinazione per indicare problemi di raggiungibilit√†.\n\nEs. tipo 3 codice 3 (porta non raggiungibile): succede quando invii UDP a una porta chiusa.\nTipo 3 codice 4 (fragmentation required): usato quando il pacchetto √® troppo grande e il bit ‚Äúdon‚Äôt fragment‚Äù √® attivo ‚Üí utile per scoprire la MTU.\n\n\n\nüîπ Source Quench (Tipo 4)\n\nPermetteva al router di segnalare congestione ‚Üí ora deprecato e non pi√π supportato nei protocolli moderni (sostituito da ECN).\n\nüîπ TTL Expired (Tipo 11)\n\nFondamentale per il comando traceroute: ogni hop lungo il percorso invia questo messaggio quando il TTL arriva a 0.\nServe per ‚Äúmappare‚Äù i router intermedi tra sorgente e destinazione.\n\nFocus su Traceroute e ICMP\n\ncon Traceroute possiamo tracciare il percorso di un pacchetto\n\nposso inviare un pacchetto ‚Äúsonda‚Äù con UDP o ICMP\ninvio questo pacchetto con TTL=1 time to live=1\n\nun messaggio speciale che dopo un tot di secondi o hop dei router scade\nil router decrementa TTL di 1 poi appunto diventa expired e invia un messaggio al mittente\nil mittente cos√¨ capisce quale percorso √® stato eseguito e da quali router\n\n\n\nTTL √® di tipo incrementale cio√® inizia con TTL=1 poi di solito si fa incrementare finch√© non si raggiunge la destinazione voluta\n\nsi fanno pi√π tentativi prima con TTL a 1 poi 2 ecc‚Ä¶\nConcetto di probes(prove):\nil numero di probes √® il numero di pacchetti che vengono inviati tutti con lo stesso TTL\n\nserve per vedere magari pi√π casistiche di percorso\n\n\n\nil traceroute mi serve per capire quanto RTT ho dal i-esimo router\nNuova versione ICMP v6\n\nmiglioramenti vari\ni nuovi router non fanno pi√π troppa frammentazione quindi viene anche reso aggiornato sotto questo punto di vista\n\nGestione delle reti\nUna rete √®:\n\nun sistema formato da migliaia di componenti software e hardware che interagiscono tra loro\nal posto di rete pu√≤ anche chiamarsi Sistema Autonomo\n\n\n\n                  \n                  Gestire e creare una rete √® estremamente difficile \n                  \n                \n\n\nserve pianificare\nmonitorare\ngestire le risorse economiche in modo intelligente\n\n\n\nComponenti che gestiscono la rete\n\n\nServer di gestione\n\n√à il cervello del sistema.\nRaccoglie, elabora e analizza le informazioni inviate dai dispositivi.\nInvia comandi per configurare o modificare il comportamento dei dispositivi.\nCoinvolge spesso operatori umani.\n\n\n\nDispositivi di rete gestiti\n\nSono gli switch, router, firewall, server, ecc.\nHanno componenti hardware e software configurabili e monitorabili.\nOgni dispositivo ha un agente che comunica con il server.\n\n\n\nDati\n\nRappresentano gli ‚Äústati‚Äù del dispositivo:\n\nConfigurazione: es. indirizzo IP, assegnato dall‚Äôamministratore.\nDati operativi: es. vicini OSPF, rilevati automaticamente.\nStatistiche: es. traffico, errori, uptime.\n\n\n\n\n\nAgente di gestione\n\n√à il software installato nel dispositivo gestito.\nRaccoglie e fornisce i dati di stato al server di gestione.\nRiceve e applica i comandi del server.\n\n\n\nProtocollo di gestione di rete\n\nServe a scambiare informazioni tra server e dispositivi gestiti.\nIl server lo usa per interrogare e comandare.\nI dispositivi lo usano per inviare aggiornamenti e notifiche.\nEsempi di protocolli: SNMP, NetConf, RESTCONF.\n\n\n\n\nCome si gestisce una rete?\nSpieghiamo diversi modi per gestire una rete\n\nse sei tipo uno che lavora per modificarle ecc‚Ä¶\n\nCon CLI(Command Line Interface)\n\nMetodo pi√π diretto e tradizionale\nL‚Äôoperatore accede manualmente al dispositivo (es. via SSH) e inserisce comandi\nSupporta anche script automatizzati\nMolti dispositivi offrono anche un‚Äôinterfaccia web\nVantaggio: controllo preciso\nLimite: poco scalabile in reti grandi\n\nCon SNMP/MIB\n(Simple Network Management Protocol / Management Information Base)\n\nSNMP √® un protocollo standard per la gestione dei dispositivi di rete.\nI dati sono organizzati in strutture chiamate MIB (oggetti informativi).\n\ne informazioni che descrivono lo stato, la configurazione e le statistiche di un dispositivo di rete\n\n\nIl server di controllo interroga o modifica i dati tramite SNMP\nVantaggio: standard, supportato da quasi tutti i dispositivi\nLimite: poco adatto alla gestione di configurazioni complesse\nin poche parole hai un software sul server di controllo che comanda e gestisce i tuoi dispositivi senza che devi modificarli tu singolarmente\npuoi farlo ma non conviene\npiuttosto hai una interfaccia e dal server di controllo mandi dei comandi ai dispositivi\n\nCon NETCONF/YANG\n\nApproccio pi√π moderno e astratto\nProgettato per gestire configurazioni in modo robusto e coerente\nYANG √® un linguaggio di modellazione dei dati\nNETCONF √® il protocollo per leggere/scrivere dati compatibili con YANG su dispositivi remoti\nVantaggio: gestione multi-dispositivo, configurazioni strutturate e coerenti\nIdeale per reti complesse e dinamiche\nCon questo hai proprio un linguaggio di configurazione che migliora di molto il tutto\n\nIN POCHE PAROLE\n\ncon CLI vai proprio l√¨ manualmente pezzo per pezzo ecc‚Ä¶\ncon SMNP+MIB aumenti l‚Äôastrazione ma comunque devi manualmente fare determinate operazioni di monitoraggio ecc solo che lo fai dal server di gestione\ncon NETCONF+YANG √® tutto astratto e molto meno manuale\n\nSNMP spiegato meglio con anche MIB\n\nI dati di un dispositivo di rete (sia operativi che di configurazione) sono organizzati in moduli MIB.\nOgni modulo MIB √® come un ‚Äúfile‚Äù che descrive un certo gruppo di informazioni (es. quelle relative a UDP).\n\nNe esistono centinaia definiti dagli standard RFC e moltissimi altri proprietari, forniti dai produttori di hardware.\n\n\nI dati sono definiti usando un linguaggio chiamato SMI (Structure of Management Information).\nnella foto qua sotto puoi vedere come sono strutturate delle variabili MIB\n\nLa MIB √® come un ‚Äúdizionario‚Äù di tutti i dati che un dispositivo di rete pu√≤ rendere disponibili o modificabili via SNMP.\n\nla MIB ha una struttura ad albero, gerarchica:\n\nGli oggetti sono nidificati in rami (es. system ‚Üí sysDescr, sysUpTime, ecc.).\nOgni voce √® indicizzata da un OID (Object Identifier), ad esempio .1.3.6.1.2.1.1.1 per sysDescr.\nQuesto vuol dire che quando chiedi un dato a un dispositivo con SNMP, gli indichi un OID per sapere esattamente quale parametro vuoi leggere o modificare.\nüìç Esempio: per sapere il nome del dispositivo, potresti chiedere .1.3.6.1.2.1.1.5 (che corrisponde a sysName).\n\nusa per il trasporto UDP\n\nvuole essere rapido\n\n\n\nTipi di messaggio SNMP\nquesti messaggi quindi vengono usati tipo per dire\n‚ÄúDimmi quanti pacchetti UDP hai ricevuto‚Äù\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTipoDa‚Ä¶ ‚Üí A‚Ä¶A cosa serveGetRequestManager ‚Üí AgenteLeggere un valore specificoGetNextRequestManager ‚Üí AgenteNavigare nella MIBGetBulkRequestManager ‚Üí AgenteOttenere pi√π dati in un colpo soloSetRequestManager ‚Üí AgenteScrivere/aggiornare valoriResponseAgente ‚Üí ManagerRispondere a una richiestaTrapAgente ‚Üí ManagerSegnalare un evento inaspettato\nFormati dei messaggi SNMP\n\n\ncome √® fatto un messaggio SNMP (PDU ‚Äì Protocol Data Unit), cio√® cosa si invia realmente tra server e dispositivi:\n‚úÖ Tipi di messaggi 0,1,2,3 (per get/set):\n\nRequest ID: per abbinare richiesta e risposta.\nError Status e Index: indicano se qualcosa √® andato storto (es. oggetto inesistente).\nName / Value: la variabile da leggere o scrivere, con il suo valore.\n\nüîî Tipo 4 (Trap):\n\nUsato dai dispositivi per inviare messaggi spontanei al server (eventi).\nInclude info come:\n\ntipo di trap\nOID dell‚Äôevento (es. ‚Äúlink down‚Äù)\nindirizzo IP dell‚Äôagente\ntimestamp\nvariabili coinvolte\nüìå Le trap sono fondamentali per monitoraggio in tempo reale: avvisano il server quando accade qualcosa (es. porta di rete disconnessa).\n\n\n\nNETCONF spiegato meglio\n\nServe per gestire in modo attivo i dispositivi sulla rete\nFunziona tramite comandi come:\n\nretrieve (recupera configurazioni o dati operativi),\nset, modify, activate (modifica e attiva configurazioni).\n\n\nSupporta il commit atomico:\n\ntutte le modifiche vengono applicate insieme, oppure nessuna viene applicata se c‚Äô√® un errore.\nPu√≤ anche interrogare statistiche, ricevere notifiche, ecc.\n\n\nUsa il modello RPC (Remote Procedure Call):\n\nil server invia richieste XML ‚Üí il dispositivo risponde con &lt;rpc-reply&gt;.\n\n\nusa come protocollo di trasporto affidabile\n\nSSH o TLS\n\n\n\nOperazioni tipiche di NETCONF\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOperazioneFunzione&lt;get-config&gt;Legge la configurazione corrente (es. quella in esecuzione, detta running)&lt;get&gt;Legge i dati operativi (es. traffico, stato delle interfacce)&lt;edit-config&gt;Modifica una parte della configurazione&lt;lock&gt; / &lt;unlock&gt;Blocca/sblocca la configurazione per evitare conflitti da altre fonti&lt;create-subscription&gt;Permette di ricevere notifiche automatiche (&lt;notification&gt;)\nEsempio di scambi NETCONF in XML\nIl dialogo tipico tra server e dispositivo segue questi passaggi:\n\n&lt;hello&gt;: scambio iniziale di capability.\nScambio di richieste &lt;rpc&gt; e risposte &lt;rpc-reply&gt;.\nRicezione eventuale di &lt;notification&gt; (es. eventi, cambiamenti).\nChiusura della sessione con &lt;close-session&gt;.\n\n‚û°Ô∏è Tutti i messaggi sono in formato XML.\n\nEsempio concreto in XML\n\nYANG (usato con netconf) spiegato meglio\n(Yet Another Next Generation)**\nCome abbiamo detto i comandi di NETCONF sono in XML ma le strutture dati che contengono i dati utili sono spesso in YANG\n\n√® un linguaggio di modellazione dei dati,\n\npensato appositamente per le reti.\nServe a descrivere la struttura, il tipo e i vincoli dei dati che si possono gestire tramite NETCONF.\n\n\nDefinisce le strutture dati che rappresentano configurazioni o stati operativi (interfacce, hostname, MTU, ecc.).\nPermette di generare automaticamente la struttura XML dei messaggi NETCONF.\nGarantisce validit√† e coerenza dei dati con vincoli tra campi (es. range, obbligatoriet√†, relazioni tra elementi).\nCome lo SMI (usato con SNMP), YANG descrive i dati, ma in modo pi√π ricco e moderno.\n\n\nEsempio vero e proprio di YANG+NETCONF\n\ncon yang:\n\ndefinisce la struttura dei dati che il dispositivo pu√≤ accettare o restituire.\n√à come dire: ‚ÄúNella configurazione del dispositivo ci sar√† una sezione chiamata system, che contiene login, che a sua volta contiene un campo message (di tipo stringa)‚Äù.\nsu netconf:\nSignifica: ‚ÄúNel blocco system, nella sezione login, il messaggio da visualizzare al login √® ‚ÄòGood morning‚Äô‚Äù.\n"},"UNI/ANNO-2/RETI/RETI-LEZ.17":{"slug":"UNI/ANNO-2/RETI/RETI-LEZ.17","filePath":"UNI/ANNO 2/RETI/RETI LEZ.17.md","title":"RETI LEZ.17","links":[],"tags":[],"content":"INTRODUZIONE AL LIVELLO DI COLLEGAMENTO\nil livello di collegamento ha la responsabilit√† di trasferire i datagrammi da un nodo a quello fisicamente adiacente lungo un collegamento\nle terminologie che vengono spesso usate sono:\n\n\nGli host router switch ecc sono dei NODI\n\n\nI vari canali di comunicazione che collegano i nodi adiacenti tra loro sono i COLLEGAMENTI(LINK)\n\ntipo cavi o wireless\n\n\n\nPacchetto che viene gestito al livello 2 sono i frame, incapsula i datagrammi\n\n\n\nPossiamo notare come i livelli di tipo 2 aggiungono dettagli al formato della rete\n\n\nPrima con il livello di rete non avevamo visione sugli switch ma solo sui router\n\ngli switch sono del livello 2\n\n\n\nil datagramma viene trasferito da protocolli di collegamento di tipo differenti\n\noltretutto anche su collegamenti di tipo differenti\nreti cavi ecc\n\n\n\ndopo parleremo dei vari servizi che hanno i protocolli di collegamento ma si pu√≤ tipo pensare a servizi come trasferimenti affidabili ecc\n\n\n\nMetafora con i trasporti\n\nServizi aggiuntivi del livello di collegamento\n\n\nFraming\n\nIncapsula i datagrammi (provenienti dal livello di rete) in frame, aggiungendo intestazione (header) e trailer.\nServe a delimitare l‚Äôinizio e la fine di ogni unit√† di trasmissione.\n\n\n\nAccesso al collegamento\n\nGestito da protocolli MAC (Medium Access Control) per controllare l‚Äôaccesso al mezzo trasmissivo quando √® condiviso (es. Ethernet, WiFi).\nGli indirizzi MAC sono usati per identificare univocamente la sorgente e la destinazione a livello locale, diversi dagli indirizzi IP.\n\n\n\nconsegna affidabile tra nodi adiacenti\n\nPermette la rilevazione e/o correzione degli errori nei collegamenti diretti.\nRara nei mezzi affidabili (es. cavo).\nUtile nei wireless (WiFi, cellulare) dove gli errori sono pi√π frequenti.\nEvita di sovraccaricare i livelli superiori con ritrasmissioni, gestendo l‚Äôerrore localmente.\n\n\n\ncontrollo del flusso\n\nRegola la velocit√† di trasmissione tra mittente e destinatario adiacenti\n\n\n\nrilevazione e correzione di errori sui veri e propri bit\n\nogni protocollo di collegamento HA UN CONTROLLO SUGLI ERRORI\n\nattenzione per√≤ perch√© la ethernet non ha necessit√† di avere la correzione\n\n\nquesto copre i singoli percorsi, nel livello di trasporto invece era proprio end-to-end\n\novvero da inizio a fine percorso\n\n\nDue strategie:\n\nARQ (Automatic Repeat reQuest): ritrasmissioni.\nFEC (Forward Error Correction): correzione senza ritrasmissioni.\n\nla correzione avviene direttamente sui bit errati (FEC)\n\n\n\n\n\n\n\nHalf-Duplex e Full-Duplex\n\nHalf-duplex: trasmissione alternata nei due sensi.\nFull-duplex: trasmissione simultanea in entrambe le direzioni.\n\n\n\n\nImplementazione del livello di collegamento negli host\nnegli host i livelli che abbiamo visto ora erano di tipo software\n\nquello di collegamento invece √® tra hardware e software\nPresente in ogni host.\nImplementato dalla scheda di rete (NIC) o adattatore di rete.\nLa NIC:\n\nRealizza sia il livello fisico che quello di collegamento.\nSi collega al bus di sistema (es. PCI).\n\n\n√à una combinazione di hardware, software e firmware.\n\n\ncome √® fatto non troppo nei dettagli un adattatore di rete negli host\n\nmittente vs ricevente\nparte del mittente\nüîß Il controller (nella scheda di rete) si occupa di:\n\nIncapsulare il datagramma (proveniente dal livello di rete) dentro un frame, cio√® l‚Äôunit√† del livello di collegamento.\nAggiungere bit di controllo degli errori (es. checksum).\nGestire:\n\nil trasferimento affidabile,\nil controllo di flusso,\naltri servizi del livello di collegamento.\n\n\n\nüíª La CPU dell‚Äôhost collabora:\n\nCostruisce i dati da inviare,\nInteragisce con la NIC per assemblare il pacchetto da trasmettere.\n\nParte del ricevente\nüîß Il controller della NIC:\n\nVerifica la presenza di errori nei bit ricevuti.\nGestisce il trasferimento affidabile, il controllo del flusso, ecc.\nEstrae il datagramma dal frame e lo passa al livello di rete.\nüíª La CPU riceve i dati dal controller e li elabora ai livelli superiori (rete, trasporto, applicazione).\n\nRilevazione degli errori nel particolare\nIMPORTANTE HA DETTO la parola ‚ÄúCAVOLO‚Äù\nPer applicare un meccanismo di rilevazione degli errori ci√≤ che faccio √® utilizzare un codice come quello EDC(Error Detection and Correction)\n\n\naggiungo alla informazione normale\n\ndei bit che servono per fare la rilevazione degli errori che sono lunghi r\ni dati D sono lunghi d\nabbiamo una funzione f che applichiamo a D e che ci ritorna un codice EDC\n\ndopo aver scambiato i dati su un collegamento a potenziali errori\ncontrolliamo D‚Äô e gli applichiamo la stessa funzione\n\nse ci da EDC‚Äô uguale a EDC precedente ecco fatto nessun errore\n\n\n\n\n\n\n\n\nnon usiamo funzioni troppo complesse perch√© aumenterebbero troppo overhead\n\n\n\n\n                  \n                  possibili problemi \n                  \n                \n\n\nNon √® affidabile al 100%.\nPossibilit√† di errori non rilevati (es. quando D‚Ä≤ produce casualmente lo stesso EDC).\nLa probabilit√† di mancata rilevazione √® ‚âà 2‚Åª ≥ (r = bit dell‚ÄôEDC).\n\n\n\novviamente pi√π si aumentano i bit di rilevazione pi√π √® facile rilevare errori\n\nquesto per√≤ comporta aumenti di overhead\n\nTecniche sensate per fare il controllo degli errori\nBit di parit√†\nSingolo bit di parit√†\n\nSi aggiunge 1 bit ai dati per rendere il numero di 1 pari o dispari (a seconda della parit√† scelta).\nIl ricevente ricalcola la parit√† e la confronta con quella ricevuta:\n\nse coincidono ‚Üí nessun errore rilevato;\nse divergono ‚Üí errore rilevato.\n\n‚ö†Ô∏è Pu√≤ rilevare solo un numero dispari di errori ‚Üí se gli errori sono 2, 4, ecc. non li vede!\n\n\n\nEsempi con bit di parit√† in due dimensione:\n\nOrganizza i bit in una matrice (righe e colonne).\nAggiunge bit di parit√† per ogni riga e ogni colonna.\n‚úÖ Permette di:\n\nrilevare tutte le combinazioni fino a 3 errori,\ncorreggere 1 errore singolo (incrociando la riga e la colonna con parit√† errata).\n\n\n\n\n\n\n                  \n                  Limiti del controllo di parit√†: gli errori a burst \n                  \n                \n\nIl controllo di parit√† (singolo bit) √® adatto se:\n\ngli errori sono rari,\ngli errori sono indipendenti (cio√® sparsi casualmente).\nma il problema √® che in realt√†:\nGli errori reali tendono a essere ‚Äúa burst‚Äù:\n\npi√π bit consecutivi vengono alterati insieme (es. interferenza elettromagnetica).\n\n\nIn questo caso, un singolo bit di parit√† pu√≤ fallire nel rilevarli.\n\n\n\n\nESEMPI\n\nad una riga viene rilevato un errore di parit√† ma non si riesce a capire a quale colonna corrisponde per correggerlo\n\nci sono 3 errori e non 1 che son fuori\n\nanche qui non sa quale correggere\n\n\n\n\n\n\nQuando ci sono pi√π righe e pi√π colonne non riesce a correggere e rilevare l‚Äôerrore\nChecksum internet\nIl checksum √® un meccanismo di controllo dell‚Äôintegrit√† dei dati che viene usato su Internet, ad esempio nei protocolli IP, TCP e UDP. Serve per verificare che i dati inviati non siano stati alterati durante la trasmissione.\nMittente:\n\nInterpreta il contenuto del pacchetto come una sequenza di interi a 16 bit (compresi intestazione e indirizzi IP).\nSomma tutti questi numeri usando l‚Äôaritmetica in complemento a 1.\nCalcola il complemento a 1 del risultato e lo inserisce nel campo checksum.\n\nRicevente:\n\nSomma tutto, compreso il checksum ricevuto.\nControlla se il risultato √® tutto 1 (che equivale a 0 in complemento a 1):\n\nSe s√¨ ‚Üí nessun errore.\nSe no ‚Üí errore presente.\n\n\nIn alternativa, pu√≤ rifare il complemento a 1: se il risultato √® tutto zero, va bene.\n\nCRC Codici di Controllo a Ridondanza Ciclica\nIl CRC (Controllo di Ridondanza Ciclico) √® un sistema molto affidabile e pi√π potente del checksum tradizionale per rilevare errori nei dati trasmessi. Viene usato, ad esempio, nelle reti Ethernet, nei dischi e nei protocolli avanzati di comunicazione.\nüì¶ Elementi di partenza:\n\nD: i dati da trasmettere (una sequenza di d bit).\nG: una sequenza di r+1 bit chiamata generatore, nota sia al mittente che al destinatario.\n\nüë§ Lato mittente (chi invia):\n\nIl mittente deve calcolare r bit (chiamati R) da aggiungere ai dati D.\nLo fa in modo che la sequenza completa &lt;D,R&gt; (cio√® D seguita da R) sia divisibile per G, usando una divisione speciale in aritmetica modulo 2 (cio√® si lavora solo con 0 e 1, e le operazioni si fanno con lo XOR al posto della normale sottrazione, senza riporti).\nIn sostanza, R viene calcolato come il resto della divisione tra D‚ãÖ2 ≥ e G. Si scelgono gli R in modo che il resto sia zero.\nüëâ Nota evidenziata: &lt;D,R&gt; vuol dire semplicemente che si prende la sequenza D e poi si attaccano i bit R alla fine.\n\nüì• Lato destinatario (chi riceve):\n\nRiceve la sequenza &lt;D,R&gt;.\nEsegue la divisione per G:\n\nSe il resto √® zero, significa che non ci sono stati errori: tutto ok.\nSe il resto √® diverso da zero, allora c‚Äô√® stato un errore nella trasmissione.\n\n\n\nüìå Propriet√† utili del CRC:\n\n√à molto bravo nel rilevare errori a raffica (cio√® quando pi√π bit consecutivi si corrompono).\nPi√π √® grande il numero di bit di controllo (r), maggiore √® la capacit√† di rilevare errori.\n√à ampiamente usato in reti come Ethernet, WiFi, ecc.\n\n\nüßÆ Operazioni usate nel CRC\n‚ñ∂Ô∏è Addizione e sottrazione:\n\nIn modulo 2, l‚Äôaddizione e la sottrazione sono identiche.\nSi usa lo XOR bit a bit (esempio: 1011 XOR 1101 = 0110)\nNon c‚Äô√® mai il riporto, quindi tutto √® pi√π semplice rispetto all‚Äôaritmetica decimale.\n\n‚ñ∂Ô∏è Moltiplicazione e divisione:\n\nSi fanno come nel sistema decimale, ma usando XOR al posto delle somme normali.\nL‚Äôoperazione √® analoga alla moltiplicazione a mano: si sommano i termini spostati (shiftati), ma con XOR al posto del ‚Äù+‚Äù.\nAnche qui non esistono riporti.\n\nEsempio di moltiplicazione:\n1011 √ó 101 =    1011 + 0000       (perch√© il secondo bit di 101 √® 0) +1011 &lt;&lt; 2   (cio√® 1011 spostato di due posizioni) = 100111\nüß† Rappresentazione dei bit come polinomi\nNel CRC, si pu√≤ pensare ogni sequenza di bit come un polinomio, dove ogni bit a 1 rappresenta una potenza di x.\n1011 ‚Üí 1¬∑x¬≥ + 0¬∑x¬≤ + 1¬∑x¬π + 1¬∑x‚Å∞ = x¬≥ + x + 1\nQuindi, la moltiplicazione di due sequenze binarie √® come la moltiplicazione di due polinomi:\n(x¬≥ + x + 1) √ó (x¬≤ + 1)\nQuando si sommano termini identici (es. due volte x¬≥), si fa XOR:\nx¬≥ + x¬≥ = 0  (perch√© 1+1 = 0 in modulo 2)\nAlla fine otteniamo un polinomio risultato, che pu√≤ essere ricondotto di nuovo a una sequenza binaria.\n‚úÖ Come il mittente calcola i bit di controllo (R)\nL‚Äôobiettivo √® trovare dei bit di controllo (R) da aggiungere ai dati (D) in modo che l‚Äôintera sequenza finale sia divisibile per G (il polinomio generatore)\nüìò Passaggi:\n\nIl mittente prende i dati D.\nAggiunge in fondo a D r zeri (indicati come D¬∑2 ≥): questo crea lo spazio per i bit di controllo.\nEsegue una divisione binaria (con lo XOR) tra D¬∑2 ≥ e G.\nIl resto della divisione √® proprio R ‚Üí i bit di controllo.\nIl messaggio finale trasmesso sar√†: D seguito da R.\n\n\nüß† Ricorda: le operazioni sono in modulo 2, quindi si usa l‚ÄôXOR e non ci sono riporti.\n\n\n‚úèÔ∏è Esempio pratico:\n\nD = 101110\nG = 1001 (4 bit ‚Üí r = 3)\nSi aggiungono 3 zeri a D: 101110000\nSi divide 101110000 √∑ 1001 usando XOR\nIl resto della divisione √® 011 ‚Üí questo √® R\nIl messaggio completo da inviare √® 101110011 (D + R)\n\nüöÄ Cosa invia il mittente\nIl pacchetto finale inviato (T) √®:\nT = D ¬∑ 2 ≥ ‚äï R\nOvvero\n\nD = i dati\n2 ≥ = serve a fare spazio per R\nR = i bit di controllo calcolati con la divisione\nIl mittente invia quindi D seguito da R\n\nüì• Come il ricevente verifica se ci sono errori\nIl ricevente riceve T‚Äô, cio√® il messaggio ricevuto (che pu√≤ essere uguale a T o alterato da errori).\n\n\nSe non ci sono errori: T‚Äô = T\n\n\nSe ci sono errori, possiamo scrivere: T‚Äô = T ‚äï E, dove E √® il ‚Äúpolinomio errore‚Äù (i bit a 1 indicano dove ci sono errori).\nIl ricevente divide T‚Äô per G:\n\n\n\nSe il resto √® 0, allora E era divisibile per G e l‚Äôerrore non viene rilevato.\nSe il resto √® diverso da 0, allora E non √® divisibile per G e l‚Äôerrore viene rilevato\n\n\nüü° Conclusione importante: la scelta del generatore G √® cruciale. Deve essere fatta in modo che non divida mai i polinomi errore pi√π comuni, altrimenti gli errori passano inosservati.\n\n‚úÖ Come scegliere G: attenzione alla parit√†\nQuando scegliamo un polinomio generatore G, dobbiamo evitare che abbia un numero pari di bit a 1. Questo perch√© il CRC lavora con lo XOR, che √® sensibile alla parit√† (cio√® al numero di bit a 1).\nüìò XOR e parit√†:\n\nSe fai XOR tra due numeri con parit√† diversa ‚Üí ottieni un risultato dispari\nSe fai XOR tra due numeri con parit√† uguale ‚Üí ottieni un risultato pari\n\n‚ùå Problema:\nSe G ha un numero pari di bit a 1, e si verifica un errore che cambia un numero dispari di bit, allora il CRC potrebbe non accorgersene.\nQuesto perch√©:\n\nDurante la divisione CRC, G viene shiftato e usato nello XOR.\nSe G ha parit√† pari, anche tutti i multipli di G avranno parit√† pari ‚Üí quindi se fai XOR con un errore a parit√† dispari, la parit√† non cambia e l‚Äôerrore passa inosservato.\n\nüß† Soluzione: scegliere bene G\n‚úÖ Buone pratiche:\n\nScegliere G con un numero dispari di bit a 1\nScegliere G con almeno due bit a 1, cos√¨:\n\nPu√≤ rilevare qualsiasi errore su un solo bit\nPu√≤ rilevare errori particolari, come due bit errati lontani tra loro, o molti errori consecutivi\n\n\n\nüí° Esempio finale:\nSe un errore corrisponde a un polinomio come E(x) = x¬≥, allora questo errore √® divisibile solo da polinomi semplici, come x, x¬≤, x¬≥, ecc.\nSe G ha almeno due termini (es. x¬≥ + 1), non pu√≤ dividere x¬≥, e quindi un errore su un solo bit viene rilevato."},"UNI/ANNO-2/RETI/RETI-LEZ.18":{"slug":"UNI/ANNO-2/RETI/RETI-LEZ.18","filePath":"UNI/ANNO 2/RETI/RETI LEZ.18.md","title":"RETI LEZ.18","links":[],"tags":[],"content":"Due tipi di collegamento\n\nPunto a Punto\n√® presente un trasmittente a un‚Äôestremit√† e dall‚Äôaltra c‚Äô√® un ricevente esempi:\n\ncollegamento punto a punto tra host e switch Ethernet\n\nun collegamento diretto con un cavo\n\n\nprotocollo PPP per accesso dial-up\n\n(Point-to-Point Protocol)\nveniva usato per collegarsi ai modem telefonici, collegavi il pc al modem telefonico ed eri connesso al tuo ISP\n\n\n\n\nBroadcast\nun canale di tipo broadcast che √® condiviso tra pi√π nodi che trasmettono e pi√π nodi che ricevono, ogni frame viene condiviso tra tutti, ad esempio:\n\nEthernet ai vecchi tempi dove tutto il cavo era condiviso\nwireless LAN oppure 4g/5g oppure il satellitare\n\n\n\n\n\n\n                  \n                  cosa succede per√≤ con questi canali broadcast? \n                  \n                \n\nse avvengono due trasmissioni in modo simultaneo dai nodi si pu√≤ incorrere in una collisione o interferenza\n\n\n\n\n                  \n                  per risolvere si usano protocolli ad accesso multiplo \n                  \n                \n\npresenta l‚Äôuso di un algoritmo che determina come i nodi condividono il canale, e quando essi possono trasmettere su di esso\n\nIl canale di comunicazione √® uno solo: anche i messaggi per organizzare l‚Äôaccesso (es. ‚Äústo per trasmettere‚Äù) viaggiano sullo stesso canale dei dati.\nüîµ Quindi non c‚Äô√® un canale separato (out-of-band) per il coordinamento.\n\n\n\nEntriamo nel dettaglio di questi protocolli ad accesso multiplo\nProtocollo di accesso multiplo di tipo IDEALE\n\nquesto protocollo MAC(Multiple Access Channel)\nha un canale con velocit√† di R bps\nL‚Äôideale sarebbe che\nquando solo un nodo trasmette, esso pu√≤ farlo con una velocit√† R\nquando invece M nodi si aggiungono alla trasmissione la velocit√† si riduce e diventa di circa R/M\nnon ci sono nodi speciali che coordinano le trasmissioni √® tutto decentralizzato\nnon ci sono clock, time slot o altro\n\ntipi di protocolli ad accesso multiplo reali\ncon Channel Partitioning\n\nil canale viene suddiviso\nogni nodo ha la sua fetta di canale\nse non la usa quella fetta √® inutilizzata\n\na Random Access\n\nil canale non √® diviso e sono presenti le collisioni\nper risolverlo si effettuano delle ritrasmissioni ogni volta con operazioni di recover\n\na Taking Turns\n\ni nodi usano il canale a turno\ni nodi con pi√π materiale da inviare possono usare il canale per pi√π tempo\n\nSpieghiamo nel dettaglio i vari protocolli\nI TDMA (Time Division Multiple Access)\nFanno parte della categoria dei Channel Partitioning\n\nil canale qui viene suddiviso per istanti temporali fissi\nla durata di questo tempo si dice time slot e di solito serve per trasmettere un pacchetto del livello di collegamento\ngli slot che non vengono utilizzati si dicono idle\n\n\n\nquando tocca a un determinato nodo esso pu√≤ trasmettere a velocit√† R bps\nma visto che tanto pu√≤ farlo in un lasso temporale di 1/N comunque trasmette a velocit√† media R/N\n\nGLI FDMA (Frequency Division Multiple Access)\nFanno anche questi parte della categoria dei Channel Partitioning\n\nIl canale viene diviso in uno spettro di frequenze\nogni nodo prende una determinata frequenza\nse un nodo non trasmette sulla sua frequenza semplicemente essa viene inutilizzata\n\nla velocit√† √® comunque R/N\n\nSLOTTED ALOHA\nFa parte della categoria dei segnali ad Accessi Casuali\n\nricordiamo che questi ultimi hanno dei nodi che trasmettono alla massima velocit√†, poi quando ci sono collisioni, ovvero due nodi trasmettono simultaneamente\npoi sar√† opportuno rilevare le collisioni e recuperare i dati dalle collisioni\n\nattraverso protocolli ad accesso casuale\nCome funziona SLOTTED ALOHA?\n\n\nsostanzialmente abbiamo una serie di slot temporali\nquando un nodo vuole trasmettere attende l‚Äôinizio del nuovo slot temporale e invia\nse avviene una collisione perch√© un altro nodo lo stava usando avviene il recupero e quel nodo prova a ritrasmettere il frame allo slot temporale successivo con una probabilit√† p di successo che ora spiegher√≤ meglio\n\nla collisione rilevabile ad esempio dalla mancanza di ACK.\n\n\n\n\nPRO e CONTRO dello SLOTTED ALOHA\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n‚úÖ Pro‚ùå ControTrasmissione continua per nodo singoloCollisioni frequenti: se pi√π nodi scelgono lo stesso slot, si perdono i dati.Alta decentralizzazione: i nodi decidono in autonomia, senza coordinatore centrale.Slot sprecati: la trasmissione probabilistica pu√≤ lasciare slot vuoti anche se ci sono dati.Semplicit√†: l‚Äôalgoritmo √® facile da implementare.Sincronizzazione necessaria: i nodi devono avere clock allineati per rispettare gli slot.Lentezza nel rilevare collisioni: i nodi capiscono solo dopo aver completato lo slot.\nEFFICIENZA dello SLOTTED ALOHA\n√à la frazione di tempo in cui il canale viene usato con successo, cio√® slot che non vanno sprecati per collisioni o inattivit√†.\n\n‚ûù Obiettivo: capire quanta parte del tempo il protocollo √® realmente utile per trasmettere dati senza errori.\n\n\nvengono fatti una serie di calcoli probabilistici che portano a dire che:\n\npu√≤ usare il canale in modo efficace solo nel 37% del tempo, al massimo!\n\n\n\n\n\n                  \n                  sezione con i vari calcoli \n                  \n                \n\n\n\n\n\n\nALOHA PURO(Unslotted ALOHA)\n\nnon vi √® presente alcuna sincronizzazione\nappena arriva un frame esso viene trasmesso per intero e in modo immediato\nse avviene una collisione lo ritrasmette immediatamente con una probabilit√† p\nla probabilit√† di collisione senza sincronizzazione aumenta ancora di pi√π\nEfficienza 18%\n\n\nCSMA(Carrier Sense Multiple Access)\n\nanche questo tipo √® ad accesso Casuale\n\nper√≤ risolve parecchie cose\n\n\nil nodo prima di trasmettere ascolta il canale e vede se √® libero o occupato\n‚ÄúCome una conversazione tra persone: non parlo se sento che qualcuno sta gi√† parlando.‚Äù\nanche se il tutto √® sincronizzato bene possono avvenire lo stesso collisioni\n\nquesto perch√© potrebbero esserci ritardi di propagazione ecc‚Ä¶\n\n\n\n\nCSMA/CD(Carrier Sense Multiple Access)/(Collision Detection)\n\ncon questo aggiornamento del protocollo viene aggiunta una detection delle collisioni\nMentre trasmette, il nodo continua ad ascoltare:\nSe rileva una collisione, interrompe subito la trasmissione.\nCos√¨ evita di sprecare banda per un frame che comunque sarebbe perso.\nquesto funziona bene via cavo ethernet ma difficilmente pu√≤ funzionare via wireless\n\n‚ÄúCome se inizio a parlare, ma se sento qualcun altro iniziare a parlare contemporaneamente, mi fermo subito.‚Äù\n\nSpiegazione nel dettaglio dell‚Äôalgoritmo CSMA/CD su una rete Cablata Ethernet\nsuddivisione in step:\n\nSTEP 1:\n\nEthernet riceve un pacchetto dai livelli superiori, lo incapsula in un frame per la trasmissione di esso\n\n\nSTEP 2:\n\nLa scheda Ethernet controlla se il canale di trasmissione √® libero\n\nse libero trasmette senn√≤ aspetta finch√© non si libera\n\n\n\n\nSTEP 3:\n\nSe il frame viene trasmesso tutto senza collisioni, la trasmissione √® conclusa con successo ‚úÖ\n\n\nSTEP 4:\n\nüî¥ Se sta per avvenire una collisione\n\nil nodo che sta trasmettendo si interrompe subito\nsi invia un segnale di disturbo per avvisare tutti dell‚Äôavvenuta collisione\n\n\n\n\nSTEP 5:\n\nDopo la collisione Ethernet(il nodo che vuole trasmettere) aspetta un tempo casuale prima di rientrare nel canale\n\nentra in una fase di binary exponential backoff\n\nsostanzialmente dopo una m-esima collisione sceglie un numero K tra {0,1,2,...,2^{m‚àí1}}\n\ne attende un tempo pari a K√ó512bit di tempo trasmissivo.\n\n\npoi si torna allo STEP 2\n\n\n\n\n\n\n\nSpiegazione grafica\n\n\n\nEfficienza di questo protocollo\n\nProtocolli a rotazione di tipo POLLING\n\ni protocolli a suddivisione di canale visti prima\n\ncon Channel Partitioning\n\nse condivisi tra pi√π nodi si ha una certa equit√†\nma se solo un nodo usa il canale avr√† una porzione del canale e non pu√≤ usarlo a pieno\n\n\n\n\ncon i protocolli ad accesso casuale\n\ncon Random Access\n\nun singolo nodo pu√≤ usare il massimo del carico\nse per√≤ pi√π nodi vogliono usarlo aumenta l‚Äôoverhead per le troppe collisioni\n\n\n\n\ncon i protocolli a rotazione\n\nsi cercano di mixare i due elencati prima\nNel polling √© presente un controllore centralizzato nel sistema che dice ai nodi quanti frame possono trasmettere per turno con un massimo di frame per turno prestabiliti\n\n\nquesto riduce collisioni e slot inutilizzati\nil controllore verifica se il canale √® utilizzato, cos√¨ riesce a capire se il nodo che invia sta sfruttando quei frame che pu√≤ inviare\nper√≤ purtroppo\nil fatto che ci sia un controllore che deve inviare al nodo un segnale che dice che pu√≤ procedere a inviare tot frame\n\naumenta il ritardo\n\n\nil fatto che ci sia un solo controllore se esso ha problemi si rompe tutto\nil Bluetooth usa questo sistema\n\n\nToken passing\nViene passato questo token tra i nodi, il nodo pu√≤ trasmettere quando ha questo token\n\nil fatto che questo token debba essere scambiato tra nodo e nodo aumenta overhead\nanche qui abbiamo un singolo punto di rottura il token\n\n\naccesso a Internet via cavo, con un mix di FDM, TDM e accesso multiplo casuale\n\nPer fare il downstream vengono usati dei canali FDM in broadcast\n\nun solo CMTS(Cable Modem Termination System) trasmette nei canali quindi nessun problema di accessi multipli\nPer fare l‚Äôupstream vengono usati diversi canali che vengono contesi da i diversi utenti con un accesso casuale\nvengono usati mini-slot a determinati utenti mentre gli altri vengono assegnati in modo casuale\n\nPrecisazione sullo standard DOCSIS\nserve per impostare uno standard tra i modem via cavo e i CMTS\n\nper il downstream viene usata una FDM che ricordiamo era una divisione delle frequenze\nil CMTS invia un frame MAP che serve per dire a chi appartiene quale frequenza\nper sincronizzare il tutto\nper l‚Äôupstream il tutto √® diviso in mini-slot come spiegato sopra\n"},"UNI/ANNO-2/RETI/RETI-LEZ.19":{"slug":"UNI/ANNO-2/RETI/RETI-LEZ.19","filePath":"UNI/ANNO 2/RETI/RETI LEZ.19.md","title":"RETI LEZ.19","links":[],"tags":[],"content":"LAN\nsta per Local Area Network\n\nindica una zona di network limitata a una area ristretta come\n\nuna casa\nuna scuola\nun ufficio\nCi sono due tecnologie principali che la usano:\n\n\nEthernet\nWi-Fi\n\nIndirizzi MAC\nper identificare un determinato device abbiamo gi√† nominato gli\n\nindirizzi IP a 32 bit con IPv4 oppure 128 con IPv6\nEssi vengono usati per effettuare inoltri al livello di rete\n\nun esempio √® tipo 128.119.40.136\npoi ci sono gli indirizzi MAC che sostanzialmente hanno la funzione di identificare le interfacce per effettuare uno scambio dei frame tra interfacce connesse fisicamente, tipo stessa sottorete\n\n\nil MAC √® a 48 bit ed √® memorizzato nella ROM della NIC\n\novvero la memoria della scheda di rete del dispositivo\nNIC = Network Interface Card\nad esempio:\n\n\n1A-2F-BB-76-09-AD\nCiascuna interfaccia in una LAN ha un suo indirizzo MAC e indirizzo IP\nentrambi univoci\n\n\nCome vengono scelti gli indirizzi IEEE\n\nL‚ÄôIEEE (ente internazionale) si occupa di gestire lo spazio degli indirizzi MAC per garantire che siano univoci nel mondo.\nI produttori di schede di rete (NIC) comprano dei ‚Äúblocchi‚Äù di indirizzi MAC da IEEE.\n\nIn pratica, ogni produttore riceve un prefisso identificativo univoco, che user√† per assegnare gli indirizzi ai suoi dispositivi.\nMentre gli indirizzi IP possono variare rispetto a quale rete siamo connessi, gli indirizzi MAC invece sono univoci e portabili\n\n\n\nCome posso sapere l‚Äôindirizzo MAC di una interfaccia se so solo quello IP?\nUtilizzo un protocollo chiamato ARP che ha una tabella chiamata ARP\n\nin questa tabella\n\nOgni nodo IP sulla LAN ne ha una per ciascuna interfaccia\nQuesta tabella ha una corrispondenza tra Indirizzo IP e MAC e anche il rispettivo TTL\n\n&lt;indirizzo IP,indirizzo MAC, TTL&gt;\nil TTL rappresenta il (Time To Live) ovvero dopo quanto questa mappatura verr√† dimenticata nella tabella\n\ndi solito 20 min\n\n\n\n\n\n\n\nQuesto protocollo in azione\n\n\nA invia un messaggio in broadcast chiedendo chi √® B\n\nB risponde e invia il suo indirizzo MAC\n\nA pu√≤ popolare la sua tabella\n\nARP SPOOFING o POISONING\n\nUn attaccante invia risposte ARP false (contraffatte) a dispositivi della rete.\nQueste risposte fanno credere a un nodo che un certo IP √® associato a un MAC sbagliato (cio√® quello dell‚Äôattaccante).\nIl nodo aggiorna senza controllare la sua cache ARP ‚Üí qui nasce la vulnerabilit√†.\nIl protocollo ARP √® senza stato: ogni nodo accetta qualsiasi risposta ARP ricevuta, anche se non l‚Äôha chiesta.\nUn attaccante ora pu√≤:\n\n\nattacchi DoS\n\n\nAssocia tanti indirizzi IP allo stesso MAC (il suo) ‚Üí sovraccarica la scheda di rete, che si blocca.\n\n\nMan in the Middle\n\n\nL‚Äôattaccante fa in modo che il traffico destinato a un nodo passi prima da lui:\n\nPu√≤ intercettare, modificare o registrare i dati,\nPoi li inoltra al vero destinatario, cos√¨ nessuno si accorge dell‚Äôattacco.\n\n\n\nScenario dove voglio inviare il datagramma a un nodo esterno della sottorete\n\n\nDHCP era quel server che prevedeva che appena un dispositivo si connette a una rete gli viene assegnato un indirizzo IP ecc‚Ä¶\n\n\n\n\n\n\nEthernet\n\nUtilizzata per le reti LAN cablate\nnel tempo si √® evoluta e ora pu√≤ raggiungere fino a 400 Gbps\n\nCome sono topologicamente disposti i dispositivi che usavano una Ethernet\n\na bus\n\nera popolare fino alla met√† degli anni 90\ntutti i nodi erano nello stesso dominio con collisione\n\n\ntopologia a stella con hub\n\npopolare fino ai 2000\ni nodi sono interconnessi da un hub che rimandava il segnale a tutti\nstesso dominio di collisione\n\n\ncommutata con switch\n\nusata oggi\nuno switch di livello 2 al centro\nognuno ha un suo protocollo ethernet, i nodi non si scontrano tra loro\n\n\n\n\nUn frame ethernet\nQuando un dispositivo (es. un PC) vuole inviare dati (es. un datagramma IP), la scheda di rete incapsula quei dati in un frame Ethernet, con queste sezioni:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCampoDimensioneContenutoFunzionePreambolo8 byte7√ó10101010 + 1√ó10101011Sincronizza il ricevente e segnala l‚Äôinizio del frameMAC destinazione6 byteIndirizzo MAC del destinatarioIndica a chi √® diretto il frameMAC sorgente6 byteIndirizzo MAC del mittenteIndica chi ha inviato il frameTipo2 byteEs. 0x0800 (IPv4), 0x0806 (ARP)Specifica il tipo di protocollo incapsulato nei datiDati (Payload)46‚Äì1500 byteDatagramma IP, pacchetto ARP, ecc.Dati del livello superiore; se &lt;46 byte viene aggiunto paddingCRC4 byteCodice di controlloVerifica errori di trasmissione con algoritmo di ridondanza ciclica\n\nIl frame minimo (senza preambolo) √® di 64 byte\n\nIl massimo √® 1518 byte (senza estensioni tipo jumbo frame)\n\n\nIl preambolo non fa parte del conteggio del frame Ethernet vero e proprio, ma √® comunque trasmesso\nQuando qua sopra si parla di padding si intende\nuna sequenza di byte aggiunti artificialmente alla fine del campo dati (payload) per raggiungere una lunghezza minima del frame Ethernet.\n\nEthernet e la sua sicurezza\nEssa √® senza handshake\n\nquando si connette alla scheda di rete non effettua nessun controllo e i dati vengono trasmessi e basta sperando che arrivino\nse un frame vene perso o scartato non esistono ACK o NACK per segnalarlo\nInfatti vengono usati i servizi soprastanti ad esso come il TCP che consente le varie ritrasmissioni ecc‚Ä¶\nAnche qui abbiamo un MAC ovvero un Media Access Control(non l‚Äôindirizzo)\nche spesso usa la CSMA/CD per gestire pi√π dispositivi connessi allo stesso cavo senza per√≤ collisioni e anche\nUnslotted = non ci sono slot di tempo predefiniti.\n\nI dispositivi possono provare a trasmettere in qualsiasi momento.\n\n\n\nGli standard del livello Ethernet\n\nTutti gli standard Ethernet usano lo stesso frame Ethernet.\nCambiano:\n\nVelocit√†: da 2 Mbps a 100 Gbps\nMezzo fisico: cavo coassiale, doppino, fibra ottica\nLimiti di distanza e propagazione\n\nsostanzialmente il cavo in base alla sua lunghezza presenta delle limitazioni\ni cavi ethernet si dividono in categorie chiamate cat\nVi √® anche il concetto di dominio di collisione\n\n\n\n\nuna zona della rete dove si pu√≤ verificare una collisione tra vari frame ethernet\nse vi √® un ritardo troppo grande tra andata e ritorno il sistema che controlla le collisioni potrebbe perdere lo slot time e quindi andare alla prossima interfaccia e fregarsene di eventuali errori\nin questa foto possiamo vedere come ci sono degli standard al livello fisico che si differenziano in base al tipo di doppino in rame o fibra\nmentre invece nella parte di collegamento viene tutto visto come un unico frame\n\n\nTempi di rilevazione delle collisioni\nNella rete Ethernet, le collisioni sono rilevabili solo entro un certo tempo massimo. Questo limite √® di 512 bit time, che equivale a:\n\n512 bit / 100 Mbps = 5,12 microsecondi (cio√® il tempo per trasmettere 512 bit)\nPer calcolare se la collisione viene rilevata per tempo vengono presi da questa tabella\ni cavi con un ritardo 111.2 bit time\ndue adattatori TX/FX con ritardo 127\nun margine di sicurezza per tenere conto di altre fonti\neventuali ripetitori con un ritardo di 140\nsommando tutto possiamo vedere che fa sotto i 512 bit time quindi va bene\nNOTA: i bit time indicano quanto tempo ci vuole a inviare un solo bit\n\n\n\nNella tabella sopra abbiamo detto che\nun cavo di 100m UTP(Unshielded Twisted Pair) cat.5 ha un round trip delay di 111.2 bit time dimostriamolo con un po‚Äô di calcoli\n\nper round trip delay si intende che se un cavo √© di 100m allora il tempo di andata e di ritorno del cavo √® su 200m\n\n\n\nSwitch Ethernet\nil router lavora sul livello di rete mentre invece lo switch lavora sul livello di collegamento\n\nesso ha un ruolo attivo:\n\nmemorizza e inoltra frame Ethernet\n\ndetto anche store and forward\n\n\nlegge l‚Äôindirizzo MAC di destinazione e lo inoltra a quest‚Äôultimo\nsfruttando anche algoritmi come il CSMA/CD per gestire accessi ai canali\ninoltre:\n\n\n√® Trasparente: gli host collegati non si accorgono della sua presenza.\nSupporta collegamenti eterogenei: diverse velocit√†, diversi tipi di cavi (rame, fibra‚Ä¶).\n√® Plug and play + autoapprendimento:\n\nNon devi configurarlo manualmente.\nLo switch impara automaticamente quali MAC sono collegati a quali porte.\nGli host hanno ognuno una connessione dedicata a questi switch\n\n\nlo switch mette su un buffer questi pacchetti\nil protocollo Ethernet √® presente su ogni collegamento e vi sono due sostanziali differenze\n\nFull duplex o Half duplex\nsostanzialmente per Full duplex si intende quando un dispositivo pu√≤ sia inviare che ricevere contemporaneamente mentre invece √® Half quando pu√≤ fare una sola cosa per volta\n\nnel caso di Half √® necessario regolare il tutto con gestione di collisioni\n\nin questa foto le due A possono parlare senza collisioni e anche le due B\ninvece A‚Üí A‚Äô e C‚Üí A‚Äô non pu√≤ avvenire perch√© avverrebbe una collisione\n\n\nCome fa lo switch a sapere quali nodi sono raggiungibili a quale interfaccia?\n\nLo switch impara da solo le varie tabelle(infatti √® pul-and-play)\n\nFiltraggio e inoltro dei frame dallo Switch\nCosa fa lo switch quando riceve un frame:\n\nSalva il MAC sorgente della porta che lo ha inviato\nAggiorna quindi la Switch Table\nCerca sulla tabella se gi√† sa dove inviarlo\nse il destinatario √® sulla stessa porta del mittente non serve inviarlo di nuovo perch√© sicuramente √® arrivato anche al destinatario senza uso dello switch quindi lo scarta\nse √® da un‚Äôaltra porta lo inoltra facendo lo switching selettivo\nse non lo conosce fa una operazione di flood, invia a tutte le porte tranne quella del mittente per dire ‚Äúchi sei?‚Äù\n\nEsempio di autoapprendimento fatto dal prof\n\n\n\nSwitch vs Router\n\nEntrambi lavorano in modalit√† store and forward\n\nuno si interfaccia con i dispositivi del livello di rete\nuno con quelli di collegamento\n\n\nEntrambi hanno tabelle di inoltro\n\nuno usa algoritmi di instradamento e indirizzi IP\nl‚Äôaltro usa autoapprendimento e la tabella di Switching con indirizzi MAC e flooding\nTopologia della rete:\n\n\ni router possono gestire i cicli della rete grazie ai vari protocolli e al campo TTL time to live presente nei pacchetti IP, evita che circolino all‚Äôinfinito\ngli switch devono essere collegati senza presenza di cicli logici\noppure devono usare il protocollo Spanning Tree Protocol (STP) per evitare loop di frame broadcast che non possono essere fermati (perch√© i frame Ethernet non hanno TTL).\nNumero di nodi:\ni router usano instradamento di tipo gerarchico, gestiscono grandi nodi in modo efficiente grazie ad aggregazioni di indirizzi IP\ngli switch devono memorizzare ogni indirizzo MAC nella tabella di commutazione, troppi dispositivi=tabelle troppo grandi\nIsolamento del traffico:\ni router non fanno broadcast tra reti diverse, inoltrano pacchetti indirizzati solo se la rete √® conosciuta nella tabella di routing, le reti quindi sono isolate e pi√π sicure\ngli switch se non conoscono l‚Äôindirizzo MAC di destinazione inviano frame in modalit√† broadcast su tutte le porte, questo crea problematiche come connessioni a effetto valanga se ci sono altri switch collegati\n\n\nVLAN\nCosa succede se i dispositivi di una rete LAN aumentano e sono solo collegate da uno switch?\n\ntutti i dispositivi sono su un unico dominio di broadcast, se avviene un broadcast tutti lo ricevono\ndecrescita della sicurezza e della privacy\n\nSoluzione: Le VLAN\nle Virtual Local Area Network permettono\ndi rimanere nella stessa rete\n\nma creare delle indipendenze logiche usando switch diversi\n\n\nQuesto semplifica la gestione con pi√π dispositivi e concede maggiore flessibilit√†\n\n\nVLAN basate sulle porte\nGli switch che supportano le funzionalit√† VLAN possono essere configurati per definire pi√π LAN virtuali ma su una unica infrastruttura fisica, usando un singolo switch come se per√≤ ce ne fosse pi√π di uno\n\nquesto concede isolamento del traffico e le varie porte possono essere assegnate in modo dinamico\ndue dispositivi su VLAN diverse non possono comunicare direttamente, nemmeno se collegati allo stesso switch: serve un router (o uno switch di livello 3) che si occupi di instradare i pacchetti tra le due VLAN, proprio come se fossero due reti distinte.\n\n\nVLAN su pi√π switch\nconnettere tra di loro due reti che appartengono alla stesa VLAN ma non presenta troppa scalabilit√† perch√© ogni switch che colleghiamo toglie una porta allo switch principale\n\nUna porta trunk √® una porta speciale che collega due switch e permette loro di:\n\nscambiarsi frame Ethernet appartenenti a pi√π VLAN diverse\nmantenendo l‚Äôinformazione su quale VLAN appartiene ogni frame\n\nID VLAN\nDi default i frame ethernet non hanno come dettaglio l‚ÄôID VLAN\n\nidentificativo che dice a quale VLAN stai\nesso viene aggiunto da un protocollo che aggiunge al frame un tag VLAN che dice proprio a quale ID appartiene un determinato frame\nil frame ora si chiama VLAN 802.1Q\n\n\nEVPN\n\n√à una tecnologia di tunneling che permette di:\n\nCollegare reti Layer 2 (Ethernet) che si trovano in luoghi fisicamente diversi (es. data center a Sunnyvale e a Bangalore).\nUsare una rete IP Layer 3 preesistente (chiamata underlay) come mezzo di trasporto.\n\nCome funziona\n\nI frame Ethernet (Layer 2) vengono incapsulati dentro pacchetti IP (Layer 3).\nQuesti pacchetti IP viaggiano attraverso una rete Layer 3 (come Internet o una WAN).\nQuando arrivano a destinazione, il frame Ethernet originale viene estratto e consegnato allo switch remoto, come se provenisse da una rete locale.\nserve per:\n\n\n\nAllungare reti Layer 2 su distanze geografiche.\n\n\nUnificare VLAN remote (utile in ambienti cloud, datacenter, multi-sito).\n\n\nSeparare logicamente pi√π clienti o dipartimenti usando VLAN over IP.\n\n\nCome inviare un datagramma a un nodo non adiacente nella rete\n\n\n\nVerifica della destinazione ‚Üí se il destinatario si trova in un‚Äôaltra sottorete, il frame va instradato tramite un router gateway,\nCreazione del datagramma IP + Incapsulamento in un frame ‚Üí i vari IP (sorgente e destinatario), i vari MAC (sorgente e destinatario) e il MAC del router si ottiene tramite ARP,\nRicezione e analisi da parte del router ‚Üí il router riceve il frame, estrare il datagramma e si accorge che l‚ÄôIP di destinazione non √® il suo,\nInstradamento verso la rete di destinazione ‚Üí il router incapsula di nuovo il datagramma e spedisce il frame alla giusta interfaccia e quindi poi al giusto destinatario\n"},"UNI/ANNO-2/RETI/RETI-LEZ.2":{"slug":"UNI/ANNO-2/RETI/RETI-LEZ.2","filePath":"UNI/ANNO 2/RETI/RETI LEZ.2.md","title":"RETI LEZ.2","links":[],"tags":[],"content":"Nucleo della rete\nHa il compito di trasmettere una richiesta da una periferia all‚Äôaltra, quindi da un host ad un altro.\nQuesto nucleo √® composto da una ‚Äúmaglia‚Äù di commutatori di pacchetti (router o switch) e i vari collegamenti tra i vari host.\nUn host non pu√≤ inviare dati (messaggi di livello applicativo) di grandezza arbitraria, per questo vengono suddivisi in pacchetti (packets) che la rete inoltra (forwards) da un router all‚Äôaltro attraverso i collegamenti (links) lungo un percorso (path o route) dalla sorgente alla destinazione.\nDue funzioni chiave del nucleo della rete\n1. Inoltro (forwarding o switching)\n√à un‚Äôazione locale che avviene all‚Äôinterno di ogni singolo router.\nIl router riceve il pacchetto su un‚Äôinterfaccia di ingresso e, tramite una tabella (detta di inoltro locale) sceglie a quale interfaccia di uscita inoltrarlo.\nLa tabelle sono uniche per ogni router.\nPrendiamo questa tabella\n\n\nl‚Äôintestazione rappresenta l‚Äôidentificativo di un pacchetto\nl‚Äôuscita indica, al singolo router, dove ‚Äúinstradare‚Äù quel pacchetto\n\n2. Instradamento (Routing)\n√à un‚Äôazione globale che riguarda l‚Äôintero percorso dalla sorgente alla radice.\nSi occupa di determinare il percorso migliore possibile tra i router della rete e per farlo i router utilizzano algoritmi di instradamento che calcolano le migliori rotte in base a parametri (es. distanza, velocit√† del collegamento, ecc.).\n\nCommutazione di pacchetto: store-and-forward\nRicordando che servono \\frac L R secondi per trasmettere (transmit) un pacchetto di L bit attraverso un collegamento di R bps.\nUn router deve aspettare che TUTTO il pacchetto arrivi prima di poterlo trasmettere collegamento in uscita (store-and-forward).\n\nCon un pacchetto\nQuindi, il ritardo da un capo all‚Äôaltro (end-to-end) per la trasmissione di un pacchetto su un percorso di N collegamenti di pari velocit√† R √® dato da d_{end-to-end} = N \\frac L RTrascurando il ritardo di propagazione e altre forme di ritardo.\nCon P pacchetti\nd_{end-to-end} = (N + P - 1) \\frac L Rdove il -1 lo mettiamo perch√© il primo arriva prima degli altri senza intoppi (quindi nella formula non lo contiamo), mentre gli altri invece saranno vincolati sempre dal primo.\nAnche qui trascurando il ritardo di propagazione e altre forme di ritardo.\nAccodamento\nIl problema dell‚Äôaccodamento (queuing) si verifica quando il lavoro arriva pi√π velocemente di quanto possa essere servito, ossia se il tasso di arrivo (arrival rate, in bps) al collegamento successivo eccede il tasso di trasmissione (bps) del collegamento per un certo periodo di tempo\nRicordiamo che abbiamo un buffer in ogni router, e se questo si riempie i pacchetti si accodano sul collegamento di entrata (o di uscita del router precedente).\nI pacchetti possono essere scartati in base a degli algoritmi che vedremo poi.\nAlternativa: commutazione di circuito\nLa commutazione di circuito √® un metodo di comunicazione in cui viene stabilito un percorso fisso tra il mittente e il destinatario prima che inizi la trasmisisone dei dati.\nLe risorse lungo il percorso vengono riservate (es. buffer, banda di trasmissione) e rimangono dedicate per tutta la durata della comunicazione.\nIl trasferimento dei dati avviene a velocit√† costante e garantita.\n\n\n                  \n                  PROBLEMA \n                  \n                \n\nSe il circuito non √® in uso, rimane inattivo e quindi diventa inefficiente rispetto alla commutazione di pacchetto.\n\n\nDue tecniche di multiplexing per la comunicazione di circuito\n1. Multiplexing a Divisione di Frequenza (FDM)\nL‚Äôintero spettro di frequenza del collegamento viene suddiviso in bande di frequenza e ogni utente ha la propria banda dedicata.\nPRO: pi√π utenti possono essere trasmessi in parallelo\nCONTRO: la velocit√† di banda √® ridotta\n\n\n\n                  \n                  Ma se due utenti trasmettono contemporaneamente, come faccio a capire chi ha trasmesso? \n                  \n                \n\nLa luce √® un‚Äôonda elettromagnetica, la cui frequenza √® connessa ad un colore.\nOgni combinazione di colori ha un risultato differente, quindi partendo da un colore possiamo risalire alla combinazione che l‚Äôha generato.\n\n\n\n2. Multiplexing a Divisione di Tempo (TDM)\nIl tempo viene suddiviso in frame, che a loro volta contengono slot temporali.\nPRO: utilizzi tutta la larghezza di banda del circuito\nCONTRO: puoi trasmettere solo nel tuo slot dedicato\n\nCommutazione di circuito VS commutazione di pacchetto\n\nQuindi\n\nCome si verificano ritardi e perdite?\nI pacchetti si accodano nei buffer del router, aspettando il proprio turno per la trasmissione.\nLa perdita di pacchetti si verifica quando la memoria che contiene la coda dei pacchetti si riempie.\n\nQuattro cause principali\n\n(d sta per delay).\nDove\n\n\nd_{elab} : elaborazione di nodo\n(tipicamente &lt; microsecondi) si verifica per\n\ncontrollo errori sui bit\ndeterminazione del canale di uscita\n\n\n\nd_{acc} : ritardo di accodamento\nsi verifica per\n\nattesa di trasmissione\ne dipende dal livello di congestione del router.\n\n\n\nd_{trasm} : ritardo di trasmissione\ntutto il discorso di \\frac L R\n\n\nd_{prop} : ritardo di propagazione\nd_{drop} = \\frac d v\ndove\n\nd: lunghezza del collegamento fisico\nv: velocit√† di propagazione (\\sim 2 \\times 10^{8})\n\n\n\nAnalogia della carovana\n\nQuindi il ritardo totale √® dato dalla somma dei ritardi che subisce ogni pacchetto ad ogni nodo, ossia d_{end-to-end} = \\sum_{i} \\left( d_{elab_i} + d_{acc_i} + d_{trasm_i} + d_{prop_i} \\right)\nIntensit√† di traffico\nIl ritardo di accodamento dipende dall‚Äôintensit√† di traffico, ossia il tasso di utilizzo della rete, definita dalla formula \\frac {L \\times a} Rdove\n\na = velocit√† media di arrivo dei pacchetti (in pacchetti al secondo).\n\nAbbiamo tre casi\n\n\nSe \\frac {L \\approx a} R \\sim 0\n\nil traffico √® molto basso rispetto alla velocit√† disponibile e non ci sono ritardi significativi\n\n\n\nSe \\frac {L \\times a} R \\rightarrow 1\n\nil traffico si avvicina alla capacit√† massima del collegamento con quindi un ritardo medio che tende a crescere\n\n\n\nSe \\frac {L \\times a} R &gt; 1\n\nI pacchetti arrivano pi√π velocemente di quanto possano essere trasmessi; in questo caso il ritardo tende all‚Äôinfinito e la rete diventa congestionata\n\n\n\n\nPerdita di pacchetti\nLa coda (buffer) che precede un collegamento ha capacit√† finita e quando il pacchetto trova la coda piena, viene scartato.\n\nThroughput\nIl throughput √® la frequenza (\\frac {bit} {unit√† \\ di \\ tempo}) alla quale i bit sono trasferiti tra mittente e ricevente.\nAbbiamo due tipi\n\nistantaneo: in un determinato istante\nmedio: in un periodo di tempo pi√π lungo (es. un file di F bit in T secondi √® \\frac F T bps)\n\n\nGuarda questa immagine\n\nIn entrambi i casi abbiamo un collo di bottiglia che vincola il throughput end to end\nScenario di internet\n\nOvviamente abbiamo due casi\n\n\nse il traffico non √® interessato (sto usando solo io la connessione) allora throughput \\approx min\\{R_j\\}\ndove R_{j} √® la velocit√† di trasmissione dell‚Äôi-esimo collegamento\n\n\naltrimenti devo fare come nella foto sopra e suddividere la velocit√† tra i vari flussi che lo attraversano.\n\n"},"UNI/ANNO-2/RETI/RETI-LEZ.20":{"slug":"UNI/ANNO-2/RETI/RETI-LEZ.20","filePath":"UNI/ANNO 2/RETI/RETI LEZ.20.md","title":"RETI LEZ.20","links":[],"tags":[],"content":"Differenza tra wireless e mobilit√†\n\nwireless\n\nla comunicazione effettiva su un collegamento di tipo senza fili\n\n\nmobilit√†\n\nazione del cliente che spostandosi cambia punti d‚Äôaccesso a cui √® connesso\n\n\n\nComponenti di una rete wireless\n\nHost wireless\n\nlaptop, smartphone ecc‚Ä¶\nesegue operazioni e ha un collegamento wireless\neseguono le applicazioni\npossono essere fissi o stazionari\n\n\nCollegamento wireless\n\nutilizzato per collegare un host wireless alla stazione di base oppure un altro host wireless\ndi tipo condiviso, tutti potrebbero condividere stessa banda di frequenze\n\npotrebbero esserci collisioni quindi i vari protocolli di accesso multiplo sono fondamentali\n\n\n\n\nStazione base\n\nelemento che funge da ripetitore, relay al livello di collegamento\ndi solito essa √® connessa ad una rete cablata\nes: access point o tower delle reti cellulari\n\n\n\n\nDifferenze tra raggio di copertura e velocit√† dei collegamenti wireless su una tabella\n\nModalit√† differenti\nsi dividono principalmente in 2 tipologie\n\ncon infrastruttura\n\nvengono forniti dei servizi di rete\n\ngrazie alle stazioni base su cui si connettono gli host wireless\n\n\nhandoff\n\nazione che avviene quando un host si sposta dall‚Äôarea di copertura e cambia punto di accesso con una rete pi√π ampia\npu√≤ addirittura cambiare sottorete\n\n\n\n\n\nReti ad hoc, senza infrastruttura\n\nsenza stazioni base\ngli host condividono solo ad altri nodi entro la loro copertura\ngli host provvedono da se per fornire servizi di instradamento e altro ancora\n\n\n\n\nTassonomia delle due modalit√† differenti\ntabella con hop multipli e non\n\nCaratteristiche dei collegamenti wireless\nConcetto di attenuazione\n\nIl segnale pu√≤ essere assorbito o attenuato a causa dei diversi ostacoli\nanche solo semplicemente esso pu√≤ essere attenuato dalla dispersione del segnale nella distanza\n\nquando c‚Äô√® uno spazio libero questa attenuazione si chiama di spazio libero\n\nfree space path loss\nsi pu√≤ derivare una piccola formula\n(frequenza‚ãÖdistanza)^2=(fd)^2\n\n\n\n\nPi√π alta √® la frequenza o pi√π lontano √® il ricevitore, pi√π rapidamente si perde il segnale.\n\n\nPropagazione wireless su cammini differenti\n\nquando un segnale viene riflesso su diversi elementi che ci circondano, possono modificarne il loro tempo di arrivo o addirittura possono arrivare stessi pacchetti con tempi diversi\n\nPer questo viene aggiunto il tempo di coerenza\n√® un tempo per cui all‚Äôarrivo di un impulso ne possono arrivare altri da eventuali riflessi\ni tempi di coerenza non possono sovrapporsi quindi questo fa variare le velocit√† di trasmissione\n\n\nInterferenze da parte di altre sorgenti\npotrebbero esserci interferenze anche da altre frequenze come quelle Bluetooth oppure rumori elettromagnetici ambientali\n\nconcetto di rapporto segnale-rumore (signal-to-noise-ratio) SNR\n\nun SNR pi√π grande facilita chi riceve il segnale ad estrarre il segnale trasmesso rispetto al rumore di fondo\ninfatti avremo un numeratore pi√π grande dell‚Äôaltro\n\n\ntasso di errore sui bit (bit error rate) BER\n\nprobabilit√† che un bit sia ricevuto in errore\n\n\n\nBilanciamento\n\nAumentare la potenza ‚Üí aumenta SNR ‚Üí riduce BER\n\nMa consuma pi√π energia (problema per smartphone, sensori, ecc.)\nE aumenta il rischio di interferenze con altre comunicazioni\nPoich√© lo SNR cambia continuamente (mobilit√†, ostacoli, interferenze), i dispositivi wireless adattano automaticamente:\n\n\n\n\nLa modulazione\nLa velocit√† di trasmissione\nQuesto garantisce:\nQualit√† accettabile\nConsumo energetico controllato\nMinori errori\nL‚Äôimmagine qua sotto fa vedere diverse tipologie di modulazioni\n\n\nTerminali nascosti dei collegamenti delle reti wireless\nA e C possono mandare a B ma non si comunicano tra di loro quindi non si sa se ci sono collisioni\nci sono due scenari dove abbiamo un terminale nascosto\n\nProtocollo di accesso multiplo per le reti wireless\nCDMA (Code Division Multiple Access)\n√® un protocollo che permette di condividere lo stesso canale di comunicazione con pi√π utenti senza troppe interferenze\nOgni utente ha un codice unico (una sequenza chiamata chipping sequence):\n\nTutti gli utenti trasmettono sulla stessa frequenza e allo stesso tempo\nMa il loro segnale √® ‚Äúcodificato‚Äù con un codice specifico\nad esempio si possono applicare codici ortogonali con segnali che non si disturbano a vicenda\n(es. \\vec{c}_1 \\cdot \\vec{c}_2 = 0)\n\nquindi per fare questa codifica:\n\nSi rappresentano i bit:\n\n0 ‚Üí -1\n1 ‚Üí +1\n\n\nOgni bit d_i √® moltiplicato per la sequenza del codice c‚Éó , ottenendo d_i \\cdot \\vec{c}\n\nSe il codice ha lunghezza M, il bit viene ‚Äúespanso‚Äù in M valori\ninvece poi per fare la decodifica chi riceve il segnale deve\n\n\nIl ricevitore riceve la somma dei segnali di tutti gli utenti\nPer estrarre i dati di un utente specifico:\n\nDivide i dati ricevuti in blocchi di M\nCalcola il prodotto scalare con il codice dell‚Äôutente\nDivide per M ‚Üí ottiene il bit originale\n\n\n\n\n\n\n\n                  \n                  dimostrazione del perch√© funziona \n                  \n                \n\n\n\n\nReti Wi-Fi con uno standard chiamato (802.11)\n802.11 Canali utilizzati\n\n802.11 architettura di queste LAN\nqui gli host wireless comunicano con la stazione base come un access point\nUna BSS √® una infrastruttura che contiene:\n\nhost wireless\npunto di accesso AP\nmodalit√† ad hoc in cui i dispositivi comunicano tra loro direttamente\n\n\nCanali del 802.11 ovvero il Wi-Fi\n\ni canali sono la suddivisione di questo spettro di frequenze differenti\n\nl‚Äôaccess point admin sceglie le frequenze per il punto di accesso\npotrebbero esserci interferenze\n\nun altro AP la vicino pu√≤ scegliere lo stesso canale\n\n\n\n\n\n\n802.11 Associazione\n\nun host in arrivo nella BSS deve essere associato a un AP per farlo deve\n\nscansionare gli AP vicini prendendo i vari frame beacon, ovvero quei frame che mandano periodicamente gli access point per farsi rilevare\n\ncontengono MAC address dell‚ÄôAP e l‚ÄôSSID( nome della rete)\n\n\nl‚Äôhost deve sceglierne uno e accedervi rispettando le varie protezioni come WPA2\nUna volta associato e autenticato, l‚Äôhost invia un messaggio DHCP Discover per ottenere un indirizzo IP.\nQuesto messaggio passa attraverso l‚ÄôAP, che lo inoltra nella sottorete.\n\n\n\n\nScansione attiva vs passiva\n\nWi-Fi con accesso multiplo\nAbbiamo bisogno di un protocollo per evitare collisioni nell‚Äôuso della rete Wi-Fi\n\nIn questo caso ne vedremo uno con accesso casuale\n\nnon elimina collisioni ma le gestisce\n\n\n\nCSMA/CA (Carrier Sense Multiple Access)\n\nascolto il canale e vedo se qualcuno sta gi√† trasmettendo\n\nnella Ethernet era con collision detection CD Collision Detection\n\n\ninvece qui abbiamo la CA, quindi senza rilevamento delle collisioni\n\nQuindi si cercano di evitare, Collision Avoidance\nCon il Wi-Fi per motivi hardware non si possono rilevare collisioni\n\n\n\nCSMA/CA da parte del mittente\n\nDIFS(Distributed Inter Frame Space) √® un intervallo di tempo per cui devo vedere per quanto tempo il canale deve essere libero prima di inviare i dati\nSIFS(Short Inter Frame Spacing) √® pi√π corto del DIFS e serve come intervallo di tempo per gli ACK e altre cose\nbackoff: tempo del vero e proprio contatore dell‚Äôhost\n\n\ncontrollo se il canale √® inattivo per DIFS, se lo √® trasmetto il frame per intero senza Collision Detection\nse invece √® attivo bisogna trasmettere in differita\n\nsi sceglie un valore di ritardo casuale usando la binary exponential backoff\nquando il timer backoff non √® a zero allora aspetto che il canale sia libero per DIFS\nil backoff decrementa, ogni volta che uno slot di tempo si libera\n\n\n\n\nquando il timer raggiunge lo zero allora si pu√≤ accedere al canale se libero e si trasmette il frame per intero\nse non si riceve l‚ÄôACK si ripete il punto 2 incrementando intervallo di backoff\nSe riceve ACK e ha altri dati da trasferire resetta intervallo backoff e ripete il punto 2\n\nDa parte del destinatario\nInvia un ACK dopo un intervallo SIFS\nIMPORTANTE: non entro nel canale appena si libera ma aspetto il tempo di backoff, perch√© non ci sono CD, le collisioni possono comunque esserci\n\nRicapitolando\nnelle reti wireless non posso avere Collision Detection, questo perch√© √® tutto su frequenze alterne e oltretutto non tutto √® visibile da tutti allo stesso modo\n\ninoltre la potenza di segnale trasmessa √® sicuramente pi√π forte di quella che dovresti sentire per rilevare se il canale √® libero o meno\nquindi quello che succede davvero √®:\nIl nodo ascolta il canale.\nSe √® occupato: aspetta che si liberi.\nQuando si libera: attende un tempo fisso (DIFS), poi parte un backoff casuale.\nQuesto evita che pi√π nodi trasmettano esattamente nello stesso istante.\nLe collisioni possono comunque avvenire:\nüï≥Ô∏è Terminale nascosto:\n\nDue nodi non si vedono tra loro, ma entrambi vedono il destinatario.\nTrasmettono pensando che il canale sia libero ‚Üí collisione sul destinatario.\n\n\n‚è±Ô∏è Timer simili:\n\nDue nodi scelgono numeri di backoff simili.\nEntrambi iniziano a trasmettere quasi contemporaneamente ‚Üí collisione.\nPer risolvere queste collisioni √® stato ideato un meccanismo con prenotazioni per usare la rete\n\n\n\nMeccanismo di prenotazione\nil mittente deve prenotare il canale\n\nviene inviato un RTS al AP per prenotare l‚Äôuso del canale\n\npotrebbero verificarsi collisioni con l‚Äôinvio del RTS ma essendo pacchetti piccoli ci√≤ non √® un problema\n\n\nviene inviato poi dal AP un segnale di tipo CTS a tutti i nodi per dare pulizia\n\nsostanzialmente tutti i nodi ricevono questo pacchetto Clear To Send dopo che un nodo ha inviato un pacchetto Request To Send\ntutti gli altri dovranno rimandare eventuali trasmissioni\nFoto esempio:\n\n\n\n\n\nA ‚Üí AP: RTS (Request To Send)\nIl nodo A invia un messaggio RTS per ‚Äúprenotare il canale‚Äù.\nB ‚Üí AP: RTS (collisione!)\nAnche il nodo B prova a inviare un RTS nello stesso momento ‚Üí collisione della prenotazione (niente dati ancora persi!).\nAP ‚Üí A e B: CTS (Clear To Send)\nL‚ÄôAccess Point risponde a A con un CTS. Tutti i nodi che sentono il CTS, incluso B, tacciono per il tempo specificato.\nA ‚Üí AP: trasmette DATA\nSolo A trasmette, perch√© ha ricevuto il CTS.\nAP ‚Üí A e B: ACK\nL‚ÄôAP invia conferma della ricezione del frame.\n\n802.11 i frame in particolare l‚Äôindirizzamento\n\nCome cambia il frame da Ethernet a Wi-Fi?\nViene aggiunto l‚Äôindirizzo MAC dell‚ÄôAP\n\nIl router R1 non sa che H1 √® collegato via Wi-Fi\nquando il passaggio invece √® da Wi-Fi a Ethernet si ha il contrario\n\nFrame di indirizzamento con dei dettagli su\n\nla durata della trasmissione\nil numero di quel determinato frame\nil campo frame control si divide nei campi della foto sotto\ncon tipologia del frame\n\n\nMobilit√† nella stessa sottorete\n\nquando un host si sposta da un AP a un altro per√≤ mantenendo stesso indirizzo IP\n\ninevitabilmente per avere stesso indirizzo IP sono collegati tutti e due dallo stesso switch\n\n\ncome fa lo switch a capire da quale AP raggiungere H1\n\ncon auto-apprendimento\n\nriceve un frame da H1 e si ricorder√† quale porta usare per raggiungerlo\nil nuovo AP invia un frame in broadcast con mittente H1 per far vedere allo switch dove si trova\nlo standard 802.11f definisce un protocollo inter-AP per affrontare questi tipi di problemi e tanti altri\n\n\n\n\n\n\nFunzionalit√† avanzate del 802.11\n\nla stazione base e la stazione mobile possono cambiare dinamicamente il tasso trasmissivo\n\nla stazione mobile si sposta e cambia SNR\n\n\ngestione dell‚Äôenergia\n\nun host pu√≤ dire di entrare in stato dormiente all‚ÄôAP\nhost si riattiver√† solo quando l‚ÄôAP sta per mandare un frame beacon\n\nsi sveglia, controlla se √® nella lista e in caso si rimette a dormire\nLa lista nel beacon dice: ‚Äúehi, ho qualcosa per questi dispositivi!‚Äù\n\n\n\n\n"},"UNI/ANNO-2/RETI/RETI-LEZ.21":{"slug":"UNI/ANNO-2/RETI/RETI-LEZ.21","filePath":"UNI/ANNO 2/RETI/RETI LEZ.21.md","title":"RETI LEZ.21","links":[],"tags":[],"content":"Bluetooth\n\n\nLavora sulle PAN(Personal Area Network)\n\ncon bassissimo diametro (10 metri)\n\n\n\nCerca di sostituire i vari cavi come mouse tastiera cuffie ecc‚Ä¶\n\n\nCon le ultime connessioni arriva fino a 3 Mbps\nIl TDM (Time Division Multiplexing) del Bluetooth √® a 625 micro secondi\n\n\nClient device e Master controller comunicano su due slot alternati\n\ntipo uno prende gli slot pari uno i dispari\ngli slot sono divisi per un intervallo di tempo di 625 microsecondi\nFDM con FHSS\nIl FDM consiste nell‚Äôusare diverse frequenze per trasmettere dati in parallelo. Bluetooth lo combina con FHSS (Frequency-Hopping Spread Spectrum) per aumentare robustezza e sicurezza.\nL‚Äôordine dei salti di frequenza √®:\n\n\n\nPseudocasuale (sembrano casuali ma sono deterministici).\n\n\nSincronizzato tra master e client.\n\nTDM ‚Üí gestisce chi parla quando.\nFDM con FHSS ‚Üí gestisce su quale frequenza si parla\n\n\n\nM (Master Controller): dispositivo centrale che controlla la comunicazione.\n\n\nC (Client Device): dispositivi attivi che comunicano con il master.\n\n\nP (Parked Device): dispositivi registrati ma inattivi (non comunicano finch√© non vengono ‚Äúrisvegliati‚Äù).\n\n\n\nIl Bluetooth non presenta infrastruttura fissa ma ha architettura ad hoc\n\ni dispositivi si organizzano in modo dinamico ponendo master controller e client device\nFino a 8 dispositivi attivi contemporaneamente (1 master + 7 client).\nIl master ha un ruolo fondamentale:\n\nDecide la sequenza dei salti di frequenza (FHSS).\nControlla la potenza di trasmissione.\nEsegue il polling, cio√® interroga i client per sapere se hanno dati da trasmettere (i client non parlano autonomamente).\n\n\n\n\n\n                  \n                  una piccola rete Bluetooth si chiama PICONET \n                  \n                \n\nBootstrapping processo che fa entrare in una piconet\nsi pu√≤ entrare in 2 modi\n\nNeighbor discovery\n\nil master invia dei messaggi in broadcast chiamati inquiry su diversi canali\nI dispositivi in ascolto (su un canale) rispondono con un ritardo casuale ‚Üí per evitare collisioni.\nServe a scoprire chi √® nelle vicinanze.\n\n\nPaging\n\nil master invita un dispositivo specifico a entrare\n\nQuando il dispositivo risponde con ACK, il master gli comunica:\nIl pattern dei salti di frequenza.\nL‚Äôorologio (clock).\nL‚Äôindirizzo di partecipazione.\n\n\n\n\n\nCovid e Bluetooth\n\n\nReti Cellulari 4G/5G\nRappresentano una soluzione diffusa e funzionale per avere internet mobile in wide-area\nSimilarit√† con Internet Cablato\n\nEntrambe hanno una struttura a livelli formata da:\n\nuna Periferia di accesso, dove si collegano tutti gli utenti\nun Nucleo che √® la parte di accesso centrale pi√π potente\n\ngestisce e smista il traffico tra le reti\n\n\nPeriferia e Nucleo sono differenti ma fanno parte dello stesso carrier, ovvero operatore telefonico Tim ecc‚Ä¶\n\n\nGlobalizzazione delle reti, proprio come internet le reti mobili sono reti di reti, anche se sei connesso a una rete TIM di Roma puoi comunicare con un utente Vodafone di Milano\nLe reti mobili usano gli stessi protocolli di comunicazione delle reti cablate\n\nHTTP, DNS, TCP, UDP, IP, NAT\nAnche qui troviamo tecnologie moderne come:\n\nSDN (Software Defined Networking)\nEthernet\nTunneling (per trasmettere informazioni in modo protetto o virtuale)\n\n\n\n\nLa rete mobile √® connessa alla rete cablata, attraverso punti di interconnessione\n\nDifferenze con Internet Cablato\n\nla rete cablata ha collegamenti fissi e usa protocolli come quello Ethernet\n\ninvece nelle reti mobili abbiamo protocolli specifici per funzionare via wireless\n\nLTE PHY per il livello fisico\nMAC per il controllo di accesso al mezzo\nRLC per il controllo al collegamento radio\n\n\n\n\nil passaggio da una cella all‚Äôaltra √® gestito autonomamente nelle reti mobili\n\nquesto fenomeno si chiama handoff\nnelle reti cablate no\n\n\nSulle reti cablate, chiunque pu√≤ collegarsi (spesso senza autenticazione).\n\nNelle reti mobili, invece, ogni utente ha una SIM card:\n\n\nEsistenza del concetto Home network\n\nsostanzialmente quando sei connesso alla rete a cui sei abbonato sei connesso alla home network\nquando cambi paese ed entri in roaming invece sei in una rete ospite, visited network\n\n\n\nArchitettura 4G semplificata e i suoi elementi\n\nOra spiegheremo per bene tutte queste cose qua sopra che cosa rappresentano\nEsagono in alto a sx Mobile device e Base station\n\nil Mobile device e  il dispositivo dell‚Äôutente dotato di abbonamento e SIM\n\nla SIM funziona con un identificativo IMSI a 64 bit\nnelle reti LTE si chiama UE, User Equipment\nEsso comunica con la rete tramite la base station\n\n\nla base station si trova alla periferia della rete dell‚Äôoperatore\n\n√® simile a un Access Point ma pi√π avanzato perch√© deve\n\ncoordinare le varie autenticazioni dei device\ngestire le risorse radio per far si che ogni UE stia nella sua cella\nsupporta handover con i vari passaggi di cella per la movilit√†\ncollabora quindi con altre Base station per ottimizzare l‚Äôuso della radio\n\n\n\n\n\nNuvola a dx HSS, Gateway e MME\n\nHome Subscriber Server ha il compito di memorizzare le informazioni degli utenti come IMSI, profili utente, chiavi di autenticazione\n\n√à il ‚Äúregistro centrale‚Äù dell‚Äôoperatore (es. TIM, Vodafone‚Ä¶)\nLa rete dell‚ÄôHSS √® considerata la home network per quei determinati dispositivi\n\nquando invece sei in roaming loro non hanno i tuoi dati devono chiederli\n\n\nLavora con l‚ÄôMME per autenticare i dispositivi mobili\n\n\nMME(Mobility Management Entity)\n\nCoordina l‚Äôautenticazione dei device con l‚ÄôHSS\nGestisce in particolare la parte della mobilit√† tra gli utenti\n\neseguendo handover tra celle\nsa la posizione dei vari dispositivi\n\n\nsi occupa di sistemare adeguatamente i tunnel tra UE e P-GW\n\n\nGateway S-GW e P-GW\n\nsono delle componenti all‚Äôinterno della rete che hanno il compito di instradare correttamente i dati nelle reti mobili\n\nS-GW(Serving Gateway), inoltra i dati tra UE e P-GW\nP-GW(PDN Gateway), fa da gateway verso internet\n\nappare come un normale router ed √® connesso alla rete globale\nfornisce servizi NAT\n\nse sei dietro un IP condiviso fa da intermediario tra UE e internet\n\n\nusa il tunneling per garantire una comunicazione trasparente\nche sia anche sicura mente ti muovi\n\n\n\n\n\n\n\nSeparazione tra piano dati e di controllo della rete LTE\nuna rete LTE presenta una divisione tra piano dati e piano di controllo\nüîí Piano di Controllo\nüìå Scopo:\nGestire mobilit√†, sicurezza e autenticazione.\nüì¶ Non trasporta dati reali, ma solo informazioni di gestione.\n√à come dire: ‚ÄúChi sei? Dove vuoi andare? Ti autorizzo? Hai il biglietto?‚Äù.\nüîß Componenti principali:\n\nBase station (eNode-B): comunica con il telefono (UE).\nMME (Mobility Management Entity): gestisce autenticazioni, mobilit√† e sessioni.\nHSS (Home Subscriber Server): contiene chi sei (es. IMSI, profili, chiavi).\nS-GW / P-GW: anche loro partecipano alla fase iniziale per preparare la connessione.\nüß† Importante:\nI protocolli qui non spostano dati, ma fanno le regole, come GTP-C (Control), S1-AP, NAS‚Ä¶\n\nüåê Piano Dati\nüìå Scopo:\nTrasportare il traffico IP vero e proprio, cio√® quello che stai facendo su Internet (YouTube, WhatsApp, siti, ecc.).\nüì¶ Viaggio diretto dei dati:\nTelefono (UE) ‚Üí eNode-B ‚Üí S-GW ‚Üí P-GW ‚Üí Internet\nüöá I dati passano in un ‚Äútunnel‚Äù IP chiamato GTP-U (User) che serve a\n\nSeparare i dati reali dal resto della gestione rete\nProteggere e indirizzare correttamente il traffico\n‚úÖ Vantaggi\nPi√π velocit√†\nPi√π efficienza\nIl piano di controllo pu√≤ cambiare (ad es. spostarti su un‚Äôaltra antenna) senza disturbare il traffico in corso\n\n\nPila protocollare del piano dei dati LTE\nogni comunicazione segue una struttura a strati (chiamata pila protocollare)\nvediamo come √® formato il livello di collegamento di questa pila nel first hop e nel tunneling core\n1.  First hop\n\n√® suddiviso in 3 sottolivelli\n\nPDCP- Packet Data Convergence Protocol\n\nha il compito di prendere ogni header dei pacchetti e di ridurle per occupare meno spazio attraverso compressioni\ncriptazione dei dati per maggiore sicurezza\n\n\nRLC- Radio Link Control\n\nquesto livello ha il compito di suddividere i dati in pezzi pi√π piccoli per trasmetterli e poi vengono rimessi insieme una volta ricevuti\npresente anche una correzione degli errori garantendo che ogni pezzo arrivi a destinazione\n\n\nMAC- Medium Access Control\n\ngestisce gli accessi al vanale radio per gestire chi deve parlare e quando\n\nassegna slot di tempo\n\n\nOFDM √® la tecnologia usata per suddividere la banda in pi√π canali paralleli riducendo interferenze\nQuesto primo hop LTE √® quindi molto strutturato e complesso, con protocolli dedicati alla sicurezza, affidabilit√† e gestione della radio.\n\n\n\n2. Tunneling nel core LTE\n\ndalla base station ai vari gateway al vero e proprio internet e abbiamo dei cambiamenti\nPer trasferire tutti questi dati adeguatamente si effettua il tunneling\n\ni dati dell‚Äôutente vengono impacchettati e spediti attraverso una sorta di tubo\n\nsi usa un protocollo chiamato GTP-U (GRPS Tunneling Protocol- User Plane) che ha il compito di impacchettare i dati e inserirli dentro un pacchetto UDP che verr√† spedito nel tubo\n\n\n\n\n\nüîÑ Come funziona, passo dopo passo\n\nIl datagramma GTP-U viene creato nella base station.\nViene inoltrato al S-GW, che non lo guarda dentro, ma semplicemente lo passa avanti.\nIl S-GW lo incapsula dentro un nuovo tunnel e lo spedisce al P-GW.\nAlla fine, il P-GW lo spacchetta e lo invia a Internet.\nüîÅ Tutto questo avviene in maniera trasparente per l‚Äôutente: √® come se fosse sempre connesso, anche se si muove o cambia celle.\n\nPresenta diversi vantaggi di mobilit√†, sicurezza e soprattutto √® complementare a internet senza stravolgerlo al suo interno\npiano dati: Associazione con una Base Station\nL‚Äôassociazione di un dispositivo UE a una base station avviene in 4 fasi\nFase 1 ‚Äì La base station si fa riconoscere\n\nogni 5 millisecondi la BS invia un segnale in broadcast di sincronizzazione primario\ni dispositivi mobili sentono quel segnale\ntutti i BS trasmettono su frequenze differenti\n\nFase 2 ‚Äì Il telefono ascolta e analizza\n\ndopo aver sentito il segnale primario ora avviene quello secondario con pi√π dettagli\n\nper ogni BS rilevata il nostro UE avr√†:\n\nüì∂ Configurazione del canale: larghezza di banda, tipo di frequenza, ecc.\nüÜî ID della cella: identifica univocamente la BS.\nüè∑Ô∏è ID operatore: capisce se la BS appartiene al suo operatore.\n‚öôÔ∏è Parametri extra: ad esempio priorit√†, risorse disponibili.\n\n\n\n\n\nFase 3 ‚Äì Il telefono sceglie la base station\n\nil telefono sceglie quale BS usare in base a quella che ha un segnale pi√π forte e preferendo le varie home network senza andare in roaming\n\nFase 4 ‚Äì Cosa succede dopo la scelta?\n\navviene la connessione vera e propria\n\n‚úÖ Autenticazione: il telefono si identifica con la SIM card ‚Üí HSS e MME verificano chi sei.\nüß† Creazione del collegamento: viene riservato un canale per te.\nüåç Configurazione del piano dati:\n\nTi viene assegnato un indirizzo IP.\nVengono stabilite le regole per far passare i tuoi pacchetti dati.\n\n\n\n\n\nLa rete LTE prevede nodi dormienti per ridurre il loro consumo energetico che si dividono in\n\nlight sleep\n\nsi attiva dopo alcune centinaia di millisecondi di inattivit√† ma si risveglia periodicamente per controllare se ci sono dati in arrivo\n\n\ndeep sleep\n\nsi attiva dopo 5-10 secondi di inattivit√†\nla connessione e sospesa e non riceve pi√π dati periodicamente, ma se si sveglia pu√≤ ancora riceverli\nse si sposta serve una nuova associazione con la BS\n\noverhead aggiuntivo\n\n\n\n\n\nRete cellulare globale una rete di reti IP\n\n5G\nsi √® passati al 5G per tre scenari\n\neMBB (Enhanced Mobile Broadband): connessioni pi√π veloci e ad alta capacit√†.\nmMTC (Massive Machine-Type Communications): supporto a milioni di dispositivi IoT.\nURLLC (Ultra-Reliable Low Latency Communications): comunicazioni ultra-affidabili a bassa latenza.\n\nil 5G ha un incremento delle velocit√† rispetto al 4G di 10x e capacit√† di traffico del 100x\n\nfrequenza maggiore\npotrebbero esserci problemi su distanze pi√π lunghe dalle antenne rispetto al 4G\n\nPrecisazioni sul concetto di mobilit√†\n\n\n                  \n                  Definizione \n                  \n                \n\nLa mobilit√† √® la capacit√† di un dispositivo di muoversi tra le reti mantenendo attive le comunicazioni in corso, senza perdere la connessione.\n\n\nSpettro della mobilit√†\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLivello di mobilit√†DescrizioneNessuna mobilit√†Il dispositivo si muove tra reti di accesso ma √® spento durante lo spostamento. Nessuna necessit√† di mantenere la connessione.Bassa mobilit√† (inattiva)Il dispositivo √® acceso, si muove ma non mantiene connessioni attive (es. accendi il telefono in una nuova area).Mobilit√† intra-reteIl dispositivo si muove all‚Äôinterno della stessa rete wireless dello stesso operatore. Cambia cella, ma rimane nella stessa rete di fornitore.Mobilit√† inter-rete (interessante per l‚Äôesame)Il dispositivo si muove tra reti di accesso ma resta nella stessa rete del fornitore, mantenendo attive le connessioni. (Es. da una cella a un‚Äôaltra, durante una videochiamata)Mobilit√† globale (interessante per l‚Äôesame)Il dispositivo si muove tra reti di fornitori differenti, mantenendo le connessioni attive. (Richiede roaming e coordinamento pi√π complesso tra operatori.)\nIl problema della mobilit√† √® che se un dispositivo si sposta da una rete  all‚Äôaltra come fa la rete vecchia a sapere che deve inoltrare i pacchetti alla rete nuova?\n\nDue approcci differenti al problema\n1. Lasciare che i router gestiscano la cosa\nIn questo approccio:\n\nOgni volta che un dispositivo si sposta in una nuova rete, il router della nuova rete annuncia al mondo ‚ÄúEhi, ora questo dispositivo √® con me!‚Äù\nLa rete interna aggiorna le sue tabelle di routing, ovvero le ‚Äúmappe‚Äù per capire dove mandare i dati.\nMa la cosa che rende questo approccio pessimo √® che funziona se i dispositivi sono pochi\nse ci sono miliardi di utenti non possono aggiornarsi queste tabelle in continuazione\nsarebbe un disastro\n\n2. Far gestire la mobilit√† al dispositivo stesso o a chi gli sta vicino(Home Agent)\nsi divide in 2 tecniche principali\n\na instradamento indiretto (indirect Routing)\n\nil dispositivo ha un suo home agent nella rete di origine\nquando si sposta i pacchetti vengono prima spediti all‚Äôhome agent\npoi l‚Äôhome agent li reinvia al dispositivo nella nuova posizione\n\nl‚Äôhome agent non conosce direttamente quali sono le base station che invieranno il tutto al dispositivo, il tutto avviene in modo indiretto\n\n\nSvantaggio: i dati fanno un giro pi√π lungo, non ottimale.\n\n\ninstradamento diretto (Direct Routing)\n\nil mittente scopre dove si trova il dispositivo(il suo nuovo indirizzo IP)\ngli invia i pacchetti in modo diretto senza passare dall‚Äôhome agent\nin poche parole i servizi che ti forniscono informazioni ti mandano i dati sul nuovo indirizzo IP che scambi ad ogni spostamento\nveloce ed efficiente\n\n\n\n\nRete domestica, Rete visitata\n4G/5G\n\nIn sostanza ci sono due tipi di network\n\nhome network\n\nrete gestita dal tuo operatore con cui hai un contratto\n\n\nvisited network\n\nrete gestita da altri operatori con cui ti connetti in roaming\nfunziona tramite accordi\n\n\n\nISP/WI-FI\n\nNel concetto ISP/WI-FI non c‚Äô√® un discorso di home network, ogni rete √® indipendente e l‚Äôutente deve accedere ad esse attraverso le credenziali salvate sul loro device\n\nsolo alcune reti hanno concetti di roaming come eduroam con un discorso simile\n\nRete domestica/Rete visitata\n\n\nil dispositivo mobile ha due identit√†\n\nIMSI identificatore globale\nIP pu√≤ essere permanente nella rete domestica e NAT nella rete visitata\n\n\nLa rete domestica assegna l‚ÄôIP permanente e ha l‚ÄôHSS, mobility manager ecc‚Ä¶\nLa rete visitata assegna un IP locale ma fa tunneling verso la rete domestica\ninstradamento e autenticazione vengono fatti sulla rete domestica anche se sei altrove\n\nRegistrazione: come far capire ‚Äúa casa‚Äù dove sei\nQuando ti sposti in una rete diversa da quella del tuo operatore\n\nla rete domestica deve sapere dove inoltrare i tuoi dati, questo processo si chiama registrazione\n\nüîÅ Passaggi della registrazione\n\n\n\nIl nodo mobile si associa al mobility manager della rete visitata\n\nAppena entra nella rete visitata, il dispositivo invia una richiesta al Mobility Manager (MM) locale.\nQuesto MM √® responsabile di sapere che il dispositivo si trova l√¨ in quel momento.\n\n\n\nIl mobility manager visitato registra la posizione del nodo presso l‚ÄôHSS della rete domestica\n\nInvia un messaggio all‚ÄôHSS (Home Subscriber Server), che si trova nella rete del tuo operatore.\nL‚ÄôHSS aggiorna la posizione del nodo mobile, registrando in quale rete (e in quale MM) si trova attualmente.\n\n\n\nRisultato finale\n\nIl Mobility Manager visitato sa che il dispositivo √® collegato a lui.\nL‚ÄôHSS domestico sa che il tuo terminale √® associato a quel mobility manager visitato.\nCos√¨, quando un corrispondente ti invia un pacchetto (es. chiamata, messaggio, dati), il tuo operatore sa in quale rete inoltrarlo grazie all‚Äôaggiornamento ricevuto.\n\n\n\nRouting indiretto\nQuando un dispositivo entra in una rete visitata non cambia il suo IP logico(domestico)\n\ncome fa allora a ricevere pacchetti nella nuova rete?\n\nla soluzione √® il routing indiretto\n\n\n\nüîÑ Fasi del routing indiretto\n\n\nComunicazione in ingresso\n\nIl corrispondente (es. un server o un altro utente) invia un datagramma al dispositivo mobile usando l‚ÄôIP della rete domestica (es. 128.119.40.186).\nIl pacchetto arriva al gateway della rete domestica (Home Network Gateway).\n\n\nTunneling\n\nIl gateway non pu√≤ inoltrare direttamente il pacchetto al dispositivo, perch√© si trova altrove.\nQuindi lo incapsula (tunnel IP) e lo invia attraverso Internet al gateway della rete visitata (es. 79.129.16.x).\n\n\nConsegna\n\nIl gateway visitato inoltra il datagramma al dispositivo mobile tramite il suo indirizzo NAT locale (es. 10.0.0.99).\n\n\n\nüîÅ Comunicazione in uscita\nIl dispositivo mobile, una volta ricevuto il pacchetto, pu√≤ rispondere in due modi:\n\n4a. Routing indiretto simmetrico:\n\nInvia la risposta al gateway domestico, che poi la consegna al corrispondente.\n\n\n4b. Routing diretto:\n\nInvia direttamente la risposta al corrispondente (possibile, ma rompe la simmetria IP).\n\n\n\nRouting indiretto pregi e difetti\nConcetto di instradamento triangolare\n\nil corrispondente invia i dati all‚ÄôIP domestico del dispositivo\nla rete domestica inoltra il tutto alla rete visitata tramite tunneling\nSe il corrispondente e il dispositivo sono vicini(tipo stesso paese), questo instradamento √® altamente inefficiente\n\nAnche se l‚ÄôIP del dispositivo cambia il corrispondente non se ne accorge e non vengono fermati inoltri dei dati\n\nRouting diretto\nNel routing diretto il corrispondente invia i pacchetti direttamente alla rete visitata dove si trova attualmente il dispositivo mobile, senza passare per reti domestiche\n\nüîÑ Passaggi principali\n\n(1) Il corrispondente vuole inviare un pacchetto al dispositivo mobile.\n(2) Contatta l‚ÄôHSS della rete domestica per sapere dove si trova il dispositivo.\n(3) Riceve l‚Äôindirizzo della rete visitata (es. NAT o IP temporaneo).\n(4) Invia i dati direttamente alla rete visitata, che li inoltra al dispositivo.\n\nquesto rende il tutto estremamente pi√π veloce e con latenza minore\nma il corrispondente deve ogni volta ottenere il nuovo care-of-address, quindi il nuovo IP nella rete visitata\nse il nodo mobile cambia ancora rete\nil sistema riesce a gestirlo ma ad ogni cambio bisogna aggiornare e registrare di nuovo tutto aggiungendo maggiore complessit√†"},"UNI/ANNO-2/RETI/RETI-LEZ.22":{"slug":"UNI/ANNO-2/RETI/RETI-LEZ.22","filePath":"UNI/ANNO 2/RETI/RETI LEZ.22.md","title":"RETI LEZ.22","links":[],"tags":[],"content":"RICORDIAMO CHE:\n\nHSS\n\nsi trova nella rete home dove hai il tuo abbonamento\n√® un database che ha i tuoi dati crittografati ecc‚Ä¶\n\n\nMME\n\n√® vicino a te in quel momento, si connette con l‚ÄôHSS per avere i tuoi dati\ne inoltre sa anche dove ti trovi per farti collegare con una BS adeguata\n\n\n\nCompiti di mobilit√† principali delle reti 4G\nI passi che avvengono quando un dispositivo si connette a una rete\n\nIl dispositivo mobile deve fornire l‚ÄôIMSI alla stazione base\n\nIMSI serve per identificare in modo univoco l‚Äôutente\n\ninoltre serve anche per far riconoscere la rete domestica a cui √® collegato in modo contrattuale\n\n\n\n\nla MME dialoga con l‚ÄôHSS per dire la nuova posizione del dispositivo\n\nla rete domestica ora sapr√† dove si trova\n\n\nMME ora deve configurare il tunnel per inoltro dei dati\n\ntunnel che passa dal dispositivo al P-GW (Packet Gateway) della home network, passando eventualmente dal S-GW (Serving Gateway) della visited network.\n\n\nQuando il dispositivo si sposta (es. cambia cella), viene eseguito l‚Äôhandover, cio√® il cambio del punto di connessione alla rete.\n\n\nConfigurazione degli elementi del piano di controllo LTE\nIl piano di controllo √® il ‚Äúcervello‚Äù della rete, responsabile dell‚Äôautenticazione, del tracciamento del dispositivo, e della configurazione dei percorsi dati.\n\nil dispositivo mobile comunica con la MME attraverso un canale del piano di controllo\n\nquel canale che consente di inviare segnali del piano di controllo\nquesto canale avviene attraverso la BS\n\n\nl‚ÄôMME sfrutta IMSI per capire la rete domestica del dispositivo, MME contatta HSS per informare la home network dove si trova il dispositivo e per scoprire le informazioni crittografiche che ha solo HSS\nLa BS e il dispositivo mobile si metteranno d‚Äôaccordo per definire i parametri radio tra i due\n\ndefinisci frequenze ecc‚Ä¶\n\n\n\n\nConfigurazione dei tunnel del piano dati per un cellulare\nPrima abbiamo visto quelli del piano di controllo ora per i veri e propri dati\n\nAbbiamo un tunnel di comunicazione tra la stazione base e la S-GW\n\nLa S-GW invia informazioni all‚Äôindirizzo IP della stazione base\n\n\nun altro da S-GW a P-GW\n\nquesto tunnel serve per instradare i dati dalla rete dove siamo alla Home network anche se ci troviamo in una rete ospite\n\ntutti i nostri dati andranno sempre nella nostra Home network anche se ci troviamo in Giappone\nmeccanismo di instradamento indiretto\n\n\n\n\nincapsulamento attraverso GTP GPRS Tunneling Protocol\n\nma come facciamo a capire poi a quale device va inviato?\n\nGTP incapsula i pacchetti del dispositivo dentro un altro pacchetto\n\nal suo interno avremo il vero e proprio UDP che dentro avr√† a sua volta IP\nGTP ci permette di indirizzare adeguatamente i dati al nostro dispositivo mobile sempre in movimento\n\n\n\n\n\n\n\n\nprocesso di Handover tra BS nella stesa rete cellulare\ncosa succede quando un dispositivo si sposta da una cella all‚Äôaltra senza cambiare rete\nil processo di Handover serve proprio a gestire casi come questi\n\nil dispositivo si sposta ma rimane connesso alla rete\n\nFase prima dell‚Äôhandover\n\nRichiesta di Handover e completamento dal dispositivo\n\n\n\n\nLa source BS si accorge che il segnale dal dispositivo sta degradando questo perch√©:\n\n\nLe BS hanno varie statistiche come\n\nquante celle hanno libere\nil dispositivo con cui comunicano quanto va veloce ecc\n\n\n\n\n\n\nContatta la target BS inviando un messaggio di ‚ÄúRichiesta di handover‚Äù.\n\n\nla target BS si prepara ad accogliere un dispositivo in pi√π tenendo\n\nuna frequenza libera\nuna cella libera\n\n\ninvia poi un ACK alla BS source con le info necessarie per il collegamento.\n\n\n\n\nLa source BS informa adesso il dispositivo del nuovo BS target\n\n\nA questo punto, dal punto di vista del dispositivo, l‚Äôhandover √® gi√† avvenuto: comincia a inviare e ricevere dati dalla nuova target BS.\n\n\n\nSe la vedono i BS\n\n\n\nora la source BS inoltra tutti i pacchetti che ancora gli arrivavano alla target BS\n\n\nper non interrompere la connessione\n\n\n5)target BS informa l‚ÄôMME che √® la nuova BS\n\nL‚ÄôMME aggiorna la S-GW, ordinando di cambiare il punto finale del tunnel verso la nuova BS\n\n\n\n\nLa target BS invia un ACK finale alla source BS cos√¨ che possa chiudere il canale radio e liberare la banda.\nTutti i nuovi pacchetti ora fluiscono direttamente dal P-GW ‚Üí S-GW ‚Üí target BS ‚Üí dispositivo, senza passare dalla BS precedente.\n\n\n\n\n7)Tutti i nuovi pacchetti ora fluiscono direttamente dal P-GW ‚Üí S-GW ‚Üí target BS ‚Üí dispositivo, senza passare dalla BS precedente.\n\n\nesse potrebbero fare un operazione di handover per staccare quel dispositivo per farne cercare uno migliore\nIl dispositivo adesso si connetter√† a una nuova BS target\n\nora i dati della S-GW verranno inviati alla nuova BS-target\n\nattraverso‚Ä¶\n\n\n\nMobile-IP\n√à un tipo di architettura che serve per mantenere la mobilit√† nei dispositivi e quindi funzionare sempre\n\nagli inizi non si usava\npresentava delle caratteristiche:\n\n\nil traffico IP viene sempre instradato nella Home Network come nelle reti indirette\n\n\n\n\nHome agent √® un nodo nella home network che funge da punto di riferimento per il device\n\n\n\n\nForeign agent invece √® un nodo nella rete visitata, gestisce la rete quando il dispositivo √® fuori casa\nI protocolli di Mobile IP usavano estensioni ICMP (simili a ‚Äúping‚Äù) per:\n\n\nRilevare la presenza di home/foreign agent,\nRegistrare la posizione del dispositivo nella home network.\n\nWireless e mobilit√†, che impatto hanno su protocolli a livelli superiori?\nSi riflette su protocolli di livelli superiori come TCP e UDP che sono protocolli fissi\n\ncome funzionano con la mobilit√†?\n\nLivello logico\nal livello logico non cambia nulla perch√© sono sempre ‚Äúbest effort‚Äù\ni protocolli si possono ancora usare perch√© si usano le Base Station e i vari nodi che lavorano su una rete fisica, √® solo alla fine che viene usata una rete wireless\nLivello prestazionale\nqui peggiora tutto:\n\nil fatto che sia wireless aumenta drasticamente i ritardi ecc‚Ä¶ soprattutto con gli handover dove si possono perdere molti pacchetti\n\nci√≤ comporta scarti e ritrasmissioni\n\n\nIl protocollo TCP interpreta ogni perdita come segnale di congestione, quindi riduce la velocit√† di invio\n\nquindi si peggiora la velocit√† di volta in volta\n\n\nessendo il traffico condiviso possono esserci problemi\n\npi√π utenti = meno banda per ciascuno\n\n\n\nSoluzioni:\n\nal livello 2 si cercano di implementare ritrasmissioni affidabili cos√¨ da far fare ritrasmissioni al protocollo TCP solo se strettamente necessario\nSe il mittente sa che √® su un collegamento wireless, pu√≤ gestire meglio le perdite (es. distinguere errori da congestione).\nDividere la connessione TCP in due parti:\n\nUna tra client e access point.\nL‚Äôaltra tra access point e destinazione finale.\nQuesto isola la parte wireless dal TCP end-to-end.\n\n\n"},"UNI/ANNO-2/RETI/RETI-LEZ.3":{"slug":"UNI/ANNO-2/RETI/RETI-LEZ.3","filePath":"UNI/ANNO 2/RETI/RETI LEZ.3.md","title":"RETI LEZ.3","links":[],"tags":[],"content":"Internet e la sua sicurezza\ninternet di base √® nato senza includere la sua sicurezza\nAnalisi dei pacchetti\n\nuna interfaccia di rete legge e registra tutti i pacchetti che l‚Äôattraversa\n\n\nidentit√† falsa\n\nattraverso un IP spoofer che inietta pacchetti con indirizzi ip falsi\n\n\nNegazione del servizio\n\nattraverso attacchi Dos(Denial of Service)\n\nrendono una rete, un host o altri elementi di infrastruttura non disponibili per gli utenti\nsi dividono in 3 categorie\n\n\n\ninvio di pochi pacchetti ma che sono costruiti per far bloccare il servizio attraverso vulnerabilit√†\n\n\n\n\nbandwidth flooding invio in massa di pacchetti che impediscono il traffico legittimo\n\n\navviene in una situazione in cui il client invia un numero di bit al secondo maggiore di quelli che pu√≤ ricevere il server\n\n\n\n\nconnection flooding connessioni in massa TCP al servizio impedendogli di accettare le connessioni da parte di utenti legittimi\nfoto del bandwidth flooding\n\nfoto del connection flooding\n\n\n\n\n\n\n\n\nLinee di difesa\n\nautenticazione: attraverso identit√† hardware ad esempio una carta SIM\nriservatezza: attraverso la cifratura\nintegrit√†: le firme digitali prevengono/rilevano le manomissioni\nrestrizioni di accesso:VPN con protezione da password\nfirewalls: middlebox che fa da intermediario e che\n\n‚Äúoff-by-default‚Äù filtra i pacchetti in entrata e limita i mittenti i destinatari e le applicazioni\nrilevare/reagire agli attacchi DOS\n\n\n\nLivelli di protocollo e modelli di riferimento\nLe reti sono complesse e composte da diverse componenti, per gestirle e collegarle al meglio si decise di dividere l‚Äôorganizzazione della rete in pi√π strati e livelli\nUtilit√† della stratificazione\n\nla modulazione facilita la manutenzione e l‚Äôaggiornamento di un sistema\nuna struttura impostata in modo esplicito consente l‚Äôidentificazione dei vari componenti\n\nSvantaggi della stratificazione\n\nun livello sopra deve violare la separazione di questi livelli e deve scendere sotto per ottenere informazioni\nun livello superiore pu√≤ duplicare un livello inferiore\n\ncome la correzione di errori che √® presente in pi√π livelli\n\n\n\nPila di protocolli di internet\n\nServizi, Stratificazione e Incapsulamento\n\nQuesta slide ci fa vedere come i livelli siano usati sia da sorgente che destinazione ovvero client e server\nad ogni livello abbiamo un aggiunta di quello che era il pacchetto nel livello precedente\npossiamo vedere la cosa come\nUn pacco postale:\n\nIl messaggio originale (M) √® l‚Äôoggetto che vuoi spedire.\nIl livello di trasporto aggiunge un‚Äôetichetta con il nome del destinatario.\nIl livello di rete aggiunge un indirizzo pi√π dettagliato (via, citt√†, codice postale).\nIl livello di collegamento impacchetta tutto in una busta.\nIl livello fisico lo trasporta tramite camion o aereo.\nQui ogni livello lo invia al sottostante aggiungendo un header ovvero informazioni aggiuntive che servono per la comunicazione del pacchetto\nil datagramma √® il nome del tipo di dato che si trova nel livello di rete, in tutti gli altri livelli si chiama in un altro modo\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLivello OSINome dell‚Äôunit√† di datiDescrizioneApplicazione (7)MessaggioDati generati da un‚Äôapplicazione (es. una richiesta HTTP, un‚Äôemail, un file inviato su FTP).Trasporto (4)Segmento (TCP) / Datagramma (UDP)TCP divide i dati in segmenti per garantire la consegna affidabile. UDP usa datagrammi, che sono pi√π veloci ma non garantiscono la ricezione.Rete (3)Datagramma IPUnit√† di dati del protocollo IP, che trasporta i segmenti da un host all‚Äôaltro nella rete.Collegamento (2)FrameIl datagramma IP viene incapsulato in un frame Ethernet o Wi-Fi per essere trasmesso tra dispositivi direttamente connessi.Fisico (1)BitIl frame viene trasformato in segnali elettrici, onde radio o impulsi ottici per viaggiare nel mezzo fisico.\nI servizi\nOgni livello ha i suoi servizi che fornisce al livello superiore in modo indipendente ogni livello di solito ha pi√π protocolli per fornire diversi sistemi come TCP o UDP per quello di trasporto\nDa qui prendiamo il concetto di matrioska (incapsulamento)\n\n\nsi pu√≤ tutto vedere come una matrioska e i vari livelli che aggiungono informazioni al pacchetto finale\nVisione end-to-end incapsulamento (senza intermediari)\n\nn-PDU cosa √® e come vengono implementati i livelli\npossiamo da questa immagine notare come il livello di rete faccia da intermediario tra hardware e software\n\nl‚Äôunit√† di dati definita prima prende il nome generico in PDU(Protocol Data Unit)\nogni PDU ha come nome quello che era presente nella tabella precedente ed √® composto da\n\ninformazioni di controllo sono dati aggiuntivi (metadati) che aiutano il protocollo a gestire la comunicazione.\npayload il contenuto effettivo\n\nmodello TCP/IP vs ISO/OSI\n\npossiamo vedere come esista il modello ISO/OSI che presenta 2 livelli in pi√π\n\npresentazione\n\naggiunge l‚Äôinterpretazione di un determinato dato prima che venga dato ai livelli sottostanti(discorsi di crittografia dei dati ecc‚Ä¶)\n\n\nsessione\n\nserve per sincronizzazione\ninternet non prevede questi strati vanno messi nelle applicazioni\n\n\n\nparentesi su Wireshark\n\nWireshark lavora al livello applicativo analizzando i vari pacchetti che arrivano in rete attraverso il packet capture del computer"},"UNI/ANNO-2/RETI/RETI-LEZ.4":{"slug":"UNI/ANNO-2/RETI/RETI-LEZ.4","filePath":"UNI/ANNO 2/RETI/RETI LEZ.4.md","title":"RETI LEZ.4","links":[],"tags":[],"content":"Livello di applicazione\nNel livello applicativo ci sono le applicazioni di rete\nad esempio\n\nposta elettronica\ntrasferimento file\nsocial media\nstreaming di video-clip memorizzati\nVoIP\nI dispositivi che eseguono le applicazioni di rete non sono quelle nel nucleo bens√¨ quelle che confinano al nucleo\n\n\nCome architettare le nostre applicazioni di rete\nabbiamo due approcci principali\nclient-server\nabbiamo due attori principali\n\n\nserver\n\nmacchina che deve essere sempre attiva per soddisfare le richieste dei client\nindirizzo IP ben noto\nse necessario deve essere potente per soddisfare enormi richieste\n\n\nclient\n\ncontattano il server\npossono funzionare in modo intermittente\npossono cambiare indirizzi IP perch√© il server non deve per forza conoscere il client\nin questa struttura i client non comunicano tra di loro ma solo con il server\n\n\n\nesempio di app client-server: servizio di posta elettronica che vedremo meglio dopo\n\noppure abbiamo host client o host server (√® la stessa cosa ma dicendo host intendi il dispositivo vero e proprio)\ndire solo client-server si riferisce pi√π all‚Äôarchitettura\n\npeer-to-peer\nNon c‚Äô√® un server sempre attivo e non ci deve essere una infrastruttura complessa e costosa\n√à definito dai peer pari che comunicano direttamente tra di loro\nHa una scalabilit√† intrinseca:\n\naggiungere un peer aumenta carico perch√© chiedo dei chunk ma aumento anche le disponibilit√† quindi si deve avere un certo equilibrio\ni peer sono degli host che possono apparire o sparire e quindi non devono avere per forza stesso indirizzo IP\nchunk: singolo pezzetto di un file\n\n\nProcessi comunicanti\nCome comunicano i processi\nNel contesto delle reti un processo √® un programma in esecuzione su un host\ni processi possono comunicare:\nNello stesso host\nComunicano con un sistema interconnesso dettato dal sistema operativo\nSu host differenti\nComunicano attraverso messaggi\nPrecisazione su Client Server\nServer: fornisce il servizio\nClient: colui che lo richiede\nUn server non deve per forza avere un solo ruolo ma pu√≤ averli entrambi basta che siano su due nodi differenti della rete\nad esempio P2P\nSocket\nSocket √® una interfaccia software che permette a un processo di inviare e ricevere messaggi\n\nfunziona come una porta comunicante per cui il mittente pu√≤ inviare il messaggio e avere una struttura dati che finir√† nelle mani del destinatario\nI livelli fino a quello di trasporto sono gestiti dal SO\ni livelli di applicazione sono controllati dallo sviluppatore dell‚Äôapplicazione\n\n\nIndirizzamento\nSe vogliamo mandare un messaggio a un processo dobbiamo poterlo identificare \n\nUn host ha il uso Indirizzo IP univoco a 32 o 128 in base al ipv4-6\nSe vogliamo inviare a un processo un messaggio dobbiamo identificare l‚Äôhost e poi l‚Äôapplicazione\nUna volta identificato l‚Äôhost attraverso l‚Äôindirizzo IP con quale processo parlo? esso √® dato dal numero di porta che identifica una determinata socket su cui si appoggia il processo\nil numero √® a piacere soprattutto se sopra 1024\nalcuni sono registrati da IANA che registra delle porte standard\n\nad esempio ha registrato\n\nporta HTTP:80\nporta di posta elettronica:25\nesempio di invio di un messaggio a un server utilizzando\n\n\n\n\nindirizzo IP: 128.119.245.12\nnumero di porta: 80\nIl DNS aiuta per l‚Äôindirizzo IP invece per il numero di porta bisogna segnarne uno noto senn√≤ non si trova\n\nProtocollo\nDefinizione di protocollo nel livello applicativo\ncosa definisce:\n\nil tipo di messaggi\n\ntipo se √® un messaggio di richiesta di risposta\n\n\nla sintassi del messaggio\n\ncampi del messaggio\n\n\nsemantica dei messaggi\n\ncosa significano le informazioni nei campi\n\n\nregole\n\nregole generali di invio e ricezione dei messaggi\n\n\n\nCi sono due tipi di protocolli\n\ndi pubblico dominio\n\nspecifica nota\nscritte in documenti come RFC definiti dalla IETF(un ente)\ntipo HTTP o SMTP\ngarantiscono interoperabilit√†\n\nquando due dispositivi sviluppati da aziende diverse possono funzionare assieme\n\n\n\n\nproprietari\n\nskype e zoom\nspecifiche non note\n\n\n\nQuale servizio di trasporto usare in base a un‚Äôapplicazione\n\ncosa √® una perdita di dati\n\ndata da coda o congestione\nErrori di trasmissione\nrecuperi con algoritmi dei dati\nalcune applicazioni pretendono il 100% dei dati\naltre possono tollerare ad esempio app che gestiscono contenuti multimediali come audio/video\n\n\nsensibilit√† al fattore tempo\n\napplicazioni interattive ne risentono\n\n\ntroughput\n\nLe applicazioni multimediali necessitano di un troughput minimo\n\n\nsicurezza\n\nriservatezza, integrit√† dei dati, autenticazione\nTabella interessante sui vari requisiti\n\n\n\n\nServizi e protocolli forniti da internet\nServizio TCP\nServizio affidabile che consente il trasferimento e il controllo del flusso di dati da una parte a un‚Äôaltra\n\nconsente di bloccare momentaneamente il processo d‚Äôinvio quando la rete √® sovraccarica\n\nServizio UDP\nServizio senza particolari fronzoli\nmanda un messaggio a un processo ma non offre affidabilit√†\n\nha solo un piccolo controllo degli errori che li segnala e basta\nnon fornisce correzioni, si limita a rinviare l‚Äôinformazione\n(per la correzione vedremo ECC o Ritrasmissioni)\na fronte di minori garanzie offre maggiore velocita\n\n\nRendere sicuro TCP\nnessuno dei due √® sicuro ma per TCP venne ideato un protocollo di wrap al TCP che aggiunge un livello di sicurezza detto TLS\nLa libreria TLS cifra e decifra il messaggio facendo da ‚Äúintermediario‚Äù al TCP, controllando inoltre l‚Äôintegrit√† dei dati\naltrimenti sarebbe tutto in chiaro\nWeb e HTTP\nConcetto di hypertext: √® un sistema di organizzazione delle informazioni in cui i contenuti sono divisi in pagine collegate tra loro tramite link\nAccedo a oggetti(risorse) che sono gli elementi che compongono una pagina web come anche un file HTML o il CSS o gif\nognuno di questi oggetti e diviso da un URL\n\n\nil nome dell‚Äôhost non √® l‚Äôindirizzo IP ma viene convertito dal DNS in indirizzo IP il DNS non √® nel nucleo infatti il nucleo ha solo inoltro e instradamento\nil percorso dell‚Äôoggetto √® come un file system da remoto\n\nPanoramica su http\n√à alla base delle applicazioni web\n√à un protocollo basato sul paradigma client server\ndove un client richiede un oggetto al server che lo restituisce\nil client √® uno user agent il server √® un server agent\nil web √® indipendente dal dispositivo usato ad esempio basta che ho un browser con http\n\nCosa usa http\nusa TCP fino alla versione 2.0 per trasferire i dati sulla porta 80\nHTTP √® un protocollo stateless poich√© non mantiene memoria dettagliata delle interazioni precedenti\n\nnon ci conviene avere uno stato aumenta overhead\n\nüîπ Passaggi della comunicazione HTTP su TCP (porta 80)\n1Ô∏è‚É£ Il client inizializza la connessione TCP\n\nIl client (ad esempio un browser web) crea una socket e tenta di aprire una connessione TCP con il server sulla porta 80 (che √® la porta standard per HTTP).\nQuesto avviene tramite il 3-way handshake di TCP.\n\n2Ô∏è‚É£ Il server accetta la connessione TCP\n\nIl server web (es. Apache, Nginx) riceve la richiesta di connessione e la accetta.\nLa connessione TCP √® ora stabilita e pronta per lo scambio di dati.\n\n3Ô∏è‚É£ Scambio di messaggi HTTP\n\nIl client (browser) invia una richiesta HTTP al server\nIl server web risponde con il contenuto richiesto\n\n4Ô∏è‚É£ Chiusura della connessione TCP\n\nUna volta terminato lo scambio dei dati, la connessione TCP viene chiusa.\nLa chiusura pu√≤ essere iniziata dal client o dal server tramite un 4-way handshake di TCP.\n\nTipi di HTTP\nconnessioni non persistenti\n\nsi aprivano diverse connessioni per ogni richiesta\nusato fino alla versione 1 di http\nconnessioni persistenti\nin http 2 le connessioni erano persistenti\nogni richiesta era veicolata tra client e server\nsenza disconnessione istantanea\npraticamente potevi scambiare pi√π oggetti\n\nesempio grafico di non persistenti\n\nRTT Definizione\nper calcolare il tempo di risposta bisogna introdurre il RTT\nindica quanto tempo impiega un piccolo pacchetto per andare dal client al server e ritornare al client\n\ntenendo conto di tutti i ritardi possibili\n\ntipo coda o congestione\nL‚Äôintervallo richiesta-risposta √® indicato da un singolo RTT\nil tempo di risposta √® dato da\n2RTT+tempo \\ di \\ trasmissione \\ del \\ file\nin questo caso abbiamo 2 RTT quindi abbiamo 2\n\n\n\n\nConnessioni persistenti\nLe connessioni persistenti rispetto alle connessioni non persistenti\nci consentono di pagare 1 RTT per tutti gli oggetti richiesti quando invece prima ne servivano 2 per oggetto\nPresentano una notevole riduzione di overhead e facilitazione sul controllo delle connessioni(ne controllo meno)\nMessaggi HTTP\nIl protocollo HTTP funziona con messaggi di richiesta e risposta\nun messaggio √® formato da ASCII\nMessaggio di richiesta\nesempio di richiesta http\nUn tipico messaggio di richiesta HTTP appare cos√¨:\nGET /index.html HTTP/1.1\\r\\n\nHost: www.example.com\\r\\n\nUser-Agent: Mozilla/5.0\\r\\n\nAccept: text/html\\r\\n\nAccept-Language: en-us,en;q=0.5\\r\\n\nConnection: keep-alive\\r\\n\n\\r\\n\n \n\nGET /index.html HTTP/1.1 ‚Üí Indica il metodo HTTP, il file richiesto (/index.html) e la versione del protocollo (HTTP/1.1).\nHost: www.example.com ‚Üí Specifica il server a cui inviare la richiesta.\nUser-Agent: Mozilla/5.0 ‚Üí Specifica il browser e il sistema operativo del client.\nAccept: text/html ‚Üí Indica i tipi di contenuto che il client pu√≤ ricevere.\nAccept-Language: en-us ‚Üí Indica la lingua preferita e la formattazione\nConnection: keep-alive ‚Üí Chiede di mantenere la connessione aperta.\n/r sposta all‚Äôinizio delle colonne del testo e invece /n va a capo\n\nStruttura generale di una richiesta HTTP\nprincipalmente la struttura generale √® divisa in 3 punti\n\n1Ô∏è‚É£ Riga di richiesta (Request Line)\n\nContiene il metodo HTTP, l‚Äô URL richiesto e la versione HTTP.\n2Ô∏è‚É£ Intestazioni (Header Lines)\nContengono informazioni sul client e sulle preferenze della richiesta.\n3Ô∏è‚É£ Corpo del messaggio (Entity Body)\nPresente solo in alcuni metodi HTTP, come POST e PUT.\nContiene dati inviati al server (ad esempio, un form compilato dall‚Äôutente).\n\nPiccola parentesi su altri messaggi di richiesta HTTP\nüîπ Metodo POST\n‚úÖ Utilizzato per inviare dati al server.\n‚úÖ L‚Äôinput dell‚Äôutente viene inviato nel corpo della richiesta HTTP (non nell‚ÄôURL).\n‚úÖ Spesso usato nei form di login, registrazione o invio di dati sensibili.\n\nüîπ Metodo GET\n‚úÖ Utilizzato per richiedere risorse dal server (es. pagine web).\n‚úÖ I dati inviati al server sono inclusi nell‚ÄôURL, dopo un ?.\n‚úÖ Non sicuro per dati sensibili (es. password), perch√© i parametri sono visibili nell‚ÄôURL.\n\nüîπ Metodo HEAD\n‚úÖ Funziona come GET, ma richiede solo le intestazioni della risposta, senza il corpo.\n‚úÖ Utile per verificare se una risorsa esiste o controllare le metainformazioni (es. dimensione di un file).\nl‚Äôintestazione sono tutti quei dati aggiuntivi al di fuori del corpo del messaggio\nad esempio\nHTTP/1.1 200 OK\nDate: Tue, 19 Mar 2024 14:00:00 GMT\nServer: Apache/2.4.41 (Ubuntu)\nContent-Type: text/html; charset=UTF-8\nContent-Length: 5123\n‚Üë\nqueste sono le intestazioni\n \nquesto √® il body\n‚Üì\n&lt;html&gt;\n&lt;body&gt;\n&lt;h1&gt;Benvenuto!&lt;/h1&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n\nüîπ Metodo PUT\n‚úÖ Utilizzato per caricare o aggiornare un file sul server.\n‚úÖ Se il file esiste gi√†, viene sostituito completamente.\n\nMessaggio di risposta\n√® il messaggio di risposta che invia il server al client dopo che ha effettuato una richiesta\nAd esempio\nHTTP/1.1 200 OK ‚Üê RIGA DI STATO\n \nDate: Tue, 19 Mar 2024 14:00:00 GMT\nServer: Apache/2.4.41 (Ubuntu)\nLast-Modified: Mon, 18 Mar 2024 10:00:00 GMT\nContent-Length: 5123\nContent-Type: text/html; charset=UTF-8\n‚Üë\nTUTTO QUESTO √à LA RIGA DI INTESTAZIONE\n \nBODY IL CORPO DELLA RISPOSTA\n‚Üì\n&lt;html&gt;\n&lt;body&gt;\n&lt;h1&gt;Benvenuto!&lt;/h1&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n \n1Ô∏è‚É£ Riga di stato (Status Line)\n\nContiene la versione del protocollo, il codice di stato e una breve descrizione.\n2Ô∏è‚É£ Intestazioni della risposta (Header Lines)\nForniscono informazioni aggiuntive sulla risposta, come il tipo di contenuto, la dimensione, la data ecc‚Ä¶\n3Ô∏è‚É£ Corpo della risposta (Body)\nContiene il contenuto effettivo della risposta (es. codice HTML di una pagina web, un‚Äôimmagine, un file JSON, ecc.).\n\nTipologie di codici di stato\nPer ogni errore esiste un codice che appartiene a un insieme ben definito dalla cifra delle centinaia\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCodiceDescrizione1xx (Informational)Messaggi informativi, raramente usati.2xx (Success)La richiesta √® andata a buon fine.3xx (Redirect)Il client deve fare un‚Äôaltra richiesta perch√© la risorsa si √® spostata.4xx (Client Error)La richiesta contiene un errore (es. risorsa non trovata, richiesta non valida).5xx (Server Error)Errore lato server, il server non ha potuto soddisfare la richiesta.\nüîπEsempi di codici di stato HTTP pi√π comuni\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCodiceSignificatoDescrizione200 OK‚úÖ SuccessoLa richiesta √® stata completata con successo.301 Moved PermanentlyüîÄ ReindirizzamentoLa risorsa √® stata spostata in modo permanente. Il client deve aggiornare l‚ÄôURL.400 Bad Request‚ùå Errore ClientLa richiesta non √® valida (es. sintassi errata).404 Not Foundüö´ Non trovatoLa risorsa richiesta non esiste sul server.406 Not Acceptable‚ùå Contenuto non accettabileIl server non pu√≤ fornire il contenuto nel formato richiesto dal client.500 Internal Server Error‚ö†Ô∏è Errore ServerIl server ha riscontrato un errore interno.505 HTTP Version Not Supported‚ùå Versione HTTP non supportataIl server non supporta la versione HTTP usata dal client.\nUsare http per effettuare una richiesta con netcat (poi lo faremo)"},"UNI/ANNO-2/RETI/RETI-LEZ.5":{"slug":"UNI/ANNO-2/RETI/RETI-LEZ.5","filePath":"UNI/ANNO 2/RETI/RETI LEZ.5.md","title":"RETI LEZ.5","links":[],"tags":[],"content":"I cookie mantenere stato utente/server\nL‚Äôinterazione HTTP GET/risposta era senza stato\nci√≤ comporta a dei non problemi\n\na nessuno importa di tenere traccia dello stato durante lo scambio\ntutte le richieste sono indipendenti quindi non serve\nse si generano errori si rif√† la richiesta\n\n\n\n\n                  \n                  che succede se la connessione di rete o il client si blocca al tempo t&#039;? \n                  \n                \n\nverr√† modificato solo fino a x‚Äù creando delle problematiche di lock della variabile\n\n\nUtilizzo dei cookie\nI siti web e i browser client usano i cookie per mantenere lo stato delle varie transazioni\nogni cookie rappresenta un identificativo per il client dell‚Äôutente ad esempio\nPer gestire i cookie servono 4 componenti\n1Ô∏è‚É£ Riga di intestazione nella risposta HTTP\n\nQuando un utente visita un sito per la prima volta, il server invia un‚Äôintestazione HTTP che imposta un cookie sul browser dell‚Äôutente.\n2Ô∏è‚É£ Riga di intestazione nella richiesta HTTP\nNelle richieste successive, il browser include il cookie nell‚Äôheader HTTP per identificare l‚Äôutente.\n3Ô∏è‚É£ File cookie sul sistema dell‚Äôutente\nIl browser salva il cookie localmente nel computer dell‚Äôutente, permettendo di usarlo per richieste future.\n4Ô∏è‚É£ Database sul sito\nIl server memorizza le informazioni relative a ciascun sessionID in un database\n\nEsempio grafico su come funziona il sistema dei cookie\n\ni cookie vengono usati per\n\nautorizzazioni\ncarrelli degli acquisti\nraccomandazioni per pubblicit√†\n\nDi default il protocollo HTTP √® stateless come fanno client e server a mantenere salvati gli stati?\nci sono due metodi:\n1Ô∏è‚É£ Presso gli endpoint del protocollo\n\nIl trasmettitore e il ricevitore (client e server) devono conservare lo stato tra pi√π transazioni.\nAd esempio, un sito di e-commerce salva nel database gli articoli del carrello dell‚Äôutente.\n2Ô∏è‚É£ Nei messaggi HTTP (usando i cookie)\nI cookie vengono trasmessi con ogni richiesta HTTP, permettendo al server di riconoscere l‚Äôutente.\nEs. Un cookie di sessione pu√≤ contenere un session ID, che il server usa per associare la richiesta all‚Äôutente corretto.\n\nSIMPATICA GIF DI UN ESEMPIO :)\n\nGDPR\nSerie di regole europee per garantire la privacy riservatezza dei dati ecc‚Ä¶\nWeb cache\n√à un intermediario tra il server d‚Äôorigine e i client per soddisfare le richieste senza coinvolgerlo\nIl browser ha una sua web cache locale che se ha gi√† salvato la richiesta HTTP la rimanda direttamente altrimenti comunica con il server\n\nWeb cache di tipo proxy\nIl proxy funziona come da client perch√© fa delle richieste al server d‚Äôorigine e le salva\npoi quando un client comunica con il proxy esso funge da server\nVantaggi\nriduzione del traffico tempi di risposta pi√π rapidi e evita la queue\nEsempi di miglioramento di una infrastruttura di rete\n\nNel primo esempio abbiamo una velocit√† di trasferimento troppo lenta e una infrastruttura che presenta delle problematiche che causano un enorme ritardo\nOpzione 1\nmiglioro la velocit√† di collegamento riducendo cos√¨ il ritardo\n\nproblema: costa troppo\n\nOpzione 2\nmetto una cache locale per ridurre il ritardo\n\nfunziona evviva che bello\n\nGet condizionale\nNon fare la get(inviare) se nei metadati c‚Äô√® la stessa data di modifica\n\nHTTP 1.1\nViene introdotta la GET multipla in pipeline su una singola connessione TCP\n\n\n                  \n                  problemi \n                  \n                \n\n\nusa First Come First Served che causa problematiche\n\nse ho un blocco piccolo dopo blocchi grandi esso verr√† inviato molto dopo (HOL)\nrecupero delle perdite di informazioni blocca tutto\n\n\n\n\n\nHTTP/2\nPer risolvere i problemi di prima viene usato un sistema a priorit√†\n\ninvio push al client di oggetti aggiuntivi senza richieste per avvantaggiare il tutto\nDividere gli oggetti in frame cos√¨ da ridurre HOL\nriduce overhead\nfunziona meglio il controllo della congestione TCP\n\nEsempio di mitigazione con HTTP/2\nEsempio di richiesta da un client di 1 oggetto grande e 3 pi√π piccoli\nessi vengono divisi in frame per fare una trasmissione interlacciata ovvero trasmessi alternando i vari oggetti\n\nperch√© passare da HTTP/2 a HTTP/3\nHTTP/2 cerca di inviare su una singola connessione TCP\n\nci√≤ causa problemi per eventuali recuperi delle informazioni che bloccano tutta la trasmissione degli oggetti\nnon c‚Äô√® grande sicurezza su una TCP semplice\n\nHTTP/3 viene in nostro aiuto\nmigliora\n\nsicurezza\nerrori\nutilizza direttamente UDP come protocollo di trasporto, migliorandolo con il protocollo QUIC per gestire\n\nsicurezza\ncontrollo di errore\ncongestione\n\n\n"},"UNI/ANNO-2/RETI/RETI-LEZ.6":{"slug":"UNI/ANNO-2/RETI/RETI-LEZ.6","filePath":"UNI/ANNO 2/RETI/RETI LEZ.6.md","title":"RETI LEZ.6","links":["mailto:paolo@sbors.it","mailto:pippo@azienda.it","mailto:franco@azienda.it"],"tags":[],"content":"Posta elettronica\nCi sono tre componenti principali\n\nuser agent\n\nil programma che consente di comporre email leggerle ecc‚Ä¶ tipo outlook\n\n\nmail server\n\nserver di posta che gestisce la casella di posta dell‚Äôutente\nil server di posta prende i messaggi nella coda di uscita e prova a mandarli al server di posta del destinatario\nsotto ho fatto un esempio\n\n\nsimple mail transfer protocol: SMTP\n\nprotocollo che consente il trasferimento di messaggi tra server di posta\n\n\n\n\nEsempio di posta elettronica\n\nio paolo@sbors.it invio al mio server di posta sbors.it la mail con SMTP\nsuccessivamente il server di posta usa SMTP per inviare la lettera al server di posta del destinatario che lo ricever√† con SMTP\nma come fa il tizio ad accedere alla sua casella di posta?\n\ncon il protocollo IMAP che spieghiamo tra poco\n\n\n\nA che serve avere un server? non basta inviare alla persona e basta?\nServe un server perch√© e bene avere un servizio esterno che gestisce le cose mettiamo che Samuele ha il pc spento poi pu√≤ prelevare le cose dal server\nSMTP RFC (5321)\n\nRFC indica i documenti definiti dagli enti in modo universale che abbiamo citato alla scorsa lezione\nQuesto protocollo serve per instradare i pacchetti con un sistema client-server\ni pacchetti sono messaggi di posta elettronica\nQuesto protocollo si serve del protocollo TCP per trasmettere i pacchetti\nPer fare il trasferimento ci sono 3 step:\nhandshaking TCP per stabilire la connessione\nhandshaking smtp per presentare le due parti client server con i vari codici di stato\nil trasferimento dei messaggi veri e propri\npoi la chiusura\n\n\nEsempio stupido con Alice e Bob\n\nEsempio dettagliato\nserver di posta crepes.fr invia al server di posta hamburger.edu possiamo vedere tutti gli step\n\nspiegazione\nQui possiamo vedere come il . venga usato per indicare la fine del messaggio\nMAIL FROM E RCPT vengono usate per indicare il mittente e il destinatario\nDATA avverte che stanno per arrivare i dati\nSMTP VS HTTP\nsmtp: √® di tipo client push(invia i dati senza che essi vengano richiesti)\nhttp: √® di tipo client pull(il client richiede esplicitamente dei dati)\n\nentrambi hanno una interazione comando/risposta in ascii e usano codici di stato\nhttp: ciascun oggetto √® incapsulato nel suo messaggio di risposta\nsmtp: pi√π oggetti vengono trasmessi in un unico messaggio\nsmtp usa connessioni persistenti e durature fino al quit a differenza di http\n\nper indicare la terminazione del messaggio:\n\n\nhttp: usa CRLF (\\r\\n) per separare le righe degli header e una riga vuota CRLF (\\r\\n\\r\\n) per segnalare la fine degli header e l‚Äôinizio del corpo del messaggio.\n\n\nsmtp: usa CRLF (\\r\\n) per terminare ogni riga. La fine del messaggio √® indicata da \\r\\n.\\r\\n, cio√® una riga con solo un punto (.) dopo un CRLF\n\n\nFormato dei messaggi di posta elettronica\n\nACCEDERE ALLA MAIL DI POSTA CON IMAP\n\nprotocollo che permette di scaricare i messaggi sul server di posta elettronica\n\nconsente di recuperare cancellare e archiviare i messaggi memorizzati nel server\nIMAP sta per Internet Mail Access Protocol\n\nLa web mail funziona con http\naccedo tramite browser e basta come Gmail Hotmail ecc‚Ä¶\nutilizzano una interfaccia web\nDNS\nGli host su internet sono definiti da indirizzi IP da 32 o 128 bit\nanche gli host hanno diversi identificatori non solo indirizzi IP, quest‚Äôultimi sono difficili da digitare\nSoluzione vecchia e pasticciona cogliona\nun tempo si usava un file con indirizzi IP che corrispondevano a nomi\n\nil problema di questo file √® che deve crescere costantemente\nquesto file era registrato da NIC un ente che aveva il compito di tenere conto dei vari indirizzi IP\nSoluzione\nPer ovviare questo problema di host.txt venne introdotto il DNS\nche sta per Domain Name System\nun database distribuito(ma anche il protocollo che consente la comunicazione con essi) che ha una applicazione che traduce il nome in un indirizzo IP\nil DNS √® nella periferia della rete e funziona nel livello applicativo\nesso ha un modello di servizi:\n\ntraduce da host name a indirizzo IP\nfa l‚Äôhost aliasing dove si pu√≤ avere un nome friendly alias tipo se cerchi google.it va su google.com\nmail server aliasing permette a pi√π indirizzi email diversi di confluire sulla stessa casella tipo pippo@azienda.it franco@azienda.it\nload distribution distribuzione del carico di rete, supponiamo di avere netflix.com esso corrisponde a un indirizzo IP di una macchina, il DNS pu√≤ sapere che esso √® associato a piu host con indirizzi IP, quindi pu√≤ darne piu di uno a ruota per evitare sovraccarichi\n\n\n\n                  \n                  perch√© non centralizzare il DNS \n                  \n                \n\n\nci sarebbe solo un punto vulnerabile\nmaggiore volume di traffico\nmanutenzione difficile\ninfatti il DNS e DISTRIBUITO\ndifferenza tra centralizzato e distribuito?\ncentralizzato: Tutto (dati, logica, risorse) si trova su un solo server o in un singolo nodo centrale.\ndistribuito: distribuito su pi√π server che collaborano tra loro\n\n\n\nquasi tutte le interazioni su internet passano per il DNS\nil DNS deve essere affidabile e sicuro\nGerarchia nel dettaglio  del DNS\n\nC‚Äô√® una divisione dei livelli dei server del DNS\n\nla root dove ci sono i server che indirizzano ai server DNS pi√π specifici\nTLP dove abbiamo i domini pi√π usati e sono infatti strettamente collegati alla radice\npoi ci sono gli autoritativi tipo uniroma2.it\n\ni server autoritativi sono quelli che sanno l‚Äôindirizzo IP effettivo\n\n\n\n\n\n                  \n                  Ricordiamo il DNS √® distribuito gerarchico e decentralizzato \n                  \n                \n\nEsempio con amazon.com\n\nIl client interroga un root server DNS\nIl client interroga un TLD server per .com\nIl client interroga il server autorevole per amazon.com\n\nDNS locale\nA questa gerarchia bisogna aggiungere un DNS server locale\nun server terzo a cui noi chiediamo la conversione dell‚Äôindirizzo e la fa per nostro conto se non √® presente nella sua cache\nOgni DNS locale √® in ogni ISP(Internet Service Provider)\n\nnon appartiene alla gerarchia dei DNS\n\nInterrogazione DNS come funziona?\nci sono di due tipi\ndi tipo iterativo\n\n\nil DNS server locale deve interrogare tutti i vari server se non ha nella cache l‚Äôip convertito\n\ndi tipo ricorsivo\n\n\nin questo caso si ‚Äúrisolvono‚Äù tra di loro\n\nCaching del DNS\nAnche il DNS ha una cache che ha un time to live delle conversioni\n\nquesta cache tiene conto della mappatura basandosi sulla determinata query e restituisce il risultato\nil DNS √® un servizio best effort che non assicura sempre una conversione corretta\n\nCome √® fatto un record DNS\nil database usa un formato RR(risorse record) con\n(name, value, type, ttl)\ndove rispettivamente abbiamo:\n\nname: Il dominio o sottodominio a cui il record si riferisce\nvalue: L‚Äôinformazione associata (es. IP, altro hostname, mail server)\ntype: Il tipo di record DNS\nTTL: Il tempo di vita della cache DNS prima di una nuova risoluzione\n\nCi sono diversi tipi di Record in ogni DNS (autoritativi?)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTipo di RecordDescrizioneEsempio a paroleAMappa un hostname a un indirizzo IPv4Il dominio ‚Äòwww.esempio.com‚Äô punta all‚ÄôIP 192.168.1.1NSSpecifica il name server responsabile per un dominioIl dominio ‚Äòesempio.com‚Äô √® gestito dal name server ‚Äòns1.esempio.com‚ÄôCNAMEDefinisce un alias per un altro hostnameIl dominio ‚Äòblog.esempio.com‚Äô √® un alias di ‚Äòserver1.esempio.com‚ÄôMXSpecifica il mail server per il dominioIl dominio ‚Äòesempio.com‚Äô gestisce le email attraverso ‚Äòmail.esempio.com\nMessaggi DNS\n\nMettere un nostro sito nel sistema\n\nSicurezza nel DNS\n\nDeve essere sicuro da attacchi DDoS\nattacco di spoofing: dove io rintraccio una richiesta e fornisco l‚Äôinformazione fasulla avvelenando le cache\n\nper ovviare abbiamo DNSSEC , garantisce che le risposte DNS siano autentiche e non alterate da terze parti.\n\n\n"},"UNI/ANNO-2/RETI/RETI-LEZ.7":{"slug":"UNI/ANNO-2/RETI/RETI-LEZ.7","filePath":"UNI/ANNO 2/RETI/RETI LEZ.7.md","title":"RETI LEZ.7","links":["UNI/ANNO-2/RETI/RETI-LEZ.4"],"tags":[],"content":"Differenza tra URI URL e URN\nüîπ URI ‚Äî Uniform Resource Identifier\n\nli indica tutti\nüî∏ URL ‚Äî Uniform Resource Locator\ndice dove √® localizzata una risorsa\nüî∏ URN ‚Äî Uniform Resource Name\nindica il nome identificativo univoco della risorsa ma non dice dove sta\n\n\nArchitettura Peer-to-peer\narchitettura che si basa su pi√π dispositivi che fungono sia da client che da server\nper avere la definizione perfetta vai a vederti questo\nEsempio Distribuzione file client server P2P\nSe ho N peer quanto impiego a trasferire un file di dimensione F?\n\nClient-server vs P2P\nEsempio con Client-Server\n\nIl server: Deve inviare N copie in sequenza con\n\nun tempo per singola copia di F/u_s\ntempo per N copie N*F/u_s\nil client: Ogni utilizzatore del servizio deve scaricare una copia del file con:\nd_{min}= quantitativo di banda non fissa\ntenere ben presente un dato\n\nla banda minima di un determinato client segnata da F/d_{min}\nQuindi avremmo:\n\n\n\n\nEsempio con P2P\nTrasmissione via server: Esso deve inviare almeno una copia cos√¨ che entri in circolo tra i client con un tempo di\n\nF/u_s\nclient: ogni client deve scaricare la copia una volta con tempo\nF/d_{min}\ni client dopo aver scaricato: loro devono caricare NF bit\ncon una capacit√† di upload che √® u_s+\\sum u_i\n\n\nGrafico P2P VS Client-server\n\ntracker e torrent\npossiamo innanzitutto dire che i file sono divisi in(chunk) che vengono scambiati tra peer\n\nPer sapere la lista dei peer a me vicino utilizzo il tracker che tiene traccia di tutti i peer che partecipano al torrent\nPer torrent si indica il gruppo di peer che partecipano alla distribuzione di un file\n\nQuindi quando scarichi un file .torrent hai tutti i metadati che ti rimandano al tracker e sai la dimensione e il nome dei chunk e dei file\n\n\n\nEsempio nella prospettiva di un peer\n\nRichiesta e invio di chunk file(BitTorrent)\nCome avviene la richiesta dei chunk:\nc‚Äô√® innanzitutto da precisare che ogni peer di solito non ha la totalit√† dei chunk bens√¨ una parte\n\nAlice quando vuole fare una richiesta andr√† a chiedere ai peer vicini una lista dei chunk in loro possesso\nAlice andr√† a scaricare i pi√π rari per fare in modo che vadano in circolo prima e che essi siano pi√π accessibili a tutti\ninizialmente pu√≤ richiedere un blocco casuale perch√© cos√¨ lo condivide subito ma poi, quando ha quasi finito di scaricare il file pu√≤ adottare la strategia end game ovvero:\n\nchiede quegli ultimi chunk rimanenti a pi√π peer possibili cos√¨ da soddisfare la richiesta il prima possibile\n\n\n\nCome avviene l‚Äôinvio dei chunk(tit-for-tat):\n\nAlice invia i chunk ai quattro peer a lei vicini che le inviano i chunk con la velocit√† pi√π alta(sono detti unchoked)\n\nrivaluta i posti ogni 4 secondi per definire chi saranno quelli choked e chi unchoked\n\n\nOgni 30 secondi ne sceglie uno a caso tra i vicini e gli inizia a inviare i chunk\n\nesso √® detto optimistically unchoked\nesso pu√≤ rientrare nella top 4\n\n\n\n\nStreaming e Video CDN\nLo streaming video rappresenta circa l‚Äô80% del traffico Internet. I video in genere sono registrati e memorizzati su server a disposizione degli utenti su richiesta¬†on demand.\nCosa sono i video\ni video sono una sequenza di frame(immagini) visualizzate a tasso costante(fps)\nCosa sono le immagini\nsono un array di pixel dove ogni pixel √® rappresentato da bit\nCodifica\nEsistono codifiche per ridurre la ridondanza di informazioni all‚Äôinterno di immagini, ci√≤ ci consente di ridurre quindi la dimensione in bit\n\nad esempio se ho una schermata nera non mi conviene scrivere nero per ogni pixel ma scrivere che ogni pixel √® nero e poi decodificarlo\nEsiste la:\ncodifica spaziale: vale per la singola immagine\ntemporale: si applica tra pi√π immagini\n\n\nGestione del bitrate nei video¬†\nCBR¬†-¬†Constant Bit Rate¬†\n\nBitrate fisso, usa sempre la stessa quantit√† di dati per ogni secondo di video.¬†\nVBR¬†‚Äì¬†Variable Bit Rate¬†\nIl bitrate¬†varia¬†in base al contenuto del video.¬†\n\nScene complesse = pi√π bitrate¬†\nScene semplici = meno bitrate¬†\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFormatoDove si usaBitrate tipicoMPEG-1CD-ROM~1.5 MbpsMPEG-2DVD3‚Äì6 MbpsMPEG-4Internet/streamda 64 kbps a 12 Mbps\nQuindi come funziona lo streaming video(in modo semplice)\nSemplicemente abbiamo un server video che ha il video registrato e che attraverso internet invia i contenuti al client\nbisogna per√≤ tenere conto di 2 complicazioni principali:\n\nla larghezza di banda tra server e client varia nel tempo a causa di eventuali congestioni della rete\nscarsa qualit√† del video o ritardi del video\n\nIn teoria il tempo di invio del server dovrebbe essere costante verso il client cos√¨ che il contenuto pu√≤ essere visto in maniera fluida, ci√≤ per√≤ √® impossibile perch√© potrebbero esserci dei jitter(ritardi di rete), perci√≤ il client dovr√† utilizzare dei buffer per immagazzinare un po‚Äô le informazioni per avvantaggiarsi\nAltri problemi potrebbero essere legati al fatto che:\nil client pu√≤ muoversi avanti indietro mettere in pausa andare alla fine ecc..\npacchetti persi da dover ritrasmettere al client\n\n\nQui possiamo notare tutte le varie compensazioni per ridurre questi problemi\n\nabbiamo un buffer video\nandiamo a riprodurre leggermente in ritardo sul client(caricamento)\n\nin questo modo il client avr√† una riproduzione costante anche se\npossiamo vedere che la linea nera non lo √® affatto\n\n\n\nVari tipi di streaming\nStreaming UDP\n\nin questo caso il protocollo abbiamo visto che se ne frega di eventuali controlli e di congestioni\npossiamo dunque dire che i pacchetti verranno inviati a una frequenza simile a quella del bitrate del video stesso\nil client ricever√† le informazioni e le salver√† su un buffer piccolo perch√© tanto arrivano in tempi ristretti\nil controllo da parte del client √® su una connessione separata\n\ncontrollo inteso come pausa play avanti ecc‚Ä¶\n\n\nSe la banda peggiora il video si interrompe perch√© il buffer √® troppo piccolo\n\nStreaming HTTP\n\nil server invia alla massima velocit√† possibile\n\nil fenomeno per cui il buffer continua a riempirsi anche se il client sta vedendo il video si chiama prefetching\n\n\nquando il buffer si riempie la velocit√† rallenta e si adatta alla velocit√† di consumazione del dato da parte del client\ngestisce molto meglio le variazioni di banda\nper fare il controllo si usa una riga di intestazione chiamata range che dice al server quale punto del video inviare\n\nStreaming dinamico adattivo HTTP\n\nIl client pu√≤ scegliere tra diverse qualit√† del video (es. 480p, 720p, 1080p) anche durante la visione, in base alla rete disponibile in quel momento.\nQuesto √® il metodo usato da piattaforme come YouTube e Netflix.\n\nStreaming multimediale DASH\nsta per Dynamic Adaptive Streaming over HTTP\nil lato server:\n\ndivide il file in pi√π chunk\nogni chunk ha diverse versioni con bitrate diversi\nogni versione √® in un file diverso\ni file sono replicati in nodi CDN(vedi dopo)\nesiste un file manifesto che fornisce gli URL per andare a prendere i diversi chunk\nil lato client:\nfa una stima periodica della banda che c‚Äô√® tra client e server\nattraverso il manifesto richiede chunk di volta in volta\n\nin base alla versione del bitrate pi√π sostenibile per la banda corrente\npu√≤ cambiare bitrate quando vuole\n√® intelligente perch√©\n\npu√≤ determinare quando prendere un chunk\nche encoding rate richiedere\ndove richiedere il chunk in un server vicino\nLo streaming video in sostanza √® formato da\ncodifica+DASH+buffering\\ di\\ riproduzione\n\n\n\n\n\nLe CDNs\nsta per Content Distribution Networks e risponde alla sfida di dover condividere milioni di video a milioni di utenti in modo simultaneo\nCi sono due opzioni\nOpzione 1\nPrevede un unico grande data center ci√≤ causa problemi di:\n\nin caso di rottura non ho fonti di recupero\ncreo congestione su un unico punto\npotrei essere lontano da alcuni client\npoco scalabile\n\nOpzione 2\nMemorizzo pi√π copie video in punti diversi distribuiti geograficamente\n\n(enter deep)installo server della CDN in profondit√† di molti reti di accesso\n\ncos√¨ sono pi√π vicino agli utenti\n\n\n(bring home) pochi ma grandi cluster di server in IXP vicino alle reti di accesso\nAkamai √® una azienda che conta centinaia di migliaia di server\n\nEsempio con BOB\n\nEsempio con NETFLIX\n\n"},"UNI/ANNO-2/RETI/RETI-LEZ.8":{"slug":"UNI/ANNO-2/RETI/RETI-LEZ.8","filePath":"UNI/ANNO 2/RETI/RETI LEZ.8.md","title":"RETI LEZ.8","links":[],"tags":[],"content":"Relazione tra livello di trasporto e rete\nUn protocollo a livello di trasporto mette a disposizione una comunicazione logica tra processi che comunicano su host diversi.\nUn protocollo a livello di rete fornisce comunicazione logica tra host.\nESEMPIO\n\nIl protocollo di rete (IP) si occupa di far arrivare il pacco al suo indirizzo di casa.\nIl protocollo di trasporto (TCP/UDP) si occupa di far arrivare il pacco alla persona giusta nella casa.\n\nI protocolli di trasposto vengono eseguiti nei sistemi periferici\n\nLATO INVIO: scinde (se necessario in caso di messaggi troppo grandi) il messaggio dell‚Äôapplicazione inserendo un‚Äôintestazione per identificare a quale messaggio ricondurre questo ‚Äúpezzo‚Äù\nLATO RICEZIONE: riassembla il messaggio rimuovendo le intestazioni e lo invia all‚Äôapplicazione\n\nI router non si preoccupano dei segmenti, ma guardano solo l‚Äôintestazione del datagramma IP per capire dove deve andare il pacchetto (tipo i corrieri).\n\nDue metodi per la comunicazione\nUDP (User Datagram Protocol)\nUn protocollo molto leggero, semplice e veloce pensato per mandare dati in fretta, senza concentrarsi troppo sulla perfezione.\n√à un protocollo per√≤ inaffidabile, in quanto senza connessione e con il rischio che i dati possano perdersi o arrivare fuori ordine.\nViene utilizzato spesso per\n\nstreaming video/audio\ngiochi online\nchiamate vocali (dove conta pi√π la velocit√† che la perfezione)\n\nTCP (Transmission Control Protocol)\nSi basa su un ‚Äúaccordo‚Äù di connessione tra i due host comunicanti ed √® quindi pi√π affidabile.\nTCP si occupa di\n\nassicurarsi che ogni pacchetto arrivi\nmetterli nell‚Äôordine giusto (anche se potrebbero comunque arrivare sfasati)\nritrasmettere i pacchetti persi\nregolare la velocit√† di trasmissione per non intasare la rete\nViene usato prediligendo la perfezione alla velocit√†.\n\n\n\n                  \n                  Entrambi hanno dei servizi non garantiti \n                  \n                \n\n\nnon garantiscono che i dati arrivino in un tempo specifico (es. ogni due secondi)\nnon garantiscono che la connessione abbia una certa velocit√† minima (es. sempre 100 \\frac {Mb} s)\n\n\n\nMultiplexing e Demultiplexing\nQuando si parla di livello di trasporto √® importante soffermarsi su come vengano organizzati i dati in partenza e di come vengano smistati una volta arrivati.\nMultiplexing (lato mittente)\nQuando un host invia dati, pu√≤ avere pi√π applicazioni attive nello stesso momento (es. browser, videogioco, Spotify) e tutte queste applicazioni vogliono inviare dati attraverso la stessa comunicazione di rete.\nIl livello di trasposto allora deve\n\nraccogliere i dati di ciascun processo (attraverso le socket)\naggiungere un‚Äôintestazione per indicare la provenienza del dato\nQuesto √® il multiplexing.\n\n\nDemultiplexing\nAll‚Äôarrivo dei dati, questi devono essere smistati ai giusti destinatari.\nIl livello di trasporto ha ora un nuovo compito: deve leggere le intestazioni e capire a quale processo (socket) consegnarli.\n\nFunzionamento effettivo\nOgni pacchetto √® un datagramma IP, che contiene dentro di s√© un segmento del livello di trasporto (TCP o UDP) e in questo segmento ci sono due informazioni fondamentali\n\nindirizzo IP del mittente e destinatario\nnumero di porta del mittente e destinatario\n\nquesto √® molto utile perch√© identifica il processo che invia e riceve i dati\n\n\n\nQuindi, una volta che il pacchetto arriva:\n\nil livello di rete consegna il datagramma IP al livello di trasporto\nil livello di trasporto estrae il segmento TCP/UDP e guarda l‚Äôintestazione (quindi indirizzo IP e numero di porta)\ncapisce a quale socket (applicazione attiva) consegnare i dati\n\n\n\n                  \n                  Socket \n                  \n                \n\nSocket √® una interfaccia software che permette a un processo di inviare e ricevere messaggi\n\nfunziona come una porta comunicante per cui il mittente pu√≤ inviare il messaggio e avere una struttura dati che finir√† nelle mani del destinatario\nI livelli fino a quello di trasporto sono gestiti dal SO\ni livelli di applicazione sono controllati dallo sviluppatore dell‚Äôapplicazione\n\n\n\nDemultiplexing con UDP (senza connessione)\nVengono inviate le stesse identiche informazioni di un Demultiplexing normale, solo che quando un pacchetto arriva viene controllato solo il numero di porta e l‚ÄôIP del destinatario (in questa fase quelli del mittente non contano).\n\n\n                  \n                  E allora perch√© IP e porta del mittente vengono comunque inviati? \n                  \n                \n\nServono esclusivamente per far s√¨ che il destinatario possa rispondere se necessario.\n\n\n\nDemultiplexing con TCP\nQui abbiamo una connessione e quindi la trasmissione diventa pi√π ‚Äúcomplessa‚Äù ma molto pi√π sicura.\nQui viene controllata la quadrupla formata da\n\nIP di origine\nPorta di origine\nIP di destinazione\nPorta di destinazione\nQuando un pacchetto arriva, viene controllato sia il destinatario ma anche il mittente, per poter identificare esattamente quale connessione √® attiva tra due processi.\n\nüõ† Cosa succede sul server?\n\n\nIl server crea una socket passiva, ossia una (unica) socket passiva per ‚Äúascoltare‚Äù le richieste dei vari client.\nQuesto significa: ‚Äúchiunque voglia connettersi, mi mandi un segnale qui.‚Äù\n\n\nQuando un utente si connette a questa socket invia una richiesta di connessione.\n\n\nIl server accetta la connessione e crea una nuova socket ‚Äúconnessa‚Äù (privata con il client).\nQuesta nuova socket ha\n\nstesso IP e porta locali del server\nIP e porta remoti diversi (del client)\n\n\n\nse un altro client invia una richiesta viene creata una nuova socket con le stesse caratteristiche dell‚Äôaltra\n\n\n\n\n                  \n                  NOTA BENE \n                  \n                \n\nAnche se entrambe le connessioni vanno allo stesso IP e porta del server, il server le distingue grazie alla quadrupla.\n\n\n"},"UNI/ANNO-2/RETI/RETI-LEZ.9":{"slug":"UNI/ANNO-2/RETI/RETI-LEZ.9","filePath":"UNI/ANNO 2/RETI/RETI LEZ.9.md","title":"RETI LEZ.9","links":[],"tags":[],"content":"molte applicazioni usano UDP\n\nDNS\n\nusa il protocollo UDP poich√© necessita di uno scambio rapido delle informazioni\npu√≤ anche usare TCP per messaggi lunghi ma con meno frequenza\n\n\nSMNP\n\nprotocollo di rete che consente di gestire e monitorare i dispositivi di una rete\n\n\nHTTP/3\n\nusa QUIC di google, una forma specifica di UDP\n\n\n\nStruttura di UDP\n\n\nintestazione a 4 campi ognuno da 2 byte:\n\nnumeri di porta definiscono con quale processo comunicare\nlunghezza specifica quanti byte ha il segmento UDP\nchecksum permette al ricevente di controllare eventuali errori(spieghiamo dopo come)\nil messaggio non pu√≤ essere spezzettato in pi√π messaggi deve entrare in tutto il body\nperch√© UDP non stabilisce nessuna connessione invia direttamente i pacchetti senza fare controlli\n\n\n\nChecksum UDP\nper rilevare gli errori si effettua la checksum\n\nper inviare due numeri faccio la loro somma - il risultato\nl‚Äôimportante √® che io vado a controllare e non escano errori(ris &gt;0)\n\n\n\n\n                  \n                  spiegazione in bit \n                  \n                \n\n\nil mittente\n\nInterpretazione dati: Il contenuto del segmento (compresi header UDP e indirizzi IP) viene trattato come una sequenza di interi a 16 bit.\nCalcolo checksum: Si fa la somma di questi interi (considerando inizialmente il campo checksum come 0) e si prende il complemento a 1 del risultato(inverso).\nInserimento: Il valore ottenuto viene inserito nel campo checksum del segmento UDP.\n\n\nil ricevente\n\nRicalcolo: Il ricevente ricalcola la checksum nello stesso modo, ma include anche il valore di checksum ricevuto.\nVerifica:\n\nSe il risultato sono tutti 1 (cio√® 0 nel complemento a 1), significa nessun errore rilevato.\nSe il risultato √® diverso, c‚Äô√® stato un errore nella trasmissione.\n\n\nAlternative: Alcune implementazioni fanno una verifica ricalcolando la checksum (come fa il mittente) e la confrontano con il valore ricevuto.\n\n\n\n\nricapitolando:\nse avremo tutti 1 allora coincide altrimenti c‚Äô√® un errore\n\n\nFOTO DI RIASSUNTO DI UDP\n\nProblema di affidabilit√† nei trasferimenti di dati\n\n\n                  \n                  si richiede un trasferimento affidabile che garantisca lo scambio di bit senza nessuna perdita o corruzioni e che arrivino nell&#039;ordine corretto \n                  \n                \n\n\n\n                  \n                  Una mezza soluzione √® con il protocollo TCP, un protocollo di trasporto molto affidabile che si appoggia al livello di rete tramite il protocollo IP(non affidabile, spedisce e basta), infatti il protocollo TCP deve controllare quello IP per non fargli fare stupidaggini \n                  \n                \n\nModi diversi per rendere un collegamento affidabile\nNella foto qui sotto possiamo vedere come il canale fin dal principio √® affidabile ma difficile da realizzare (pura fibra da una parte all‚Äôaltra in purezza)\n\nqui invece abbiamo un canale che √® inaffidabile ma che attraverso il protocollo di trasferimento abbiamo dei risultati affidabili\n\nCi tengo a precisare che di solito il mittente non sa lo stato del destinatario e il destinatario non sa quello del mittente\nTCP cerca di dedurre lo stato del destinatario tramite:\n\nAcknowledgment (ACK)\nTimeout\nControllo di congestione\n\nUn concetto di affidabilit√†: RDT\nRDT sta per Reliable Data Transfer ed √® un concetto  o modello a scopo teorico che viene applicato da diversi protocolli come quello TCP per effettuare connessioni affidabili\n\nDescrizione dell‚Äôimmagine:\n\nil canale √® inaffidabile ma bidirezionale\nmittente:\nabbiamo il mittente che si serve di rdt_send() ad alto livello\n\nincapsula i dati e li passa alla funzione sottostante\n\n\npoi si serve di udt_send() a basso livello\n\ninvio del pacchetto sul canale inaffidabile\nricevente:\n\n\nil ricevente si serve di rdt_rcv() a basso livello\n\ncontrolla se il pacchetto √® arrivato integro\n\n\npoi deliver_data() per ricevere i dati da rdt_rcv al processo ricevente(in alto)\n\nDiverse versioni\ncome sempre ci sono diverse versioni che migliorano di volta in volta e variano\nEsse vengono spiegate attraverso gli stati finiti\n\nun sistema che spiega i passaggi in modo chiaro\n\nRDT 1.0\nIl canale √® completamente affidabile quindi non abbiamo alcun problema\n\n\nattende una chiamata dal processo con i dati da inviare\nil processo chiama rdt_send(data)\nil protocollo crea il pacchetto con i dati\nlo invia a udt_send(packet)\nritorna in attesa\n\nattende il pacchetto dal canale di trasporto\nuna volta fatto esso viene chiamato attraverso rdt_rcv(packet)\nestrae il pacchetto e lo invia a deliver_data(data)\nritorna in attesa\n\nRDT 2.0\nIn questo modello invece assumiamo che esso abbia un canale non affidabile ma comunque i bit vengono inviati con l‚Äôordine corretto, possono solo corrompersi\ninoltre si applica il concetto degli acknowledgements\n\nse un pacchetto non rispetta il checksum viene chiesto di ripetersi(NACK‚ÄôS)\nse lo rispetta vien inviato un OK (ACK‚ÄôS)\ne di conseguenza avviene uno stop and wait\n\nI protocolli ARQ sono quei protocolli dove il pacchetto viene ritrasmesso in caso di errori\n\n\nabbiamo una attesa di chiamata dall‚Äôalto con la stessa prerogativa\ndopo aver inviato il pacchetto incapsulato\n\nattende ACK o NAK\nse √® true torna allo stato iniziale\nsenn√≤ ritrasmette l‚Äôultimo pacchetto\nIl simbolo \\Delta indica non inviare nessuna funzione se si √® verificata la condizione\n\n\n\nabbiamo un solo stato di attesa\n\nquando riceve i pacchetti e sono corrotti invia un NACK e torna ad attendere\nquando riceve i pacchetti e non sono corrotti invia un ACK e torna ad attendere\n\n\n\nCosa succede se ACK o NACK sono corrotti\nabbiamo 3 possibilit√†:\n\nuno dei due pu√≤ dire di non aver capito il segnale di ACK o NACK e quindi esso viene rimandato, se non viene capito n volte si crea una sorta di loop dove uno dice di ripetere e l‚Äôaltro dice di ripetere ecc‚Ä¶\nVengono aggiunti dei bit di checksum per recuperare i bit\nche sia un ACK o NACK inalterato il pacchetto viene comunque reinviato per sicurezza(pu√≤ causare duplicazione dei pacchetti)\n\nCome risolvere la duplicazione(numero di sequenza)\nper risolverla si aggiunge un nuovo campo dati che numera il pacchetto in modo da identificarlo\ncos√¨ il destinatario sa se il pacchetto √® uguale a un altro e pu√≤ eliminarlo\nRDT 2.1\nCome il 2.0 ma introduce il numero di sequenza\n\nha 4 stati che comprendono l‚Äôaggunta dei numeri di sequenza e dei vari stati\n\nsi attende la chiamata dall‚Äôalto di tipo 0, viene creato il pacchetto ecc‚Ä¶\nsi attende ACK O NACK di tipo 0\nse √® corrotto si va in attesa di tipo 1\nsi passa al tipo 1 di ACK o NACK\nsi torna in caso alla attesa di tipo 0\n\n\nil ricevente anche ha due numeri di sequenza 0 o 1\nla cosa che succede √® la stessa ma dipende con quale sequenza siamo\n\nse arriva un pacchetto non corrotto ma siamo con seq=1 allora significa che esso √® un duplicato e bisogna inviare ACK ignorando il pacchetto ricevuto\n\nRDT 2.2\nversione migliorata del 2.1 senza il NACK\nACK viene usato con un numero di sequenza\nse il numero non corrisponde √® successo qualcosa di sbagliato\nEsempio:¬†\n\nIl mittente invia pacchetto con seq=0;¬†\nIl ricevente riceve il pacchetto ma √® corrotto, non manda NAK ma ripete l‚Äôultimo ACK valido¬†(es. ACK 1)¬†\nIl mittente riceve ACK 1 e capisce che l‚Äôultimo pacchetto a seq=0 non andava bene e ritrasmette.¬†\nCambia qualcosa nella logica del mittente sono quasi uguali.\n\n\nRDT 3.0\nRDT 3.0 √® una versione del protocollo Reliable Data Transfer progettata per funzionare anche quando i pacchetti o ACK possono essere persi, non solo corrotti.\nQuesta gestione √® demandata al mittente che dovr√† ritrasmetterli\nCosa succede in RDT 3.0?\n\nIl mittente invia un pacchetto dati al destinatario.\nIl pacchetto pu√≤:\n\nArrivare correttamente ‚û°Ô∏è il destinatario invia un ACK\nEssere perso\nArrivare, ma l‚ÄôACK va perso\n\n\nIn entrambi gli ultimi due casi, il mittente non riceve alcuna risposta.\nil mittente pu√≤ capire che c‚Äô√® stato un problema se dopo un tot di tempo (timeout) non riceve un ACK\n\n\n\n                  \n                  quanto deve essere il tempo? \n                  \n                \n\nQuesto tempo √® generalmente almeno\n\nil ritardo di andata e ritorno tra mit e dest+il tempo di elaborazione.\n\nMa il ritardo (RTT) pu√≤ cambiare molto (a seconda della rete, del traffico, ecc.). Quindi\n\nIl timeout viene stimato in modo approssimativo\nSe scade senza ricevere risposta, si suppone che il pacchetto sia andato perso\n\n\n\nOsservazione importante:\nLa ritrasmissione √® la soluzione che viene posta a qualunque tipo di perdita in questo protocollo.\nQuindi per implementare questo meccanismo usiamo un countdown timer.\nIl mittente dovr√†:\n\ninizializzare il contatore ogni volta che invia un pacchetto\nrispondere con una azione appropriata in base al risultato del contatore\nfermare il contatore se tutto fila liscio\n\n\n\nsi pu√≤ notare come viene gestito anche il timer stavolta\nIl ricevente √® lo stesso di RDT 2.1\n\n\nCarrellata di esempi\nEsempio dove √® tutto ok\n\nEsempio dove abbiamo una perdita di un pacchetto\n\n\nptk1 viene perso\nil tempo scade\nviene reinviato pkt1\n\nEsempio dove abbiamo una perdita di un ACK\n\n\nperdita di ack1\ntimeout scade\nreinvio di pkt1\nack1 inviato correttamente\n\nEsempio dove abbiamo un timeout che termina troppo presto\n\n\nil mittente invia due volte lo stesso pacchetto perch√© il timeout non da tempo al ricevente di inviare ack\n\nUso di protocolli per il trasferimento dati affidabile senza pipeline\nanche il 3.0 √® stop and wait quindi molto inefficiente\n\nuna serie di calcoli per capire l‚Äôinefficienza dello stop and wait\n\n1000 byte vengono trasferiti in 30,008 \\ ms con un troughput di 267 \\ kbps, ma abbiamo 1 \\ Gbps\n\nUso di protocolli per il trasferimento dati affidabile con pipeline\n\n\n                  \n                  usare il pipelining consente di migliorare decisamente le cose \n                  \n                \n\nIl mittente potr√† inviare pi√π pacchetti di fila senza attendere i vari ACK‚Äôs\n\nogni pacchetto ha un nseq univoco, quindi usa pi√π numeri\nsia mittente che ricevente devono avere un Buffer\n\nil mittente tiene i pacchetti nel buffer finch√© non arrivano ACK‚Äôs\n\ndopo li pu√≤ eliminare\n\n\nal ricevente potrebbe servire un buffer\nsi usano protocolli Go-Back-N e selective repeat per gestire questo sistema(ora spiego bene)\n\nU_{mittente}= Utilizzazione del mittente\n\n\n\nSpiegazione approfondita di GBN\n√à un protocollo di trasmissione affidabile con pipeline, il mittente pu√≤ inviare quanti pacchetti vuole senza attendere ACK‚Äôs ma pu√≤ inviare un tot numero di essi prima di dover attendere per forza uno o pi√π ACK‚Äôs\n\n\nla base √® il numero di sequenza del pacchetto pi√π vecchio che non ha ancora ricevuto ACK‚ÄôS\ni nextseq invece sono quei numeri di sequenza non ancora utilizzati(per inviare altri dati)\nCi sono 4 intervalli di numeri:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIntervalloDescrizioneColore (nella figura)Stato dei pacchetti[0,base‚àí1]Pacchetti gi√† trasmessi e gi√† confermati (ACK ricevuto)üü© VerdeConfermati, possono essere eliminati dal buffer[base,nextseqnum‚àí1]Pacchetti gi√† inviati ma non ancora confermatiüü® GialloIn attesa di ACK, devono rimanere nel buffer[nextseqnum,base+N‚àí1]Pacchetti non ancora inviati, ma inviabili subitoüîµPronti per l‚Äôinvio, se serve‚â• base + NNumeri di sequenza non utilizzabili finch√© il pacchetto con seq = base non √® confermato‚ö™Bloccati, in attesa di liberare spazio nella finestraQuesto protocollo viene detto a finestra scorrevole perch√© i pacchetti non ancora riconosciuti (senza ACK‚ÄôS) sono detti finestre\n\nappena avviene l‚ÄôACK esse vengono incrementate creando uno scorrimento\n\nquindi se poniamo una base tipo 5 un numero compreso tra 0 e 5-1 √® gi√† confermato e cos√¨ via per gli altri‚Ä¶\n\nLe finestre in numeri‚Ä¶\n\nCon un campo di k bit¬†i numeri di sequenza possibili vanno da 0 a 2k-1¬†\n\nDopo questo valore si torna a 0¬†\nTutte le operazioni sui numeri di sequenza devono essere fatte modulo di 2k¬†\n\n\n\nPraticamente se il numero di bit fisso √® 3 posso rappresentare al massimo i numeri fino a  7 dopodich√© riparto\nOperazioni modulo 2^k\nTutte le operazioni aritmetiche sui numeri di sequenza (ad esempio: confronto, differenza, somma) vanno fatte modulo 2k2^k2k.\nQuesto serve a gestire correttamente il ciclo di ritorno a zero.\nAd esempio: se hai inviato pacchetto 7 e il prossimo √® 0,\nallora nextseqnum = (7 + 1) mod 8 = 0\nAltro esempio\n\nFSM del mittente\n\n\nrdt_send(data) √® la chiamata che invia il pacchetto se viene chiamato dall‚Äôapplicazione sopra\n\nil mittente verifica se pu√≤ inviare con if(nextseqnum&lt;base+N)\ncostruisce il pacchetto con make\nlo invia con udt_send\ncontrolla se √® il primo pacchetto della finestra\n\nin caso avvia il timer\n\n\nincrementa il prossimo numero seq per la prossima finestra\nrefuse data se non pu√≤ essere inviato altro( √® tutto pieno)\n\nDeve garantire che i pacchetti vengano consegnati in ordine\n\n\nil pacchetto viene accettato se\n\nesso √® del numero seq aspettato\nnon √® corrotto\n\n\nsi invia un ACK e si passa a deliver_data\nquesto sopra si chiama ACK cumulativo perch√© conferma l‚Äôarrivo di n-pacchetti\nnon viene accettato se\n\n√® fuori ordine ed √® corrotto\nnon memorizza nulla\ninvia l‚Äôultimo ACK fino al pacchetto valido\n\n\n\nESEMPIO\n\n\nil mittente invia i vari pacchetti\nil ricevente riceve i pacchetti e invia i vari ACK-n\npkt2 non viene preso\nvengono inviati pkt3,4,5\nil ricevente li scarta perch√© gli manca 2\ntimeout\nil mittente rimanda tutti i pacchetti\nack-n vari fino a 5\n\nConcetto di ripetizione selettiva\nGBN funziona ma ha diverse limitazioni, se un pacchetto viene perso vengono ritrasmessi tutti quelli dopo quel pacchetto compreso anch‚Äôesso ovviamente\nI¬†protocolli a ripetizione selettiva¬†evitano le ritrasmissioni non necessarie facendo ritrasmettere al mittente solo quei pacchetti per cui non si √® ricevuto ACK valido.\nIl destinatario SR invia un ACK per i pacchetti correttamente ricevuti sia in ordine che fuori sequenza. Questi vengono memorizzati in un buffer finch√© non sono stati ricevuti tutti i pacchetti mancanti (che di conseguenza hanno nseq pi√π basso).\nMITTENTE\nGestisce una finestra di invio con ampiezza N, questi pacchetti possono essere di vari tipi scritti nelle immagini\n\nRICEVENTE\nAnche il destinatario possiede una finestra di ricezione di ampiezza N, il che significa che pu√≤ accettare e memorizzare al massimo N pacchetti con numeri di sequenza consecutivi, anche se arrivano fuori ordine.\nQuesti pacchetti possono trovarsi in diversi stati:\n\n\nRicevuti ma fuori ordine, memorizzati nel buffer (grigio scuro);\n\n\nAttesi ma non ancora ricevuti (grigio chiaro);\n\n\nFuori dalla finestra, quindi non utilizzabili (bianco).\n\n\nIl destinatario utilizza come riferimento la variabile rcv_base, che rappresenta il primo numero di sequenza atteso.\nQuando il pacchetto con numero rcv_base arriva, la finestra pu√≤ avanzare e vengono consegnati tutti i pacchetti consecutivi gi√† presenti nel buffer.\n\n\n\n                  \n                  tra i due vi √® una sorta di asimmetria \n                  \n                \n\nIl mittente e il destinatario non condividono la stessa visione dei pacchetti, anche se usano finestre della stessa ampiezza.\nLe loro finestre si muovono in momenti diversi e in base a eventi diversi.\nüì§ Mittente:\nInvia pacchetti tra send_base e nextseqnum - 1, ma pu√≤ avanzare la finestra solo quando riceve l‚ÄôACK di send_base.\nAnche se arrivano ACK per pacchetti successivi, non si muove finch√© non arriva quello ‚Äúgiusto‚Äù.\nüì• Destinatario:\nAttende il pacchetto rcv_base.\nPu√≤ ricevere pacchetti fuori ordine e metterli nel buffer, ma non consegna nulla n√© fa avanzare la finestra finch√© non arriva proprio rcv_base.\n\nüéØ In breve:\n\n\nIl mittente si muove con gli ACK (e solo quando arriva quello alla base).\n\n\nIl destinatario si muove con i pacchetti ricevuti, ma solo quando riceve quello che si aspetta per primo.\n\n\n‚û°Ô∏è Le finestre si aggiornano in modo indipendente.\n\n\n\nüìå Contesto generale\nLa finestra ha ampiezza N = 4.\nIl protocollo √® Selective Repeat, perch√©:\n\nIl mittente ritrasmette solo pkt2 (non tutto)\nIl destinatario accetta e bufferizza pacchetti fuori ordine\n\nüì§ Lato mittente:\n\nInvia pkt0, pkt1, pkt2, pkt3\n‚û°Ô∏è La finestra √® piena (ha raggiunto N = 4), quindi attende ACK per poter inviare altro.\nRiceve ACK0 ‚Üí la finestra avanza, invia pkt4\nRiceve ACK1 ‚Üí avanza ancora, invia pkt5\nIl pkt2 era andato perso ‚Üí timeout ‚Üí viene ritrasmesso\nRiceve ACK3 ‚Üí ma non pu√≤ avanzare la finestra, perch√© manca ancora ACK2 (il pacchetto alla base).\n\nüì• Lato destinatario:\n\nRiceve pkt0 ‚Üí lo consegna, invia ACK0\nRiceve pkt1 ‚Üí lo consegna, invia ACK1\nNon riceve pkt2 (si perde)\nRiceve pkt3, pkt4, pkt5 ‚Üí sono fuori ordine, quindi:\n\nVengono messi nel buffer\nInvia comunque i rispettivi ACK (ACK3, ACK4, ACK5)\n\n\nRiceve la ritrasmissione di pkt2:\n\nOra ha i pacchetti 2, 3, 4, 5 ‚Üí tutti consecutivi\nLi consegna in ordine\nInvia ACK2\n\n\n\n\nüîÅ Differenza con Go-Back-N:\nNel Selective Repeat:\n\nIl mittente ritrasmette solo i pacchetti mancanti (pkt2)\nIl destinatario memorizza i pacchetti arrivati fuori ordine e li consegna appena possibile\nNel Go-Back-N, invece:\nIl mittente avrebbe ritrasmesso anche pkt3, pkt4, pkt5\nIl destinatario avrebbe scartato pkt3‚Äì5 finch√© non arrivava pkt2\n\nAmbiguit√† nel protocollo\nquelli a dx delle foto sotto sono gli ACK‚ÄôS\nüìå Caso (a): tutto ok\n\nHai 4 numeri di sequenza possibili (0, 1, 2, 3) e una finestra di dimensione N = 3.\nIn Selective Repeat:\n\nOgni pacchetto ha un numero di sequenza.\nPoich√© lo spazio √® limitato (4 in questo caso), i numeri vengono riutilizzati ciclicamente.\n\n‚ñ∂Ô∏è Scenario:\n\nIl mittente invia i pacchetti con numeri 0, 1, 2.\nIl destinatario li riceve correttamente e invia ACK0, ACK1, ACK2.\nLa finestra del destinatario avanza e ora accetta i pacchetti con numeri 3, 0, 1 ‚Üí tutto funziona come previsto.\n\n‚ùó Caso (b): errore dovuto alla perdita degli ACK\n\n‚ñ∂Ô∏è Cosa succede:\n\nGli ACK inviati dal destinatario vanno persi, quindi il mittente non fa avanzare la sua finestra.\nScatta il timeout ‚Üí il mittente ritrasmette pkt0 (che pensa non sia mai arrivato).\nMa il destinatario aveva gi√† ricevuto e confermato quel pkt0, e ha gi√† avanzato la finestra.\n‚ùå Problema:\nIl destinatario riceve di nuovo un pacchetto con numero di sequenza 0,\nma non pu√≤ sapere se √® un duplicato vecchio o un nuovo pacchetto!\nQuesto accade perch√©:\nIl numero di sequenza √® riciclato (sempre 0)\nIl mittente e il destinatario non sono pi√π sincronizzati\nNon c‚Äô√® abbastanza spazio numerico per distinguere pacchetti vecchi da nuovi\n\nPer scegliere la giusta grandezza delle finestre\n\nLa¬†finestra deve essere al massimo met√† dello spazio dei numeri di sequenza.\n"},"UNI/ANNO-2/RETI/RIPASSO":{"slug":"UNI/ANNO-2/RETI/RIPASSO","filePath":"UNI/ANNO 2/RETI/RIPASSO.md","title":"RIPASSO","links":[],"tags":[],"content":"LIVELLO APPLICAZIONE\n\ndefinizione di internet\n\nInfrastruttura composta da un insieme di reti interconnesse tra loro\n\n\nHost\n\nospitano le applicazioni di rete\nsi trovano ai bordi di internet\ncomunicano attraverso pacchetti di dati\ninoltrati da altri dispositivi come router e switch\n\n\nISP\n\norganizzazioni che offrono l‚Äôaccesso a internet a utenti o varie aziende\nsono interconnessi tra loro per garantire il corretto funzionamento della rete\nse locali sono nei margini della rete\nse globali sono nel nucleo della rete\n\n\nCommutazione di una rete\n\nTecniche di scambio di pacchetti seguendo determinate regole\nCommutazione di pacchetto\n\nIl singolo messaggio viene diviso in pacchetti di L bit\nviene inviato il singolo pacchetto senza flussi di bit\n\n\nCommutazione di circuito\n\nviene dedicato un collegamento tra mittente e destinatario e vengono inviati i bit in sequenza\n\n\n\n\nLan o Wan\n\nLocal Area Network\nWide Area Network\n\n\nNucleo di rete\n\n√à un insieme di commutatori di pacchetti e link tra i vari host che sono poi collegate alle varie periferie di rete\ngli utenti non ci accedono direttamente\nazioni:\n\ninoltro\n\nattraverso una tabella di inoltro, invia i pacchetti a una determinata interfaccia\n\n\ninstradamento\n\nindica il percorso che viene fatto da una serie di router per arrivare a destinazione da una radice\nfatto attraverso algoritmi\n\n\n\n\nviene calcolato instradamento e poi inoltro\n\n\n\nsicurezza di internet\n\nuna interfaccia di rete, quindi collegata alla rete\n\npu√≤ vedere tutti i pacchetti che ci passano\nwireshark\n\n\nip spoofing\n\nfingo di avere un‚Äôaltro indirizzo IP nella rete\n\n\n\n\nprotocolli\n\ninsieme di regole che definiscono i metodi per la comunicazione tra dispositivi nella rete\n\n\nDivisione in livelli della TCP/IP pila protocollare\n\nApplicazione\n\nsupporto alle applicazioni di rete con protocolli come HTTP che inviano messaggi\n\n\nTrasporto\n\nTrasferimento di segmenti tra processi come UDP e TCP\n\n\nRete\n\ntrasporto di datagrammi, pacchetti di rete tra host con indirizzo IP e protocolli IP\n\n\nCollegamento\n\nTrasferimento di frame tra dispositivi vicini\n\n\nFisico\n\nTrasferimento di bit veri e propri su link\n\n\n\n\nincapsulamento dei dati tra i vari livelli\n\n\nLivello di applicazione\n\n\ndefinizione\n\n√à un livello nella pila protocollare\ninteragisce con l‚Äôutente o con le applicazioni di rete\n\nfornendo i servizi di rete ad essi\n\n\n\n\n\narchitetture\n\nclient server chi sono?\n\nsono due attori detti host all‚Äôinterno della rete che comunicano tra loro scambiandosi messaggi\nserver\n\ndeve essere sempre attivo e deve rispondere alle richieste degli host\nindirizzo IP noto dai client\n\n\nclient\n\ncomunica con i server inviando richieste\n\n\n\n\npeer-to-peer\n\narchitettura che prevede un insieme di host che fanno sia da client che da server, sono detti peer\n\nogni peer condivide i file che ha gi√† scaricato ai peer candidati pi√π vicini\nutilizza determinate tecniche per ottimizzare lo scambio tra peer\n\n\ntorrent\n\nfile che ha tracker dei i vari peer\n\n\npeer-to-peer vs client server\n\nClient server\n\nlineare senza variazioni\n\n\npeer-to-peer\n\ndipende da il numero di utenti che condividono i dati e che li scaricano\n\n\n\n\ntit for tat\n\ntecnica di ottimizzazione del peer-to-peer\nin un intervallo di secondi vengono ogni volta definiti i peer che sono destinati a scambiare i chunk\n\nogni tanto ne viene scelto uno a caso per vedere se era candidato e utile\n\n\n\n\n\n\n\n\n\nprocessi\n\nsono un programma in esecuzione su un host\n\naccedono alla rete tramite il livello di trasporto\nma per comunicare con il livello di applicazione dove abbiamo le varie applicazione di rete vengono usate le socket\n\nsono interfacce software, permettono di comunicare con i processi che lavorano al livello di trasporto, quindi fanno da tramite con il livello di applicazione\nsono identificate da una coppia formata da\n\nIP\n\nidentifica l‚Äôhost\n\n\nPorta\n\nidentifica l‚Äôapplicazione\nalcune porte sono gi√† standardizzate per alcune applicazioni\n\n\n\n\n\n\n\n\n\n\n\n\nprotocollo del livello di applicazione\n\nsi dividono in 2 tipi\n\nproprietari\n\nnon sono noti e vengono usate da applicazioni private tipo skype\n\n\npubblici\n\nsono noti e standardizzati tipo HTTP\n\n\n\n\nvertono su\n\nsicurezza\n\ni livelli di trasporto non garantiscono chiss√† che sicurezza ma quelli di applicazione la possono migliorare con cifrature tipo TLS\n\n\ntroughput minimo garantito\nperdita di messaggi\nsensibilit√† al fattore tempo\n\n\napplicazioni che usano protocolli di trasporto\n\nHTTP usa TCP\nSMTP usa TCP\nGiochi interattivi TCP e UDP\nVoIP usa UDP\n\n\n\n\n\nHTTP\n\nalla base delle applicazioni web\n\nsfrutta il paradigma client server\npresente sulla porta 80\nconsente lo scambio di messaggi di richiesta HTTP\nvengono scambiare risorse\n\n\npassaggi che compongono una richiesta HTTP\n\nil client tenta di aprire una connessione TCP al server sulla porta 80, creando una socket, successivamente il server la riceve e accetta o meno la connessione, il client invia una richiesta HTTP al server, il server fornisce la risorsa, viene chiusa la connessione TCP\n\n\nMESSAGGIO HTTP\n\n√® composto da\n\nriga di richiesta\n\nversione HTTP, URL richiesto, metodo HTTP usato(get put‚Ä¶)\n\n\nintestazione\n\ninformazioni riguardo chi effettua la richiesta, formato, se ci sono cookie o meno ecc‚Ä¶\n\n\ncorpo del messaggio\n\ncontiene i dati inviati dal server\n\n\n\n\n\n\nMetodi HTTP\n\nPOST\nGET\nHEAD\nPUT\n\n\nVersioni a grandi linee\n\n1.0\n\nogni connessione creata TCP era uno scambio di un solo messaggio\nnon persistenti, quindi la connessione termina, gli altri sono persistenti\n\n\n1.1\n\nconsentiva di fare GET multiple di dati con politica FIFO\n\n\n2.0\n\nsenza richieste venivano inviati pi√π messaggi ma con priorit√† non FIFO\ni messaggi venivano inviati alternati tra loro divisi in frame, invio interlacciato\n\n\n3.0\n\nusa UDP con QUIC al livello di applicazione per gestire problemi di sicurezza e perdita dei messaggi\n\n\n\n\n\n\n\n\nRTT\n\ntempo che impiega un pacchetto per andare dal client al server e dal server al client\nvariabile in base a eventuali congestioni ecc‚Ä¶\n\n\n\n\nCodici di stato\n\nper ogni errore esiste un codice di stato che si trova nell‚Äôintestazione dei messaggi\n1xx messaggi informativi,\n2xx successo,\n3xx risorsa spostata,\n4xx errore,\n5xx errore server\n\n\n\nI cookie\n\nil protocollo HTTP √® stateless, quindi login non funzionano ad esempio\nper salvare eventuali client vengono o salvati gli stati in memoria sui due dispositivi client e server oppure si usano i cookie\n\ni cookie sono codici identificativi per client\ni cookie dopo la prima connessione effettuata vengono scambiati nell‚Äôheader delle richieste HTTP\nessi vengono salvati in un database dei server e vengono forniti al client, il client salver√† il proprio cookie ad esempio nel browser\n\n\n\n\n\n\nWeb Cache\n\nintermediario tra client e server\nse ha gi√† una risorsa di una eventuale richiesta HTTP la fornisce senza interpellare il server effettivo\nogni risorsa ha un TTL time to live\npu√≤ essere locale, interna al host client oppure un server come i proxy che fanno da client\nvengono usate per migliorare l‚Äôefficienza dei server e evitare congestioni\n\n\n\n\nPosta elettronica\n\napplicazione che simula lo scambio di lettere attraverso user agent e mail server\n\ntra server di posta avviene uno scambio attraverso SMTP\nuno user agent per inviare una mail la invia al suo server mail attraverso il protocollo SMTP, a sua volta questo server lo invia al server mail del destinatario attraverso il protocollo SMTP, per prelevare le mail viene usato IMAP dallo user agent\nperch√© SMTP non pu√≤ fare pull\n\n\npassaggi SMTP\n\nusa il protocollo TCP\n\neffettua prima di tutto il TCP handshake con la richiesta TCP che viene accettata\nsuccessivamente viene effettuato un handshake SMTP per presentare le due parti\nviene inviato il messaggio, come corpo ha il contenuto della mail\n\n\n\n\nHTTP VS SMTP\n\nHTTP √® di tipo pull, il client riceve dei dati solo se li richiede\nSMTP √® di tipo push, il client riceve dei dati anche se non li richiede(server mail del destinatario)\n\n\n\n\n\n\nDNS\n\nServizio di rete decentralizzato(con pi√π server) che consente la conversione di indirizzi URL in IP attraverso un Database\nCi sono 3 server noti di tipo DNS\n\nroot\n\nindirizza a quale server TLD riferirsi\n\n\nTop Level Domain\n\nforniscono la parte finale dei domini e rimandano a quelli autoritativi che sono meno generici, hanno solo .com ecc‚Ä¶\n\n\nAutoritativi\n\nServer DNS che contengono indirizzi IP completi richiesti\n\n\n\n\nrichiesta DNS pu√≤ essere\n\nricorsiva\n\ni server DNS a partire da quello locale si risolvono da soli interrogandosi a vicenda\n\n\niterativa\n\nil server DNS locale interroga i vari Server DNS personalmente\n\n\n\n\n\n\n\n\n\nURL\n\nindirizzo che contiene sito di riferimento che poi dovr√† essere convertito in IP\nrisorse di riferimento richieste dopo lo /\n\n\n\nstreaming video\n\nstreaming invio di sequenze di dati che vengono riprodotte\nsequenza di immagini codificate per ottimizzare il peso\nbitrate\n\nunit√† di misura che indica quanti bit vengono trasmessi al secondo\nfisso o variabile\n\n\nviene usato TCP per evitare perdite\n\ncon HTTP pu√≤ essere scelta la qualit√† scegliendo la determinata risorsa\n\n\nCDN\n\nserver nel mondo che hanno stessi contenuti video per rispondere alle eccessive richieste\n\n\n\n\n\nLIVELLO DI TRASPORTO\nLivello di trasporto\n\nintroduzione breve\n\nlivello che consente la comunicazione tra processi su host differenti mediante protocolli e segmenti\n\n\ntecniche di smistamento dei dati mediante IP+porta\n\nmultiplexing\n\neffettuato al lato mittente\ni segmenti di ciascun processo vengono compattati e inviati, differenziati poi da una intestazione\n\n\ndemultiplexing\n\neffettuato al lato destinatario\ntramite le intestazioni dei singoli segmenti viene definito a quale processo socket destinare quel determinato segmento\nsi divide in\n\ncon connessione\n\nvengono creare socket passive\n\n\nsenza\n\n√® sufficiente IP+porta\n\n\n\n\n\n\n\n\n\n\n\nUDP\n\ndefinizione\n\nProtocollo di trasporto veloce senza handshake, con ritrasmissione\n\n\nutilizzi\n\nDNS\nDHCP\nHTTP/3 con QUIC\n\n\nstruttura del segmento\n\nIntestazione, in cui abbiamo porta di origine, porta di destinazione, lunghezza, checksum\n\norigine serve solo se si vuole inviare eventualmente una risposta\n\n\ndati dell‚Äôapplicazione\n\n\nchecksum\n\nspazio di dati all‚Äôinterno di UDP con lo scopo di rilevare errori e eventualmente ritrasmettere\nil mittente calcola la checksum e la invia al destinatario\nil destinatario calcola a sua volta la checksum e la confronta con quella inviata dal mittente\n\nse tutti i bit sono a 1 allora non vi sono errori\n\n\n\n\n\n\nModello teorico RDT\n\n\n\naffidabilit√† con RDT\n\nRDT Reliable Data Transfer, modello astratto che indica come gestire un canale inaffidabile per garantire la corretta trasmissione dei dati √® diviso in versioni\n\nesso venne poi usato come idea per TCP\n\n\n1.0\n\ncanale affidabile, mittente e destinatario devono solo aspettare di essere interpellati per inviare o ricevere dati\n\n\n2.0\n\ncanale inaffidabile ma con segmenti che vengono inviati in ordine, vengono introdotti ACK e NAK\nil mittente prima di rimettersi in attesa di inviare un nuovo segmento attende uno di questi due segnali\nil destinatario invia ACK o NAK se i dati ricevuti sono ok oppure corrotti\nproblematiche:\n\ni segnali possono essere anche essi corrotti\nnel dubbio viene inviato ma presenterebbe delle duplicazioni\n\n\n\n\n2.1\n\nintroduce numero di sequenza per evitare duplicazioni\nil numero di sequenza viene usato tra mittente e destinatario per capire se sono sullo stesso numero di sequenza\nil mittente invia un pacchetto con un numero di sequenza 0 o 1, si aspetta un ACK con lo stesso numero dal destinatario se √® differente allora ci sono problematiche\nsono ancora usati ACK e NAK\n\n\n2.2\n\nrimuove i NAK, se invio un ACK non corrispondente √® come se sto inviando un NAK\n\n\n3.0\n\naggiunge RTT, ovvero una soglia di tempo per attendere un segnale necessario per effettuare una ritrasmissione\nusata per gestire perdite e non solo errori\n\n\n\n\n\ntrasferimento dati con stop and wait  vs pipeline\n\nstop and wait viene inviato un segmento e si attende un riscontro per esso\npipeline, vengono inviati in sequenza i segmenti e poi vengono accumulati su una pipe i rispettivi ACK, nel caso del mittente, per il destinatario i veri e propri segmenti\n\n\n\n\nGBN\n\nprotocollo teorico che prevede utilizzo di finestre\n\nper tenere conto dei segmenti confermati, in attesa di conferma, ancora da inviare\nse in una sequenza di N segmenti un segmento non viene confermato, il mittente dovr√†, dopo il timeout rinviare tutti da quel segmento in poi\n\n\n\n\n\n\ncon ripetizione selettiva\n\nmigliora la GBN\nogni segmento √® una istanza a se numerata, non devo reinviare tutta la sequenza ma solo il singolo interessato\n\n\n\n\nTCP\n\n\nintroduzione\n\nprotocollo di trasporto affidabile basato su connessione tra gli host e correzione di errori\n\n\n\ndettagli sul segmento MSS e MTU\n\nMSS rappresenta la massima dimensione di un segmento, escludendo l‚Äôintestazione\nMTU rappresenta la massima dimensione di un datagramma del protocollo IP che racchiude anche il segmento\n\n\n\n\nsegmento PDU del TCP\n\nsi divide in\n\nintestazione\n\nnumeri di porta origine e destinazione checksum, ack, numero di sequenza, receive window\n\n\ncorpo, i dati effettivi\n\n\n\n\n\n\nnumero di sequenza e ACK\n\nogni byte √® numerato sequenzialmente\nil campo numero di sequenza include il primo byte di sequenza\nil campo ACK include l‚Äôultimo byte a essere confermato\n\n\n\nRTT Round Trip Time\n\nsoglia di tempo che deve attendere un mittente prima di effettuare un reinvio se non si ricevono segnali\nviene stimato calcolando una media degli ACK ricevuti\n\n\n\nControllo e gestione del flusso\n\nTCP permette al mittente di gestire il flusso di dati che pu√≤ ricevere il buffer  del destinatario, per evitare saturazioni del buffer\nreceive window\n\ncampo dell‚Äôintestazione TCP per definire quanti byte pu√≤ ancora ricevere il buffer del destinatario\n\n\n\n\n\n\nTCP con handshake\n\nprocedura che instaura un collegamento sicuro tra due host\nmalgrado aumenti l‚Äôoverhead dovuto a questa procedura diminuisce notevolmente la perdita di dati attraverso segnali di ACK scambiati tra le due parti\n2 vie\n\nil mittente invia una richiesta di collegamento al destinatario\nil destinatario manda una conferma con un segnale di ACK\nla connessione √® stabilita e i due possono comunicare fino alla chiusura\nproblemi: perdita del segnale di ACK o di richiesta\n\n\n3 vie\n\ncome quello a 2 vie solo che adesso anche il mittente deve inviare a sua volta un ACK dell‚ÄôACK del destinatario e per iniziare la sincronizzazione viene usato un Synbit che deve essere uguale tra i due\n\nquesti ACK sono identificati da\nACKbit\n\nsemplice ACK 1=NAK       0=ACK\n\n\nACKnum\n\nindica fino a quale sequenza di byte ha ricevuto i dati\n\n\n\n\nBit di reset\n\nin caso di errori √® possibile terminare repentinamente la connessione stabilita\n\n\nChiusura connessione TCP\n\nViene inviato un Finbit=1\nil destinatario invier√† un Finbit=1+ACK\nil mittente invia un ACK e basta\n\n\n\n\n\n\n\n\n\nattacco Syn flood\n\nvengono inviate molteplici richieste di handshake per far crashare un server\nsi risolve con i cookie\n\nil client dovr√† rispondere con il cookie assegnato altrimenti non alloca memoria\n\n\n\n\n\nCongestione\n\n\ndefinizione\n\nfenomeno che avviene quando il carico da inviare supera la capacit√† di risorse che supporta la rete\n\n\n\nscenario 1\n\nbreve descrizione\n\nrouter con buffer illimitato, ogni coppia mittente/destinatario ha il suo collegamento al router\nse aumenta il troughput pi√π di R/2 si presentano rallentamenti\n\n\n\n\n\n\nscenario 2\n\nbreve descrizione\n\nbuffer del router limitato\nritrasmissioni presenti al livello di trasporto non di applicazione\nsi divide in 3 sotto-scenari\n\ncaso 1 ideale, buffer libero\n\ni pacchetti vengono inviati regolarmente\nil mittente sa quando il buffer √® pieno\n\n\ncaso 2, buffer pieno e conoscenza meno perfetta della situazione\n\nvengono scartati pacchetti e ritrasmissioni\n\n\ncaso 3, timeout prematuro\n\ntimeout non impostato correttamente\nduplicazioni\n\n\n\n\n\n\n\n\n\n\n\nscenario 3\n\nbreve descrizione\n\n4 host\npercorsi multi hop\ntimeout e ritrasmissioni\n\n\nproblematiche\n\nhost adiacenti a router prendono tutta la banda possibile\n\n\n\n\n\n\ncontrollo della congestione 2 approcci\n\nend-to-end\n\nil controllo della congestione √® demandato solo al mittente, che effettuer√† dei calcoli\n\ndella finestra di ricezione prende solo ed esclusivamente il cwnd, ovvero i byte che devono ancora essere ACK e anche quelli non inviati\ncalcolando poi cwnd/RTT riesce a definire circa il tasso di invio\nnon preciso\n\n\n\n\nassistito dalla rete\n\nil router invia dei pacchetti informativi detti choke al destinatario, lui li rimanda il mittente insieme a eventuali ACK\ninformano del loro stato di congestione\nusato in TCP ECN\n\n\n\n\n\ngestione del tasso di invio.\n\nconcetto di AIMD\n\nAdditive increase Multiplicative Decrease\nquesto concetto regola dinamicamente gli MSS\nMaximum Segment Size, ovvero regola quanti segmenti pu√≤ inviare prima di attendere una ricezione\ninizia da 1 aumenta additivamente ad ogni RTT e appena avviene un fault gli cwnd vengono dimezzati\n\n\n\n\n\n\nfasi di gestione del tasso di invio\n\nslow start\n\nsi inizia piano e poi ad ogni RTT cwnd si raddoppia\n\n\ncongestion avoidance\n\nviene usata una variabilesstresh che definisce un limite per cui si smette di crescere esponenzialmente(slow start) ma linearmente\n\n\ngestione errori\n\nse non si ricevono ACK(timeout)\n\nentra in timeout e dimezza sstresh e cwnd=1\n\n\nse riceve 1 o 2 ACK duplicati\n\nprova semplicemente a ritrasmetterli\n\n\nse invece ne riceve 3 duplicati\n\naumenta notevolmente cwnd per aumentare il tasso di trasmissione\npoi entra in fast recovery\n\n\n\n\nfast recovery\n\nquando si verifica una perdita, triplo ACK duplicato si entra in fast recovery\nquesta fase dura 1RTT per attendere l‚Äôack del pacchetto perso\nquindi si entra in congestion avoidance partendo da\n\ncwnd=cwnd \\ del \\ blocco \\ precedente+3 \\ tutto \\ fratto \\ 2\n\n\n\n\n\n\n\nevoluzioni TCP\n\nTCP Reno\n\nimplementazione di TCP che utilizza un algoritmo con fast recovery e dimezzamento di 1 MSS quando si ha un ACK\n\n\nTCP Cubic\n\nutilizza W_{max}, dimensione della finestra nel momento in cui avviene una congestione\n\nsuccessivamente a una congestione viene ogni volta dimezzata la velocit√† di trasmissione  e viene settata una variabile K nei pressi di W_{max}\nprima di K si cresce velocemente in un valore compreso tra K e W_{max} meno velocemente\nogni volta viene causata la congestione\n\n\n\n\nTCP Vegas\n\nevoluzione di CUBIC\ncalcola una stima e vede ogni volta se viene rispettata effettivamente\n\n\nECN\n\npresente in alcune implementazioni di TCP\nvengono usate due variabili\n\nECN\n\nil router le invia per segnalare congestioni\n\n10 non c‚Äô√®\n11 c‚Äô√®\n\n\n\n\nECE\n\nle invia il destinatario al mittente\n1 se c‚Äô√®\n0 se non c‚Äô√®\n\n\n\n\n\n\n\n\n\n\nfairness di TCP e UDP\n\nTCP √® fair perch√© il troughput √® dato da R/K\n\novvero il numero la capacit√† del collegamento fratto il numero delle connessioni\n\n\nTCP paralleli\n\nse dallo stesso host faccio pi√π socket con pi√π richieste TCP non diventa pi√π fair\n\n\nUDP non √® fair perch√© non pu√≤ controllare il tasso di trasmissione\n\n\n\nEvoluzioni protocolli di trasporto\n\nQUIC\n\nusa UDP e al livello di applicazione implementa le varie sicurezze e migliorie\ntipo TCP ha HOL(Head Of Line blocking) QUIC no\nessendo pi√π recente √® meno supportato\n\n\n\n\n\nLIVELLO DI RETE\nLIVELLO DI RETE\n\n\nIntroduzione*\n\nil livello di rete si occupa di trasportare datagrammi da un host mittente a un host destinatario che possono trovarsi anche su reti differenti\n\n\n\nDescrizione protocollo IP*\n\nprotocollo fondamentale del livello di rete, si occupa del vero e proprio trasferimento dei datagrammi attraverso una rete di dispositivi\n√à BEST EFFORT, non da garanzie dei servizi che offre ma fa del suo meglio\n\nservizi che vuole offrire la rete:\n\nservizi per il singolo datagramma\n\nconsegna garantita\nconsegna con ritardo ridotto\n\n\nservizi per datagrammi multipli(flussi)\n\nconsegna in ordine\nbanda di trasferimento minima garantita\nframmenti che arrivano a intervalli regolari\n\n\n\n\n\n\nDATAGRAMMA IP\n\nintestazione con indirizzi IP sorgente e destinazione, lunghezza totale del datagramma versione e TTL, protocollo usato al livello superiore, checksum\ncorpo dati\n\n\n\n\n\n\nFRAMMENTAZIONE DATAGRAMMI\n\nse un datagramma supera la MTU(Maximum Transmission Unit)\nviene frammentato con stesso identificatore\n\nflag che indica se √® l‚Äôultimo del suo blocco,\noffset per indicare dove si inserisce nel datagramma totale\n\n\nseguendo questi campi viene riassemblato nel destinatario finale\nPMTUD (Path Maximum Transmission Unit Discovery)\n\nobiettivo: scoprire quanto deve essere grande al massimo la MTU in 2 modi\n\n\n\nICMP invia un datagramma con obbligo di non frammentazione, se riceve una segnalazione dal router che da un obbligo di frammentazione allora bisogna modificare la MTU con quella suggerita da parte del router\n\n\n\n\nMitigazione durante l‚Äôhandshake, insomma viene accordato prima\n\n\n\n\n\n\n\n\n\nfunzioni chiave del livello di rete\n\ninoltro\n\nsi occupa dell‚Äôeffettivo invio dei datagrammi\nsi divide in:\n\nbasato sulla destinazione\n\nusa indirizzo IP e la tabella di inoltro\n\n\ngeneralizzato\n\nguarda altri campi come il protocollo e il servizio\nusato su reti pi√π complesse\ntipo Match+Action\n\n\n\n\n\n\ninstradamento\n\nprocesso che calcola i percorsi nella rete serve per effettuare un inoltro dei datagrammi coerente con l‚Äôinfrastruttura di rete\n\n\n\n\n\nclassful addressing\n\nutilizzo di classi prima dell‚Äôinvenzione di CIDR per definire indirizzi IP\n\n\n\ncome trovare Ip nell‚Äôinoltro basato sulla destinazione\n\ni router hanno un sacco di IP sulla tabella di inoltro\n\ncome capire l‚ÄôIP di input a quale appartiene?\n\nCIDR standard di formattazione che divide IP in 2 parti indirizzo subnet e indirizzo host\n\nfunziona tipo indirizzo/16, indica che i primi 16 bit sono della subnet e i successivi 32-16 sono dell‚Äôhost\n\n\npotremmo avere pi√π IP simili in termini di bit, viene effettuata una ricerca della corrispondenza sulla tabella fino ai bit meno significativi, l‚Äôindirizzo con pi√π informazioni viene selezionato\n\n\n\n\nTCAM+ priority encoder\n\nusata per rappresentare le tabelle di inoltro\nTCAM √® una memoria speciale che permette di trovare la riga con l‚ÄôIP adeguato in un tempo ridotto\nquando ci sono pi√π indirizzi IP simili, entra in gioco il priority encoder che sceglier√† quello con la priorit√† pi√π alta\n\n\n\n\n\n\ndivisione in 2 del livello di rete\n\npiano dei dati\n\nfunzione locale dei router che decide come inoltrare un datagramma\n\n\npiano di controllo\n\nsi occupa della logica globale della rete\n\n\n\n\n\n\nSDN(Software-Defined Networking)*\n\narchitettura dove il piano di controllo √® centralizzato in un unico server per tutta la rete\n\nrouter esecutori il controller calcola lui le tabelle di inoltro\n\n\nposizionamento di SDN\n\nabbiamo il piano dei dati con i vari router e le AS\npoi a un livello intermedio abbiamo le SDN con il controller\nancora sopra abbiamo il piano di controllo con le varie applicazioni di gestione della rete\n\n\n\n\n\n\ncome √® fatto il controller delle SDN\n\n√® diviso in\n\nLivello di interfaccia con le applicazioni\n\nLivello che si collega alle app del piano di controllo, attraverso varie API north-bound fornisce a loro dell informazioni\n\n\nGestione dello stato di rete\n\nDatabase che contiene le varie info sulla rete, router, link, host e switch\n\n\nComunicazione con i dispositivi che controlla\n\nAttraverso protocolli come Open Flow comunica con i vari dispositivi della rete come switch ecc‚Ä¶\nquesto insieme di protocolli √® detto Southbound API\n\n\n\n\n\n\n\n\n\n\n\nRouter*\n\ndispositivi di rete che hanno il compito di instradare datagrammi\nse non c‚Äô√® la SDN si divide in\n\npiano di controllo\n\nvia software\n\n\npiano dati\n\nhardware\n\n\nstruttura di commutazione\n\ncomponente del router che permette di instradare i datagrammi da una porta di ingresso a una di uscita\n\n\nporte di ingresso\n\ninterfacce destinate all‚Äôingresso dei datagrammi ai router\nogni porta deve ricevere e processare un datagramma in modo veloce\n√® divisa in step\n\nterminazione di linea\n\nriceve i bit grezzi e li passa al successivo step\n\n\nelaborazione al livello di collegamento\n\ninterpreta il frame e decapsula il datagramma\n\n\nricerca e inoltro\n\nguarda il datagramma e capisce a quale struttura di commutazione inoltrarlo\n\n\n\n\n\n\nporte di uscita\n\nprende input da un commutatore e poi esegue gli step inversi delle porte di ingresso\n\n\naccodamento in entrata e in uscita\n\nin entrata potrei avere problemi di HOL\nin uscita potrei avere problemi di buffer troppo pieno e quindi scarti\n\n\n\n\n\n\n\n\nCommutazione*\n\n\ncomponente del router che permette di instradare i datagrammi da una porta di ingresso a una di uscita\n\ncentralizzata\n\ntutto passa per una cpu unica del router\n\n\ndecentralizzata\n\nogni porta del router ha una sua piccola cpu che elabora a quale porta di uscita mandare il pacchetto\n\n\n3 strutture\n\n1 memoria\n\ntutte le porte hanno una memoria condivisa\ni datagrammi vengono copiati dentro essa e le porte di uscita copiano il tutto\nlento\n\n\n2 bus\n\nbus tra le porte di entrata e uscita\n\nproblemi di congestione del bus\n\n\n\n\n3 interconnessione\n\nparallelismo\nsi divide in\n\ncrossbar\n\nmatrice di bus\n\n\nmultistage\n\npiccoli switch tra le due porte che indirizzano il tutto\n\n\n\n\n\n\n\n\n\n\n\n\nGestione del buffer*\n\ntroppo buffering causa aumenti di RTT facendo allocare troppi pacchetti nella rete\n3 politiche di scarto\n\ntail drop\n\nviene scartato l‚Äôultimo che arriva\n\n\npriorit√†\n\ni pacchetti hanno una priorit√†\n\n\nmarcatura\n\nprima di scartare invia dei segnali come ECN per avvisare che il buffer √® pieno\n\n\n\n\n3 algoritmi di scheduling per decidere quali mandare prima\n\nFCFS first come first served\n\nil primo che arriva √® il primo ad uscire\n\n\ncon priorit√†\n\nogni pacchetto viene classificato con una sua priorit√† e viene definito in quale ordine inviarli\nstarvation: una delle code potrebbe non essere mai selezionata\n\n\nRR Round Robin\n\nsempre diviso in classi ma si invia un po di tutto\n\n\nWFQ Weighted Fair Queuing\n\nogni priorit√† ha un suo spazio di banda per mantenere le cose fair\n\n\n\n\n\n\n\n\nIndirizzi IP e gestioni varie\n\n\nSottorete\n\ndefinizione\n\ninsieme di dispositivi che possono comunicare tra loro senza dover passare per un router ma uno switch si\n\n\n\n\n\nDHCP(Dynamic Host Configuration Protocol)\n\ndefinizione\n\n√® una alternativa al sistema manuale dove bisognava scrivere gli indirizzi IP in fase di inizializzazione della macchina\nin DHCP √® presente un server che assegna ai nuovi host in ingresso un IP dinamico che pu√≤ variare nel tempo\n\nquesto server si trova di solito interno ai router\n\n\n\n\n4 step del DHCP\n\n\n\nDiscover\n\n\nl‚Äôhost che entra nel server manda un broadcast per trovare se ci sono DHCP disponibili\n\n\n\n\nOffer\n\n\nil DHCP offre un indirizzo IP all‚Äôhost\n\n\n\n\nRequest\n\n\nl‚Äôhost conferma l‚ÄôIP offerto al DHCP\n\n\n\n\nAck\n\n\nil DHCP invia un Ack di assegnazione dell‚ÄôIP\n\n\n\n\nnon serve solo per IP\n\nsuggerisce quale Server DNS usare\nRouter First-Hop da usare\n\novvero router gateway, colui che si collega ad altre reti non interne facendo da tramite\n\n\n\n\n\n\n\n\nCome si ottengono IP pubblici/privati da condividere con la tua rete\n\nISP ha un grande blocco di indirizzi che assegner√† a sua volta ad ogni rete che ne richiede\n\nun ISP ha magari indirizzoIP/x\n\nquesto significa che ho i primi x bit fissi e gli altri posso usarli per definire IP di rete da condividere con i richiedenti\nse x=20 posso dare 2^{32-20} indirizzi IP\n\n\n\n\nRoute aggregation\n\n√® una tecnica di aggregazione di indirizzi IP per alleggerire la tabella di instradamento condivisa tra i vari ISP/grandi router\nognuno scrive sulla tabella solo il blocco di indirizzi senza precisarli tutti\nse un indirizzo IP specifico passa a un‚Äôaltra rete quella determinata rete deve fornire pi√π dettagli di quell‚Äôindirizzo IP\n\nricordiamo che viene data la precedenza alle corrispondenze migliori\n\n\n\n\n\n\n\nICANN\n\norganizzazione centrale che gestisce gli indirizzi IP al livello mondiale\n\nfornisce questi indirizzi IP a 5 grandi fornitori RR\n\nquesti 5 RR forniscono poi i vari blocchi di indirizzi agli ISP\n\n\n\n\n\n\n\nNAT(Network Address Translation)\n\ndefinizione\n\ngli indirizzi IPv4 sono limitati\n√® una tecnica che riduce gli indirizzi IPv4\nper ovviare a questo problema esistono ad esempio dei router NAT che consentono di utilizzare solo un indirizzo IP pubblico per tutta la rete che gestiscono\ni dispositivi della rete avranno un indirizzo IP privato\nil router NAT dovr√† ogni volta cambiare le varie intestazioni dei datagrammi mettendo l‚ÄôIP pubblico, i dispositivi esterni alla rete vedranno solo il router NAT come dispositivo nella rete e poi dovr√† essere lui a condividere i datagrammi corretti nella rete interna al dispositivo corretto\nper ricordarsi a chi deve condividere quel datagramma utilizza una tabella NAT con salvate le varie occorrenze\n\n\n\n\n\n\nIPv6\n\ndescrizione\n\nNasce per aumentare i possibili IP\n√® a 128 bit non a 32\n\n\ntunneling\n\nnon √® retrocompatibile ma ci sono router misti che usano entrambi gli IP\n\nlavorano su reti miste con router Dual Stack\nho un datagramma IPv6 che deve passare in una rete IPv4, per farlo incapsulo IPv6 in IPv4 e poi de capsulo il tutto\n\n\n\n\ncosa avviene nella frammentazione\n\nframmentazione non presente, scopro la MTU del datagramma IPv6 con PMTUD\n\n\n\n\n\n\nTabella dei flussi o di inoltro\n\nper capire dove inoltrare i vari datagrammi esiste questa tabella\nper gli inoltri di tipo generalizzato avevamo detto che non era sufficiente un indirizzo IP e basta\n\nvengono usati dei dati interni al datagramma ricercati con la funzione Match\nche poi forniscono le informazioni per una determinata Action che deve fare il router\n\ninoltro, scarto, modifica e se siamo in un SDN pu√≤ essere inviato al controller\n\n\nda qui nasce Match+ Action che √® la vera e propria tabella\nse due Match hanno due action diverse viene data una priorit√† alle Action  vince quella con priorit√† maggiore\n\n\n\n\n\n\nOpen flow\n\nconcetto\n\nrappresenta uno standard che caratterizza la struttura delle reti a SDN, dove il piano di controllo √® demandato a un controller\nOpenFlow ha una tabella che contiene\n\nMatch, √® diviso in livelli perch√© l‚Äôinformazione potrebbe stare su quello di collegamento, di rete, di trasporto\nAction azioni che si possono fare come blocchi\nPriorit√†, per Match con pi√π Action\nContatore dei byte o dei pacchetti, che tiene conto di quelli che hanno usato una certa regola\n\n\n\n\nprotocollo\n\nprotocollo utilizzato dai dispositivi OpenFlow come router ecc‚Ä¶ che permette di comunicare con il server controller della SDN\n\n\n\n\n\n\nLoad Balancing\n\ncaratteristica dell‚Äôinoltro generalizzato\nconsente di spalmare il carico su pi√π porte per instradare pi√π pacchetti che vanno a uno stesso indirizzo IP\n\n\n\nMiddleBox\n\ndispositivi che forniscono servizi all‚Äôinterno della rete e che non sono router\ncome i firewall o i NAT o i DHCP\n\n\n\nAlgoritmi di instradamento\n\ndefinizione\n\nAlgoritmi che si occupano di riempire la tabella di instradamento, cercando un percorso migliore con la distanza minore possibile tra i vari dispositivi nella rete\n\n\ntipologie\n\nGlobale\n\nha una visione ampia della rete\n\n\nNon globale\n\nnon ha bisogno di avere una visione ampia\n\n\nCentralizzato\n\ncalcolo dei percorsi centralizzato\nconoscenza globale della rete\n\n\nDecentralizzati (link-state)\n\nogni dispositivo deve calcolare i percorsi\ninizialmente il router conosce solo i costi dei dispositivi adiacenti\n\n\n\n\ninoltre anche\n\nstatici\n\ncambiano raramente\nrichiedono aggiornamenti manuali\n\n\ndinamici\n\nsi aggiornano automaticamente al variare dei costi dei vari collegamenti tra nodi\n\n\n\n\nDijkstra\n\nalgoritmo Globale link-state che consente di trovare il percorso migliore ha un funzionamento iterativo\n\n\nVector Distance\n\n√à di tipo decentralizzato\nSi basa sull‚Äôequazione di Bellman-Ford e funziona cos√¨: ogni router sa quanto costa raggiungere le reti vicine, e scambia informazioni con i router vicini per scoprire nuovi percorsi. Nel tempo, ogni router costruisce una tabella che indica: la distanza verso ogni rete e da quale router passare per raggiungerla nel modo pi√π economico.\ncambio dei costi\nproblema di conteggio infinito\n\ninversione avvelenata\n\n\n\n\n\nAS (Autonomous System)\n\ndefinizione\n\ninsieme di router scalabili interconnessi tra loro che si trovano nella stessa ISP o amministrazione di rete\nstrategia per gestire in modo scalabile l‚Äôinstradamento\n\n\ndifferenza tra\n\nintra-AS\n\ntutti i router che si trovano nella stessa AS e condividono gli stessi protocolli\n\n\ninter-AS\n\ninsieme dove deve essere effettuato un routing tra AS differenti, attraverso dei router gateway che appunto li collegano tra di loro\n\n\n\n\n\n\n\nprotocolli usati nell‚Äôintra-AS\n\nRIP\nEIGRP\nOSPF\n\ndefinizione\n\ndi tipo Link-State, i router si scambiano tra loro le varie informazioni di instradamento in broadcast(flooding) e aggiornano cos√¨ la mappa di instradamento\nil messaggio usa protocollo TCP e algoritmi di Dijkstra per effettuare i calcoli\n\n\n√® divisa in 2 livelli ma riguarda comunque tutta la intra-AS\n\nArea Locale\n\nsottoinsieme della rete senza router gateway\n\n\nBackbone\n\nDorsale che collega tutti i dispositivi della stessa area intra-AS\n\n\n\n\nestensioni associate\n\nper reti senza SDN viene usato OSPF, permettendo di scambiare informazioni utili per effettuare instradamenti corretti senza uso di SDN\nMPLS-TE protocollo che consente di evitare congestione\n\n\n\n\n\n\n\n\nBGP protocollo usato nella inter-AS\n\ndefinizione\n\npermette di far comunicare tra loro i vari router gateway si divide in due modalit√†\n\n\ni-BGP\n\nmodalit√† che consente di inviare informazioni alla intra-AS riguardo le cose che vengono inviate dalla inter-AS\n\n\ne-BGP\n\nmodalit√† che consente lo scambio di informazioni tra AS esterne\nfunziona attraverso annunci\n\n\nsessione BGP\n\n√® una connessione TCP semi permanente tra i router gateway detti peers\n\n\nmessaggi BGP\n\nservono per stabilire e mantenere la connessione TCP tra peer\n\nkeepalive\n\nserve per mantenere la connessione attiva\n\n\nopen\n\navvia connessione tra due peer\n\n\nupdate\n\nannuncia nuove rotte o ritira vecchie rotte\n\n\nnotification\n\nsegnalazione di errori\n\n\n\n\n\n\nconcetto di rotta BGP\n\ninsieme di informazioni inviate tra AS che indicano il percorso da seguire\n\nprefisso\n\nindica la rete di destinazione con il vero e proprio indirizzo\n\n\nattributi\n\ninformazioni sul percorso per evitare cicli oppure trovare facilmente il primo router di salto\n\n\nAS-PATH\n\nindica il vero e proprio percorso, la successione di AS\n\n\nNext-Hop\n\nrappresenta il router gateway\n\n\n\n\n\n\nEsempio con o senza percorsi multipli\n\nsolo i router gateway possono modificare router di next hop per indicare ‚Äúse volete inviare ad altre AS passate per me‚Äù\nun router che lavora in inter-AS annuncia anche l‚ÄôAS-PATH ovvero il percorso che deve seguire per raggiungere quella determinata destinazione\nsu percorsi multipli √® simile solo che vengono seguite delle policy\n\n\nCriteri usati da router BGP per riempire tabella di instradamento\n\n1.Next Hop modificato\n\ni router gateway modificano il Next-Hop su loro stessi cos√¨ i dispositivi nella intra-AS devono solo raggiungerlo seguendo un percorso nella inter-AS mediante OSPF\n\n\n2.Next Hop non modificato\n\nil router gateway non modifica il Next-Hop e lascia quello da lui raggiungibile di un‚Äôaltra AS, i dispositivi interni devono capire che devono passare per il router gateway\n\n\n3.Instradamento a patata bollente\n\nse ci sono pi√π percorsi simili prende quello meno costoso mandando il pacchetto nella inter-AS meno costosa per far passare il traffico il pi√π velocemente possibile\n\n\n4.Forzare percorsi tramite annunci\n\nannuncio=azione di inviare un messaggio update tramite BGP\nper non intasare il traffico della sessione BGP vengono inviati solo gli annunci pi√π utili\nse ad esempio so che un AS pu√≤ raggiungerne un altro senza passare per un determinato AS, esso sceglie di non annunciare il proprio percorso\n\n\n\n\n\nIP ANYCAST\n\ndefinizione\n\npi√π server con stesso indirizzo IP pubblico, il client avr√† scambi con quello pi√π vicino\noffrono stessi contenuti o servizi\n\n\n\n\nIngegneria del traffico\n\ndefinizione\n\ninsieme di tecniche che consentono di modulare e ottimizzare il traffico della rete\n\n\n\nConcetto di IBN(Intent-Based-Networking)\n\ndefinizione\n\nsistema dichiarativo che funziona attraverso intenti per modificare la struttura della rete in modo automatizzato\nes: voglio ridurre la latenza tra due router, spiego l‚Äôintento e essi verranno configurati in tal maniera\ncolui che effettua queste modifiche √® il controller SDN\n\n\n\nODL e ONOS\n\ndefinizioni\n\ndue tipi di controller\nODL\n\nusa API per comunicare con applicazioni\n\n\nONOS\n\ncontroller che usa nel pratico il concetto IBN con gli intenti\n\n\n\n\n\nICMP(Internet Control Message Protocol)\n\n\ncosa √®\n\nprotocollo incapsulato nel protocollo IP consente di scambiare messaggi utili per la gestione tra host e router\n\n\n\nmessaggio ICMP\n\ncomposto da\n\ntipo\ncodice\nchecksum\naltri dati\n\n\n\n\n\ntipi di messaggio\n\n1.Echo Request(0) o Reply\n\npermettono di capire se un host √® raggiungibile e con quale distanza\n\n\n2.Destination Unreachable(3)\n\nutilizzato per segnalare Host non raggiungibili\n\n\n3.Source Quench\n\npermetteva di segnalare congestioni ora deprecato\n\n\n4.TTL expired(8)\n\nserve per quando imposti un determinato limite di hop utilizzando un contatore TTL che decrementa ad ogni hop\nse arriva a 0 invia questo segnale\n\n\n\n\n\n\nTraceroute\n\nstrumento di diagnostica per capire quanti hop deve effettuare un pacchetto sonda per raggiungere un determinato punto di destinazione\ndi volta in volta si incrementano i TTL\n\n\n\n\nnuova versione ICMPv6\n\nadattato ai nuovi router che non fanno troppa frammentazione\n\n\n\nGestione delle reti\n\ndescrizione e componenti\n\nper gestire una rete adeguatamente si ha bisogno di\n\nserver di gestione\n\nserver che raccoglie dati e invia comandi per configurare i dispositivi della rete\n\n\ndispositivi di rete da gestire\n\nrouter switch ecc‚Ä¶\n\n\ndati\n\ndati utilizzati per gestire la rete come statistiche varie\n\n\nagente di gestione\n\nSoftware di gestione della rete\n\n\nprotocollo di gestione di rete\n\nprotocolli utilizzati per comunicare ai dispositivi i vari cambiamenti\n\n\n\n\n\n\nmetodi per gestire una rete\n\nCLI\n\nlinea di comando manuale\nmetodo diretto ma non scalabile anche se prevede uso di eventuali script automatizzati\n\n\nSNMP/MIB\n\ninterfaccia server che usa come protocollo di comunicazione per i dispositivi SNMP\ni dati raccolti sono organizzati in MIB\nnon propriamente automatizzato\n\n\nNETCONF/YANG\n\nYANG √® un linguaggio astratto che consente di configurare delle reti\nla configurazione e la modifica di questi YANG per poi cambiare i dispositivi remoti sono mediante un protocollo NETCONF\nconsente commit atomici\nideale per reti complesse, dinamiche e centralizzate\n\n\n\n\n\nLIVELLO DI COLLEGAMENTO\nLIVELLO DI COLLEGAMENTO\n\nintroduzione\n\nil livello di collegamento si occupa di trasferire i datagrammi da un nodo a quello fisicamente adiacente lungo il percorso\n\nha una visione pi√π dettagliata su dispositivi come switch\n\n\nil livello di collegamento si serve di frame, con al loro interno i datagrammi incapsulati\n\n\nservizi del livello di collegamento\n\nFraming\n\nprocesso di incapsulamento dei datagrammi che provengono dal livello di rete aggiungendo intestazione e trailer che servono a delimitare la singola unit√†\n\n\nAccesso al collegamento\n\neffettuare un accesso al mezzo di trasmissione condiviso tra dispositivi si usano protocolli MAC(Medium Access Control)\nper identificare i dispositivi che condividono questo stesso mezzo di trasmissione si usano gli indirizzi MAC che identificano univocamente la scheda di rete del dispositivo, √® statico a differenza degli IP che lavorano sul livello di rete\n\n\nConsegna affidabile tra nodi adiacenti\n\nservizi che rilevano errori, usati soprattutto in reti wireless dove ci sono errori pi√π frequenti\n\n\nControllo del flusso\n\nRegola la velocit√† di trasmissione del singolo collegamento\n\n\nRilevazione degli errori e correzione\n\nOgni protocollo di collegamento ha controllo sui vari errori e possono essere risolti con o senza ritrasmissioni\n\nARQ(Automatic Repeat reQuest) con ritrasmissioni\nFEC(Forward Error Correction) senza ritrasmissioni\n\n\n\n\n\n\ntipi di trasmissione\n\nHalf duplex\n\nLa trasmissione non pu√≤ essere simultanea da entrambe le direzioni\n\nWifi\n\n\n\n\nFull duplex\n\nLa trasmissione √® simultanea per entrambe le direzioni\n\nEthernet\n\n\n\n\n\n\nLivello di collegamento negli host\n\ncome componenti del livello di collegamento gli host hanno la scheda di rete detta\n\nNIC(Network Interface Card) che fa da intermediario sia del livello fisico che quello di collegamento\n\n\nCome √® fatto un host\n\nmittente\n\nil mittente sfrutta il controller nella scheda di rete per\n\nincapsulare il datagramma dentro un frame\naggiungere vari bit di controllo\ngestire flusso trasferimento affidabile ecc‚Ä¶\n\n\nla CPU dell‚Äôhost consente di costruire i dati e interagisce con la NIC(Network Interface Card) per assemblare il pacchetto\n\n\ndestinatario\n\nil controller della scheda di rete\n\nverifica eventuali errori nei bit ricevuti\ngestisce anche lui trasferimento affidabile e flusso\nestrae il datagramma dal frame\n\n\nla CPU in questo caso prende i dati e li passa ai livelli superiori rete trasporto ecc‚Ä¶\n\n\n\n\n\n\n\n\nRilevazione degli errori\n\n\nintroduzione alla rilevazione degli errori\n\nper rilevare errori si usano tecniche come l‚Äôutilizzo di un codice EDC(Error Detection and Correction)\n\nquando vengono inviati dei dati D viene aggiunto questo codice EDC\nquesto codice EDC viene generato a partire da una funzione applicata sui dati D\nuna volta generato viene inviato al destinatario\nil destinatario adesso riceve questi dati D ci riapplica la funzione e vede se corrisponde a EDC precedente\nnon √© super affidabile e in pi√π c‚Äô√® overhead\n\n\n\n\n\n\n3 tecniche utilizzate per fare controllo sugli errori migliori di EDC\n\nBit di parit√†\n\nObbiettivo\n\nvengono presi i dati in bit e vengono aggiunti eventuali bit per rendere il numero di 1 totali pari\ndopo aver inviato il tutto se il numero di bit a 1 compreso quello di parit√† sono dispari, errore\nunico problema se ho errori su un numero di bit pari ritornerei comunque a una sequenza pari quindi non rileverei errori\nvengono spesso usate matrici di bit per verificarli\nparit√† bidimensionale\n\ncreare una matrice per calcolare parit√† su righe e colonne\ncomprende anche un bit globale\n\n\n\n\nChecksum\n\nObbiettivo\n\nIl checksum √® un meccanismo di controllo dell‚Äôintegrit√† dei dati che viene usato principalmente a livelli superiori come quello di trasporto con UDP TCP ecc‚Ä¶ oppure anche sul livello di rete come IP\n\nil mittente prende il contenuto del pacchetto come una sequenza di interi, la somma facendo il complemento a 1\n\novvero la somma con i suoi bit normali e la sua controparte in complemento a 1\n\n\nil risultato viene a sua volta complementato a 1 e lo inserisce nel campo checksum\n\n\nil ricevente somma tutto compreso checksum\n\ncontrolla se il risultato sono tutti 1 per vedere se non ci sono errori\n\n\n\n\n\n\nCRC\n\nSistema estremamente affidabile per rilevare errori\nil mittente tratta i dati come una lunga sequenza di bit e li divide per un polinomio binario predefinito\n\nil resto della divisione CRC viene allegato al frame\n\n\nil destinatario svolge la stessa divisione e verifica il resto\n\nse √® 0 i dati sono probabilmente corretti altrimenti c‚Äô√® stato un errore nella trasmissione\n\n\n\n\n\n\n\n\n\nCollegamenti e accesso multiplo\n\nPunto a Punto\n\ncollegamento di tipo punto a punto\ncomposta da un trasmittente e un ricevente\n\n\nBroadcast\n\ncanale di collegamento che comprende pi√π nodi che trasmettono e piu nodi che ricevono\npresentano problemi di accesso multiplo da risolvere\n\n\n\nGestione accesso multiplo\n\nIniziamo con la spiegazione di un protocollo ideale MAC\n\nMultiple Access Channel\nin modo ideale √® previsto che se in un collegamento ho pi√π nodi ho trasmissione pari a R/M\nse invece ho solo un dispositivo avr√≤ velocit√† R totale\ninattuabile\n\n\n\nTipi di protocolli ad accesso multiplo reali\n\n\nsi dividono in\n\nChannel Partitioning\n\ncon canale suddiviso\nogni nodo ha una sua fetta del canale\nle fette rimanenti sono inutilizzate\n\n\nRandom Access\n\nil canale presenta collisioni e per risolverle vengono fatte ritrasmissioni e operazioni di recover\n\n\nTaking Turns\n\ni nodi usano il canale a turno\ni nodi con maggiore priorit√† potrebbero avere il turno pi√π duraturo\n\ntipo i nodi con pi√π materiale da inviare\n\n\n\n\n\n\n\nQuelli a Channel Partitioning\n\nTDMA\n\nil canale viene suddiviso per istanti temporali fissi\n\ndetti time slot\nogni nodo ha il suo timeslot\nin quel timeslot ha accesso completo\ngli slot inutilizzati si dicono idle\n\n\n\n\n\n\n\n\nFDMA\n\nil canale viene suddiviso in spettri di frequenze diverse interna un cavo FDM\nogni nodo trasmette sulla sua frequenza non alla massima velocit√†\n\n\n\n\nQuelli ad Accesso casuale\n\nSLOTTED ALOHA\n\nl‚Äôuso del collegamento √® diviso in slot temporali\nogni nodo che vuole inviare qualcosa accede attende il prossimo slot temporale libero e vi accede\n\nse viene occupato prima da qualche altro nodo avviene una collisione e deve attendere il time slot successivo\n\n\nogni nodo decide in autonomia quando trasmettere\npossono esserci collisioni frequenti o inutilizzi di slot temporali\ni nodi devono essere sincronizzati\nun nodo pu√≤ utilizzare il canale in modo efficace con una probabilit√† del 37% del tempo\n\n\n\n\n\n\nUNSLOTTED ALOHA\n\nsenza sincronizzazione tra nodi\n\ntrasmettono finch√© non avviene una collisione\ni nodi non aspettano il time slot successivo\n\n\ndiminuisce probabilit√† di efficienza arrivando al 18%\n\n\n\nCSMA\n\nil nodo prima di trasmettere ascolta il canale e vede se √® libero o occupato\npossono comunque esserci collisioni dovute a ritardi di propagazione\n\n\n\nCSMA/CD\n\nmiglioria di CSMA con una detection delle collisioni\nil nodo che trasmette rimane in ascolto di eventuali collisioni\nse avviene smette di trasmettere cos√¨ non viene sprecata banda per un frame che andrebbe perso\n\nnon funziona bene via wireless\n\n\nfunzionamento\n\nun nodo sta trasmettendo nel collegamento, allo stesso tempo si mette in ascolto per vedere se ci sono collisioni in atto\nse un nodo prova a collegarsi il nodo che trasferiva i dati lo rileva\nsi interrompe la trasmissione dei nodi coinvoli nella collisione\nviene segnalata\ne poi viene assegnato un tempo casuale di accesso ad ogni nodo coinvolto e si riprende cos√¨ il tutto\n\n\n\n\n\n\nQuelli a Taking Turns\n\nPOLLING\n\n√® presente un controllore centralizzato che dice ai nodi quanti frame possono trasmettere al massimo per un dato turno\nil fatto che ci sia un controllore aumenta il ritardo ma allo stesso tempo si riducono collisioni o slot inutilizzati\nusato nel Bluetooth\n\n\n\n\n\n\nToken Passing\n\nToken che viene passato per ogni nodo, chi lo ha pu√≤ usare il collegamento\n\n\n\n\nGestione via cavo di\n\ndownstream\n\nvengono usati canali FDM in broadcast\n\n\nupstream\n\nviene usato il sistema ad accesso casuale\n\n\nper mettere d‚Äôaccordo i vari modem via cavo viene usato uno standard DOCSIS che precisa quali tipologie di politiche di accesso devono essere usate\n\n\n\nLAN\n\nDefinizione\n\nLocal Area Network\nindica una area ristretta come una casa o una scuola\n\n\nspesso si usano Ethernet o Wifi\n\nIndirizzi MAC\n\ndescrizione\n\nPer identificare un dispositivo di rete ad esempio una scheda di rete per effettuare uno scambio dei frame abbiamo bisogno di un indirizzo MAC, √® a 48 bit ed √® memorizzato nella ROM della NIC Network Interface Card\n\n\ncome vengono scelti IEE\n\nente internazionale che ha lo scopo di gestire e fornire indirizzi MAC ai vari produttori di NIC\n\n\n\nDa IP a MAC\n\nViene utilizzato un protocollo ARP che ha una tabella ARP dove sono presenti\n\nOgni nodo IP nella LAN con le sue interfacce e il suo Indirizzo MAC con anche un TTL per la validit√† dell‚Äôinformazione\n\n\n\n\nProtocollo ARP\n\nCome funziona Se la tabella non presenta il MAC di un dato IP\n\nse un nodo nella rete vuole avere il MAC di un dispositivo usa il protocollo ARP che invier√† un broadcast di richiesta con quel determinato indirizzo IP\nil dispositivo corretto risponde\nora potr√† essere popolata la tabella ARP\n\n\nAttacco ARP SPOOFING o POISONING\n\nviene inviata una risposta ARP falsa fingendosi di avere un‚Äôaltro indirizzo IP\nfai confluire il traffico verso di te puoi intercettarlo oppure puoi fare un attacco Dos associando 1000 indirizzi IP allo stesso MAC\n\n\n\n\nCome inviare un datagramma a un nodo non adiacente nella rete\n\nSe il destinatario si trova su un‚Äôaltra sottorete allora bisogna instradare il frame a un router gateway\nviene creato un frame con all‚Äôinterno il datagramma IP con le varie informazioni\nil router riceve il frame e lo decapsula, vede il datagramma che l‚ÄôIP √® da inoltrare a un altro dispositivo\nre incapsula il tutto e lo invia alla interfaccia dello switch corretta con il giusto destinatario\n\n\n\nETHERNET\n\ncosa √®\n\nStandard di comunicazione utilizzato per le reti LAN cablate\n\n\nframe ethernet\n\ncomposto da\n\npreambolo\n\nsincronizza il ricevente e segnala quando un frame inizia\n\n\nMac di destinazione\nMAC di sorgente\nTipo di protocollo incapsulato nel payload per poi de capsularlo e vedere cosa c‚Äô√®\nDati\nCodici di controllo errori CRC\n\n\nTutti gli standard di Ethernet usano stesso frame\n\n\n\nsicurezza di ethernet\n\n√® senza handshake\nvengono gestiti accessi multipli come ad esempio con CSMA/CD\nle altre sicurezze varie vengono gestite ai livelli superiori\n\n\nConcetto di dominio di collisione\n\npunto in cui si condivide stesso mezzo di trasmissione\nsi pu√≤ verificare una collisione tra vari frame ethernet se si trasmette insieme\nsi consiglia di ridurre i dispositivi collegati a un singolo collegamento\n\n\n\nSwitch Ethernet\n\nCosa sono\n\nLo switch √® un dispositivo che lavora sul livello di collegamento\nha il compito di memorizzare e inoltrare i frame Ethernet\n\n\nCaratteristiche\n\n√® plug and play non devi configurarlo\n\n\nTabella di commutazione degli Switch\n\nOgni switch ha una sua tabella di commutazione con un\n\nindirizzo MAC del nodo\ninterfaccia che conduce al nodo\nTTL\n\n\nlo switch auto riempie le varie tabelle\n\nogni volta che riceve un frame aggiunge alla tabella il mittente\n\n\n\n\nCosa fa lo switch quando riceve un frame\n\nAggiorna la Switch table mettendo il mittente\nse il mittente ha stessa porta del destinatario allora non serve che ci sia questo passaggio per lo switch e scarta il pacchetto\nse √® su un‚Äôaltra porta lo inoltra facendo lo switching\nse non ha nella tabella il destinatario fa una operazione di flood per trovarlo\n\n\nDifferenze con i router\n\ngli switch lavorano sul livello di collegamento i router no\ngli switch possono lavorare con pochi dispositivi perch√© usano una tabella normale\n\n\n\n\nVLAN\n\n\ncosa sono\n\nSe si ha bisogno di utilizzare il concetto e la comodit√† delle LAN su reti di grandi dimensioni senza per√≤ dover ricorrere a un solo Switch che non garantirebbe privacy e problemi di dimensioni della tabella\nesistono le VLAN\n\nsi possono usare switch differenti per rimanere sulla stessa rete ma allo stesso tempo creare flessibilit√† di gestione\n\n\n\n\n\nversione basata sulle porte\n\nun singolo switch viene usato come due switch differenti per mantenere la sicurezza\nuno switch viene diviso a met√† virtualmente\n\n\n\n\nversione con pi√π switch\n\nviene usata una porta trunk per collegare in serie pi√π switch\nuna volta collegato il tutto possono comunicare tra loro gli switch\n\n\n\nEVPN\n\ntecnologia di tunneling che consente di creare una rete locale anche se si hanno due reti di livello 2 quindi con switch su luoghi differenti\n\nviene collegato il router allo switch e viene incapsulato il frame ethernet che poi verr√† passato dall‚Äôaltra parte con un altro router e switch\n\n\n\n\n\nle VLAN hanno un loro ID per comunicare tra loro e riconoscersi\n\nquest‚Äôultimo √© definito dallo standard 802.1Q\n\n\n\nLE RETI WIRELESS\n\nsignificato di wireless\n\nTecnologia di collegamento senza l‚Äôuso di fili ma attraverso frequenze\n\n\nsignificato di mobilit√†\n\npropriet√† dell‚Äôinfrastruttura di rete che consente al client di muoversi cambiando punti di accesso\n\n\nHandover\n\nProcesso che consente a un dispositivo mobile di cambiare collegamento wireless senza problemi\n\n\nComponenti che compongono una rete wireless\n\nHost wireless\n\ndispositivi che eseguono operazioni e hanno un collegamento wireless\nsi dividono in fissi o stazionari\n\n\nCollegamento wireless\n\nUtilizzato per collegare un host wireless alla stazione base oppure un altro host wireless\n\n\nStazione base\n\nelemento che funge da ripetitore\ndi solito connessa a una rete cablata\ndispositivo di relay al livello di collegamento\n\n\n\n\na una determinata velocit√† di banda varia il raggio di copertura\n\n2 Tipi di infrastrutture\n\n\ncon infrastruttura\n\nSono presenti stazioni base che hanno il compito di offrire servizi di rete\navvengono operazioni di handoff, quando un dispositivo si sposta dall‚Äôarea di copertura e cambia punto di accesso\n\n\n\n\nsenza infrastruttura\n\nreti senza stazione base con host che comunicano tra di loro\ndevono provvedere da se per fornire servizi di instradamento\n\n\n\n\nCaratteristiche dei collegamenti wireless\nConcetto di attenuazione\n\nil segnale pu√≤ essere assorbito o attenuato a seconda della presenza di determinati ostacoli o anche solo dalla distanza\nl‚Äôattenuazione con spazio libero si calcola con\n\n(frequenza‚ãÖdistanza)^2=(fd)^2\nPi√π alta √® la frequenza o pi√π lontano √® il ricevitore, pi√π rapidamente si perde il segnale.\n\n\n\n\nTempo di coerenza\n\nTempo che ci indica se all‚Äôarrivo di un segnale ne possono arrivare degli altri uguali a causa di possibili riflessioni a distanza di un determinato tempo\n\nquesto tempo √® detto di coerenza\n\n\n\ninterferenze da altre sorgenti\n\nIl fenomeno fisico di interferenza pu√≤ anche verificarsi a causa di altri dispositivi che lavorano su frequenze simili\n\nper definire il segnale e la frequenza su cui lavoriamo usiamo il SNR(Signal-To-Noise-Ratio)\n\nrappresenta un rapporto tra il segnale e il rumore di fondo\nun SNR alto consente di estrarre le informazioni facilmente\n\n\nIl BER  (Bit error rate) rappresenta la probabilit√† che un bit sia ricevuto in errore\n\n\nBilanciamento di rete\n\naumentare la potenza del segnale aumenta la SNR e riduce i BER\n\nma non √® proprio facile da attuare dovuto a consumi eccessivi\ni dispositivi wireless si adattano automaticamente modulando la frequenza e la velocit√† di trasmissione\ncos√¨ da avere maggiore stabilit√†\n\n\n\n\nTerminali nascosti\n\nI terminali nascosti sono nodi che non possono vedere altri nodi perch√© sono fuori dalla loro portata ma possono comunque causare collisioni che li riguardano\n\nad esempio con un nodo intermedio che vede entrambi\n\n\n\n\nAccesso multiplo\n\nCDMA\n\nprotocollo che permette di condividere stessa frequenza di comunicazione con pi√π utenti\nogni utente ha un suo codice unico chiamato chipping sequence per identificarli\nil loro segnale √® codificato su questo\n\n\n\n\n\nStandard Reti Wi-Fi 802.11\n\n\nrappresenta un insieme di protocolli che consentono la comunicazione wireless tra pi√π dispositivi\n\n\nArchitettura delle LAN 802.11\n\ngli host wireless comunicano con una stazione base detta anche Access Point\nle singole infrastrutture wireless sono dette BSS e hanno vari host punto di accesso ecc‚Ä¶\n\n\n\n\nDivisione dei canali\n\ntecnica che consente la modulazione di frequenze per creare una divisione dei canali di comunicazione\nci√≤ comunque non riduce a zero le interferenze\nquesti canali vengono scelti dal AP admin\n\n\n\n\ningresso di un dispositivo nella rete\n\nun host in arrivo su una BSS deve essere associato a un AP e per farlo si hanno due modalit√†\n\nscansione attiva\n\nil dispositivo che si collega deve mandare un frame sonda in broadcast per trovare l‚ÄôAP corretto\n\n\npassiva\n\ngli AP a intervalli regolari inviano questi frame beacon per essere rilevati dai dispositivi che vogliono accedervi\n\nal loro interno hanno un MAC e un identificativo dell‚ÄôAP il SSID\n\n\n\n\n\n\ndopo aver instaurato questo collegamento con accessi sicuri attraverso ad esempio WPA2\nl‚Äôhost pu√≤ inviare un DHCP discover che sar√† passato all‚ÄôAP e poi al server DHCP\n\n\n\n\ncollisioni nelle reti wireless\n\nCSMA/CA\n\nper gestire accesso multiplo nelle reti WiFi non si possono usare CD ovvero collision Detection perch√© con le reti wireless √® complesso e inutilizzabile vengono usate variabili\nDIFS\n\nvariabile che indica l‚Äôintervallo di tempo che bisogna aspettare per vedere se un canale √® libero\nse lo √® il mittente trasmette\nsenn√≤ aspetta un tempo backoff casuale\n\n\nSIFS\n\nvariabile che indica un intervallo di tempo che deve aspettare il destinatario prima di inviare un ACK di ricevuta dei dati\n\n\n\n\nMeccanismo di prenotazione\n\nvengono usati segnali RTS(Request to Send)\n\nper prenotare il canale di comunicazione\n\nvengono inviati ai vari AP\n\n\npossono avvenire collisioni di prenotazione\n\n\n\n\n\n\n\nquando un frame viene passato a un AP ha come destinazione l‚Äôindirizzo MAC dell‚ÄôAP\n\nquando un frame deve passare per un router viene incapsulato in un altro frame che avr√† come mittente il MAC dell‚ÄôAP e come destinatario il MAC del router\n\n\n\nTecnologie wireless\n\n\nBluetooth\n\ndefinizione\n\nTecnologia wireless che consente un collegamento di tipo PAN(Personal Area Network)\n\n\npiconet\n\nnome che prende una singola rete Bluetooth che consente fino a 8 dispositivi compreso 1 master controller\n\n\nbootstrapping\n\nprocesso di accesso a una piconet di un dispositivo client\nsi divide in 2 modalit√† possibili\n\nNeighbor discovery\n\nil master invia dei messaggi in broadcast detti inquiry\nil dispositivo in ascolto lo rileva e instaura cos√¨ una connessione\n\n\nPaging\n\nil master invita un dispositivo specifico a entrare quando lo conosce\n\nviene successivamente comunicato l‚Äôindirizzo di partecipazione e altre informazioni utili\n\n\n\n\n\n\n\n\n\n\n\n\nReti 4G/5G\n\ndefinizione\n\nTecnologia funzionale che consente il collegamento wireless su WAN\nattraverso Access Point\n\n\nsimilarit√† e differenze con internet cablato\n\nUsano stessi protocolli e sono reti globali\ntecnologie radio da parte delle reti 4G\nsupporto alla mobilit√† nativa da parte delle reti 4G/5G\n\n\narchitettura 4G\n\ncomposta da\n\nMobile device(UE)User Equipment\n\ndispositivi mobili connessi alle base station\nha un IMSI ovvero un suo identificativo\n\n\nBase station(eNode-B)\n\ndispositivo che condivide le informazioni ai mobile Device\n\ncoordinandoli tra loro e gestendo le varie celle di collegamento\n\n\ngestione di handover per mobilit√† dei device\n\n\nMME(Mobility Management Entity)\n\nServizio che\nconosce la posizione dei vari dispositivi\nfa da intermediario con i dispositivi e i P-GW\nidentifica i dispositivi usando l‚ÄôHSS\n\n\nHSS(Home Subscriber Server)\n\nmemorizza le informazioni degli utenti con le varie chiavi di autenticazione\nServe per identificare i dispositivi con ad esempio il loro piano dati\n\n\nS-GW\n\nrouter gateway interno alla rete che instrada i dati da parte delle UE verso i P-GW\n\n\nP-GW\n\nrouter gateway che porta a internet i dati che vengono dalle S-GW attraverso il tunneling\nrouter connesso alla vera e propria rete globale\n\n\n\n\n\n\nmigliorie del 5G\n\nmaggiore velocit√†\npotrebbero esserci problemi di distanza di banda\n\n\n\n\n\n\nRete LTE\n\ndefinizione\n\nStandard di comunicazione wireless con delle modifiche alle reti 4G soprattutto nella fase di tunneling dei dati √® diviso in 2\n\n\npiano di controllo\n\ngestisce la mobilit√† e la sicurezza\n\nnon trasporta i dati effettivi\n\n\n\n\npiano di dati\n\ntrasportare il vero e proprio traffico dati\n\n\npila protocollare LTE\n\nogni comunicazione LTE ha una sua pila protocollare che si differisce in 2 punti\n\n\n\nquando avviene lo scambio dal UE al first hop nella base station abbiamo un incapsulamento complesso che vuole garantire sicurezza e affidabilit√† nella gestione dei segnali radio\n\n\n\n\nuna volta raggiunto invece il passaggio di tunneling dove i dati passano tra i vari Gateway attraverso un tunnel\n\n\nla comunicazione avviene attraverso u n protocollo GTP-U\nche impacchetta i dati in un pacchetto UDP per poi spedire i dati al P-GW passando per l‚ÄôS-GW\n\n\n\n\n\n\n\n\n\n\nproblema della mobilit√†\n\ndefinizione\n\nquando un dispositivo si muove bisogna rinstaurare una connessione a una base station con la copertura adatta e che magari √® collegata a un router differente\n\n\nHome agent\n\ndefinizione\n\nNodo nella rete che rappresenta il riferimento per la ricezione dei dati del dispositivo UE\n\n\n\n\napprocci di routing\n\n1.il router della base station differente annuncia agli altri che il dispositivo ha effettuato questo cambiamento e viene aggiornata la tabella di routing\n\ncon troppi dispositivi non funziona\n\n\n2.viene sfruttato il concetto di Home agent,\nsi divide in 2 altri sottopunti\n\n1.ROUTING INDIRETTO\n\nl‚Äôhome Agent invia i dati che riceve per quel determinato UE al nuovo router della nuova base station\n\n√® lento e vengono fatti giri troppo lunghi\n\n\n\n\n2.ROUTING DIRETTO\n\ni mittenti che vogliono mandare i messaggi all‚ÄôUE non inviano pi√π le informazioni all‚ÄôHome agent ma al nuovo router della base station\n\nveloce ed efficiente ma i mittenti devono capire il tutto\n\n\n\n\n\n\n\n\n\n\n\n\n\nLe reti si dividono in\n\nhome network\n\nrete gestita dall‚Äôoperatore con cui si ha un contratto\n\n\nvisited network\n\nrete gestita da altri operatori\nviene concessa attraverso il roaming\n\n\n\n\n\n"},"UNI/ANNO-2/RETI/TICKET-TO-RIDE-PRATICO":{"slug":"UNI/ANNO-2/RETI/TICKET-TO-RIDE-PRATICO","filePath":"UNI/ANNO 2/RETI/TICKET TO RIDE PRATICO.md","title":"TICKET TO RIDE PRATICO","links":[],"tags":[],"content":"Ritardo_{e2e‚Äã}=T_{tx}‚Äã+T_{prop‚Äã}+T_{queue}‚Äã+T_{proc}‚Äã\nT_{trasm}‚Äã=L/C‚Äã\nT_{prop}‚Äã=d/v‚Äã\nT_{queue‚Äã}=inizio¬†\\ trasmissione¬†\\ effettiva‚àítempo¬†\\ di¬†\\ arrivo¬†\\ al¬†\\ nodo\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSimboloNomeValorekkilo10¬≥ = 1.000Mmega10‚Å∂ = 1.000.000Ggiga10‚Åπ = 1.000.000.000\nRitardo¬†totale‚âàœÑ1‚Äã+œÑ2‚Äã+œÑ3‚Äã+\\frac{D_{bit} file}{\\min_i(C_i)}\n\nritardi di propagazione+ Dim bit/bandapi√πlenta\nRitardo_{e2e‚Äã}\\ 1 \\ tunnel= MIN\\{R_C,R_S,R/LINK\\}\nCollodibottiglia/client o server\n Tempo \\ utilizzo \\ singolo \\ link =R_S/R_C\nse per un collegamento passano pi√π collegamenti, moltiplica per il numero di collegamenti\n\nCorrezione errori\n1101 1010 1001 0110\n\nEDC con bit di parit√†\n\ndividi in 4 gruppi\n\nfai matrix\nbit di parit√† x righe e colonne\ne quello globale\n\n\n\n\nEDC con checksum\n\ndividi in gruppi da 16\ngruppo 1+gruppo 2\n\nris+gruppo 3\n\n\nriporto lo elimini sommandolo ai meno signific\ncompl a 1\n\n\n\nCSMA/CD\n\nil vincolo √®\n\nT_{trasmissione} \\geq 2*T_{propagazione}\nT_{trasm}‚Äã=L/R\n\nDimensione/velocit√† del collegamento\n\n\nT_{prop}‚Äã=d/v‚Äã\n\ndistanza/velocit√†\n\n\n\n\n\nTCP RENO\n\nserve sapere il tasso di trasmissione al TCP reno si calcola facendo\nT_{trasmissione}=\\frac{W*MSS}{RTT}\n\nR\\geq \\frac{W*MSS}{RTT}\nda questa considerazione  sopra si pu√≤ ritrovare W facendo la formula inversa\n\n\nPoi trovi il troughput medio\n\ntroughput \\ medio = \\frac{3}{4}*\\frac{W_{max}*MSS}{RTT}\n\n\nPer trovare il tempo impiegato per raggiungere la dimensione massima\n\n(W_{max}-\\frac{W_{max}}{2} )*RTT\n\n\n\nnumero /x\n2^x-2\\geq interfacce"},"UNI/ANNO-2/RETI/TICKET-TO-RIDE-TEORICO":{"slug":"UNI/ANNO-2/RETI/TICKET-TO-RIDE-TEORICO","filePath":"UNI/ANNO 2/RETI/TICKET TO RIDE TEORICO.md","title":"TICKET TO RIDE TEORICO","links":[],"tags":[],"content":"Livello di applicazione\n\nPila protocollare\nLivello di applicazione\n\nArchitetture del livello di applicazione\n\nPeer to peer\n\ntit for tat\ntorrent\nchunk\n\n\nClient Server\n\n\nSocket cosa sono\nProtocolli di applicazione\n\nHTTP\ncosa √®\n\nMessaggio HTTP(Metodo, versione, cookie, URL richiesto)\nv1\nv1.1\nv2\nv3\n\n\nBiscottini\nDNS\n\nSERVER DNS\niterativa\nricorsiva\n\n\nEmail\n\nUser agent\nServer mail\nSMTP\nIMAP\n\n\nWeb Cache e proxy\nRTT\n\n\n\n\n\nLivello di Trasporto\n\nLivello di trasporto\n\nmultiplexing\ndemultiplexing\nProtocolli del livello di trasporto\n\nUDP\n\nSegmento UDP\nchecksum\n\n\nTCP\n\nMTU\nMSS\nsegmento TCP(porta mittente, porta destinatario, rcwnd, ACK, checksum, ECE)\nHandshake\n\n1 via\n2 vie\n\n\nfinestra di ricezione\nNumero di sequenza\nACK\nControllo del flusso\n\n\n\n\nTrasferimenti su canali inaffidabili\n\nstop and wait\n\nRDT\n\n\npipeline\n\nGBN\nRipetizione selettiva\n\n\n\n\nEsempi di congestione\nControllo della congestione\n\nend to end\nassistito dalla rete\n\nBit ECN ECE\n\n\n\n\nGestioni del tasso di invio\n\nAIMD(Additive Increase Multiplicative Decrease)\nslow start\ncongestion avoidance\nfast recovery\n\n\nTCP RENO\nTCP CUBIC\nTCP VEGAS\nTCP √® fair?\n\n\n\nLivello di Rete\n\ndefinizione\n\nProtocollo IP\n\nbest effort\ncosa cerca di fare\n\nriduzione perdita datagrammi\nconsegna con basso ritardo\nconsegna in ordine\n\n\n\n\nil livello di rete si divide in 2 principali funzioni\n\nInoltro\n\nbasato su destinazione\n\nIP classful addressing\nNotazione CIDR\n\nRoute Aggregation\n\n\nTCAM+priority encoder\ncome ottiene IP un ISP\nICANN\n\n\ngeneralizzato\n\ntabella di flusso\nmatch+action+counter+priority\nregola=voce\n\n\n\n\ninstradamento\n\n\nFrammentazione datagrammi\n\nPMTUD\n\nICMP\nMitigazione\n\n\n\n\nla rete inoltre si pu√≤ dividere in 2 principali piani\n\npiano di controllo\npiano dati\n\n\nSDN\n\ncosa sono\ndove sono posizionate\nsouthbound, Dati , northbound\nOpenflow\n\ntabella di flusso\n\n\n\n\nRouter\n\ntabella di inoltro\ntabella di instradamento\nsottorete\nporta di ingresso\nporta di uscita\ncommutazione\n\ncentralizzata\ndecentralizzata\n4 tipologie\n\nMemoria\nbus\nCrossbar switch\nmultistage\n\n\n\n\ngestione buffer dei router\n\n3 politiche\n\ntail drop\npriorit√†\nmarcatura\n\n\n\n\n\n\nDHCP\n\nDiscovery\nOffer\nRequest\nAck\n\n\nNAT\n\ncome funziona\n\n\nIpv6\n\ntunneling\n\n\nAS\n\nintra-AS\ninter-AS\nOSPF\n\nbackbone\nnodi interni\n\n\nBGP\n\nI-BGP\nE-BGP\nrotta BGP\n\nAS-PATH\nNext-HOP\n\n\nsessione BGP\n\n\n\n\nICMP\n\nmessaggi ICMP\ntraceroute\nping\n\n\nAlgoritmi di instradamento\n\nGlobali\nNon globali\ncentralizzati\ndecentralizzati\nstatici\ndinamici\nDijkstra\nVector Distance\n\n\nGestione della rete\n\nCLI\nSNMP/NETCONF\nMIB/YANG\n\n\n\n\n\nLivello di collegamento\n\nLivello di collegamento\nDispositivi\n\nNIC\nincapsulamento decapsulamento\n\n\nservizi\n\nframing\ncontrollo del flusso\naccesso al collegamento\naccessi multipli MAC\nidentificare i dispositivi MAC\n\nIEE\n\n\n\n\nrilevazione e correzione di errori\n\nritrasmissioni\nnon\n\n\ntipi di collegamento\n\nhalf duplex\nfull duplex\n\n\ncollegamento\n\nend-to-end\nbroadcast\n\n\nprotocolli di gestione dell‚Äôaccesso multiplo\n\nsuddivisione di canale\n\nTDMA\nFDMA\n\n\naccesso casuale\n\nSLOTTED ALOHA\nUNSLOTTED ALOHA\nCSMA\nCSMA/CD\n\n\na turni presi\n\nPOLLING\nTOKEN PASSING\n\n\n\n\nSwitch\n\ntabella di commutazione\n\n\nEthernet\n\nframe\ndominio di collisione\nLAN\nMAC\n\n\nProtocollo ARP\n\nARP reply\nARP request\n\n\nVLAN\n\nVLAN a switch singolo\nVLAN a switch multipli\nEVPN\nID VLAN 802.1Q\n\n\nReti Wireless\n\n2 modalit√†\n\ncon infrastruttura\nsenza infrastruttura\n\n\nattenuazione del segnale\nriflessione del segnale\n\ntempo di coerenza\n\n\ninterferenza dei segnali\n\nSNR\nBER\n\n\nterminali nascosti\nCDMA\nWi-Fi standard 802.11\n\nBSS\n\n\nGestione frequenze\nAccesso\n\nmodalit√† passiva\nattiva\n\n\nCSMA/CA\n\nDIFS\nSIFS\n\n\nprenotazione\n\nRTS\nCTS\n\n\nBluetooth\n\nPiconet PAN\n\n\nMaster\nBootstrapping\n\nneighbor discovery\npaging\n\n\n\n\nReti 4G/5G\n\nUE\nBase Station\nHSS\nMME\nP-GW\nS-GW\nmobilit√† handoff\n\nrouting diretto\nindiretto\n\n\nReti LTE\n\npiano di controllo\npiano di dati\ntunneling\n\n\nhome network\nvisited network\n\n\n"},"UNI/ANNO-2/RICERCA-OPERATIVA/Guida-Aurora":{"slug":"UNI/ANNO-2/RICERCA-OPERATIVA/Guida-Aurora","filePath":"UNI/ANNO 2/RICERCA OPERATIVA/Guida Aurora.md","title":"Guida Aurora","links":[],"tags":[],"content":"\n\nper l‚Äôesercizio in AMPL\ndato il seguente file zip con degli esercizi di ampl svolgi la seguente richiesta di ampl\n\n\nesercizi normali prompt sostituisci il numero dell‚Äôesercizio x scritto sotto\ndato il seguente esame, basandoti sul pdf fornito che spiega passo passo come svolgere gli esercizi\n\n\nmi raccomando lascia le frazioni senza approssimare a numeri con la ,\n\n\nscrivi tutti i passaggi dell‚Äôesercizio in modo chiaro e completo in modo che io li possa ricopiare\n\n\napplica alla lettera solo quello che trovi nella guida del pdf in modo preciso seguendo la struttura dettata che √® come vuole l‚Äôinsegnante\n\n\ncontrolla se hai eseguito tutti i passaggi correttamente e non hai saltato dei pezzi\n\n\nsvolgi esercizio x\nDOPO AVER MANDATO QUESTO A GPT 4O mandalo a GPT o3 per fargli controllare i calcoli in modo corretto\n\n"},"UNI/ANNO-2/RICERCA-OPERATIVA/Lista-esercizi-samuele/PDF-SAMU":{"slug":"UNI/ANNO-2/RICERCA-OPERATIVA/Lista-esercizi-samuele/PDF-SAMU","filePath":"UNI/ANNO 2/RICERCA OPERATIVA/Lista esercizi samuele/PDF SAMU.md","title":"PDF SAMU","links":[],"tags":[],"content":""},"UNI/ANNO-2/RICERCA-OPERATIVA/lista":{"slug":"UNI/ANNO-2/RICERCA-OPERATIVA/lista","filePath":"UNI/ANNO 2/RICERCA OPERATIVA/lista.md","title":"lista","links":[],"tags":[],"content":"LISTA ESERCIZI\n\nvettore pu√≤ essere soluzione di base ammissibile?\nvertice della regione ammissibile del problema con x1 e x2 strettamente positivi\npu√≤ esistere una soluzione ottima con x3 in base?\n\ncosa succede se ho due variabili nel vincolo che voglio del duale?\n\n\npu√≤ esistere una soluzione ottima con x1 e x2 strettamente positivi\nalgoritmo del simplesso a 2 fasi\nsimplesso\nsimplesso primale-duale a partire da una soluzione duale y\nverificare se le soluzioni del punto a sono ottime\n\napplicare le condizioni di complementariet√† primale-duale per verificare se la soluzione x √® ottima(dato un vettore) uguale al punto 8\n\n\ncome si fa il duale\nforma standard\n\n1. vettore pu√≤ essere soluzione di base ammissibile?\nl‚Äôesercizio sar√† tipo cos√¨\n\n\nsostituisco le rispettive x nel vettore sul problema di program lineare\n4 corrisponde a x1 0 corrisponde a x2 e cos√¨ via‚Ä¶\nverifico se la disequazione ha senso\nfaccio la forma standard\nsostituisco pure nella forma standard il vettore\ngli slack in pi√π vengono recuperati facendo sostituzioni\ncreo il nuovo vettore con in pi√π anche i valori degli slack\ncontrollo se il numero dei vincoli √® uguale a quello delle variabili diverse da 0 nel vettore\nse sono diverse no SBA se uguali SBA\n\n2.vertice della regione ammissibile del problema con x1 e x2 strettamente positivi\n\n\nsi pongono le variabili richieste x1 e x2 a &gt; di 0 e tutte le altre a 0\nsi sostituisce cos√¨ nella forma standard\nci√≤ che rimane √® tutto tranne x1 e x2 perch√© gli altri sono a 0\nsi mettono a sistema con l‚Äôuguale i vincoli\nsvolgi il sistema\nil sistema ti dir√† quanto valgono x1 e x2\nconfronta i loro valori con le variabili del programma lineare\nin questo esempio x1 e x2 devono essere &gt;= di 0\nin questo caso li chiede strettamente positivi quindi non possono essere uguali a 0\n\n3.Pu√≤ esistere una soluzione ottima con x3 in base?\n\n\nfai il duale non a partire dalla standard\nda min a max\nselezioni la riga della base richiesta in questo caso x3\nsvolgi la disequazione\nla disequazione deve rispettare le variabili nel problema di programmazione lineare\n\n\ncosa succede se ho due variabili nel vincolo che voglio del duale?\n\n4. pu√≤ esistere una soluzione ottima con x1 e x2 strettamente positivi\n\n\nfai il duale\ndefinisci la complementariet√† delle due variabili che ti ha detto il prof e mettile positive\nsostanzialmente devi scrivere questo\n\nmetti a sistema i due vincoli con l‚Äôuguale al posto dei segni delle disequazioni\nsvolgi il sistema\nle variabili del sistema devono rispettare i segni iniziali che avevi sul duale quindi se Y1 √® uguale a 1/2 e nel duale avevi scritto che doveva essere \\leq 0 allora significa che c‚Äô√® una contraddizione e non esiste soluzione ottima\n\n5. algoritmo del simplesso a due fasi\nquando il prof chiede il simplesso duale fai questo\n\n\nfai la forma standard\nse nella forma standard hai degli slack negativi allora significa che la base non √® ottima\napplichi il simplesso a 2 fasi\nfase 1, poni come obiettivo facendo il min con le variabili che hai che non vanno bene\n\nin questo caso il problema era su solo un vincolo e quindi faccio\n\naggiungo solo una variabile artificiale\nsuccessivamente riprendo i vincoli fatti prima ma aggiungo al vincolo quello strano la variabile artificiale(proprio al sommo se vedi)\nda qui effettuo il simplesso per√≤ senza sostituire S1 alla funzione z\ndevo sottrarre il vincolo con S1 con l‚Äôobiettivo per togliere 1 su S1\n\nsuccessivamente faccio un simplesso normale finch√© la b di z non torna uguale a 0\ndopo essere arrivati qui prendo la vecchia funzione obiettivo della forma standard e la sostituisco alla riga di z\nfaccio il simplesso finch√© non ho tutte le variabili di z maggiori o uguali a 0\nin questo caso \\geq perch√© abbiamo la standard in forma di min se fosse stato max tutte le variabili dovevano essere \\leq\n\n6. simplesso normale\nper fare il simplesso bisogna\n\n\nforma standard\n\n\nmetti tutto a tabella\n\n\n\ndevi trovare sulla riga obiettivo il valore pi√π piccolo\n\n\nsuccessivamente devi trovare la corrispondente riga degli altri e per farlo devi prendere i termini noti di ogni vincolo e farlo fratto la colonna scelta, se per√≤ devi fare una frazione negativa o con lo 0 non lo prendi in considerazione\n\n\n\nora abbiamo definito esattamente quale √® il pivot\n\n\nuna volta scelto il pivot faccio tutta la riga scelta fratto il pivot scelto, se √® 1 fai tutto fratto 1, quindi in questo caso tutta la riga di x6 fratto il pivot 1\n\n\ninoltre scrivi che la variabile della riga ora diventa quella della colonna scelta\n\n\n\ncancello tutte le righe tranne quelle che nella colonna scelta hanno gi√† coefficiente zero\n\n\nper ricreare la riga faccio un giochetto\n\n\nse ad esempio voglio riscrivere b di z prendo l‚Äôelemento della riga scelta sulla colonna di b lo moltiplico per la riga corrispondente a z negando tutto e poi sommo con la b di z iniziale\n\n\n\nlo fai per tutte le righe e tutte le colonne che hanno il coefficiente della colonna diverso da 0\n\n\nriempio una tabella nuova praticamente\n\n\nuna volta fatto controlli se la funzione obiettivo era un min tutti i valori devono essere \\geq0 se era un max tutti devono essere \\leq0\n\n\npoi scrivi alla fine dell‚Äôesercizio\n\n\n\n7. simplesso primale-duale a partire da una soluzione duale y\n\nfare la forma standard\nDuale della forma standard\nprendi il vettore fornito oppure inventalo tu e sostituiscilo al duale fatto se non ti viene fornito un vettore metti 0,0 a caso\ndopo aver sostituito al duale vedi se ammissibile, ti devono tornare tutte le disuguaglianze\n\nse si prendi e isola le variabili del duale\nse la risposta √® no devi definire una nuova base e poi fai il punto 5\n\nprimale ristretto lo fai sempre in min e metti tante a quante le variabili con scritto NO\nla forma sar√† cos√¨ devi prendere quante variabili quanti NO\npoi sostituisci e metti a 0 nella forma standard e le variabili con no le lasci libere\nriscrivi aggiungendo le a\n\nfaccio il tableaux e come sempre cerco di togliere i valori alle a\n\nsostanzialmente faccio il simplesso se z diventa uguale a 0 allora significa che la y scelta √® base ottima\naltrimenti devo scegliere la nuova base Y^1=Y^0+\\Theta \\pi\nper trovare \\pi faccio il duale del primale ristretto\n\ndi tutto questo prendo in considerazione solo le variabili che stavano a sinistra del tableaux uscito male quindi in questo caso sono a1 e a2 e le metto uguali a 1\nsaranno i valori di \\pi\n\nprendo il duale fatto all‚Äôinizio e ci sostituisco i valori del nuovo Y per vedere se tornano le disuguaglianze mettendole su un grafico dei segni\nsostanzialmente bisogna vedere se nel grafico si hanno le intersezioni di tutte le disuguaglianze e si deve prendere quel punto per trovare il valore di theta\nin questo caso theta √® 1/4 e viene sostituito nel vettore Y\n\nper verificare ora devi ripartire dal punto 6 ma sicuramente esce base ottima(spero)\n\n8. verificare se le soluzioni del punto a sono ottime\noppure\n\napplicare le condizioni di complementariet√† primale-duale per verificare se la soluzione x √® ottima(dato un vettore) uguale al punto 8\n\n\nsostituisci il vettore al problema di programmazione lineare originale e vedi se c‚Äô√® ammissibilit√† vedendo se le disuguaglianze tornano\nfaccio il duale senza forma standard\napplico la complementariet√†\nraccolgo moltiplicando alle y i vincoli del programma lineare classico\n\nY3 √® appartenente ai reali quindi non la prendo in considerazione\nora faccio la stessa cosa mettendo tra parentesi i vincoli del duale e fuori le x della forma normale\n\nin questo caso il vincolo che appartiene ai reali lo metto un attimo da parte\nmetto a sistema i due tipi di raccoglimenti fatti e applico il vettore sulle rispettive x\nquello che prendeva i vincoli della forma normale verr√† come il primo sistema mentre l‚Äôaltro √® il secondo\nda questi sistemi possiamo trarre quanto valgono le varie y in base al fatto se si saturano o mento ovvero se c‚Äô√® uno zero o meno\n\nora posso aggiungere quella riga che nel raccoglimento con i vincoli del duale avevo tolto perch√© aveva i reali\nci posso ora sostituire i valori delle y trovati\ncontrollo se le y rispettano le variabili scritte sul duale\nora che ho tutti i valori delle y posso sostituirli al duale e controllare se le disuguaglianze tornano\nmetto a sistema gli obiettivi del duale e del programma lineare e vedo se sostituendo vengono uguali\n"},"UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/CODICI-CROCE/COPYFILE.C":{"slug":"UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/CODICI-CROCE/COPYFILE.C","filePath":"UNI/ANNO 2/SISTEMI OPERATIVI/CODICI IN C/CODICI CROCE/COPYFILE.C.md","title":"COPYFILE.C","links":[],"tags":[],"content":"/* Programma di copia di file con controllo errori minimale e reportistica. */\n \n  \n \n#include &lt;sys/types.h&gt; // Include i file header necessari\n \n#include &lt;fcntl.h&gt;\n \n#include &lt;stdlib.h&gt;\n \n#include &lt;unistd.h&gt;\n \n#include &lt;stdio.h&gt;\n \n  \n \n#define BUF_SIZE 4096 // Dimensione del buffer: 4096 byte\n \n#define OUTPUT_MODE 0700 // Bit di protezione per file di output\n \n  \n \n#define TRUE 1\n \n  \n \n// Prototipo della funzione main secondo lo standard ANSI\n \nint main(int argc, char *argv[]);\n \n  \n \nint main(int argc, char *argv[]) {\n \nint in_fd, out_fd; // File descriptor per i file di input e output\n \nint rd_count, wt_count; // Contatori per la lettura e scrittura\n \nchar buffer[BUF_SIZE]; // Buffer per la lettura e scrittura dei dati\n \n \n \n// Controllo del numero di argomenti\n \nif (argc != 3) {\n \n// Stampa un messaggio di errore se il numero di argomenti non √® corretto\n \nfprintf(stderr, &quot;Errore di sintassi. Uso: %s input_file_path output_file_path\\n&quot;, argv[0]);\n \nexit(1);\n \n}\n \n  \n \n// Apertura del file di input\n \nin_fd = open(argv[1], O_RDONLY); // Apre il file di origine\n \nif (in_fd &lt; 0) exit(2); // Se non pu√≤ aprirlo, esce\n \n  \n \n// Creazione del file di output\n \n// Nota: equivalenza tra\n \n// - creat(path, mode);\n \n// - open(path, O_WRONLY | O_CREAT | O_TRUNC, mode);\n \n// YES: Ken Thompson, the creator of Unix, once joked that the missing letter was his largest regret in the design of Unix.\n \nout_fd = creat(argv[2], OUTPUT_MODE); // Crea il file di destinazione\n \nif (out_fd &lt; 0) exit(3); // Se non pu√≤ crearlo, esce\n \n  \n \n// Ciclo di copia\n \nwhile (TRUE) {\n \nrd_count = read(in_fd, buffer, BUF_SIZE); // Legge un blocco di dati\n \nif (rd_count &lt;= 0) break; // Se fine del file o errore, esce dal ciclo\n \n  \n \nwt_count = write(out_fd, buffer, rd_count); // Scrive i dati\n \nif (wt_count &lt;= 0) exit(4); // wt_count &lt;= 0 √® un errore\n \n}\n \n  \n \n// Chiusura dei file\n \nclose(in_fd);\n \nclose(out_fd);\n \n  \n \nif (rd_count == 0) exit(0); // Nessun errore sull‚Äôultima lettura\n \nelse exit(5); // Errore sull‚Äôultima lettura\n \n}\n#include &lt;fcntl.h&gt; serve per aprire i file con open o roba simile\ndefinisco come dimensione del buffer 4096 byte\ndefinisco le propriet√† di accesso in questo caso solo il proprietario pu√≤ fare tutto.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBitValoreDescrizione4LetturaPermesso di leggere.2ScritturaPermesso di scrivere.1EsecuzionePermesso di eseguire.Creo un prototipo della funzione tipo le interfacce(serve davvero?bho)creazione di un buffer che alla fine √® un array di char lungo 4096l‚Äôesercizio prevede 3 stringhe quindi si fa un controllo se sono stati messi dei numeri differenti\nin caso si va a fare una print sullo standard error e un exit con errore quindi 1\nfprintf(stderr, &quot;Errore di sintassi. Uso: %s input_file_path output_file_path\\n&quot;, argv[0]);\nsalva open in un intero, open restituisce il file descriptor che ormai conosciamo\ne gli passiamo una stringa path e il modo in cui deve aprirlo O_RDONLY\nse abbiamo un file descriptor negativo c‚Äô√® un problema e facciamo una exit con errore\nusiamo questo comando\nout_fd = creat(argv[2], OUTPUT_MODE);\nper creare un file nel path definito dalla stringa e mettiamo output mode\nanche creat ritorna il file descriptor\nfacciamo un ciclo while infinito e facciamo una read sul buffer\nspecificando il file descriptor da cui prendere il buffer su cui scrivere e la dimensione del buffer\nrd_count = read(in_fd, buffer, BUF_SIZE);\nse la read ha un valore negativo allora c‚Äô√® stato un errore altrimenti conta i byte letti\nfunziona in modo simile la write\nwt_count = write(out_fd, buffer, rd_count);\nun errore pu√≤ anche essere la fine della lettura\nse l‚Äôultima lettura ha ritornato 0 significa nessun errore e abbiamo finito di leggere e possiamo fare exit(0)"},"UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/CODICI-CROCE/COUNTDOWN.C":{"slug":"UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/CODICI-CROCE/COUNTDOWN.C","filePath":"UNI/ANNO 2/SISTEMI OPERATIVI/CODICI IN C/CODICI CROCE/COUNTDOWN.C.md","title":"COUNTDOWN.C","links":[],"tags":[],"content":"#include &lt;stdio.h&gt;\n \n#include &lt;unistd.h&gt;\n \n#include &lt;stdlib.h&gt;\n \n#include &lt;time.h&gt;\n \n  \n \nint main() {\n \n// Inizializza il generatore di numeri casuali\n \nsrand(time(NULL));\n \n  \n \nfor (int i = 20; i &gt;= 1; i--) {\n \nprintf(&quot;%d\\n&quot;, i);\n \nfflush(stdout); // Assicura che l&#039;output venga visualizzato immediatamente\n \n  \n \n// Dormi per un tempo casuale tra 0 e 2 secondi\n \nsleep(rand() % 3);\n \n}\n \n  \n \nprintf(&quot;\\nBYE\\n&quot;);\n \nfflush(stdout);\n \n  \n \nreturn 0;\n \n}\nSPIEGAZIONE\nImporto librerie in particolare\n&lt;time.h&gt; che ha delle funzionalit√† per lavorare su date e tempo\nCodice\nsrand imposta come deve generare numeri casuali la funzione rand in base a un determinato seme in questo caso time(null) che ritorna il numero di secondi trascorsi dal 1970 quindi una roba tipo 1708739200\nfflush(stdout) il printf prima di questo comando viene fatto immediatamente anche senza aspettare la fine del codice\nsleep simula una attesa di tot secondi in questo caso se si fa un rand e %3 avremo dei numeri che vanno da 0 a 2 se volessimo fare da 0 a 3 dobbiamo mettere+1"},"UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/CODICI-CROCE/HELLO-WORLD.C":{"slug":"UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/CODICI-CROCE/HELLO-WORLD.C","filePath":"UNI/ANNO 2/SISTEMI OPERATIVI/CODICI IN C/CODICI CROCE/HELLO WORLD.C.md","title":"HELLO WORLD.C","links":[],"tags":[],"content":"1. HELLO WORLD\n#include &lt;unistd.h&gt;\n \n#include &lt;stdio.h&gt;\n \n  \n \nint main()\n \n{\n \n¬†¬†¬†¬†printf(&quot;Hello world.\\n&quot;);\n \n¬†¬†¬†¬†return 0;\n \n}\nvabb√® un classico\n2. HELLO WORLD\n#include &lt;unistd.h&gt;\n \n#include &lt;stdio.h&gt;\n \n  \n \n#define STDOUT 1\n \n  \n \nint main()\n \n{\n \n¬†¬†¬†¬†char msg[] = &quot;Hello World!\\n&quot;;\n \n¬†¬†¬†¬†write(STDOUT, msg, sizeof(msg));\n \n  \n \n¬†¬†¬†¬†return 0;\n \n}\nsi utilizza un array di caratteri e si effettua una write sul file descriptor 1\n3. HELLO WORLD\n#include &lt;unistd.h&gt;\n \n#include &lt;stdio.h&gt;\n \n#include &lt;sys/syscall.h&gt;\n \n#define STDOUT 1\n \n  \n \nint main(int argc, char **argv)\n \n{\n \n¬†¬†¬†¬†char msg[] = &quot;Hello World!\\n&quot;;\n \n¬†¬†¬†¬†int nr = SYS_write;\n \n¬†¬†¬†¬†syscall(nr, STDOUT, msg, sizeof(msg));\n \n¬†¬†¬†¬†return 0;\n \n}\nsi fa una chiamata di sistema specificando la chiamata il file descriptor e la stringa e la sua dimensione"},"UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/CODICI-CROCE/MY-FIRST-FORK1.C":{"slug":"UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/CODICI-CROCE/MY-FIRST-FORK1.C","filePath":"UNI/ANNO 2/SISTEMI OPERATIVI/CODICI IN C/CODICI CROCE/MY FIRST FORK1.C.md","title":"MY FIRST FORK1.C","links":[],"tags":[],"content":"#include &lt;stdio.h&gt;\n \n#include &lt;stdlib.h&gt;\n \n#include &lt;unistd.h&gt;\n \n \n \n#define STDIN 0\n \n#define STDOUT 1\n \n#define PIPE_RD 0\n \n#define PIPE_WR 1\n \n \nint main(){\n \n  \n \n¬†¬†¬†¬†int pid, child_status;\n \n  \n \n¬†¬†¬†¬†if ((pid = fork()) == 0) {\n \n¬†¬†¬†¬†printf(&quot;I am the child and I see the PID %d\\n&quot;, pid);\n \n¬†¬†¬†} else {\n \n¬†¬†¬†¬†¬†¬†¬†wait(&amp;child_status); // Wait for child\n \n¬†¬†¬†¬†¬†¬†¬†printf(&quot;I am the parent, I see the child&#039;s PID (%d) and the status (%d)\\n&quot;, pid, child_status);\n \n¬†¬†¬†¬†}\n \n}\ndefinisco delle costanti\nuso if e else per differenziare ci√≤ che deve fare un figlio da un padre\nquando faccio fork viene generato un processo che ha un pid, se si tratta del processo figlio allora avremo 0 altrimenti un padre\nwait attende la terminazione del processo figlio e salva nell‚Äôindirizzo del child status il risultato in questo caso una terminazione senza errori quindi 0\nle costanti non vengono usate"},"UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/CODICI-CROCE/MY-FIRST-FORK2.C":{"slug":"UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/CODICI-CROCE/MY-FIRST-FORK2.C","filePath":"UNI/ANNO 2/SISTEMI OPERATIVI/CODICI IN C/CODICI CROCE/MY FIRST FORK2.C.md","title":"MY FIRST FORK2.C","links":["UNI/ANNO-2/SISTEMI-OPERATIVI/SISTEMI-OPERATIVI-LEZ.4-5-6-7"],"tags":[],"content":"#include &lt;stdio.h&gt;\n \n#include &lt;stdlib.h&gt;\n \n#include &lt;unistd.h&gt;\n \n  \n \n// Definizione di costanti per leggibilit√† per i descrittori di file\n \n#define STDIN 0\n \n#define STDOUT 1\n \n#define PIPE_RD 0 // Lato di lettura della pipe\n \n#define PIPE_WR 1 // Lato di scrittura della pipe\n \n  \n \nint main(int argc, char** argv) {\n \n  \n \npid_t cat_pid, sort_pid;\n \nint fd[2]; // Descrittori di file per la pipe: fd[0] per leggere, fd[1] per scrivere\n \npipe(fd); // Crea una pipe. fd[PIPE_RD] sar√† l&#039;estremit√† di lettura, fd[PIPE_WR] sar√† l&#039;estremit√† di scrittura\n \n  \n \ncat_pid = fork(); // Fork del processo corrente\n \n  \n \nif (cat_pid == 0) {\n \n// Questo √® il processo figlio per &#039;cat&#039;\n \nclose(fd[PIPE_RD]); // Chiude l&#039;estremit√† di lettura della pipe, non necessaria qui\n \nclose(STDOUT); // Chiude l&#039;output standard\n \n  \n \n/*\n \n  \n \nLa funzione dup viene utilizzata nei programmi Unix/Linux per duplicare un\n \nfile descriptor esistente, ottenendo un secondo file descriptor che punta alla\n \nstessa risorsa interna (ad esempio, uno stesso file o lato di una pipe).\n \nQuesto nuovo file descriptor e&#039; il pi√π Basso Disponibile: dup sceglie automaticamente\n \nil numero di file descriptor pi√π basso che √® disponibile nel processo corrente.\n \nPer esempio, se i file descriptor 0, 1, e 2 sono chiusi,\n \ndup utilizzer√† il 0 per la sua duplicazione.\n \n  \n \n*/\n \n  \n \ndup(fd[PIPE_WR]); // Duplica l&#039;estremit√† di scrittura della pipe al descrittore di\n \n// file dell&#039;output standard. Ora, &#039;cat&#039; scriver√† sulla pipe invece che sul terminale\n \nexecl(&quot;/bin/cat&quot;, &quot;cat&quot;, &quot;names.txt&quot;, NULL); // Esegui il comando &#039;cat&#039;\n \n}\n \n  \n \nsort_pid = fork(); // Fork del processo corrente ancora per &#039;sort&#039;\n \n  \n \nif (sort_pid == 0) {\n \n// Questo √® il processo figlio per &#039;sort&#039;\n \nclose(fd[PIPE_WR]); // Chiude l&#039;estremit√† di scrittura della pipe, non necessaria qui\n \nclose(STDIN); // Chiude l&#039;input standard\n \ndup(fd[PIPE_RD]); // Duplica l&#039;estremit√† di lettura della pipe al descrittore di file dell&#039;input standard\n \n// Ora, &#039;sort&#039; legger√† dalla pipe invece che dalla tastiera\n \nexecl(&quot;/usr/bin/sort&quot;, &quot;sort&quot;, NULL); // Esegui il comando &#039;sort&#039;\n \n}\n \n  \n \n// Questo √® il processo genitore\n \nclose(fd[PIPE_RD]); // Chiude l&#039;estremit√† di lettura della pipe, il genitore non la usa\n \nclose(fd[PIPE_WR]); // Chiude l&#039;estremit√† di scrittura della pipe, il genitore non la usa\n \n  \n \n// Aspetta che i processi figli terminino\n \nwaitpid(cat_pid, NULL, 0); // Aspetta il processo &#039;cat&#039;\n \nwaitpid(sort_pid, NULL, 0); // Aspetta il processo &#039;sort&#039;\n \n  \n \nreturn 0;\n \n}\ndefinisco delle costanti per facilitare la scrittura dei descrittori\nricapitolando i descrittori sono dei codici che associano a un tipo di file\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDescrittore di FileMacro associataDescrizioneDefault0STDIN_FILENOInput standardTastiera (in interattivo)1STDOUT_FILENOOutput standardTerminale (in interattivo)2STDERR_FILENOOutput standard per erroriTerminale (in interattivo)e poi le pipe con 0 e 1 dove 0 indica la lettura e 1 la scrittura\nCreazione di pid\npid_t viene usato per indicare il pid di un processo, alla fine √® un intero ma per chiarezza si usa questo pu√≤ anche essere usato per indicare un riscontro dopo la fork tipo 0 per i figli ecc\nabbiamo creato un array che contiene i 2 elementi del descriptor per la pipe\npipe(fd) crea una pipe associata al file descriptor\n\nfd[PIPE_RD] sar√† la lettura\nfd[PIPE_WR] sar√† la scrittura\nma semplicemente usa 0 e 1 solo che usa le costanti\ncreo un processo e mi salvo il suo stato in cat_pid\n√® previsto che il figlio non legga nella pipe e non scriva nello stdout\ndup(fd[PIPE_WR]); viene usato per dire al processo corrente di non scrivere pi√π sullo stdout o dove doveva fare ma di scrivere nella cosa tra parentesi in questo caso la pipe in scrittura\ncon dup di default viene messo il fd pi√π basso anche se √® chiuso\n\nUso di execl\nexecl(&quot;/bin/cat&quot;, &quot;cat&quot;, &quot;names.txt&quot;, NULL);\nviene usato per eseguire un comando della bash in questo caso cat\nspiegazione cat\nfunziona cos√¨\nexecl(&quot;directory del comando&quot;, &quot;nome comando&quot;, opzioni separate da &quot;,&quot;, NULL per indicare la fine delle opzioni);\ncreazione del processo corrente e mettiamo in sort\nchiudiamo le varie scritture e ci appoggiamo alla lettura facendo un sort di quello che ci ha dato cat\nquando usciamo da tutti i processi 0 quindi figli dobbiamo scrivere il codice per il padre\nchiudiamo le cose inutilizzate(tutto)\ne aspettiamo che i due figli terminino per andare a terminare il codice\nwaitpid(cat_pid, NULL, 0); // Aspetta il processo &#039;cat&#039;\nfunziona cos√¨\npid_t waitpid(pid_t pid, int *status, int options);\npid pu√≤ essere uno in particolare oppure\n\n-1: Aspetta qualsiasi processo figlio.\n0: Aspetta qualsiasi processo figlio appartenente allo stesso gruppo.\n\nlo status pu√≤ essere messo in una variabile per aggiornare lo stato del processo in questo caso NULL\nla 3 Modifica il comportamento della chiamata. Ad esempio:\n\n0: Comportamento predefinito (attende fino a quando il processo termina).\n\nda sapere?\n\nWNOHANG: Non si blocca se il processo specificato non √® terminato.\nWUNTRACED: Con questa opzione, waitpid riporta anche i processi figli che sono stati sospesi (es. con un segnale come SIGSTOP).\n\nse waitpid termina restituisce il pid del processo che termina\noppure altre cose in base a quelle opzioni"},"UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/CODICI-CROCE/MY-SIGNAL-2.C":{"slug":"UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/CODICI-CROCE/MY-SIGNAL-2.C","filePath":"UNI/ANNO 2/SISTEMI OPERATIVI/CODICI IN C/CODICI CROCE/MY SIGNAL 2.C.md","title":"MY SIGNAL 2.C","links":[],"tags":[],"content":"#include &lt;stdio.h&gt;\n \n#include &lt;signal.h&gt;\n \n#include &lt;unistd.h&gt;\n \n#include &lt;stdlib.h&gt;\n \n#include &lt;string.h&gt; // Per strsignal()\n \n  \n  \n \nvoid alarm_handler(int signal) {\n \nprintf(&quot;In signal handler: caught signal %d which is %s!\\n&quot;, signal, strsignal(signal));\n \nexit(0);\n \n}\n \n  \n \nint main(int argc, char **argv) {\n \nsignal(SIGALRM, alarm_handler);\n \nalarm(1); // alarm will send signal after 1 sec\n \n  \n \nwhile (1) {\n \nprintf(&quot;I am running!\\n&quot;);\n \n}\n \n  \n \nreturn 0;\n \n}\nuguale a quello prima solo che usa SIGALARM che serve per far partire l‚Äôhandler una volta che il timer alarm ha finito\nil while stamper√† finche signal handler ecc terminano"},"UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/CODICI-CROCE/MY-SIGNAL1.C":{"slug":"UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/CODICI-CROCE/MY-SIGNAL1.C","filePath":"UNI/ANNO 2/SISTEMI OPERATIVI/CODICI IN C/CODICI CROCE/MY SIGNAL1.C.md","title":"MY SIGNAL1.C","links":[],"tags":[],"content":"#include &lt;stdio.h&gt;\n \n#include &lt;stdlib.h&gt;\n \n#include &lt;signal.h&gt;\n \n#include &lt;unistd.h&gt;\n \n#include &lt;string.h&gt; // Per strsignal()\n \n \nvoid signalHandler(int signum) {\n \nprintf(&quot;Interrupt signal %d received which is %s\\n&quot;, signum, strsignal(signum));\n \n// cleanup and terminate program\n \nexit(signum);\n \n}\n \n  \n \nint main() {\n \n// register signal SIGINT and signal handler\n \nsignal(SIGINT, signalHandler); // CTRL+C\n \n  \n \nwhile(1) {\n \nprintf(&quot;Going to sleep...\\n&quot;);\n \nsleep(1);\n \n}\n \n  \n \nreturn 0; // questa riga non verr√† mai raggiunta a causa del ciclo while(1)\n \n}\nincludo in particolare la libreria signal per gestire i segnali\ncreo una funzione che gestisce i segnali e che non ritorna nulla\nstrsignal ritorna una stringa descrittiva in base al segnale tipo se passo un sig int che √® 2 la sua stringa descrittiva sar√† ‚Äúinterrupt‚Äù\nfa exit e ritorna la funzione exit il codice del segnale fatto\nnel main genera un segnale e gli passa\n\nSIGINT che √® una costante della libreria signal.h e indica 2 e termina il programma\nla funzione che gestisce il segnale\ncreo un loop infinito che fa uno sleep di 1 secondo ma abbiamo prima creato l‚Äôattesa di un possibile segnale in questo caso CTRL+C che termina il programma\nSIG_DFL per mettere un handler di default\n"},"UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/CODICI-CROCE/PRODUCER-CONSUMER-PTHREAD.c":{"slug":"UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/CODICI-CROCE/PRODUCER-CONSUMER-PTHREAD.c","filePath":"UNI/ANNO 2/SISTEMI OPERATIVI/CODICI IN C/CODICI CROCE/PRODUCER CONSUMER PTHREAD.c.md","title":"PRODUCER CONSUMER PTHREAD.c","links":[],"tags":[],"content":"#include &lt;stdio.h&gt;\n \n#include &lt;pthread.h&gt;\n \n#include &lt;stdlib.h&gt;\n \n#include &lt;unistd.h&gt;\n \n  \n \n#define MAX 10 /* Quantit√† di numeri da produrre */\n \n  \n \n/*\n \nNOTA: rispetto all&#039;esempio 6.2_producer_consumer_semaphore.c, questo esempio ha l&#039;obiettivo\n \ndi mostrare l&#039;accesso alternato (in mutua esclusione) dei due thread, non\n \n*/\n \n  \n \n/* Dichiarazione di mutex e variabili condizionali */\n \npthread_mutex_t the_mutex;\n \npthread_cond_t condc, condp; /* Usate per segnalare tra produttore e consumatore */\n \n  \n \nint buffer = 0; /* Buffer utilizzato tra produttore e consumatore */\n \n  \n \n/* Funzione del produttore */\n \nvoid *producer(void *ptr) {\n \nint i;\n \nfor (i = 1; i &lt;= MAX; i++) {\n \npthread_mutex_lock(&amp;the_mutex); /* Ottiene l&#039;accesso esclusivo al buffer */\n \n  \n \n/*\n \nNOTA: La ragione per cui viene utilizzato un ciclo while invece di un semplice\n \nif √® legata alla necessit√† di gestire le cosiddette &quot;false sveglie&quot;\n \n(spurious wakeups) che possono accadere con pthread_cond_wait.\n \nCi assicuriamo che ogni volta che il thread viene svegliato,\n \nricontrolli effettivamente la condizione.\n \n*/\n \nwhile (buffer != 0) {\n \npthread_cond_wait(&amp;condp, &amp;the_mutex);\n \n}\n \n  \n \nbuffer = i; /* Inserisce l&#039;elemento nel buffer */\n \nprintf(&quot;Producing:\\t%d\\n&quot;, i);\n \nsleep(rand()%2);\n \npthread_cond_signal(&amp;condc); /* Sveglia il consumatore */\n \npthread_mutex_unlock(&amp;the_mutex); /* Rilascia l&#039;accesso al buffer */\n \n}\n \n  \n \npthread_exit(0);\n \n}\n \n  \n \n/* Funzione del consumatore */\n \nvoid *consumer(void *ptr) {\n \nint i;\n \nfor (i = 1; i &lt;= MAX; i++) {\n \npthread_mutex_lock(&amp;the_mutex); /* Ottiene l&#039;accesso esclusivo al buffer */\n \n  \n \nwhile (buffer == 0) {\n \npthread_cond_wait(&amp;condc, &amp;the_mutex);\n \n}\n \n  \n \nprintf(&quot;Consuming:\\t%d\\n&quot;, i);\n \nbuffer = 0; /* Preleva un elemento dal buffer e lo reinizializza */\n \nsleep(rand()%2);\n \npthread_cond_signal(&amp;condp); /* Sveglia il produttore */\n \npthread_mutex_unlock(&amp;the_mutex); /* Rilascia l&#039;accesso al buffer */\n \n}\n \n  \n \npthread_exit(0);\n \n}\n \n  \n \nint main(int argc, char **argv) {\n \npthread_t pro, con; /* Threads del produttore e consumatore */\n \n  \n \n/* Inizializzazione di mutex e variabili condizionali */\n \npthread_mutex_init(&amp;the_mutex, NULL);\n \npthread_cond_init(&amp;condc, NULL);\n \npthread_cond_init(&amp;condp, NULL);\n \n  \n \n/* Creazione dei threads */\n \npthread_create(&amp;con, NULL, consumer, NULL);\n \npthread_create(&amp;pro, NULL, producer, NULL);\n \n  \n \n/* Attesa che i threads completino l&#039;esecuzione */\n \npthread_join(pro, NULL);\n \npthread_join(con, NULL);\n \n  \n \n/* Pulizia e distruzione di mutex e variabili condizionali */\n \npthread_cond_destroy(&amp;condc);\n \npthread_cond_destroy(&amp;condp);\n \npthread_mutex_destroy(&amp;the_mutex);\n \n  \n \nreturn 0;\n \n}\nin questo caso il codice crea un thread mutex e non un semaforo\npthread_mutex_t\ndichiariamo anche pthread_cond_t per fare degli eventi su cui si baseranno i mutex\ncreiamo la funzione del producer che blocca il mutex e finch√© il buffer √® diverso da 0 fa\ncreiamo una attesa con pthread_cond_wait passando la variabile di condizione condp e il mutex\nil mutex verr√† sbloccato perch√© andiamo in attesa di quello che far√† il consumatore\ndopodich√© inseriamo l‚Äôelemento nel buffer lo stampiamo e inviamo il segnale che risveglia il consumatore condc\nsblocchiamo il mutex\nfunzione del consumatore analoga e risveglia condp\nnel main creiamo due thread pro e con\ninizializziamo le cond e il mutex\ncreiamo due thread legandoli alle dichiarazioni prima e gli passiamo le due funzioni\nattendiamo che finiscano\ndistruggiamo le cond e i mutex"},"UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/CODICI-CROCE/PRODUCER-CONSUMER-SEMAPHORE.c":{"slug":"UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/CODICI-CROCE/PRODUCER-CONSUMER-SEMAPHORE.c","filePath":"UNI/ANNO 2/SISTEMI OPERATIVI/CODICI IN C/CODICI CROCE/PRODUCER CONSUMER SEMAPHORE.c.md","title":"PRODUCER CONSUMER SEMAPHORE.c","links":[],"tags":[],"content":"/*\n \n  \n \nEsempio dello schema Produttore Consumatore in C usando POSIX\n \n  \n \nAutore. Danilo Croce\n \n  \n \nNOTA: per essere eseguito in ambiente LINUX usare gcc -pthread source_file.c -o binary_output\n \n  \n \nWARNING: sembra non funzionare su MAC OS X\n \n  \n \n*/\n \n  \n \n#include &lt;pthread.h&gt;\n \n#include &lt;stdio.h&gt;\n \n#include &lt;stdlib.h&gt;\n \n#include &lt;unistd.h&gt;\n \n#include &lt;semaphore.h&gt;\n \n  \n \n#define N 10 /* numero di posti nel buffer */\n \n#define TRUE 1\n \n  \n \n/* Dichiarazione dei semafori */\n \nsem_t mutex; // Semaforo per l&#039;accesso esclusivo alla regione critica\n \nsem_t empty; // Semaforo per contare i posti vuoti nel buffer\n \nsem_t full; // Semaforo per contare i posti pieni nel buffer\n \n  \n \nint buffer[N]; // Buffer condiviso tra produttore e consumatore\n \nint in = 0; // Indice dove inserire il prossimo elemento nel buffer\n \n  \n \n/* Funzioni helper per utilizzare i semafori */\n \nvoid down(sem_t *sem) {\n \nsem_wait(sem); //www.csc.villanova.edu/~mdamian/threads/posixsem.html#wait\n \n}\n \n  \n \nvoid up(sem_t *sem) {\n \nsem_post(sem); //www.csc.villanova.edu/~mdamian/threads/posixsem.html#post\n \n}\n \n  \n \n/* Funzione per inserire un elemento nel buffer */\n \nvoid insert_item() {\n \n¬†¬†¬†¬†int item = rand() % 100; // Genera un elemento casuale\n \n¬†¬†¬†¬†printf(&quot;\\nInserisco %d in posizione %d\\n&quot;, item, (in + 1));\n \nbuffer[in] = item; // Inserisce l&#039;elemento nel buffer\n \nin++; // Incrementa l&#039;indice\n \n}\n \n  \n \n/* Funzione per rimuovere un elemento dal buffer */\n \nvoid remove_item() {\n \n¬†¬†¬†¬†printf(&quot;%i&quot;, in);\n \nint item = buffer[in - 1];\n \nprintf(&quot;\\nPrelevo %d da posizione %d\\n&quot;, item, in);\n \nin--; // Decrementa l&#039;indice\n \n}\n \n  \n \n/* Funzione per stampare il contenuto del buffer */\n \nvoid print_buffer(){\n \n¬†¬†¬†¬†for(int i=0; i&lt;in; i++){\n \n¬†¬†¬†¬†¬†¬†¬†¬†printf(&quot;%d &quot;, buffer[i]);\n \n\t}\nprintf(&quot;\\n&quot;);\n \n}\n \n  \n \n/* Funzione eseguita dal thread del produttore */\n \nvoid *producer(void *arg) {\n \n¬†¬†¬†¬†while (TRUE) {\n \n¬†¬†¬†¬†¬†¬†¬†¬†down(&amp;empty); // Attende finch√© ci sono posti vuoti nel buffer\n \n¬†¬†¬†¬†¬†¬†¬†¬†down(&amp;mutex); // Entra nella regione critica\n \n  \n \n¬†¬†¬†¬†¬†¬†¬†¬†insert_item(); // Inserisce un elemento nel buffer\n \n¬†¬†¬†¬†¬†¬†¬†¬†print_buffer(); // Stampa il contenuto del buffer\n \n  \n \n¬†¬†¬†¬†¬†¬†¬†¬†up(&amp;mutex); // Esce dalla regione critica\n \n¬†¬†¬†¬†¬†¬†¬†¬†up(&amp;full); // Segnala che c&#039;√® un posto pieno in pi√π nel buffer\n \n¬†¬†¬†¬†}\n \n}\n \n  \n \n/* Funzione eseguita dal thread del consumatore */\n \nvoid *consumer(void *arg) {\n \n¬†¬†¬†¬†while (TRUE) {\n \n¬†¬†¬†¬†¬†¬†¬†¬†down(&amp;full); // Attende finch√© ci sono posti pieni nel buffer\n \n¬†¬†¬†¬†¬†¬†¬†¬†down(&amp;mutex); // Entra nella regione critica\n \n  \n \n¬†¬†¬†¬†¬†¬†¬†¬†remove_item(); // Rimuove un elemento dal buffer\n \n¬†¬†¬†¬†¬†¬†¬†¬†print_buffer(); // Stampa il contenuto del buffer\n \n  \n \n¬†¬†¬†¬†¬†¬†¬†¬†up(&amp;mutex); // Esce dalla regione critica\n \n¬†¬†¬†¬†¬†¬†¬†¬†up(&amp;empty); // Segnala che c&#039;√® un posto vuoto in pi√π nel buffer\n \n¬†¬†¬†¬†}\n \n}\n \n  \n \nint main() {\n \npthread_t prod, cons; // Dichiarazione dei thread\n \n  \n \n// Inizializzazione dei semafori\n \nsem_init(&amp;mutex, 0, 1);\n \nsem_init(&amp;empty, 0, N);\n \nsem_init(&amp;full, 0, 0);\n \n  \n \n// Creazione dei thread\n \npthread_create(&amp;prod, NULL, producer, NULL);\n \npthread_create(&amp;cons, NULL, consumer, NULL);\n \n// Attesa della terminazione dei thread\n \npthread_join(prod, NULL);\n \npthread_join(cons, NULL);\n \n  \n \n// Distruzione dei semafori\n \nsem_destroy(&amp;mutex);\n \nsem_destroy(&amp;empty);\n \nsem_destroy(&amp;full);\n \n  \n \nreturn 0;\n \n}\nincludiamo la libreria semaphore.h per utilizzare i semafori una struttura che consente l‚Äôaccesso ai dati o lo vieta\nusiamo sem_t per dichiarare dei contatori a semaforo globali\nuno sar√† un semplice lock per la regione critica dove vengono o scritte o lette le cose nel buffer\npoi avremo due contatori uno per i full e uno empty\nserve per dire al produttore se pu√≤ produrre o al consumatore se pu√≤ consumare\ncreiamo una funzione down che decrementa quel determinato semaforo se maggiore di 0\ncon sem_wait(sem);\nun‚Äôaltra che incrementa con\nsem_post(sem);\ninsert item semplicemente inserisce un elemento e aggiorna in\npoi abbiamo quello che toglie l‚Äôultima posizione perch√© tanto √® una sorta di lifo questo buffer.\nuno che stampa abbastanza ok\ncreiamo la funzione producer\nfacciamo un decremento alla empty quindi aspettiamo che ci siano dei posti liberi &gt;0\nabbassa il mutex se esso √® libero quindi 1 e entra nella regione critica\ninserisce l‚Äôitem e lo stampa\nalza il mutex e incrementa anche il pieno perch√© significa che √® stato messo un elemento in pi√π\nil consumer invece\nfa un decremento se full √® &gt;0\nentra nel mutex se 1\ntoglie l‚Äôelemento e lo stampa\nalza il mutex\nalza l‚Äôempty\nNel main creiamo due thread uno produttore uno consumatore prima li dichiariamo\npoi creiamo i semafori effettivi con sem_init che puntano all‚Äôindirizzo dei semafori dichiarati globalmente\ninizializziamo con\nsem_init(&amp;mutex, 0, 1);\ndove il primo √® un puntatore alla variabile che poi verr√† modificata\nla seconda indica se √® un semaforo condiviso con altri thread del processo 0 oppure con altri thread di altri processi 1 il terzo indica il valore iniziale del semaforo in questo caso 1\nandiamo a creare i thread produttore e consumatore puntando alle variabili dichiarate prima mettendo opzioni NULL e specifichiamo la funzione che andranno a fare e non passiamo parametri\nattendiamo che i due finiscano con join senza ritornare nulla\ndistruggiamo i semafori con\nsem_destroy(indirizzo semaforo)"},"UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/CODICI-CROCE/READER-WRITER-SEMAPHORE.c":{"slug":"UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/CODICI-CROCE/READER-WRITER-SEMAPHORE.c","filePath":"UNI/ANNO 2/SISTEMI OPERATIVI/CODICI IN C/CODICI CROCE/READER WRITER SEMAPHORE.c.md","title":"READER WRITER SEMAPHORE.c","links":[],"tags":[],"content":"/*\n \n  \n \nEsempio dello schema Readers/Writers in C usando POSIX\n \n  \n \nAutore. Danilo Croce\n \n  \n \nNOTA: per essere eseguito in ambiente LINUX usare gcc -pthread source_file.c -o binary_output\n \n  \n \nWARNING: sembra non funzionare su MAC OS X\n \n  \n \n*/\n \n  \n \n#include &lt;pthread.h&gt;\n \n#include &lt;stdio.h&gt;\n \n#include &lt;stdlib.h&gt;\n \n#include &lt;unistd.h&gt;\n \n#include &lt;semaphore.h&gt;\n \n  \n \n#define TRUE 1\n \n#define NUM_READERS 3 // Numero di lettori\n \n  \n \nsem_t mutex; // Semaforo per l&#039;accesso esclusivo a rc\n \nsem_t db; // Semaforo per l&#039;accesso esclusivo al database\n \nint rc = 0; // Numero di processi che leggono o vogliono leggere\n \n  \n \nvoid down(sem_t *sem) {\n \nsem_wait(sem);\n \n}\n \n  \n \nvoid up(sem_t *sem) {\n \nsem_post(sem);\n \n}\n \n  \n \nvoid read_database() {\n \nprintf(&quot;Leggendo dal database...\\n&quot;);\n \nsleep(1); // Simulazione lettura dal database\n \n}\n \n  \n \nvoid write_database() {\n \nprintf(&quot;Scrivendo nel database...\\n&quot;);\n \nsleep(1); // Simulazione scrittura nel database\n \n}\n \n  \n \nvoid use_data_read() {\n \nprintf(&quot;Utilizzando i dati letti...\\n&quot;);\n \nsleep(1); // Simulazione dell&#039;utilizzo dei dati\n \n}\n \n  \n \nvoid think_up_data() {\n \nprintf(&quot;Pensando ai dati da scrivere...\\n&quot;);\n \nsleep(1); // Simulazione del processo di pensare ai dati\n \n}\n \n  \n \nvoid *reader(void *arg) {\n \nwhile (TRUE) {\n \ndown(&amp;mutex); // Ottiene accesso esclusivo a rc, in modo da non avere interferenze da altri lettori\n \n  \n \nrc++; // Un lettore in pi√π\n \n  \n \nif (rc == 1) down(&amp;db); // Se √® il primo lettore, blocca accesso al DB\n \n  \n \nup(&amp;mutex); // Rilascia accesso esclusivo a rc\n \n  \n \nread_database(); // Legge dal database\n \n  \n \ndown(&amp;mutex); // Ottiene accesso esclusivo a rc, in modo da non avere interferenze da altri lettori\n \n  \n \nrc--; // Un lettore in meno\n \n  \n \nif (rc == 0) up(&amp;db); // Se √® l&#039;ultimo lettore, &quot;sblocca&quot; accesso al DB\n \n  \n \nup(&amp;mutex); // Rilascia accesso esclusivo a rc\n \n  \n \nuse_data_read(); // Usa i dati letti (Nota: siamo fuori da zona critica)\n \n}\n \n}\n \n  \n \nvoid *writer(void *arg) {\n \nwhile (TRUE) {\n \nthink_up_data(); // Il processo &quot;finge&quot; di elaborare i dati da scrivere\n \n  \n \ndown(&amp;db); // Ottiene accesso esclusivo al database\n \n  \n \nwrite_database(); // Scrive nel database\n \n  \n \nup(&amp;db); // Rilascia accesso esclusivo\n \n}\n \n}\n \n  \n \nint main() {\n \npthread_t readers[NUM_READERS], writer_thread;\n \n  \n \nsem_init(&amp;mutex, 0, 1);\n \nsem_init(&amp;db, 0, 1);\n \n  \n \n// Creazione degli N lettori\n \nfor (int i = 0; i &lt; NUM_READERS; i++) {\n \npthread_create(&amp;readers[i], NULL, reader, NULL);\n \n}\n \n  \n \n// Creazione del thread scrittore\n \npthread_create(&amp;writer_thread, NULL, writer, NULL);\n \n  \n \n// Join degli N lettori\n \nfor (int i = 0; i &lt; NUM_READERS; i++) {\n \npthread_join(readers[i], NULL);\n \n}\n \n  \n \n// Join del thread scrittore\n \npthread_join(writer_thread, NULL);\n \n  \n \nsem_destroy(&amp;mutex);\n \nsem_destroy(&amp;db);\n \n  \n \nreturn 0;\n \n}\nil codice prevede 3 lettori\ncrea un mutex per accedere esclusivamente a rc ovvero il numero di processi che leggono\npoi un‚Äôaltro per il database\ncreo le classiche funzioni up e down viste prima\ncreo una funzione che legge il database per finta lo scrive e usa i dati e roba inutile\ncrea due funzioni una per il reader e una che andr√† al thread writer\nabbassa il mutex se gli √® possibile e si mette come lettore in pi√π\nse √® il primo allora abbassa il database se √® &gt;0 quindi libero\nalza il mutex e legge il database\nse √® l‚Äôultimo lettore quindi rc==0 allora significa che pu√≤ alzarsi il mutex\nil resto si capisce da s√®"},"UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/CODICI-CROCE/THREADS.C":{"slug":"UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/CODICI-CROCE/THREADS.C","filePath":"UNI/ANNO 2/SISTEMI OPERATIVI/CODICI IN C/CODICI CROCE/THREADS.C.md","title":"THREADS.C","links":[],"tags":[],"content":"// Includi le librerie necessarie per il programma\n \n#include &lt;pthread.h&gt;\n \n#include &lt;stdio.h&gt;\n \n#include &lt;stdlib.h&gt;\n \n#include &lt;unistd.h&gt;\n \n  \n \n// Definisci una costante per il numero di thread da creare\n \n#define NUMBER_OF_THREADS 10\n \n  \n \n// Funzione che verr√† eseguita da ogni thread\n \nvoid * print_hello_world(void * tid) {\n \n¬†¬†¬†¬†// Genera un numero casuale tra 0 e 4 (quanti secondi far dormire il thread)\n \n¬†¬†¬†¬†int r = rand()%5;\n \n¬†¬†¬†¬†// Fa dormire il thread per un numero casuale di secondi\n \n¬†¬†¬†¬†sleep(r);\n \n¬†¬†¬†¬†// Stampa un messaggio con l&#039;ID del thread\n \n¬†¬†¬†¬†printf(&quot;Hello World. Greetings from thread %d\\n&quot;, tid);\n \n¬†¬†¬†¬†// Termina il thread e restituisce NULL\n \n¬†¬†¬†¬†pthread_exit(NULL);\n \n}\n \n  \n \nint main(int arg, char* argv []) {\n \n¬†¬†¬†¬†// Dichiarazione di un array di thread\n \n¬†¬†¬†¬†pthread_t threads[NUMBER_OF_THREADS];\n \n¬†¬†¬†¬†int status, i;\n \n  \n \n¬†¬†¬†¬†// Ciclo per creare NUMBER_OF_THREADS thread\n \n¬†¬†¬†¬†for (i=0; i &lt; NUMBER_OF_THREADS; i++) {\n \n¬†¬†¬†¬†¬†¬†¬†¬†// Crea un nuovo thread e assegna la funzione print_hello_world come funzione di avvio\n \n¬†¬†¬†¬†¬†¬†¬†¬†status = pthread_create(&amp;threads[i], NULL, print_hello_world, (void * ) i);\n \n¬†¬†¬†¬†¬†¬†¬†¬†if (status == 0){\n \n¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†// Stampa l&#039;ID del thread creato e il suo stato\n \n¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†printf(&quot;Process %d created with status %d\\n&quot;, i, status);\n \n¬†¬†¬†¬†¬†¬†¬†¬†}\n \n¬†¬†¬†¬†¬†¬†¬†¬†// Se ci sono problemi nella creazione del thread, stampa un messaggio di errore e termina il programma\n \n¬†¬†¬†¬†¬†¬†¬†¬†else{\n \n¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†printf(&quot;Problems while creating process %d\\n&quot;, i);¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†\n \n¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†exit (-1);\n \n¬†¬†¬†¬†¬†¬†¬†¬†}\n \n¬†¬†¬†¬†}\n \n  \n \n¬†¬†¬†¬†// Ciclo per attendere che tutti i thread terminino\n \n¬†¬†¬†¬†for (i=0; i &lt; NUMBER_OF_THREADS; i++) {\n \n¬†¬†¬†¬†¬†¬†¬†¬†status = pthread_join(threads[i], NULL);\n \n¬†¬†¬†¬†¬†¬†¬†¬†// Stampa l&#039;ID del thread che ha terminato e il suo stato\n \n¬†¬†¬†¬†¬†¬†¬†¬†printf(&quot;Process %d terminated with status %d\\n&quot;, i, status);\n \n¬†¬†¬†¬†¬†¬†¬†¬†// Se ci sono problemi nell&#039;attesa del thread, stampa un messaggio di errore e termina il programma\n \n¬†¬†¬†¬†¬†¬†¬†¬†if (status != 0){\n \n¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†printf(&quot;Problems while waiting for process %d\\n&quot;, i);¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†\n \n¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†exit (-1);\n \n¬†¬†¬†¬†¬†¬†¬†¬†}\n \n¬†¬†¬†¬†}\n \n  \n \n¬†¬†¬†¬†// Termina il programma principale\n \n¬†¬†¬†¬†return 0;\n \n}\nusiamo pthread.h per fare operazioni su thread\ncreiamo una funzione con puntatore generico void *\ni thread funzionano creando un array che li contenga in questo caso 10 l‚Äôarray sar√† di tipo\npthread_t\ndopo aver istanziato dello spazio per ogni thread dobbiamo crearli effettivamente attraverso\npthread_create\ncon un ciclo for\npthread_create(&amp;threads[i], NULL, print_hello_world, (void * ) i)\nandiamo a creare un thread dando come prima cosa l‚Äôindirizzo di memoria del pthread detto prima poi mettiamo NULL perch√© ci sono una serie di opzioni che non ci servono e richiamiamo la funzione che deve fare passandogli come argomento la cosa dopo la virgola in questo caso i che verr√† castato come un void *\nalla fine i √® il numero del thread se ci pensi\nquesta funzione create ritorna 0 se √® stato creato con successo o valori maggiori se errore\nse avvengono errori facciamo un controllo\nfacciamo pthread_join(threads[i], NULL);\nper ogni thread con un ciclo for\nesso attende la terminazione dei singoli thread mettendosi in wait\nil secondo argomento √® un puntatore che si dovrebbe salvare il valore di ritorno del thread che altrimenti andrebbe perso\nerrore se maggiore di 0 altrimenti 0 se √® un successo"},"UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/ESERCIZI/1.PROCESSI-CHE-LEGGONO-OCCORRENZE-FILE":{"slug":"UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/ESERCIZI/1.PROCESSI-CHE-LEGGONO-OCCORRENZE-FILE","filePath":"UNI/ANNO 2/SISTEMI OPERATIVI/CODICI IN C/ESERCIZI/1.PROCESSI CHE LEGGONO OCCORRENZE FILE.md","title":"1.PROCESSI CHE LEGGONO OCCORRENZE FILE","links":[],"tags":[],"content":"\n\n                  \n                  consegna \n                  \n                \n\n\n\nCreare un programma che legge un file e conta le occorrenze di una parola nel seguente modo:\n\nIl primo processo legge dall‚Äôinizio alla met√† e conta le occorrenze della parola.\nIl secondo processo legge dalla met√† fino alla fine e conta le occorrenze della parola.\nInviano poi il numero di occorrenze al processo padre, il quale le somma e le stampa a video.\n\n\n\n\n\n#include &lt;stdio.h&gt;\n#include &lt;stdlib.h&gt;\n#include &lt;unistd.h&gt;\n#include &lt;signal.h&gt;\n#include &lt;sys/types.h&gt;\n#include &lt;fcntl.h&gt;\n#include &lt;string.h&gt;\n#include &lt;sys/wait.h&gt;\n \nint conta(char *stringa,char* buf,int start,int end)\n{\n    int lenp=strlen(stringa);\n    int contatore=0;\n    if(start!=0) end=(end-lenp+1);\n    else end--;\n    for(int i=start;i &lt;=(end);i++)\n    {\n        int cntmp=0;\n        while(cntmp&lt;lenp)\n        {\n            if(stringa[cntmp]==buf[cntmp+i])\n            {\n                cntmp++;\n            }\n            else break;\n        }\n        if(cntmp==lenp)\n        {\n            contatore++;\n        }\n \n    }\n \n \n    return contatore;\n}\n \nint main(int argc, char **argv)\n{\n \n    if(argc!=2) exit(1);\n    char *stringa = argv[1];\n    int rd;\n    int fd=open(&quot;file.txt&quot;,O_RDONLY);\n    if(fd==-1) exit(1);\n    int pip[2];\n    pipe(pip);\n    char buf[4096];\n    ssize_t len=read(fd,buf,4096);\n    buf[len] = &#039;\\0&#039;;\n    fflush(stdout);\n    printf(&quot;lunghezza %d \\n&quot;,len);\n    pid_t p1;\n    pid_t p2;\n    p1=fork();\n    if(p1==0)\n    {\n \n        close(pip[0]);\n        int counter=0;\n        counter=conta(stringa,buf,0,len/2);\n        fflush(stdout);\n        printf(&quot;primo processo %d %d \\n&quot;,counter,len/2);\n        write(pip[1],&amp;counter,sizeof(int));\n        exit(0);\n \n    }\n    if(p1&gt;0)\n    {\n        p2=fork();\n        if(p2==0){\n            int counter=0;\n            counter=conta(stringa,buf,len/2,len);\n            fflush(stdout);\n            printf(&quot;sono il secondo processo %d %d \\n&quot;,counter,len);\n            write(pip[1],&amp;counter,sizeof(int));\n            exit(0);\n        }\n \n    }\n \n \n    if(p1&gt;0 &amp;&amp; p2&gt;0)\n    {\n        int num1=0;\n        int num2=0;\n        close(pip[1]);\n        read(pip[0],&amp;num1,sizeof(int));\n        read(pip[0],&amp;num2,sizeof(int));\n        fflush(stdout);\n        printf(&quot;sono il padre e le parole sono %d \\n&quot;,(num1+num2));\n        waitpid(p1,NULL,0);\n        waitpid(p2,NULL,0);\n        exit(0);\n    }\n \n    return 0;\n}\n "},"UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/ESERCIZI/10.-thread-+1--1":{"slug":"UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/ESERCIZI/10.-thread-+1--1","filePath":"UNI/ANNO 2/SISTEMI OPERATIVI/CODICI IN C/ESERCIZI/10. thread +1 -1.md","title":"10. thread +1 -1","links":[],"tags":[],"content":"\n\n                  \n                  consegna \n                  \n                \n\nScrivere un programma C che segue le seguenti specifiche:\n\nIl programma crea un buffer come array di 11 numeri interi, inizializzati a zero.\nGenera tre thread:\n\nIl primo thread sceglie casualmente una cella del buffer e vi scrive il numero +1.\nIl secondo thread sceglie casualmente una cella del buffer e vi scrive il numero -1.\nIl terzo thread controlla se tutte le celle del buffer sono state inizializzate. In caso positivo, determina se il numero di celle contenenti +1 √® maggiore di quelle con -1 e termina tutti i thread.\nMentre un thread accede al buffer, nessun altro deve accedervi. Ogni thread attende un tempo random tra 0 e 3 secondi.\n\n\n\n\n\n#include&lt;stdio.h&gt;\n \n#include&lt;stdlib.h&gt;\n \n#include&lt;unistd.h&gt;\n \n#include&lt;fcntl.h&gt;\n \n#include&lt;time.h&gt;\n \n#include&lt;pthread.h&gt;\n \npthread_mutex_t mutex;\n \nint buffer[11]={0};\n \nint termina=0;\n \n  \n \nvoid *thread1(void *ptr)\n \n{\n \n¬† ¬† while(1)\n \n¬† ¬† {\n \n¬† ¬† ¬† ¬† pthread_mutex_lock(&amp;mutex);\n \n¬† ¬† ¬† ¬† if(termina)\n \n¬† ¬† ¬† ¬† {\n \n¬† ¬† ¬† ¬† ¬† ¬† pthread_mutex_unlock(&amp;mutex);\n \n¬† ¬† ¬† ¬† ¬† ¬† pthread_exit(NULL);\n \n¬† ¬† ¬† ¬† }\n \n¬† ¬† ¬† ¬† int pos=rand()%11;\n \n¬† ¬† ¬† ¬† printf(&quot;ho scritto nel buffer +1 nella pos %d \\n&quot;,pos);\n \n¬† ¬† ¬† ¬† buffer[pos]=+1;\n \n¬† ¬† ¬† ¬† pthread_mutex_unlock(&amp;mutex);\n \n¬† ¬† ¬† ¬† sleep(rand()%4);\n \n¬† ¬† }\n \n}\n \nvoid *thread2(void *ptr)\n \n{\n \n¬† ¬† while(1)\n \n¬† ¬† {\n \n¬† ¬† pthread_mutex_lock(&amp;mutex);\n \n¬† ¬† if(termina)\n \n¬† ¬† {\n \n¬† ¬† ¬† ¬† pthread_mutex_unlock(&amp;mutex);\n \n¬† ¬† ¬† ¬† pthread_exit(NULL);\n \n¬† ¬† }\n \n¬† ¬† int pos=rand()%11;\n \n¬† ¬† printf(&quot;ho scritto nel buffer -1 nella pos %d\\n&quot;,pos);\n \n¬† ¬† buffer[pos]=-1;\n \n¬† ¬† pthread_mutex_unlock(&amp;mutex);\n \n¬† ¬† sleep(rand()%4);\n \n¬† ¬† }\n \n}\n \nvoid *thread3(void *ptr)\n \n{\n \n¬† ¬† pthread_mutex_lock(&amp;mutex);\n \n¬† ¬† printf(&quot;controllo se il buffer √® inizializzato \\n&quot;);\n \n¬† ¬† for(int i=0;i&lt;11;i++)\n \n¬† ¬† {\n \n¬† ¬† ¬† ¬† if(buffer[i]!=0)\n \n¬† ¬† ¬† ¬† {\n \n¬† ¬† ¬† ¬† ¬† ¬† printf(&quot;buffer non inizializzato \\n&quot;);\n \n¬† ¬† ¬† ¬† ¬† ¬† pthread_mutex_unlock(&amp;mutex);\n \n¬† ¬† ¬† ¬† ¬† ¬† termina=1;\n \n¬† ¬† ¬† ¬† ¬† ¬† pthread_exit(NULL);\n \n¬† ¬† ¬† ¬† }\n \n¬† ¬† }\n \n¬† ¬† printf(&quot;buffer correttamente inizializzato \\n&quot;);\n \n¬† ¬† pthread_mutex_unlock(&amp;mutex);\n \n¬† ¬† while(1)\n \n¬† ¬† {\n \n¬† ¬† pthread_mutex_lock(&amp;mutex);\n \n  \n \n¬† ¬† int contap=0,contam=0;\n \n¬† ¬† ¬† ¬† for(int i=0;i&lt;11;i++)\n \n¬† ¬† ¬† ¬† {\n \n¬† ¬† ¬† ¬† ¬† ¬† if(buffer[i]==+1) contap++;\n \n¬† ¬† ¬† ¬† ¬† ¬† else contam++;\n \n¬† ¬† ¬† ¬† }\n \n¬† ¬† ¬† ¬† if(contap&gt;contam)\n \n¬† ¬† ¬† ¬† {\n \n¬† ¬† ¬† ¬† ¬† ¬† printf(&quot;contap&gt;contam \\n&quot;);\n \n¬† ¬† ¬† ¬† ¬† ¬† termina=1;\n \n¬† ¬† ¬† ¬† ¬† ¬† for(int i=0;i&lt;11;i++)\n \n¬† ¬† ¬† ¬† ¬† ¬† {\n \n¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† printf(&quot; ecco l&#039;array %d \\n&quot;,buffer[i]);\n \n¬† ¬† ¬† ¬† ¬† ¬† }\n \n¬† ¬† ¬† ¬† ¬† ¬† pthread_mutex_unlock(&amp;mutex);\n \n¬† ¬† ¬† ¬† ¬† ¬† pthread_exit(0);\n \n¬† ¬† ¬† ¬† }\n \n¬† ¬† ¬† ¬† else printf(&quot;niente \\n&quot;);\n \n¬† ¬† pthread_mutex_unlock(&amp;mutex);\n \n¬† ¬† sleep(rand()%4);\n \n¬† ¬† }\n \n}\n \n  \n  \n \nint main(int argc, char **argv)\n \n{\n \n¬† ¬† pthread_t t1,t2,t3;\n \n¬† ¬† pthread_mutex_init(&amp;mutex,NULL);\n \n¬† ¬† pthread_create(&amp;t3,NULL,thread3,NULL);\n \n¬† ¬† pthread_create(&amp;t1,NULL,thread1,NULL);\n \n¬† ¬† pthread_create(&amp;t2,NULL,thread2,NULL);\n \n¬† ¬† pthread_join(t3,NULL);\n \n¬† ¬† pthread_join(t1,NULL);\n \n¬† ¬† pthread_join(t2,NULL);\n \n¬† ¬† pthread_mutex_destroy(&amp;mutex);\n \n  \n \n¬† ¬† return 0;\n \n}"},"UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/ESERCIZI/11.-thread--1-0-100":{"slug":"UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/ESERCIZI/11.-thread--1-0-100","filePath":"UNI/ANNO 2/SISTEMI OPERATIVI/CODICI IN C/ESERCIZI/11. thread -1 0 100.md","title":"11. thread -1 0 100","links":[],"tags":[],"content":"\n\n                  \n                  consegna \n                  \n                \n\nScrivere un programma con tre thread che risolvono il seguente problema:\n\nUn buffer di n elementi inizializzato a -1 viene riempito nel seguente modo:\n\nIl primo thread aggiunge nelle posizioni pari del buffer un numero casuale da 0 a 100.\nIl secondo thread aggiunge nelle posizioni dispari del buffer un numero casuale da 100 a 200.\nIl terzo thread modifica il buffer nel seguente modo:\n\nbuff[0] = buff[0]\nbuff[1] = buff[1] + buff[0]\nbuff[2] = buff[1] + buff[2]\n\n\n\n\nUtilizzare la mutua esclusione.\n\n\n\n#include&lt;stdio.h&gt;\n \n#include&lt;stdlib.h&gt;\n \n#include&lt;unistd.h&gt;\n \n#include&lt;pthread.h&gt;\n \n#include&lt;fcntl.h&gt;\n \n#include&lt;time.h&gt;\n \n#define n 10\n \nint buf[n]={-1};\n \npthread_mutex_t mutex;\n \nvoid* thread1()\n \n{\n \n¬† ¬† srand(time(NULL));\n \n¬† ¬† int num=0;\n \n¬† ¬† pthread_mutex_lock(&amp;mutex);\n \n¬† ¬† for(int i=0;i&lt;n;i=i+2)\n \n¬† ¬† {\n \n¬† ¬† ¬† ¬† num=rand()%101;\n \n¬† ¬† ¬† ¬† printf(&quot;sono t1 sto stampando %d in posizione %d \\n&quot;,num,i);\n \n¬† ¬† ¬† ¬† buf[i]=num;\n \n¬† ¬† }\n \n¬† ¬† pthread_mutex_unlock(&amp;mutex);\n \n¬† ¬† pthread_exit(NULL);\n \n}\n \nvoid *thread2()\n \n{\n \n¬† ¬† srand(time(NULL));\n \n¬† ¬† pthread_mutex_lock(&amp;mutex);\n \n¬† ¬† int num=0;\n \n¬† ¬† for(int i=1;i&lt;n;i=i+2)\n \n¬† ¬† {\n \n¬† ¬† ¬† ¬† num=100+rand()%101;\n \n¬† ¬† ¬† ¬† printf(&quot;sono t2 sto stampando %d in posizione %d \\n&quot;,num,i);\n \n¬† ¬† ¬† ¬† buf[i]=num;\n \n¬† ¬† }\n \n¬† ¬† pthread_mutex_unlock(&amp;mutex);\n \n¬† ¬† pthread_exit(NULL);\n \n}\n \nvoid *thread3()\n \n{\n \n¬† ¬† pthread_mutex_lock(&amp;mutex);\n \n¬† ¬† buf[0]=buf[0];\n \n¬† ¬† buf[1]=buf[1]+buf[0];\n \n¬† ¬† buf[2]=buf[1]+buf[2];\n \n¬† ¬† pthread_mutex_unlock(&amp;mutex);\n \n¬† ¬† printf(&quot;ho scambiato i numeri&quot;);\n \n¬† ¬† pthread_exit(NULL);\n \n}\n \nint main(int argc,char **argv)\n \n{\n \n¬† ¬† pthread_t t1,t2,t3;\n \n¬† ¬† pthread_mutex_init(&amp;mutex,NULL);\n \n¬† ¬† pthread_create(&amp;t1,NULL,thread1,NULL);\n \n¬† ¬† pthread_create(&amp;t2,NULL,thread2,NULL);\n \n¬† ¬† pthread_create(&amp;t3,NULL,thread3,NULL);\n \n¬† ¬† pthread_join(t1,NULL);\n \n¬† ¬† pthread_join(t2,NULL);\n \n¬† ¬† pthread_join(t3,NULL);\n \n¬† ¬† pthread_mutex_destroy(&amp;mutex);\n \n¬† ¬† return 0;\n \n  \n \n}"},"UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/ESERCIZI/12.-MAX-E-MIN":{"slug":"UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/ESERCIZI/12.-MAX-E-MIN","filePath":"UNI/ANNO 2/SISTEMI OPERATIVI/CODICI IN C/ESERCIZI/12. MAX E MIN.md","title":"12. MAX E MIN","links":[],"tags":[],"content":"\n\n                  \n                  consegna \n                  \n                \n\nScrivere un programma in C con tre thread che operano su due array di dimensione N\ninizialmente a 0:\n\nIl primo thread scrive in un array A numeri casuali tra 1 e 150, in posizioni randomiche.\nIl secondo thread scrive in un array B numeri casuali tra 150 e 300, in posizioni randomiche.\nIl terzo thread calcola:\n\nIl massimo e il minimo in A e B.\nmax{max(A), max(B)} e min{min(A), min(B)}.\n\n\n\n\n\n#include&lt;stdio.h&gt;\n \n#include&lt;stdlib.h&gt;\n \n#include&lt;unistd.h&gt;\n \n#include&lt;time.h&gt;\n \n#include&lt;pthread.h&gt;\n \n#define N 10\n \nint max(int arr[N])\n \n{\n \n¬† ¬† int max=arr[0];\n \n¬† ¬† for(int i=0;i&lt;N;i++)\n \n¬† ¬† {\n \n¬† ¬† ¬† ¬† if(arr[i]&gt;max) max=arr[i];\n \n¬† ¬† }\n \n¬† ¬† return max;\n \n}\n \nint min(int arr[N])\n \n{\n \n¬† ¬† int min=arr[0];\n \n¬† ¬† for(int i=0;i&lt;N;i++)\n \n¬† ¬† {\n \n¬† ¬† ¬† ¬† if(arr[i]&lt;min) min=arr[i];\n \n¬† ¬† }\n \n¬† ¬† return min;\n \n}\n \n  \n \npthread_mutex_t mutex1;\n \npthread_mutex_t mutex2;\n \nint A[N]={0};\n \nint B[N]={0};\n \nvoid * thread1()\n \n{\n \n¬† ¬† pthread_mutex_lock(&amp;mutex1);\n \n¬† ¬† srand(time(NULL));\n \n¬† ¬† printf(&quot;sono il t1 e sto generando i numeri \\n&quot;);\n \n¬† ¬† for(int i=0;i&lt;N;i++)\n \n¬† ¬† {\n \n¬† ¬† ¬† ¬† A[rand()%N]=1+rand()%100;\n \n¬† ¬† }\n \n¬† ¬† printf(&quot;sono il t1 e ho finito di generare i numeri \\n&quot;);\n \n¬† ¬† pthread_mutex_unlock(&amp;mutex1);\n \n¬† ¬† pthread_exit(NULL);\n \n}\n \nvoid *thread2()\n \n{\n \n¬† ¬† pthread_mutex_lock(&amp;mutex2);\n \n¬† ¬† srand(time(NULL));\n \n¬† ¬† printf(&quot;sono il t2 e sto generando i numeri \\n&quot;);\n \n¬† ¬† for(int i=0;i&lt;N;i++)\n \n¬† ¬† {\n \n¬† ¬† ¬† ¬† B[rand()%N]=150+rand()%151;\n \n¬† ¬† }\n \n¬† ¬† printf(&quot;sono il t2 e ho finito di generare i numeri \\n&quot;);\n \n¬† ¬† pthread_mutex_unlock(&amp;mutex2);\n \n¬† ¬† pthread_exit(NULL);\n \n}\n \nvoid *thread3()\n \n{\n \n¬† ¬† pthread_mutex_lock(&amp;mutex1);\n \n¬† ¬† pthread_mutex_lock(&amp;mutex2);\n \n¬† ¬† int a1=max(A);\n \n¬† ¬† int a2=min(A);\n \n¬† ¬† int b1=max(B);\n \n¬† ¬† int b2=min(B);\n \n¬† ¬† if(a1&gt;b1) printf(&quot;il max dei max √® %d \\n&quot;,a1);\n \n¬† ¬† else printf(&quot;il max dei max √® %d \\n&quot;,b1);\n \n¬† ¬† if(a2&lt;b2) printf(&quot;il min dei min √® %d \\n&quot;,a2);\n \n¬† ¬† else printf(&quot;il min dei min √® %d \\n&quot;,b2);\n \n¬† ¬† pthread_mutex_unlock(&amp;mutex1);\n \n¬† ¬† pthread_mutex_unlock(&amp;mutex2);\n \n¬† ¬† pthread_exit(NULL);\n \n}\n \nint main(int argc, char **argv)\n \n{\n \n¬† ¬† pthread_t t1,t2,t3;\n \n¬† ¬† pthread_mutex_init(&amp;mutex1,NULL);\n \n¬† ¬† pthread_mutex_init(&amp;mutex2,NULL);\n \n¬† ¬† pthread_create(&amp;t1,NULL,thread1,NULL);\n \n¬† ¬† pthread_create(&amp;t2,NULL,thread2,NULL);\n \n¬† ¬† pthread_create(&amp;t3,NULL,thread3,NULL);\n \n¬† ¬† pthread_join(t1,NULL);\n \n¬† ¬† pthread_join(t2,NULL);\n \n¬† ¬† pthread_join(t3,NULL);\n \n¬† ¬† pthread_mutex_destroy(&amp;mutex1);\n \n¬† ¬† pthread_mutex_destroy(&amp;mutex2);\n \n¬† ¬† return 0;\n \n}"},"UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/ESERCIZI/13.-SEMAFORI-E-POSIZIONI-PARI":{"slug":"UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/ESERCIZI/13.-SEMAFORI-E-POSIZIONI-PARI","filePath":"UNI/ANNO 2/SISTEMI OPERATIVI/CODICI IN C/ESERCIZI/13. SEMAFORI E POSIZIONI PARI.md","title":"13. SEMAFORI E POSIZIONI PARI","links":[],"tags":[],"content":"\n\n                  \n                  consegna \n                  \n                \n\nDue thread:\n\nIl produttore inserisce numeri pari da 0 a 100 in posizioni pari e numeri dispari da 100 a 200 in posizioni dispari in un buffer di N elementi inizializzato a -1.\nIl consumatore legge dal buffer un numero pari e uno dispari, li somma e stampa la somma.\n\n\n\n#include&lt;pthread.h&gt;\n \n#include&lt;stdio.h&gt;\n \n#include&lt;stdlib.h&gt;\n \n#include&lt;unistd.h&gt;\n \n#include&lt;semaphore.h&gt;\n \n#include&lt;time.h&gt;\n \n#define N 10\n \nint buf[N]={-1};\n \nsem_t sem;\n \nsem_t full;\n \nsem_t empty;\n \nint stop=0;\n \nint s1=0,s2=0;\n \n  \n \nvoid up(sem_t *s)\n \n{\n \n¬† ¬† sem_post(s);\n \n}\n \nvoid down(sem_t *s)\n \n{\n \n¬† ¬† sem_wait(s);\n \n}\n \nvoid *producer()\n \n{\n \n¬† ¬† int p=0;\n \n¬† ¬† int d=1;\n \n¬† ¬† int num1=0;\n \n¬† ¬† int num2=101;\n \n  \n \n¬† ¬† while(1)\n \n¬† ¬† {\n \n¬† ¬† ¬† ¬† if(s1==1 &amp;&amp; s2==1)\n \n¬† ¬† ¬† ¬† {\n \n¬† ¬† ¬† ¬† ¬† ¬† break;\n \n¬† ¬† ¬† ¬† }\n \n  \n \n¬† ¬† ¬† ¬† down(&amp;empty);\n \n¬† ¬† ¬† ¬† down(&amp;sem);\n \n¬† ¬† ¬† ¬† //inserisco numero pari\n \n¬† ¬† ¬† ¬† if (num1&gt;=100){printf(&quot;pari arrivati %d \\n&quot;,num1); s1=1;}\n \n¬† ¬† ¬† ¬† else{\n \n¬† ¬† ¬† ¬† printf(&quot;ho scritto un numero pari nella pos %d %d \\n&quot;,p,num1);\n \n¬† ¬† ¬† ¬† buf[p]=num1;\n \n¬† ¬† ¬† ¬† p = (p + 2) % N;\n \n¬† ¬† ¬† ¬† num1+=2;\n \n¬† ¬† ¬† ¬† }\n \n¬† ¬† ¬† ¬† if (num2&gt;=200){printf(&quot;dispari arrivati %d \\n&quot;,num2); s2=1;}\n \n¬† ¬† ¬† ¬† else{\n \n¬† ¬† ¬† ¬† printf(&quot;ho scritto un numero dispari nella pos %d %d\\n&quot;,d,num2);\n \n¬† ¬† ¬† ¬† buf[d]=num2;\n \n¬† ¬† ¬† ¬† num2+=2;\n \n¬† ¬† ¬† ¬† d = (d + 2) % N;\n \n¬† ¬† ¬† ¬† }\n \n¬† ¬† ¬† ¬† up(&amp;full);\n \n¬† ¬† ¬† ¬† up(&amp;sem);\n \n¬† ¬† }\n \n¬† ¬† pthread_exit(NULL);\n \n}\n \nvoid *consumer()\n \n{\n \n  \n \n¬† ¬† int p=0;\n \n¬† ¬† int d=1;\n \n¬† ¬† int n=0;\n \n¬† ¬† int n1=0;\n \n¬† ¬† while(1)\n \n¬† ¬† {\n \n¬† ¬† ¬† ¬† if(s1==1 &amp;&amp; s2==1)\n \n¬† ¬† ¬† ¬† {\n \n¬† ¬† ¬† ¬† ¬† ¬† break;\n \n¬† ¬† ¬† ¬† }\n \n¬† ¬† ¬† ¬† down(&amp;full);\n \n¬† ¬† ¬† ¬† down(&amp;sem);\n \n¬† ¬† ¬† ¬† n=buf[p];\n \n¬† ¬† ¬† ¬† printf(&quot; ecco il numero pari: %d \\n&quot;,n); ¬†\n \n¬† ¬† ¬† ¬† p = (p + 2) % N;\n \n¬† ¬† ¬† ¬† printf(&quot; ecco il numero dispari: %d \\n&quot;,n1);\n \n¬† ¬† ¬† ¬† n1=buf[d];\n \n¬† ¬† ¬† ¬† d = (d + 2) % N;\n \n¬† ¬† ¬† ¬† up(&amp;empty);\n \n¬† ¬† ¬† ¬† up(&amp;sem);\n \n¬† ¬† ¬† ¬† printf(&quot;somma di %d+%d ¬†√® %d ¬†nelle posizioni %d %d\\n&quot;,n,n1,n+n1,p,d);\n \n¬† ¬† }\n \n¬† ¬† pthread_exit(NULL);\n \n}\n \nint main()\n \n{\n \n¬† ¬† pthread_t pro,cons;\n \n¬† ¬† sem_init(&amp;sem,0,1);\n \n¬† ¬† sem_init(&amp;full,0,0);\n \n¬† ¬† sem_init(&amp;empty,0,N);\n \n¬† ¬† pthread_create(&amp;pro,NULL,producer,NULL);\n \n¬† ¬† pthread_create(&amp;cons,NULL,consumer,NULL);\n \n¬† ¬† pthread_join(pro,NULL);\n \n¬† ¬† pthread_join(cons,NULL);\n \n¬† ¬† sem_destroy(&amp;sem);\n \n¬† ¬† sem_destroy(&amp;empty);\n \n¬† ¬† sem_destroy(&amp;full);\n \n¬† ¬† return 0;\n \n}"},"UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/ESERCIZI/14.-ESERCIZIO-THREAD-2":{"slug":"UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/ESERCIZI/14.-ESERCIZIO-THREAD-2","filePath":"UNI/ANNO 2/SISTEMI OPERATIVI/CODICI IN C/ESERCIZI/14. ESERCIZIO THREAD 2.md","title":"14. ESERCIZIO THREAD 2","links":[],"tags":[],"content":"\n\n                  \n                  consegna \n                  \n                \n\nScrivere un programma in C che, data una stringa di N caratteri, crea N/2 thread che stampano ciascuno un carattere della stringa in maiuscolo. Usare semafori binari o mutex.\n\n\n#include&lt;stdio.h&gt;\n \n#include&lt;unistd.h&gt;\n \n#include&lt;stdlib.h&gt;\n \n#include&lt;stdio.h&gt;\n \n#include&lt;pthread.h&gt;\n \n#include&lt;string.h&gt;\n \n#include&lt;ctype.h&gt;\n \nint counter=0;\n \npthread_mutex_t mutex;\n \nvoid * thread(void * stringa)\n \n{\n \n¬† ¬† char *stringa1=(char *) stringa;\n \n¬† ¬† pthread_mutex_lock(&amp;mutex);\n \n¬† ¬† printf(&quot;%c \\n&quot;,toupper(stringa1[counter]));\n \n¬† ¬† counter++;\n \n¬† ¬† pthread_mutex_unlock(&amp;mutex);\n \n¬† ¬† pthread_exit(NULL);\n \n}\n \nint main(int argc,char **argv)\n \n{\n \n¬† ¬† pthread_t t1;\n \n¬† ¬† pthread_mutex_init(&amp;mutex,NULL);\n \n¬† ¬† int n=strlen(argv[1]);\n \n¬† ¬† for(int i=0;i&lt;(n/2);i++)\n \n¬† ¬† {\n \n¬† ¬† ¬† ¬† pthread_create(&amp;t1,NULL,thread,argv[1]);\n \n¬† ¬† }\n \n¬† ¬† for(int i=0;i&lt;(n/2);i++)\n \n¬† ¬† {\n \n¬† ¬† ¬† ¬† pthread_join(t1,NULL);\n \n¬† ¬† }\n \n¬† ¬† pthread_mutex_destroy(&amp;mutex);\n \n¬† ¬† return 0;\n \n}"},"UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/ESERCIZI/15.-esercizio-5-lettori-1-scrittore":{"slug":"UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/ESERCIZI/15.-esercizio-5-lettori-1-scrittore","filePath":"UNI/ANNO 2/SISTEMI OPERATIVI/CODICI IN C/ESERCIZI/15. esercizio 5 lettori 1 scrittore.md","title":"15. esercizio 5 lettori 1 scrittore","links":[],"tags":[],"content":"\n\n                  \n                  consegna \n                  \n                \n\nSei thread: uno scrittore e cinque lettori.\n\nLo scrittore scrive su un buffer numeri dispari da 0 a 50 nelle posizioni pari e numeri pari da 50 a 100 nelle posizioni dispari.\nI lettori leggono coppie di numeri (pari, dispari), li sommano e stampano i risultati.\n\n\n\n#include &lt;stdio.h&gt;\n \n#include &lt;unistd.h&gt;\n \n#include &lt;stdlib.h&gt;\n \n#include &lt;pthread.h&gt;\n \n#include &lt;time.h&gt;\n \n#define N 10\n \nint gestione=0;\n \npthread_mutex_t mutex;\n \nvoid * scrittore(void * buffer)\n \n{\n \n¬† ¬† pthread_mutex_lock(&amp;mutex);\n \n¬† ¬† srand(time(NULL));\n \n¬† ¬† int num=0;\n \n¬† ¬† int *buffer1=(int *) buffer;\n \n¬† ¬† for(int i=0;i&lt;N;i++)\n \n¬† ¬† {\n \n¬† ¬† ¬† ¬† if (i%2==0)\n \n¬† ¬† ¬† ¬† {\n \n¬† ¬† ¬† ¬† ¬† ¬† num=rand()%51;\n \n¬† ¬† ¬† ¬† ¬† ¬† if(num%2==0) buffer1[i]=num+1;\n \n¬† ¬† ¬† ¬† ¬† ¬† else buffer1[i]=num;\n \n¬† ¬† ¬† ¬† }\n \n¬† ¬† ¬† ¬† else\n \n¬† ¬† ¬† ¬† {\n \n¬† ¬† ¬† ¬† ¬† ¬† num=50+rand()%51;\n \n¬† ¬† ¬† ¬† ¬† ¬† if(num%2==0) buffer1[i]=num;\n \n¬† ¬† ¬† ¬† ¬† ¬† else buffer1[i]=num+1;\n \n¬† ¬† ¬† ¬† }\n \n¬† ¬† ¬† ¬† printf(&quot;ho appena messo un numero \\n&quot;);\n \n¬† ¬† }\n \n¬† ¬† printf(&quot;ho appena finito \\n&quot;);\n \n¬† ¬† pthread_mutex_unlock(&amp;mutex);\n \n¬† ¬† pthread_exit(NULL);\n \n}\n \n  \n \nvoid * lettore(void * buffer)\n \n{\n \n¬† ¬† int * buffer1=(int *)buffer;\n \n¬† ¬† while(gestione&lt;N){\n \n¬† ¬† pthread_mutex_lock(&amp;mutex);\n \n¬† ¬† if(gestione==N-1)\n \n¬† ¬† {\n \n¬† ¬† ¬† ¬† printf(&quot;numero da solo\\n&quot;);\n \n¬† ¬† ¬† ¬† pthread_mutex_unlock(&amp;mutex);\n \n¬† ¬† ¬† ¬† break;\n \n¬† ¬† ¬† ¬† gestione=N;\n \n¬† ¬† }\n \n¬† ¬† printf(&quot;ecco il risultato della posizione %d %d dei numeri %d + %d = %d \\n&quot;,gestione+1,gestione+2,buffer1[gestione],buffer1[gestione+1],buffer1[gestione]+buffer1[gestione+1]);\n \n¬† ¬† gestione=gestione+2;\n \n¬† ¬† pthread_mutex_unlock(&amp;mutex);\n \n¬† ¬† }\n \n¬† ¬† pthread_exit(NULL);\n \n}\n \nint main(int argc, char** argv)\n \n{\n \n¬† ¬† int buffer[N];\n \n¬† ¬† pthread_t scrittor,lettor;\n \n¬† ¬† pthread_mutex_init(&amp;mutex,NULL);\n \n¬† ¬† pthread_create(&amp;scrittor,NULL,scrittore,buffer);\n \n¬† ¬† pthread_join(scrittor,NULL);\n \n¬† ¬† for(int i=0;i&lt;5;i++) pthread_create(&amp;lettor,NULL,lettore,buffer);\n \n¬† ¬† for(int i=0;i&lt;5;i++) pthread_join(lettor,NULL);\n \n¬† ¬† printf(&quot;codice terminato&quot;);\n \n¬† ¬† pthread_mutex_destroy(&amp;mutex);\n \n¬† ¬† return 0;\n \n}"},"UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/ESERCIZI/2.PROCESSI-GENERATI-P1-E-P2":{"slug":"UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/ESERCIZI/2.PROCESSI-GENERATI-P1-E-P2","filePath":"UNI/ANNO 2/SISTEMI OPERATIVI/CODICI IN C/ESERCIZI/2.PROCESSI GENERATI P1 E P2.md","title":"2.PROCESSI GENERATI P1 E P2","links":[],"tags":[],"content":"\n#include &lt;stdio.h&gt;\n \n#include &lt;stdlib.h&gt;\n \n#include &lt;unistd.h&gt;\n \n#include &lt;signal.h&gt;\n \n#include &lt;sys/types.h&gt;\n \nint main()\n \n{\n \n  \n \n¬† ¬† int fd [2];\n \n¬† ¬† pipe(fd); //creo ¬†pipe\n \n¬† ¬† pid_t p1, p2; // inizializzo i 2 processi figli\n \n¬† ¬† int tmp1; ¬†// variabile che uso per i numeri\n \n¬† ¬† p1 = fork(); // creo processo 1\n \n¬† ¬† if(p1==0) // il figlio vedr√† se stesso come pid 0\n \n¬† ¬† {\n \n¬† ¬† ¬† ¬† close(fd[0]);\n \n¬† ¬† ¬† ¬† while(1)\n \n¬† ¬† ¬† ¬† {\n \n¬† ¬† ¬† ¬† ¬† ¬† tmp1=rand()%101;\n \n¬† ¬† ¬† ¬† ¬† ¬† if(tmp1%2==1)\n \n¬† ¬† ¬† ¬† ¬† ¬† {\n \n¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† fflush(stdout);\n \n¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† printf(&quot;%d\\nsono il p1 \\n&quot;,tmp1);\n \n¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† write(fd[1],&amp;tmp1,sizeof(int));\n \n¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† sleep(1);\n \n¬† ¬† ¬† ¬† ¬† ¬† }\n \n¬† ¬† ¬† ¬† } ¬† ¬†\n \n¬† ¬† }\n \n¬† ¬† ¬†if (p1 &gt; 0) // il padre vedr√† il p1 come un processo con pid &gt;0\n \n¬† ¬† ¬† ¬† {\n \n¬† ¬† ¬† ¬† p2 = fork();\n \n¬† ¬† ¬† ¬† if(p2==0)\n \n¬† ¬† ¬† ¬† {\n \n¬† ¬† ¬† ¬† ¬† ¬† close(fd[0]);\n \n¬† ¬† ¬† ¬† ¬† ¬† while(1)\n \n¬† ¬† ¬† ¬† ¬† ¬† {\n \n¬† ¬† ¬† ¬† ¬† ¬† ¬†tmp1=rand()%101;\n \n¬† ¬† ¬† ¬† ¬† ¬† ¬†if(tmp1%2==0)\n \n¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† {\n \n¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬†fflush(stdout);\n \n¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬†printf(&quot;%d\\nsono il p2 \\n&quot;,tmp1);\n \n¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬†write(fd[1],&amp;tmp1,sizeof(int));\n \n¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬†sleep(1);\n \n¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† }\n \n¬† ¬† ¬† ¬† ¬† ¬† } ¬† ¬†\n \n¬† ¬† ¬† ¬† }\n \n¬† ¬† ¬†}\n \n¬† ¬† int num1,num2;\n \n¬† ¬† if(p1&gt;0 &amp;&amp; p2&gt;0)\n \n¬† ¬† {\n \n¬† ¬† ¬† ¬† while(1)\n \n¬† ¬† ¬† ¬† {\n \n¬† ¬† ¬† ¬† ¬† ¬† close(fd[1]);\n \n¬† ¬† ¬† ¬† ¬† ¬† read(fd[0],&amp;num1,sizeof(int));\n \n¬† ¬† ¬† ¬† ¬† ¬† printf(&quot;primo processo %d \\n&quot;,num1);\n \n¬† ¬† ¬† ¬† ¬† ¬† read(fd[0],&amp;num2,sizeof(int));\n \n¬† ¬† ¬† ¬† ¬† ¬† printf(&quot;secondo processo %d \\n&quot;,num2);\n \n¬† ¬† ¬† ¬† ¬† ¬† if((num1+num2)&gt;190)\n \n¬† ¬† ¬† ¬† ¬† ¬† {\n \n¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† fflush(stdout);\n \n¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† printf(&quot;\\nsono il padre e ho trovato %d sommando i numeri %d, %d\\n&quot;,num1+num2,num1,num2);\n \n¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† kill(p1,SIGTERM);\n \n¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† kill(p2,SIGTERM);\n \n¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† break;\n \n¬† ¬† ¬† ¬† ¬† ¬† }\n \n  \n \n¬† ¬† ¬† ¬† ¬† ¬† sleep(1);\n \n¬† ¬† ¬† ¬† }\n \n¬† ¬† }\n \n¬† ¬† ¬†close(fd[0]);\n \n¬† ¬† ¬†return 0;\n \n}"},"UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/ESERCIZI/3.PROCESSI-CHE-SI-PASSANO-NUMERI":{"slug":"UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/ESERCIZI/3.PROCESSI-CHE-SI-PASSANO-NUMERI","filePath":"UNI/ANNO 2/SISTEMI OPERATIVI/CODICI IN C/ESERCIZI/3.PROCESSI CHE SI PASSANO NUMERI.md","title":"3.PROCESSI CHE SI PASSANO NUMERI","links":[],"tags":[],"content":"\n\n                  \n                  consegna \n                  \n                \n\nUn processo padre genera due processi figli:\n\nIl primo processo figlio invia al padre un numero casuale da 0 a 100.\nIl padre legge questo numero, lo moltiplica per un k casuale e lo manda al secondo figlio.\nIl secondo figlio legge il numero inviato dal padre e lo stampa a video.\n\n\n\n#include&lt;stdio.h&gt;\n#include&lt;stdlib.h&gt;\n#include&lt;unistd.h&gt;\n#include&lt;sys/types.h&gt;\n#include&lt;time.h&gt;\nint main(int *argc,char **argv)\n{\n    srand(time(NULL));\n    int fd[2];\n    pipe(fd);\n    if(fd&lt;0) exit(1);\n    pid_t p1;\n    pid_t p2;\n    int numero=0;\n    p1=fork();\n    if(p1&lt;0) exit(1);\n    if(p1==0)\n    {\n        close(fd[0]);\n        numero=rand()%101;\n        if((write(fd[1],&amp;numero,sizeof(int)))&lt;0)\n        {\n            fflush(stdout);\n            printf(&quot;non ha scritto\\n&quot;);\n        }\n \n        fflush(stdout);\n        printf(&quot;processo 1 ha inviato il coso %d \\n&quot;,numero);\n        exit(0);\n    }\n    if(p1&gt;0)\n    {\n        read(fd[0],&amp;numero,sizeof(int));\n        int k=rand()%100;\n        int result=(k*numero);\n        printf(&quot;sono il padre e faccio %d x %d = %d\\n&quot;,k,numero,result);\n        write(fd[1],&amp;result,sizeof(int));\n    }\n    p2=fork();\n    if(p2&lt;0) exit(1);\n    if(p2==0)\n    {\n        close(fd[1]);\n        fflush(stdout);\n        read(fd[0],&amp;numero,sizeof(int));\n        printf(&quot;ecco il numero %d \\n&quot;,numero);\n        exit(0);\n    }\n    return 0;\n}\n "},"UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/ESERCIZI/4.PROCESSI-LEGGONO-SU-FILE":{"slug":"UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/ESERCIZI/4.PROCESSI-LEGGONO-SU-FILE","filePath":"UNI/ANNO 2/SISTEMI OPERATIVI/CODICI IN C/ESERCIZI/4.PROCESSI LEGGONO SU FILE.md","title":"4.PROCESSI LEGGONO SU FILE","links":[],"tags":[],"content":""},"UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/ESERCIZI/5.PROCESSI-MOLTIPLICANO-MATRICI":{"slug":"UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/ESERCIZI/5.PROCESSI-MOLTIPLICANO-MATRICI","filePath":"UNI/ANNO 2/SISTEMI OPERATIVI/CODICI IN C/ESERCIZI/5.PROCESSI MOLTIPLICANO MATRICI.md","title":"5.PROCESSI MOLTIPLICANO MATRICI","links":[],"tags":[],"content":"\n\n                  \n                  consegna \n                  \n                \n\nScrivere un programma che esegue la moltiplicazione tra matrici 3x3 usando la programmazione parallela:\n\nIl primo processo figlio computa la prima colonna.\nIl secondo processo figlio computa la seconda colonna.\nIl processo padre computa la terza colonna, riceve dai figli i due vettori colonna computati, compone la matrice finale e la stampa.\n\n\n\n#include&lt;stdio.h&gt;\n#include&lt;stdlib.h&gt;\n#include&lt;unistd.h&gt;\n#include&lt;fcntl.h&gt;\nvoid molt(int m1[3][3],int m2[3][3],int r[3],int index)\n{\n    int tmp=0;\n    for(int i=0;i&lt;3;i++)\n    {\n        for(int j=0;j&lt;3;j++){\n            tmp+=m1[i][j]*m2[j][index];//rappresentiamo riga poi colonna\n        }\n \n        r[i]=tmp;\n        tmp=0;\n    }\n}\nint main(int argc, char** argv)\n{\n    int m1[3][3]=\n    {\n        {9,8,18},\n        {3,5,15},\n        {3,1,27}\n    };\n    int m2[3][3]=\n    {\n        {26,6,3},\n        {3,6,5},\n        {2,4,25}\n    };\npid_t p1,p2;\nint fd[2];\npipe(fd);\np1=fork();\nif (p1==-1) exit(1);\nif(p1==0)\n{\n    close(fd[0]);\n    int r[3];\n    molt(m1,m2,r,0);\n    write(fd[1],&amp;r,sizeof(r));\n    exit(0);\n}\np2=fork();\nif(p2==-1) exit(1);\nif(p2==0)\n{\n    close(fd[0]);\n    int r[3];\n    molt(m1,m2,r,1);\n    write(fd[1],&amp;r,sizeof(r));\n    exit(0);\n}\nif(p1&gt;0 &amp;&amp; p2&gt;0)\n{\n    close(fd[1]);\n    int r[3],r1[3],r2[3];\n    molt(m1,m2,r,2);\n    read(fd[0],&amp;r1,sizeof(r1));\n    read(fd[0],&amp;r2,sizeof(r2));\n    int result[3][3];\n    for(int i=0;i&lt;3;i++)\n    {\n        result[0][i]=r1[i];\n        result[1][i]=r2[i];\n        result[2][i]=r[i];\n    }\n    for(int i=0;i&lt;3;i++)\n    {\n        printf(&quot;|colonna %d \\n&quot;,i+1);\n        for(int j=0;j&lt;3;j++)\n        {\n             printf(&quot;%d \\n&quot;,result[i][j]);\n        }\n        printf(&quot;------ \\n&quot;);\n \n    }\n \n \n}\n return 0;\n}"},"UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/ESERCIZI/6.SOMMA-MULTIPLI-3-E-2":{"slug":"UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/ESERCIZI/6.SOMMA-MULTIPLI-3-E-2","filePath":"UNI/ANNO 2/SISTEMI OPERATIVI/CODICI IN C/ESERCIZI/6.SOMMA MULTIPLI 3 E 2.md","title":"6.SOMMA MULTIPLI 3 E 2","links":[],"tags":[],"content":"\n\n                  \n                  consegna \n                  \n                \n\nGenerare due processi figli che comunicano con il padre:\n\nUno dei processi genera numeri casuali [0-50] ed invia al padre solo i numeri multipli di 3.\nL‚Äôaltro processo genera numeri casuali [51-100] ed invia al padre solo i numeri multipli di 2.\nIl padre stampa i numeri ricevuti ed esegue la loro somma quando la somma &gt; 130.\n\n\n\n#include&lt;stdio.h&gt;\n \n#include&lt;stdlib.h&gt;\n \n#include&lt;time.h&gt;\n \n#include&lt;unistd.h&gt;\n \n#include&lt;fcntl.h&gt;\n \nint main(int argc,char **argv)\n \n{\n \n¬† ¬† pid_t p1,p2;\n \n¬† ¬† srand(time(NULL));\n \n¬† ¬† int fd[2];\n \n¬† ¬† pipe(fd);\n \n¬† ¬† p1=fork();\n \n¬† ¬† if (p1==-1) exit(1);\n \n¬† ¬† if(p1==0)\n \n¬† ¬† {\n \n¬† ¬† ¬† ¬† close(fd[0]);\n \n¬† ¬† ¬† ¬† int num=0;\n \n¬† ¬† ¬† ¬† while(1)\n \n¬† ¬† ¬† ¬† {\n \n¬† ¬† ¬† ¬† ¬† ¬† num=rand()%51;\n \n¬† ¬† ¬† ¬† ¬† ¬† if(num%3==0){\n \n¬† ¬† ¬† ¬† ¬† ¬† fflush(stdout);\n \n¬† ¬† ¬† ¬† ¬† ¬† printf(&quot;numero trovato p1 %d \\n&quot;,num);\n \n¬† ¬† ¬† ¬† ¬† ¬† write(fd[1],&amp;num,sizeof(int));\n \n¬† ¬† ¬† ¬† ¬† ¬† ¬†sleep(1);\n \n¬† ¬† ¬† ¬† ¬† ¬† }\n \n¬† ¬† ¬† ¬† }\n \n¬† ¬† }\n \n¬† ¬† if(p1&gt;0){\n \n¬† ¬† p2=fork();\n \n¬† ¬† if(p2==-1) exit(1);\n \n¬† ¬† if(p2==0)\n \n¬† ¬† {\n \n¬† ¬† ¬† ¬† close(fd[0]);\n \n¬† ¬† ¬† ¬† int num=0;\n \n¬† ¬† ¬† ¬† while(1)\n \n¬† ¬† ¬† ¬† {\n \n¬† ¬† ¬† ¬† ¬† ¬† num=51+rand()%50;\n \n¬† ¬† ¬† ¬† ¬† ¬† if(num%2==0){\n \n¬† ¬† ¬† ¬† ¬† ¬† fflush(stdout);\n \n¬† ¬† ¬† ¬† ¬† ¬† printf(&quot;numero trovato p2 %d \\n&quot;,num);\n \n¬† ¬† ¬† ¬† ¬† ¬† write(fd[1],&amp;num,sizeof(int));\n \n¬† ¬† ¬† ¬† ¬† ¬† ¬† sleep(1);\n \n¬† ¬† ¬† ¬† ¬† ¬† }\n \n¬† ¬† ¬† ¬† } ¬† ¬† ¬† ¬†\n \n¬† ¬† }\n \n¬† ¬† }\n \nif(p1&gt;0 &amp;&amp; p2&gt;0)\n \n{\n \n¬† ¬† while(1)\n \n¬† ¬† {\n \n¬† ¬† close(fd[1]);\n \n¬† ¬† int num1=0;\n \n¬† ¬† int num2=0;\n \n¬† ¬† read(fd[0],&amp;num1,sizeof(int));\n \n¬† ¬† read(fd[0],&amp;num2,sizeof(int));\n \n¬† ¬† if(num1+num2&gt;130)\n \n¬† ¬† {\n \n¬† ¬† ¬† ¬† fflush(stdout);\n \n¬† ¬† ¬† ¬† printf(&quot;\\n %d + %d &gt;130 e fa %d \\n&quot;,num1,num2,num1+num2);\n \n¬† ¬† ¬† ¬† exit(0);\n \n¬† ¬† }\n \n¬† ¬† sleep(1);\n \n¬† ¬† }\n \n}\n \nreturn 0;\n \n}"},"UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/ESERCIZI/7.PROCESSI-E-POTENZA-DI-UN-NUMERO":{"slug":"UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/ESERCIZI/7.PROCESSI-E-POTENZA-DI-UN-NUMERO","filePath":"UNI/ANNO 2/SISTEMI OPERATIVI/CODICI IN C/ESERCIZI/7.PROCESSI E POTENZA DI UN NUMERO.md","title":"7.PROCESSI E POTENZA DI UN NUMERO","links":[],"tags":[],"content":"\n\n                  \n                  consegna \n                  \n                \n\nScrivere un programma C che crea un processo figlio:\n\nIl padre legge un numero casuale e lo invia al figlio attraverso una pipe.\nIl figlio fa il quadrato del numero e lo invia nuovamente al padre solo se il quadrato √® pari, attraverso la pipe.\nIl padre legge il numero e lo stampa.\n\n\n\n#include&lt;stdio.h&gt;\n \n#include&lt;stdlib.h&gt;\n \n#include&lt;unistd.h&gt;\n \n#include&lt;fcntl.h&gt;\n \n#include&lt;time.h&gt;\n \n#include&lt;math.h&gt;\n \n#include&lt;signal.h&gt;\n \nint main(int argc,char** argv)\n \n{\n \n¬† ¬† pid_t p1;\n \n¬† ¬† int fd[2],fd1[2];\n \n¬† ¬† pipe(fd);\n \n¬† ¬† pipe(fd1);\n \n¬† ¬† srand(time(NULL));\n \n¬† ¬† p1=fork();\n \n¬† ¬† if(p1==-1) exit(1);\n \n¬† ¬† if(p1&gt;0){\n \n¬† ¬† ¬† ¬† ¬†close(fd1[1]);\n \n¬† ¬† ¬† ¬† close(fd[0]);\n \n¬† ¬† while(1)\n \n¬† ¬† ¬† ¬† {\n \n¬† ¬† ¬† ¬† int num=rand();\n \n¬† ¬† ¬† ¬† write(fd[1],&amp;num,sizeof(int));\n \n¬† ¬† ¬† ¬† if ((read(fd1[0],&amp;num,sizeof(int)))&gt; 0)\n \n¬† ¬† ¬† ¬† {\n \n¬† ¬† ¬† ¬† fflush(stdout);\n \n¬† ¬† ¬† ¬† printf(&quot;%d&quot;,num);\n \n¬† ¬† ¬† ¬† kill(p1,SIGINT);\n \n¬† ¬† ¬† ¬† exit(0);\n \n¬† ¬† ¬† ¬† }\n \n¬† ¬† }\n \n¬† ¬† }\n \n¬† ¬† if(p1==0)\n \n¬† ¬† {\n \n¬† ¬† ¬† ¬† close(fd[1]);\n \n¬† ¬† ¬† ¬† close(fd1[0]);\n \n¬† ¬† ¬† ¬† while(1)\n \n¬† ¬† ¬† ¬† {\n \n¬† ¬† ¬† ¬† ¬† ¬† int num=0;\n \n¬† ¬† ¬† ¬† ¬† ¬† read(fd[0],&amp;num,sizeof(int));\n \n¬† ¬† ¬† ¬† ¬† ¬† if((num*num)%2==0)\n \n¬† ¬† ¬† ¬† ¬† ¬† {\n \n¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† num=num*num;\n \n¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† write(fd1[1],&amp;num,sizeof(int));\n \n¬† ¬† ¬† ¬† ¬† ¬† }\n \n¬† ¬† ¬† ¬† ¬† ¬† sleep(1);\n \n¬† ¬† ¬† ¬† }\n \n¬† ¬† }\n \n¬† ¬† return 0;\n \n}"},"UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/ESERCIZI/8.-array-dispari-pari":{"slug":"UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/ESERCIZI/8.-array-dispari-pari","filePath":"UNI/ANNO 2/SISTEMI OPERATIVI/CODICI IN C/ESERCIZI/8. array dispari pari.md","title":"8. array dispari pari","links":[],"tags":[],"content":"\n\n                  \n                  consegna \n                  \n                \n\nScrivere un programma C che svolge le seguenti richieste:\n\nUn processo padre genera due processi figli. Ciascun processo inizializza un proprio array di N interi.\nIl primo processo invia al processo padre solo i numeri in posizioni pari, e il secondo processo solo i numeri in posizioni dispari.\nIl padre riceve questi numeri e li scrive in un array di N interi, mettendo in posizioni pari i numeri ricevuti dal primo figlio, e in posizioni dispari i numeri ricevuti dal secondo figlio.\nIl padre stampa l‚Äôarray e calcola il max e il min.\n\n\n\n#include &lt;stdio.h&gt;\n \n#include&lt;stdlib.h&gt;\n \n#include &lt;fcntl.h&gt;\n \n#include&lt;math.h&gt;\n \n#include&lt;time.h&gt;\n \n#include&lt;unistd.h&gt;\n \n  \n \nint max(int *arr,int l)\n \n{\n \n¬† ¬† int num=arr[0];\n \n¬† ¬† for(int i=0;i&lt;l;i++)\n \n¬† ¬† {\n \n¬† ¬† ¬† ¬†if(arr[i]&gt;num) num=arr[i];\n \n¬† ¬† }\n \n¬† ¬† return num;\n \n}\n \nint min(int *arr,int l)\n \n{\n \n¬† ¬† int num=arr[0];\n \n¬† ¬† for(int i=0;i&lt;l;i++)\n \n¬† ¬† {\n \n¬† ¬† ¬† ¬†if(arr[i]&lt;num) num=arr[i];\n \n¬† ¬† }\n \n¬† ¬† return num;\n \n}\n \nint main(int argc, char **argv)\n \n{\n \n¬† ¬† int N=atoi(argv[1]);\n \n¬† ¬† int fd1[2],fd2[2];\n \n¬† ¬† srand(time(NULL));\n \n¬† ¬† pipe(fd1);\n \n¬† ¬† pipe(fd2);\n \n¬† ¬† pid_t p1;\n \n¬† ¬† pid_t p2;\n \n¬† ¬† p1=fork();\n \n¬† ¬† if(p1==-1) exit(1);\n \n¬† ¬† if(p1==0)\n \n¬† ¬† {\n \n¬† ¬† ¬† ¬† close(fd1[0]);\n \n¬† ¬† ¬† ¬† close(fd2[0]);\n \n¬† ¬† ¬† ¬† close(fd2[1]);\n \n¬† ¬† ¬† ¬† int arr[N];\n \n¬† ¬† ¬† ¬† for(int i=0;i&lt;N;i++)\n \n¬† ¬† ¬† ¬† {\n \n¬† ¬† ¬† ¬† ¬† ¬† arr[i]=rand()%101;\n \n¬† ¬† ¬† ¬† }\n \n¬† ¬† ¬† ¬† for(int i=0;i&lt;N;i=i+2)\n \n¬† ¬† ¬† ¬† {\n \n¬† ¬† ¬† ¬† ¬† ¬† write(fd1[1],&amp;arr[i],sizeof(int));\n \n¬† ¬† ¬† ¬† ¬† ¬† fflush(stdout);\n \n¬† ¬† ¬† ¬† ¬† ¬† printf(&quot;sto inviando i pari ... \\n&quot;);\n \n¬† ¬† ¬† ¬† }\n \n¬† ¬† ¬† ¬† exit(0);\n \n¬† ¬† }\n \n¬† ¬† if (p1&gt;0)\n \n¬† ¬† {\n \n¬† ¬† ¬† ¬† p2=fork();\n \n¬† ¬† ¬† ¬† if(p2==-1) exit(1);\n \n¬† ¬† ¬† ¬† if (p2==0)\n \n¬† ¬† ¬† ¬† {\n \n¬† ¬† ¬† ¬† ¬† ¬† close(fd1[0]);\n \n¬† ¬† ¬† ¬† ¬† ¬† close(fd1[1]);\n \n¬† ¬† ¬† ¬† ¬† ¬† close(fd2[0]);\n \n¬† ¬† ¬† ¬† ¬† ¬† int arr[N];\n \n¬† ¬† ¬† ¬† ¬† ¬† for(int i=0;i&lt;N;i++)\n \n¬† ¬† ¬† ¬† ¬† ¬† {\n \n¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† arr[i]=rand();\n \n¬† ¬† ¬† ¬† ¬† ¬† }\n \n¬† ¬† ¬† ¬† ¬† ¬† for(int i=1;i&lt;N;i=i+2)\n \n¬† ¬† ¬† ¬† ¬† ¬† {\n \n¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† write(fd2[1],&amp;arr[i],sizeof(int));\n \n¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† fflush(stdout);\n \n¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† printf(&quot;sto inviando i dispari ... \\n&quot;);\n \n¬† ¬† ¬† ¬† ¬† ¬† }\n \n¬† ¬† ¬† ¬† ¬† ¬† exit(0);\n \n¬† ¬† ¬† ¬† }\n \n¬† ¬† }\n \n¬† ¬† if (p1&gt;0 &amp;&amp; p2&gt;0)\n \n¬† ¬† {\n \n¬† ¬† ¬† ¬† close(fd1[1]);\n \n¬† ¬† ¬† ¬† close(fd2[1]);\n \n¬† ¬† ¬† ¬† int base=0;\n \n¬† ¬† ¬† ¬† int arr[N];\n \n¬† ¬† ¬† ¬† for(int i=0;i&lt;N;i++)\n \n¬† ¬† ¬† ¬† {\n \n¬† ¬† ¬† ¬† ¬† ¬† if(i%2==0)\n \n¬† ¬† ¬† ¬† ¬† ¬† {\n \n¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† read(fd1[0],&amp;base,sizeof(int));\n \n¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† arr[i]=base;\n \n¬† ¬† ¬† ¬† ¬† ¬† } ¬† ¬† ¬† ¬†\n \n¬† ¬† ¬† ¬† ¬† ¬† else\n \n¬† ¬† ¬† ¬† ¬† ¬† {\n \n¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† read(fd2[0],&amp;base,sizeof(int));\n \n¬† ¬† ¬† ¬† ¬† ¬† } ¬†\n \n¬† ¬† ¬† ¬† }\n \n¬† ¬† ¬† ¬† for(int i=0;i&lt;N;i++)\n \n¬† ¬† ¬† ¬† {\n \n¬† ¬† ¬† ¬† ¬† ¬† fflush(stdout);\n \n¬† ¬† ¬† ¬† ¬† ¬† printf(&quot;ecco l&#039;array %d \\n&quot;,arr[i]);\n \n  \n \n¬† ¬† ¬† ¬† }\n \n¬† ¬† ¬† ¬† int l=sizeof(arr)/sizeof(int);\n \n¬† ¬† ¬† ¬† fflush(stdout);\n \n¬† ¬† ¬† ¬† printf(&quot;il max √®... %d \\n&quot;, max(arr,l));\n \n¬† ¬† ¬† ¬† printf(&quot;il min √® %d \\n&quot;, min(arr,l));\n \n¬† ¬† }\n \n}"},"UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/ESERCIZI/9.Esercizio-file":{"slug":"UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/ESERCIZI/9.Esercizio-file","filePath":"UNI/ANNO 2/SISTEMI OPERATIVI/CODICI IN C/ESERCIZI/9.Esercizio file.md","title":"9.Esercizio file","links":[],"tags":[],"content":"\n\n                  \n                  consegna \n                  \n                \n\nImplementare un programma che utilizzi fork e pipe per la comunicazione tra processi:\n\nIl programma crea un file di testo e poi due processi figli.\nUn processo figlio scrive una sequenza di numeri interi pari nel file.\nL‚Äôaltro processo figlio scrive una sequenza di numeri interi dispari nello stesso file.\nIl processo padre legge i dati dal file e li stampa a video.\n\n\n\n#include &lt;stdio.h&gt;\n \n#include &lt;unistd.h&gt;\n \n#include &lt;fcntl.h&gt;\n \n#include &lt;stdlib.h&gt;\n \n#include &lt;time.h&gt;\n \n#include &lt;sys/wait.h&gt;\n \nint main(int argc, char **argv)\n \n{\n \n¬† ¬† int n=9;\n \n¬† ¬† int fd=open(&quot;mario.txt&quot;,O_CREAT | O_RDWR,0644);\n \n¬† ¬† pid_t p1,p2;\n \n¬† ¬† srand(time(NULL));\n \n¬† ¬† close(fd);\n \n¬† ¬† p1=fork();\n \n¬† ¬† if(p1==-1) exit(1);\n \n¬† ¬† if(p1==0)\n \n¬† ¬† {\n \n¬† ¬† ¬† ¬† fd=open(&quot;mario.txt&quot;,O_RDWR);\n \n¬† ¬† ¬† ¬† int arr[n];\n \n¬† ¬† ¬† ¬† int num=0;\n \n¬† ¬† ¬† ¬† for(int i=0;i&lt;n;i++)\n \n¬† ¬† ¬† ¬† {\n \n¬† ¬† ¬† ¬† ¬† ¬† num=rand()%100;\n \n¬† ¬† ¬† ¬† ¬† ¬† if(num%2!=0) arr[i]=num+1;\n \n¬† ¬† ¬† ¬† ¬† ¬† else arr[i]=num;\n \n¬† ¬† ¬† ¬† }\n \n¬† ¬† ¬† ¬† lseek(fd,0,SEEK_SET);\n \n¬† ¬† ¬† ¬† write(fd,arr,n*sizeof(int));\n \n¬† ¬† ¬† ¬† close(fd);\n \n¬† ¬† ¬† ¬† exit(0);\n \n¬† ¬† }\n \n¬† ¬† if(p1&gt;0)\n \n¬† ¬† {\n \n¬† ¬† ¬† ¬† fd=open(&quot;mario.txt&quot;,O_RDWR);\n \n¬† ¬† ¬† ¬† p2=fork();\n \n¬† ¬† ¬† ¬† if(p2==-1) exit(1);\n \n¬† ¬† ¬† ¬† if(p2==0)\n \n¬† ¬† ¬† ¬† {\n \n¬† ¬† ¬† ¬† ¬† ¬† int num=0;\n \n¬† ¬† ¬† ¬† ¬† ¬† int arr[n];\n \n¬† ¬† ¬† ¬† ¬† ¬† for(int i=0;i&lt;n;i++)\n \n¬† ¬† ¬† ¬† ¬† ¬† {\n \n¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† num=rand()%100;\n \n¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† if (num%2==0) arr[i]=num+1;\n \n¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† else arr[i]=num;\n \n¬† ¬† ¬† ¬† ¬† ¬† }\n \n¬† ¬† ¬† ¬† ¬† ¬† lseek(fd,sizeof(int)*n,SEEK_SET);\n \n¬† ¬† ¬† ¬† ¬† ¬† write(fd,arr,sizeof(int)*n);\n \n¬† ¬† ¬† ¬† ¬† ¬† close(fd);\n \n¬† ¬† ¬† ¬† }\n \n¬† ¬† }\n \n¬† ¬† if(p1&gt;0 &amp;&amp; p2&gt;0)\n \n¬† ¬† { ¬†\n \n¬† ¬† ¬† ¬† fd=open(&quot;mario.txt&quot;,O_RDWR);\n \n¬† ¬† ¬† ¬† if (waitpid(p1,NULL,0)==-1) exit(1);\n \n¬† ¬† ¬† ¬† if (waitpid(p2,NULL,0)==-1) exit(1);\n \n¬† ¬† ¬† ¬† int buf[4096];\n \n¬† ¬† ¬† ¬† lseek(fd,0,SEEK_SET);\n \n¬† ¬† ¬† ¬† ssize_t size=read(fd,buf,4096);\n \n¬† ¬† ¬† ¬† for(int i=0;i&lt;size/sizeof(int);i++)\n \n¬† ¬† ¬† ¬† {\n \n¬† ¬† ¬† ¬† ¬† ¬† fflush(stdout);\n \n¬† ¬† ¬† ¬† ¬† ¬† printf(&quot;stampa : %d \\n&quot;,buf[i]);\n \n¬† ¬† ¬† ¬† }\n \n¬† ¬† ¬† ¬† exit(0);\n \n¬† ¬† }\n \n¬† ¬† return 0;\n \n}"},"UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/ESERCIZI/Esercizio-Esame":{"slug":"UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/ESERCIZI/Esercizio-Esame","filePath":"UNI/ANNO 2/SISTEMI OPERATIVI/CODICI IN C/ESERCIZI/Esercizio Esame.md","title":"Esercizio Esame","links":[],"tags":[],"content":"\n\n                  \n                  consegna \n                  \n                \n\nSviluppare un programma in linguaggio C che utilizza processi e pipe per implementare quanto\nspecificato di seguito.\nUn processo padre P genera due processi figli P1 e P2.\nInizialmente, tutti i processi devono disabilitare il segnale di interruzione SIGINT; in particolare\nall‚Äôarrivo di tale segnale deve essere visualizzato il messaggio di avviso ‚ÄúInterruzione\ndisabilitata‚Äù.\nI due figli P1 e P2 generano ogni secondo un numero intero casuale da 0 a 100.\nI numeri generati dai figli vengono inviati al processo padre che provvede a sommarli e stamparli su schermo e a memorizzarli in un file.\nL‚Äôesecuzione di tutti e tre i processi viene rimandata dal processo padre quando verifica che la\nsomma dei numeri avuti dai processi figli assume il valore 100, altrimenti mette in attesa per 2\nsecondi prima di controllare i due numeri inviati dai processi figli.\n\n\n#include&lt;unistd.h&gt;\n \n#include&lt;stdlib.h&gt;\n \n#include&lt;stdio.h&gt;\n \n#include&lt;fcntl.h&gt;\n \n#include&lt;time.h&gt;\n \n#include&lt;signal.h&gt;\n \n#include&lt;string.h&gt;\n \nvoid handler_SIGINT()\n \n{\n \n¬† ¬† printf(&quot;interruttione ditabilitata \\n&quot;);\n \n¬† ¬† exit(0);\n \n}\n \nint main(int argc, char **argv)\n \n{\n \n¬† ¬† signal(SIGINT,handler_SIGINT);\n \n¬† ¬† srand(time(NULL));\n \n¬† ¬† int num=0;\n \n¬† ¬† pid_t p1,p2;\n \n¬† ¬† int fd1[2],fd2[2];\n \n¬† ¬† if(pipe(fd1)==-1 || pipe(fd2)==-1)\n \n¬† ¬† {\n \n¬† ¬† ¬† ¬† perror(&quot;errore nella pipe&quot;);\n \n¬† ¬† ¬† ¬† exit(1);\n \n¬† ¬† }\n \n¬† ¬† p1=fork();\n \n¬† ¬† if(p1==-1)\n \n¬† ¬† {\n \n¬† ¬† ¬† ¬† fflush(stdout);\n \n¬† ¬† ¬† ¬† printf(&quot;errore di creazione fork&quot;);\n \n¬† ¬† ¬† ¬† exit(1);\n \n¬† ¬† }\n \n¬† ¬† if(p1==0)\n \n¬† ¬† {\n \n¬† ¬† ¬† ¬† close(fd1[0]);\n \n¬† ¬† ¬† ¬† close(fd2[1]);\n \n¬† ¬† ¬† ¬† close(fd2[0]);\n \n¬† ¬† ¬† ¬† while(1)\n \n¬† ¬† ¬† ¬† {\n \n¬† ¬† ¬† ¬† ¬† ¬† num=rand()%101;\n \n¬† ¬† ¬† ¬† ¬† ¬† write(fd1[1],&amp;num,sizeof(int));\n \n¬† ¬† ¬† ¬† ¬† ¬† fflush(stdout);\n \n¬† ¬† ¬† ¬† ¬† ¬† printf(&quot;sono il p1 e ho tampato quetto numero %d \\n&quot;,num);\n \n¬† ¬† ¬† ¬† ¬† ¬† sleep(1);\n \n¬† ¬† ¬† ¬† }\n \n¬† ¬† }\n \n¬† ¬† if(p1&gt;0)\n \n¬† ¬† {\n \n¬† ¬† ¬† ¬† p2=fork();\n \n¬† ¬† ¬† ¬† if(p2==-1)\n \n¬† ¬† ¬† ¬† {\n \n¬† ¬† ¬† ¬† ¬† ¬† printf(&quot;errore&quot;);\n \n¬† ¬† ¬† ¬† ¬† ¬† exit(1);\n \n¬† ¬† ¬† ¬† }\n \n¬† ¬† ¬† ¬† if(p2==0)\n \n¬† ¬† ¬† ¬† {\n \n¬† ¬† ¬† ¬† ¬† ¬† close(fd1[0]);\n \n¬† ¬† ¬† ¬† ¬† ¬† close(fd1[1]);\n \n¬† ¬† ¬† ¬† ¬† ¬† close(fd2[0]);\n \n¬† ¬† ¬† ¬† ¬† ¬† while(1)\n \n¬† ¬† ¬† ¬† ¬† ¬† {\n \n¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† num=rand()%101;\n \n¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† write(fd2[1],&amp;num,sizeof(int));\n \n¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† fflush(stdout);\n \n¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† printf(&quot;sono il p2 e ho tampato quetto numero %d \\n&quot;,num);\n \n¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† sleep(1);\n \n¬† ¬† ¬† ¬† ¬† ¬† }\n \n¬† ¬† ¬† ¬† }\n \n¬† ¬† }\n \n¬† ¬† if(p1&gt;0 &amp;&amp; p2&gt;0)\n \n¬† ¬† {\n \n¬† ¬† ¬† ¬† int file=open(&quot;test.txt&quot;,O_RDWR|O_CREAT|O_TRUNC,0644);\n \n¬† ¬† ¬† ¬† close(fd1[1]);\n \n¬† ¬† ¬† ¬† close(fd2[1]);\n \n¬† ¬† ¬† ¬† int num1=0,num2=0,somma=0;\n \n¬† ¬† ¬† ¬† char buffer[50];\n \n¬† ¬† ¬† ¬† while(1)\n \n¬† ¬† ¬† ¬† {\n \n¬† ¬† ¬† ¬† ¬† ¬† read(fd1[0],&amp;num1,sizeof(int));\n \n¬† ¬† ¬† ¬† ¬† ¬† read(fd2[0],&amp;num2,sizeof(int));\n \n¬† ¬† ¬† ¬† ¬† ¬† fflush(stdout);\n \n¬† ¬† ¬† ¬† ¬† ¬† somma=num1+num2;\n \n¬† ¬† ¬† ¬† ¬† ¬† printf(&quot;la somma dei numeri %d + %d √® %d \\n&quot;,num1,num2,somma);\n \n¬† ¬† ¬† ¬† ¬† ¬† sprintf(buffer,&quot;%d %d\\n&quot;,num1,num2);\n \n¬† ¬† ¬† ¬† ¬† ¬† write(file,buffer,strlen(buffer));\n \n¬† ¬† ¬† ¬† ¬† ¬† if(somma&gt;100)\n \n¬† ¬† ¬† ¬† ¬† ¬† {\n \n¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† fflush(stdout);\n \n¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† printf(&quot;numero trovato %d \\n&quot;,somma);\n \n¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† kill(p1,SIGTERM);\n \n¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† kill(p2,SIGTERM);\n \n¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† break;\n \n¬† ¬† ¬† ¬† ¬† ¬† }\n \n¬† ¬† ¬† ¬† ¬† ¬† else sleep(2);\n \n¬† ¬† ¬† ¬† }\n \n¬† ¬† }\n \n¬† ¬† return 0;\n \n}"},"UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/INDICE-CODICI-IN-C":{"slug":"UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/INDICE-CODICI-IN-C","filePath":"UNI/ANNO 2/SISTEMI OPERATIVI/CODICI IN C/INDICE CODICI IN C.md","title":"INDICE CODICI IN C","links":["UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/LIBRERIE-E-FUNZIONI-DA-RICORDARE","UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/LISTA-CODICI-CRUX","UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/LISTA-ESERCIZI-TIPO-ESAME","UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/SPIEGAZIONE-PIPE","UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/ESERCIZI/Esercizio-Esame","UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/ESERCIZI/1.PROCESSI-CHE-LEGGONO-OCCORRENZE-FILE","UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/ESERCIZI/2.PROCESSI-GENERATI-P1-E-P2","UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/ESERCIZI/3.PROCESSI-CHE-SI-PASSANO-NUMERI","UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/ESERCIZI/4.PROCESSI-LEGGONO-SU-FILE","UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/ESERCIZI/5.PROCESSI-MOLTIPLICANO-MATRICI","UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/ESERCIZI/6.SOMMA-MULTIPLI-3-E-2","UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/ESERCIZI/7.PROCESSI-E-POTENZA-DI-UN-NUMERO","UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/ESERCIZI/8.-array-dispari-pari","UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/ESERCIZI/9.Esercizio-file","UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/ESERCIZI/10.-thread-+1--1","UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/ESERCIZI/11.-thread--1-0-100","UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/ESERCIZI/12.-MAX-E-MIN","UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/ESERCIZI/13.-SEMAFORI-E-POSIZIONI-PARI","UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/ESERCIZI/14.-ESERCIZIO-THREAD-2","UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/ESERCIZI/15.-esercizio-5-lettori-1-scrittore"],"tags":[],"content":"LIBRERIE E FUNZIONI DA RICORDARE\nLISTA CODICI CRUX\nLISTA ESERCIZI TIPO ESAME\nSPIEGAZIONE PIPE\nEsercizi completi\nEsercizio Esame\n1.PROCESSI CHE LEGGONO OCCORRENZE FILE\n2.PROCESSI GENERATI P1 E P2\n3.PROCESSI CHE SI PASSANO NUMERI\n4.PROCESSI LEGGONO SU FILE\n5.PROCESSI MOLTIPLICANO MATRICI\n6.SOMMA MULTIPLI 3 E 2\n7.PROCESSI E POTENZA DI UN NUMERO\n8. array dispari pari\n9.Esercizio file\n10. thread +1 -1\n11. thread -1 0 100\n12. MAX E MIN\n13. SEMAFORI E POSIZIONI PARI\n14. ESERCIZIO THREAD 2\n15. esercizio 5 lettori 1 scrittore"},"UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/LIBRERIE-E-FUNZIONI-DA-RICORDARE":{"slug":"UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/LIBRERIE-E-FUNZIONI-DA-RICORDARE","filePath":"UNI/ANNO 2/SISTEMI OPERATIVI/CODICI IN C/LIBRERIE E FUNZIONI DA RICORDARE.md","title":"LIBRERIE E FUNZIONI DA RICORDARE","links":[],"tags":[],"content":"LISTA DI LIBRERIE\nstdio.h(da includere sempre)\nle solite funzioni PRINTF,SCANF ecc‚Ä¶\n\nfflush\nfprintf\n\nstdlib.h\n\nrand\nsrand\nmalloc\nfree\nexit\n\nunistd.h\n\npipe\nfork\nclose\nwrite\nread\nssize_t tipo di dato\nsleep\ndup\nexecl\n\nsys/types.h\n\npid_t\n\ntime.h\n\ntime\n\nsignal.h\n\nsignal\nkill\nalarm\nstrsignal\n\nsys/wait.h\n\nwait\nwaitpid\n\nfcntl.h\n\nopen\ncreat\nmacro:\nO_RDONLY: Apertura in sola lettura.\nO_WRONLY: Apertura in sola scrittura.\nO_RDWR: Lettura e scrittura.\nO_CREAT: Crea il file se non esiste.\n\nsemaphore.h\n\nsem_t come tipo di dato\nsem_init\nsem_destroy\nsem_wait\nsem_post\n\npthread.h\n\npthread_t come tipo di dato\npthread_mutex_t come tipo di dato\npthread_create\npthread_join\npthread_mutex_init\npthread_mutex_lock\npthread_mutex_unlock\npthread_mutex_destroy\npthread_cond_init\npthread_cond_wait\npthread_cond_signal\npthread_cond_destroy\npthread_exit\n\nstring.h\n\nstrlen\n"},"UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/LISTA-CODICI-CRUX":{"slug":"UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/LISTA-CODICI-CRUX","filePath":"UNI/ANNO 2/SISTEMI OPERATIVI/CODICI IN C/LISTA CODICI CRUX.md","title":"LISTA CODICI CRUX","links":["UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/LISTA-ESERCIZI-TIPO-ESAME","UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/LIBRERIE-E-FUNZIONI-DA-RICORDARE","UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/CODICI-CROCE/HELLO-WORLD.C","UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/CODICI-CROCE/COUNTDOWN.C","UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/CODICI-CROCE/MY-FIRST-FORK1.C","UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/CODICI-CROCE/MY-FIRST-FORK2.C","UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/CODICI-CROCE/MY-SIGNAL1.C","UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/CODICI-CROCE/MY-SIGNAL-2.C","UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/CODICI-CROCE/COPYFILE.C","UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/CODICI-CROCE/THREADS.C","UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/CODICI-CROCE/PRODUCER-CONSUMER-SEMAPHORE.c","UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/CODICI-CROCE/READER-WRITER-SEMAPHORE.c","UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/CODICI-CROCE/PRODUCER-CONSUMER-PTHREAD.c"],"tags":[],"content":"LISTA ESERCIZI TIPO ESAME\nLIBRERIE E FUNZIONI DA RICORDARE\nHELLO WORLD.C\nCOUNTDOWN.C\nMY FIRST FORK1.C\nMY FIRST FORK2.C\nMY SIGNAL1.C\nMY SIGNAL 2.C\nCOPYFILE.C\nTHREADS.C\nPRODUCER CONSUMER SEMAPHORE.c\nREADER WRITER SEMAPHORE.c\nPRODUCER CONSUMER PTHREAD.c"},"UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/LISTA-ESERCIZI-TIPO-ESAME":{"slug":"UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/LISTA-ESERCIZI-TIPO-ESAME","filePath":"UNI/ANNO 2/SISTEMI OPERATIVI/CODICI IN C/LISTA ESERCIZI TIPO ESAME.md","title":"LISTA ESERCIZI TIPO ESAME","links":["UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/ESERCIZI/1.PROCESSI-CHE-LEGGONO-OCCORRENZE-FILE","UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/ESERCIZI/2.PROCESSI-GENERATI-P1-E-P2","UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/ESERCIZI/3.PROCESSI-CHE-SI-PASSANO-NUMERI","UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/ESERCIZI/4.PROCESSI-LEGGONO-SU-FILE","UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/ESERCIZI/5.PROCESSI-MOLTIPLICANO-MATRICI","UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/ESERCIZI/6.SOMMA-MULTIPLI-3-E-2","UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/ESERCIZI/7.PROCESSI-E-POTENZA-DI-UN-NUMERO","UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/ESERCIZI/8.-array-dispari-pari","UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/ESERCIZI/9.Esercizio-file","UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/ESERCIZI/10.-thread-+1--1","UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/ESERCIZI/11.-thread--1-0-100","UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/ESERCIZI/12.-MAX-E-MIN","UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/ESERCIZI/13.-SEMAFORI-E-POSIZIONI-PARI","UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/ESERCIZI/14.-ESERCIZIO-THREAD-2","UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/ESERCIZI/15.-esercizio-5-lettori-1-scrittore","UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/ESERCIZI/Esercizio-Esame"],"tags":[],"content":"TRACCE DI ESERCIZI IN C PER SISTEMI OPERATIVI\n\nPROCESSI\nESERCIZIO 1\nCreare un programma che legge un file e conta le occorrenze di una parola nel seguente modo:\n\nIl primo processo legge dall‚Äôinizio alla met√† e conta le occorrenze della parola.\nIl secondo processo legge dalla met√† fino alla fine e conta le occorrenze della parola.\nInviano poi il numero di occorrenze al processo padre, il quale le somma e le stampa a video.\n\n\n\n                  \n                   1.PROCESSI CHE LEGGONO OCCORRENZE FILE\n                  \n                \n\n\nESERCIZIO 2\nGenerare due processi figli che comunicano con il padre:\n\nUno dei processi genera numeri casuali [0-100] ed invia al padre solo i numeri pari.\nL‚Äôaltro processo genera numeri casuali [0-100] ed invia al padre solo i numeri dispari.\nIl padre fa la loro somma e quando la somma &gt; 190, termina l‚Äôesecuzione dei figli.\n\n\n\n                  \n                   2.PROCESSI GENERATI P1 E P2\n                  \n                \n\n\nESERCIZIO 3\nUn processo padre genera due processi figli:\n\nIl primo processo figlio invia al padre un numero casuale da 0 a 100.\nIl padre legge questo numero, lo moltiplica per un k casuale e lo manda al secondo figlio.\nIl secondo figlio legge il numero inviato dal padre e lo stampa a video.\n\n\n\n                  \n                   3.PROCESSI CHE SI PASSANO NUMERI\n                  \n                \n\n\nESERCIZIO 4\nDue processi leggono dallo stesso file che si trova all‚Äôinterno di una directory (es. /data/file.txt):\n\nAlternativa: Usare dirent e readdir per leggere all‚Äôinterno della directory e controllare se il file esiste o meno.\nControllare che il file sia in modalit√† lettura, altrimenti restituire errore.\nAlternativa: Invece di restituire un errore, cambiare i permessi al file con chmod.\nIl primo processo legge dall‚Äôinizio del file fino a met√†.\nIl secondo processo legge dalla met√† in poi.\nI figli mandano il contenuto al padre.\nIl padre lo stampa nel seguente formato: [PID_FIGLIO] -&gt; TESTO.\n\n\n\n                  \n                   4.PROCESSI LEGGONO SU FILE\n                  \n                \n\n\nESERCIZIO 5\nScrivere un programma che esegue la moltiplicazione tra matrici 3x3 usando la programmazione parallela:\n\nIl primo processo figlio computa la prima colonna.\nIl secondo processo figlio computa la seconda colonna.\nIl processo padre computa la terza colonna, riceve dai figli i due vettori colonna computati, compone la matrice finale e la stampa.\n\n\n\n                  \n                   5.PROCESSI MOLTIPLICANO MATRICI\n                  \n                \n\n\nESERCIZIO 6\nGenerare due processi figli che comunicano con il padre:\n\nUno dei processi genera numeri casuali [0-50] ed invia al padre solo i numeri multipli di 3.\nL‚Äôaltro processo genera numeri casuali [51-100] ed invia al padre solo i numeri multipli di 2.\nIl padre stampa i numeri ricevuti ed esegue la loro somma quando la somma &gt; 130.\n\n\n\n                  \n                   6.SOMMA MULTIPLI 3 E 2\n                  \n                \n\n\nESERCIZIO 7\nScrivere un programma C che crea un processo figlio:\n\nIl padre legge un numero casuale e lo invia al figlio attraverso una pipe.\nIl figlio fa il quadrato del numero e lo invia nuovamente al padre solo se il quadrato √® pari, attraverso la pipe.\nIl padre legge il numero e lo stampa.\n\n\n\n                  \n                   7.PROCESSI E POTENZA DI UN NUMERO\n                  \n                \n\n\nESERCIZIO 8\nScrivere un programma C che svolge le seguenti richieste:\n\nUn processo padre genera due processi figli. Ciascun processo inizializza un proprio array di N interi.\nIl primo processo invia al processo padre solo i numeri in posizioni pari, e il secondo processo solo i numeri in posizioni dispari.\nIl padre riceve questi numeri e li scrive in un array di N interi, mettendo in posizioni pari i numeri ricevuti dal primo figlio, e in posizioni dispari i numeri ricevuti dal secondo figlio.\nIl padre stampa l‚Äôarray e calcola il max e il min.\n\n\n\n                  \n                   8. array dispari pari\n                  \n                \n\n\nESERCIZIO 9\nImplementare un programma che utilizzi fork e pipe per la comunicazione tra processi:\n\nIl programma crea un file di testo e poi due processi figli.\nUn processo figlio scrive una sequenza di numeri interi pari nel file.\nL‚Äôaltro processo figlio scrive una sequenza di numeri interi dispari nello stesso file.\nIl processo padre legge i dati dal file e li stampa a video.\n\n\n\n                  \n                   9.Esercizio file\n                  \n                \n\n\nTHREAD\nMUTEX\n\nESERCIZIO 1\nScrivere un programma C che segue le seguenti specifiche:\n\nIl programma crea un buffer come array di 11 numeri interi, inizializzati a zero.\nGenera tre thread:\n\nIl primo thread sceglie casualmente una cella del buffer e vi scrive il numero +1.\nIl secondo thread sceglie casualmente una cella del buffer e vi scrive il numero -1.\nIl terzo thread controlla se tutte le celle del buffer sono state inizializzate. In caso positivo, determina se il numero di celle contenenti +1 √® maggiore di quelle con -1 e termina tutti i thread.\nMentre un thread accede al buffer, nessun altro deve accedervi. Ogni thread attende un tempo random tra 0 e 3 secondi.\n\n\n\n\n\n                  \n                   10. thread +1 -1\n                  \n                \n\n\nESERCIZIO 2\nScrivere un programma con tre thread che risolvono il seguente problema:\n\nUn buffer di n elementi inizializzato a -1 viene riempito nel seguente modo:\n\nIl primo thread aggiunge nelle posizioni pari del buffer un numero casuale da 0 a 100.\nIl secondo thread aggiunge nelle posizioni dispari del buffer un numero casuale da 100 a 200.\nIl terzo thread modifica il buffer nel seguente modo:\n\nbuff[0] = buff[0]\nbuff[1] = buff[1] + buff[0]\nbuff[2] = buff[1] + buff[2]\n\n\n\n\nUtilizzare la mutua esclusione.\n\n\n\n                  \n                   11. thread -1 0 100\n                  \n                \n\n\nESERCIZIO 3\nScrivere un programma in C con tre thread che operano su due array di dimensione N inizialmente a 0:\n\nIl primo thread scrive in un array A numeri casuali tra 1 e 150, in posizioni randomiche.\nIl secondo thread scrive in un array B numeri casuali tra 150 e 300, in posizioni randomiche.\nIl terzo thread calcola:\n\nIl massimo e il minimo in A e B.\nmax{max(A), max(B)} e min{min(A), min(B)}.\n\n\n\n\n\n                  \n                   12. MAX E MIN\n                  \n                \n\n\nSEMAFORI\n\nESERCIZIO 1\nDue thread:\n\nIl produttore inserisce numeri pari da 0 a 100 in posizioni pari e numeri dispari da 100 a 200 in posizioni dispari in un buffer di N elementi inizializzato a -1.\nIl consumatore legge dal buffer un numero pari e uno dispari, li somma e stampa la somma.\n\n\n\n                  \n                   13. SEMAFORI E POSIZIONI PARI\n                  \n                \n\n\nESERCIZIO 2\nScrivere un programma in C che, data una stringa di N caratteri, crea N/2 thread che stampano ciascuno un carattere della stringa in maiuscolo. Usare semafori binari o mutex.\n\n\n                  \n                   14. ESERCIZIO THREAD 2\n                  \n                \n\n\nESERCIZIO 3\nSei thread: uno scrittore e cinque lettori.\n\nLo scrittore scrive su un buffer numeri dispari da 0 a 50 nelle posizioni pari e numeri pari da 50 a 100 nelle posizioni dispari.\nI lettori leggono coppie di numeri (pari, dispari), li sommano e stampano i risultati.\n\n\n\n                  \n                   15. esercizio 5 lettori 1 scrittore\n                  \n                \n\n\nESAMI\nESERCIZIO SCRITTO C\nSviluppare un programma in linguaggio C che utilizza processi e pipe per implementare quanto specificato di seguito.\nUn processo padre P genera due processi figli P1 e P2.\nInizialmente, tutti i processi devono disabilitare il segnale di interruzione SIGINT; in particolare all‚Äôarrivo di tale segnale deve essere visualizzato il messaggio di avviso ‚ÄúInterruzione disabilitata‚Äù.\nI due figli P1 e P2 generano ogni secondo un numero intero casuale da 0 a 100. I numeri generati dai figli vengono inviati al processo padre che provvede a sommarli e stamparli su schermo e a memorizzarli in un file.\nL‚Äôesecuzione di tutti e tre i processi viene rimandata dal processo padre quando verifica che la somma dei numeri avuti dai processi figli assume il valore 100, altrimenti mette in attesa per 2 secondi prima di controllare i due numeri inviati dai processi figli.\n\n\n                  \n                   Esercizio Esame\n                  \n                \n\nDOMANDA APERTA\nSi invita il candidato a esporre una dettagliata analisi del concetto di memoria virtuale e del suo ruolo cruciale all‚Äôinterno di un sistema operativo moderno. Come contribuisce la memoria virtuale ad estendere la capacit√† della memoria fisica e quale effetto ha sulle prestazioni generali del sistema? In aggiunta, si fornisca una definizione chiara di ‚Äòpage fault‚Äô e si illustri il processo attraverso il quale il sistema operativo gestisce tale evento."},"UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/SPIEGAZIONE-PIPE":{"slug":"UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/SPIEGAZIONE-PIPE","filePath":"UNI/ANNO 2/SISTEMI OPERATIVI/CODICI IN C/SPIEGAZIONE PIPE.md","title":"SPIEGAZIONE PIPE","links":[],"tags":[],"content":"int fd[2]\npipe(fd)\nclose(fd[0])\nint p=fd[0]\nla pipe √® FIFO\nint tmp1=3\nwrite(fd[1],&amp;tmp1,sizeof(int))\nla write √® divisa in\n\npath\nindirizzo del dato che vogliamo scrivere\ndimensione dei byte da scrivere\n"},"UNI/ANNO-2/SISTEMI-OPERATIVI/DOMANDE-TRA-DI-NOI":{"slug":"UNI/ANNO-2/SISTEMI-OPERATIVI/DOMANDE-TRA-DI-NOI","filePath":"UNI/ANNO 2/SISTEMI OPERATIVI/DOMANDE TRA DI NOI.md","title":"DOMANDE TRA DI NOI","links":[],"tags":[],"content":"1. definizione di sistema operativo e componenti interne\n2. interrupt vs segnali\n3. memoria virtuale dalla sua storia in poi\n4. Processi Thread, come si gestiscono tra loro e come si sceglie cosa eseguire\n5. Concetto di File System, perch√© nasce e come si struttura\n6. Come lo User Program interagisce con il disco e come interagisce con il S.O.\n7. Spiegami cosa avviene quando si accende una macchina(Bios ecc‚Ä¶)\n8. Come tengo traccia dei blocchi liberi sul disco, parlami di come gli utenti hanno una divisione nell‚Äôusare i blocchi di memoria, come tenere sicuri i dati su disco\n9. Parlami del problema della virtualizzazione(macchine virtuali)\n10. Bit di pinning cosa √®? Come faccio a capire una pagina di una tabella delle pagine appartiene a quale frame se non √® mappato? quindi avviene un page fault\n11. Parlami della segmentazione\n12. Parlami del tipo di frammentazione nella pagina e il tipo di frammentazione che causano i segmenti\n13. Parlami della copy on write\n14. Read Copy Update parlamene\n15. Software di input output\nArgomenti mancanti:\n\npassaggi della compilazione di un codice\n"},"UNI/ANNO-2/SISTEMI-OPERATIVI/LISTA-ARGOMENTI-CRUX":{"slug":"UNI/ANNO-2/SISTEMI-OPERATIVI/LISTA-ARGOMENTI-CRUX","filePath":"UNI/ANNO 2/SISTEMI OPERATIVI/LISTA ARGOMENTI CRUX.md","title":"LISTA ARGOMENTI CRUX","links":[],"tags":[],"content":"Indice degli Argomenti\n1. Definizione di Sistema Operativo\n\nScopo e semplificazione delle risorse hardware.\nDifferenze tra software normale e sistema operativo.\n\n2. Librerie\n\nFunzione delle librerie per la semplificazione dello sviluppo software.\n\n3. Storia e Generazioni dei Sistemi Operativi\n\nGenerazione anni ‚Äò50: macchine specializzate.\nGenerazione anni ‚Äò60: mainframe e sistemi batch.\nGenerazione anni ‚Äò70: primi sistemi operativi (MULTICS, UNIX).\nGenerazione anni ‚Äò80: personal computer.\nGenerazione anni ‚Äò90: dispositivi mobili.\n\n4. Componenti Hardware\n\nMicroprocessori e interazione con il sistema operativo.\nProcessore: funzioni e registri principali.\nMemorie: caratteristiche e velocit√†.\nDispositivi di Input/Output (I/O): struttura e funzionamento.\n\n5. Concetti Fondamentali\n\nMultiplexing: condivisione temporale e spaziale delle risorse.\nTipi di sistemi operativi:\n\nMainframe.\nServer.\nPersonal Computer.\nSmartphone e tablet.\nSistemi embedded e IoT.\nSistemi real-time.\nSmart card.\n\n\n\n6. Concetti di Processo\n\nDefinizione e ciclo di vita di un processo.\nAlberi di processi e gerarchie.\nLayout della memoria di un processo (stack, heap, registri).\n\n7. File e File System\n\nStrutturazione e organizzazione ad albero.\nAccesso ai file: montaggio e utilizzo.\nProtezione dei file tramite permessi (read, write, execute).\n\n8. Chiamate di Sistema\n\nFunzionamento e scopo delle chiamate di sistema.\nTipi di file speciali per dispositivi hardware.\n\n9. Strutture di Sistemi Operativi\n\nSistemi monolitici.\nMicrokernel e client-server.\nVirtualizzazione (macchine virtuali e container).\n\n10. Introduzione a Linux e Bash\n\nStoria di Linux.\nComandi di base e scripting.\nGestione di variabili d‚Äôambiente e file di configurazione.\n\n11. Approfondimenti su Comandi Linux\n\nUtilizzo di comandi come grep, awk, cat, tail.\nVisualizzazione e modifica di file (sed, sort).\n\n12. Segnali e Gestione dei Processi\n\nComunicazione tra processi.\nUtilizzo di kill, nohup, e gestione dei job.\n\n13. Navigazione nel File System\n\nStruttura delle directory principali (es.: mnt, root, usr, bin).\nComandi di base:\n\npwd, cd, ls (con opzioni).\nCopia e spostamento (cp, mv).\nIdentificazione file (file, tac).\n\n\nPermessi di accesso:\n\nConcetti di chmod e mapping permessi (lettura, scrittura, esecuzione).\n\n\n\n14. Gestione dei Processi\n\nComandi per visualizzare processi (ps, top).\nInterazione con i processi:\n\nEsecuzione in foreground e background.\nUso di nohup e screen per processi persistenti.\n\n\nSegnali e gestione:\n\nkill, SIGINT, SIGKILL.\n\n\n\n15. Creazione e Gerarchia dei Processi\n\nIl modello di un processo:\n\nDifferenza tra fork ed exec.\nStato dei processi (running, ready, blocked).\nGestione delle risorse tramite PID, UID, GID.\n\n\nChiamate di sistema per i processi:\n\nwait, execv.\n\n\n\n16. Thread\n\nIntroduzione ai thread:\n\nDifferenze con i processi.\nCondivisione di memoria tra thread.\n\n\nImplementazione dei thread:\n\nThread in spazio utente e kernel.\nApprocci ibridi.\nPro e contro della programmazione multithread.\n\n\n\n17. Chiamate di Sistema (Syscall)\n\nDifferenza tra:\n\nLibrerie standard (libc), unistd.h, syscall.h.\n\n\nEsempio di chiamate di sistema:\n\nStampa con write.\n\n\nPassaggi della chiamata read da libreria a kernel.\n\n18. Segnali e Interruzioni\n\nFunzionamento dei segnali:\n\nSignal handler e tipi di segnali.\nUso di alarm per gestire temporizzazioni.\n\n\nDifferenza tra segnali hardware e software.\nGestione degli interrupt:\n\nInterrupt vector e interrupt handler.\n\n\n\n19. Esempi Pratici di Programmazione\n\nShell minimale:\n\nCreazione di processi e gestione dei comandi.\nUso di execv per eseguire programmi.\n\n\nProgrammi esempio per:\n\nGestione segnali (signal, alarm).\nComunicazione tra processi.\n\n\n\n20. Gestione dei Processi\n\nComunicazione tra processi:\n\nPipe: utilizzo e gestione (open, close, dup).\nDifferenze tra dup e dup2.\n\n\nEsempi pratici:\n\nCreazione di pipeline tra processi.\nReindirizzamento di input e output.\n\n\nProblemi comuni:\n\nBlocco delle pipe e soluzioni.\n\n\n\n21. Race Conditions e Regioni Critiche\n\nDefinizione di race condition.\nImplementazione delle regioni critiche:\n\nAlgoritmo di Peterson.\nSoluzioni al busy waiting.\n\n\nConcetti di sincronizzazione:\n\nUso di variabili di blocco.\n\n\n\n22. Concetto di Produttore-Consumatore\n\nProblemi e soluzioni:\n\nUtilizzo di semafori per sincronizzazione.\nImplementazione di codice per produttore e consumatore.\n\n\nProblemi comuni:\n\nSincronizzazione dei segnali wakeup.\n\n\n\n23. Mutua Esclusione e Semafori\n\nDefinizione e utilizzo dei semafori:\n\nOperazioni down e up.\nAtomicit√† e esclusione reciproca.\n\n\nDifferenze tra semafori e mutex.\nEsempi di codice con semafori.\n\n24. Lettori e Scrittori\n\nProblema di lettori e scrittori:\n\nSincronizzazione tramite semafori.\n\n\nGestione delle priorit√† tra lettori e scrittori.\n\n25. Pthread e Mutex\n\nFunzioni principali di Pthread:\n\npthread_mutex_lock, pthread_mutex_unlock.\npthread_cond_wait e pthread_cond_signal.\n\n\nDifferenze tra lock e trylock.\nUso delle variabili condizionali.\n\n26. Monitor\n\nIntroduzione ai monitor:\n\nVantaggi rispetto ai semafori.\n\n\nUtilizzo in linguaggi come Java.\nProblema produttore-consumatore risolto con i monitor.\n\n27. Scambio di Messaggi\n\nComunicazione tramite messaggi:\n\nFunzioni send e receive.\n\n\nProblemi e soluzioni:\n\nPerdita di pacchetti.\nAcknowledgment e autenticazione.\n\n\nImplementazione produttore-consumatore con messaggi.\n\n28. Concetti Avanzati di Sincronizzazione\n\nBarriere: sincronizzazione tra processi.\nInversione di priorit√†:\n\nProblema e soluzioni (esempio Mars Pathfinder).\n\n\nRead-Copy-Update:\n\nSeparazione tra lettori e scrittori.\n\n\n\n29. Scheduling\n\nFunzioni dello scheduler:\n\nDecisioni di esecuzione di processi e thread.\n\n\nCosti del cambio di contesto.\nDifferenza tra processi CPU-bound e I/O-bound.\n\n30. Introduzione allo Scheduling\n\nDefinizione e importanza dello scheduling.\nStati di un processo:\n\nEsecuzione\nReady\nBlocked\n\n\nFunzione dello scheduler.\nTipologie di scheduling:\n\nNon preemptive (senza prelazione)\nPreemptive (con prelazione)\n\n\nMomenti di intervento dello scheduler:\n\nCreazione di un processo\nUscita di un processo\nBlocco del processo\nInterrupt di I/O\n\n\n\n\n31. Algoritmi di Scheduling\nSistemi Batch (senza prelazione)\n\nFirst Come First Served (FCFS)\n\nEsecuzione in ordine di arrivo\nPro e contro\n\n\nShortest Job First (SJF)\n\nOttimizzazione del turnaround\nProblematiche con arrivi successivi\n\n\nShortest Remaining Time Next (SRTN)\n\nVariante con prelazione di SJF\n\n\n\nSistemi Interattivi (con prelazione)\n\nRound Robin (RR)\n\nFunzionamento\nScelta del quantum di tempo\n\n\nScheduling a Priorit√† (SAP)\n\nPriorit√† statica vs dinamica\nGestione delle code\n\n\nShortest Process Next con Aging (SPNCA)\n\nEquilibrio tra SJF e sistemi interattivi\n\n\nGuaranteed Scheduling (GS)\n\nEqua ripartizione del tempo CPU\n\n\nScheduling a Lotteria (SAL)\n\nAssegnazione casuale di tempi CPU\n\n\nScheduling Fair-Share (SFS)\n\nDivisione equa della CPU tra gli utenti\n\n\n\nSistemi Real-Time\n\nTipologie:\n\nHard Real-Time\nSoft Real-Time\n\n\nTipi di eventi:\n\nPeriodici\nNon periodici\n\n\nCondizioni di schedulabilit√†\n\n\n32. Parallelismo e Thread\n\nDifferenza tra processi e thread\nThread a livello utente vs Thread a livello kernel\nScheduling dei thread:\n\nAllocazione della CPU tra thread dello stesso processo\nProblemi di starvation\n\n\nEsecuzione concorrente e gestione delle risorse\n\n\n33. Astrazione della Memoria\n\nDefinizione e necessit√† di astrazione\nMemoria fisica vs memoria virtuale\nModelli di organizzazione della memoria:\n\nMemoria senza astrazione\nIndirizzamento assoluto e relativi problemi\n\n\nSwapping e gestione dello spazio di indirizzi\n\n\n34. Gestione della Memoria\n\nFrammentazione della memoria\nMetodi di allocazione della memoria:\n\nBitmap\nListe collegate\n\n\nMetodologie per l‚Äôallocazione dinamica:\n\nFirst Fit\nNext Fit\nBest Fit\nWorst Fit\nQuick Fit\n\n\nBuddy Allocation e relativi problemi\nSlab Allocator\nCaching e gestione delle risorse\n\n\n35. Memoria Virtuale\n\nConcetto di memoria virtuale\nTabella delle pagine e traduzione degli indirizzi\nGestione degli accessi alla memoria\nPage Fault e gestione degli errori\nEvoluzione delle tabelle di paginazione:\n\nPaging a due livelli\nPaging a quattro livelli\n\n\n\n\n36. Algoritmi di Sostituzione delle Pagine\n\nPage Replacement e Page Swap\nLista degli algoritmi principali:\n\nAlgoritmo Ottimale\nNot Recently Used (NRU)\nFirst-In, First-Out (FIFO)\nSecond-Chance Algorithm\nClock Algorithm\nLeast Recently Used (LRU)\nNot Frequently Used con Aging (NFUA)\nWorking Set Algorithm\nWS Clock Algorithm\n\n\n\n\n37. Traduzione degli Indirizzi e Ottimizzazioni\n\nTLB (Translation Lookaside Buffer)\nFunzionamento e gestione delle tabelle delle pagine\nPage Table Walk e accessi alla memoria\n\n\n38. Algoritmi di Sostituzione delle Pagine\n\nSecond-Chance Algorithm\nClock Algorithm\nLeast Recently Used (LRU)\nNot Frequently Used con Aging (NFUA)\nWorking Set Algorithm\nWS Clock Algorithm\nAllocazione Locale vs Globale\nTrashing e gestione della memoria\n\n\n39. Gestione della Memoria nei Processi\n\nPage Fault Frequency\nAllocazione equa vs proporzionale\nMitigazione del trashing\nSwapping e scheduling a due livelli\nMultiprogrammazione: gestione dei processi CPU-bound e I/O-bound\nDimensione ottimale delle pagine e bilancio dei fattori\nPaging Daemon\nTransparent Huge Pages\nCalcolo della dimensione ottimale delle pagine\nMetodi di compressione, compattazione e deduplicazione\n\n\n40. Memoria Virtuale e Gestione dei Processi\n\nCreazione di un processo e gestione delle dipendenze\nFork e Copy-On-Write\nEsecuzione e Scheduling\nPage Fault e gestione in 10 passi\nArea di Swap e scenari di gestione\nDMA e problemi di gestione delle pagine\n\n\n41. Segmentazione della Memoria\n\nMemoria monodimensionale vs segmentazione\nDifferenze tra paginazione e segmentazione\nCondivisione e protezione dei segmenti\nConversione degli indirizzi nei sistemi segmentati\nUso della TLB nei sistemi segmentati\nEsempio MULTICS e segmentazione avanzata\n\n\n42. Sistemi di Memorizzazione e File System\n\nDefinizione e funzioni di un file system\nOrganizzazione dei dati su disco\nGestione dell‚Äôaccesso ai file\nVirtual File System (VFS)\nCaching dei file (Page Cache, Buffer Cache)\nMetadati e attributi dei file\nTipi di file e directory\nFile speciali e file eseguibili\n\n\n43. Struttura e Operazioni sui File\n\nTipologie di file\nStrutture di gestione dei file\nAttributi e metadati\nOperazioni di base sui file (Creazione, Lettura, Scrittura, Eliminazione)\nAccesso sequenziale e casuale\nUso di Seek per l‚Äôaccesso rapido\nMetodi di copia dei file\nOrganizzazione delle directory\nPath assoluti e relativi\n\n\n44. Directory e Gerarchia del File System\n\nStruttura monolivello vs multilivello\nOperazioni sulle directory (Creazione, Eliminazione, Lettura)\nGestione dei percorsi nei sistemi UNIX e Windows\nGestione dei link (Hard link vs Symbolic link)\nCreazione ed estrazione di archivi (tar, zip)\n\n\n45. Boot System e Partizionamento\n\nBIOS e UEFI\nStruttura dell‚ÄôMBR e partizioni\nGUID Partition Table (GPT)\nSecure Boot\nEFI System Partition (ESP)\n\n\n46. Allocazione dei File nel File System\n\nAllocazione contigua\nAllocazione con liste concatenate\nFile Allocation Table (FAT)\nProblemi di frammentazione\nUso degli I-node per la gestione dei file\n\n\n47. I-node e Struttura Interna dei File System\n\nFunzione e struttura degli I-node\nGestione dei file di grandi dimensioni\nCaching degli I-node\nUso della memoria RAM per migliorare la gestione del file system\n\n\n48. Approfondimenti su NTFS e Sistemi di Archiviazione\n\nDifferenze tra NTFS, FAT32 ed EXT4\nGestione della memoria nei moderni file system\nOttimizzazioni per la gestione dei blocchi di memoria\nUso della cache per migliorare le prestazioni\n\n\n49. Struttura delle Cartelle e Gestione dei File\n\nStruttura delle cartelle e voci nei file system\nMetodi di organizzazione delle directory\nI-node e gestione dei metadati\nGestione dei nomi dei file nelle directory\nHeap e gestione delle voci\nRicerca dei file all‚Äôinterno delle directory\nUtilizzo della cache per l‚Äôaccesso rapido ai file\n\n\n50. File Condivisi e Link nei File System\n\nHard Link\nSoft Link\nLink simbolici e differenze tra hard e soft link\nProblemi di duplicazione dei file e backup dei symlink\n\n\n51. Gestione dello Spazio su Disco\n\nAllocazione contigua vs non contigua\nStrategie di ottimizzazione e latenza dei blocchi\nBitmap vs Free List per la gestione dello spazio libero\nGestione della latenza nei dischi\nQuota di utilizzo nei sistemi multiutente\nFile System Ext2 e gestione dei blocchi liberi\n\n\n52. Performance e Ottimizzazioni del File System\n\nCaching e buffer cache\nStruttura interna di Ext2\nOttimizzazioni per ridurre la frammentazione\nUso di bitmap per la gestione delle risorse\nTecniche per migliorare la velocit√† di accesso ai file\nAlgoritmi di sostituzione della cache\nStrategie di sincronizzazione per evitare perdita di dati\nPage Cache e Buffer Cache\n\n\n53. Virtual File System (VFS)\n\nStruttura e funzionamento del VFS\nMontaggio di nuovi file system\nGestione delle operazioni indipendenti dal tipo di file system\nSuperblock e gestione dei V-NODE\nCompatibilit√† con diversi file system (Ext4, NTFS, FAT32, ecc.)\n\n\n54. Backup e Affidabilit√† del File System\n\nTipologie di backup (fisico vs logico)\nUso di strumenti come rsync\nStrategie per la coerenza dei dati dopo un crash\nJournaling per la protezione dei file system\nDifferenze tra Ext2, Ext3 ed Ext4\nDeframmentazione e deduplicazione\n\n\n55. Principi di Hardware I/O\n\nPanoramica sui dispositivi di I/O\nDispositivi a blocchi vs dispositivi a caratteri\nVelocit√† e impatto delle periferiche sul sistema\nInterfacce standard per la comunicazione con l‚Äôhardware\nPorta USB, SATA, SCSI, Thunderbolt\nBus di sistema (PCIe, Northbridge, Southbridge)\n\n\n56. Comunicazione tra CPU e Periferiche\n\nController dei dispositivi e registri di controllo\nPort-Mapped I/O vs Memory-Mapped I/O\nGestione degli indirizzi di memoria per i dispositivi\nDMA (Direct Memory Access) e riduzione del carico sulla CPU\nModalit√† di trasferimento dati:\n\nPolling (Busy Waiting)\nInterrupt-Driven I/O\nCycle Stealing\nBurst Mode\nFly-By Mode\n\n\n\n\n57. Interrupt e Gestione degli Eventi Asincroni\n\nDifferenze tra Trap, Fault e Interrupt\nInterrupt hardware e gestione delle priorit√†\nPassaggi per la gestione di un interrupt\nInterrupt Precisi vs Imprecisi\nPipeline e gestione dei processi interrotti\nUtilizzo di un Vettore degli Interrupt\nSalvataggio del contesto del processore\n\n\n58. Software di I/O\n\nStruttura del software per la gestione dell‚ÄôI/O\nDenominazione uniforme dei file nei dispositivi di archiviazione\nGestione degli errori nei dispositivi di I/O\nTrasferimenti sincroni vs asincroni\nBuffering e gestione dei dispositivi in tempo reale\nDispositivi condivisibili vs dispositivi dedicati\nEsempio di stampa e gestione del buffer di stampa\n\n\n59. Approfondimenti su DMA e Comunicazione con le Periferiche\n\nGestione degli interrupt in ambienti multitasking\nPolling vs Interrupt-Driven I/O\nSincronizzazione tra processi e dispositivi hardware\nTecniche di accesso diretto alla memoria\nUso del DMA per l‚Äôottimizzazione delle operazioni di I/O\nDirect Memory Access e riduzione degli interrupt della CPU\n\n\n60. RAID e Disaster Recovery\n\nGestione della ridondanza nei sistemi di archiviazione\nRAID 0, RAID 1, RAID 5, RAID 6 e RAID 10\nBackup remoti e Disaster Recovery\nRiduzione delle duplicazioni di file tramite hard link\nUso di snapshot e versioning per la protezione dei dati\n\n\n61. Comandi Unix/Linux per la Gestione del File System\n\nComandi per la gestione delle partizioni (lsblk, fdisk, mount)\nMontaggio e smontaggio di dispositivi\nComandi per la gestione dei file (cp, mv, rm, ln)\nSincronizzazione dei dati con rsync\nGestione delle directory e percorsi assoluti/relativi\nUso di tar e zip per la compressione e archiviazione\n\n\n62. Software per la Gestione degli Interrupt\n\nPassaggi per la gestione di un interrupt software\nSalvataggio dello stato del processore\nEsecuzione della procedura di servizio dell‚Äôinterrupt\nRipristino del contesto del processo interrotto\nEsecuzione del processo successivo nella coda di scheduling\n"},"UNI/ANNO-2/SISTEMI-OPERATIVI/SISTEMI-OPERATIVI-E-RETI-INDICE":{"slug":"UNI/ANNO-2/SISTEMI-OPERATIVI/SISTEMI-OPERATIVI-E-RETI-INDICE","filePath":"UNI/ANNO 2/SISTEMI OPERATIVI/SISTEMI OPERATIVI E RETI INDICE.md","title":"SISTEMI OPERATIVI E RETI INDICE","links":["UNI/ANNO-2/SISTEMI-OPERATIVI/LISTA-ARGOMENTI-CRUX","UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/LISTA-CODICI-CRUX","UNI/ANNO-2/SISTEMI-OPERATIVI/SISTEMI-OPERATIVI-LEZ.1","UNI/ANNO-2/SISTEMI-OPERATIVI/SISTEMI-OPERATIVI-LEZ.2","UNI/ANNO-2/SISTEMI-OPERATIVI/SISTEMI-OPERATIVI-LEZ.3","UNI/ANNO-2/SISTEMI-OPERATIVI/SISTEMI-OPERATIVI-LEZ.4-5-6-7","UNI/ANNO-2/SISTEMI-OPERATIVI/SISTEMI-OPERATIVI-LEZ.8","UNI/ANNO-2/SISTEMI-OPERATIVI/SISTEMI-OPERATIVI-LEZ.9","UNI/ANNO-2/SISTEMI-OPERATIVI/SISTEMI-OPERATIVI-LEZ.10","UNI/ANNO-2/SISTEMI-OPERATIVI/SISTEMI-OPERATIVI-LEZ.11","UNI/ANNO-2/SISTEMI-OPERATIVI/SISTEMI-OPERATIVI-LEZ.12","UNI/ANNO-2/SISTEMI-OPERATIVI/SISTEMI-OPERATIVI-LEZ.13","UNI/ANNO-2/SISTEMI-OPERATIVI/SISTEMI-OPERATIVI-LEZ.14","UNI/ANNO-2/SISTEMI-OPERATIVI/SISTEMI-OPERATIVI-LEZ.15","UNI/ANNO-2/SISTEMI-OPERATIVI/SISTEMI-OPERATIVI-LEZ.16","UNI/ANNO-2/SISTEMI-OPERATIVI/SISTEMI-OPERATIVI-LEZ.17","UNI/ANNO-2/SISTEMI-OPERATIVI/SISTEMI-OPERATIVI-LEZ.18","UNI/ANNO-2/SISTEMI-OPERATIVI/SISTEMI-OPERATIVI-LEZ.19","UNI/ANNO-2/SISTEMI-OPERATIVI/SISTEMI-OPERATIVI-LEZ.20","UNI/ANNO-2/SISTEMI-OPERATIVI/DOMANDE-TRA-DI-NOI","UNI/ANNO-2/SISTEMI-OPERATIVI/CODICI-IN-C/INDICE-CODICI-IN-C","UNI/ANNO-2/RETI/INDICE-RETI"],"tags":[],"content":"Se vai sotto trovi anche Reti\n\n\n                  \n                  Sistemi \n                  \n                \n\nSistemi\nLISTA ARGOMENTI CRUX\nLISTA CODICI CRUX\nSISTEMI OPERATIVI LEZ.1\nSISTEMI OPERATIVI LEZ.2\nSISTEMI OPERATIVI LEZ.3\nSISTEMI OPERATIVI LEZ.4-5-6-7 (INTRODUZIONE A LINUX E BASH)\nSISTEMI OPERATIVI LEZ.8\nSISTEMI OPERATIVI LEZ.9\nSISTEMI OPERATIVI LEZ.10\nSISTEMI OPERATIVI LEZ.11\nSISTEMI OPERATIVI LEZ.12\nSISTEMI OPERATIVI LEZ.13\nSISTEMI OPERATIVI LEZ.14\nSISTEMI OPERATIVI LEZ.15\nSISTEMI OPERATIVI LEZ.16\nSISTEMI OPERATIVI LEZ.17\nSISTEMI OPERATIVI LEZ.18\nSISTEMI OPERATIVI LEZ.19\nSISTEMI OPERATIVI LEZ.20\nLISTA ARGOMENTI CRUX\nDOMANDE TRA DI NOI\nINDICE CODICI IN C\n\n\n\n\n                  \n                  Reti \n                  \n                \n\nReti\nINDICE RETI\n\n"},"UNI/ANNO-2/SISTEMI-OPERATIVI/SISTEMI-OPERATIVI-LEZ.1":{"slug":"UNI/ANNO-2/SISTEMI-OPERATIVI/SISTEMI-OPERATIVI-LEZ.1","filePath":"UNI/ANNO 2/SISTEMI OPERATIVI/SISTEMI OPERATIVI LEZ.1.md","title":"SISTEMI OPERATIVI LEZ.1","links":[],"tags":[],"content":"\n\n                  \n                  lista di domande \n                  \n                \n\nDOMANDE\n\nSi invita il candidato a descrivere il concetto di sistema operativo, evidenziando il ruolo di gestione delle risorse e di intermediazione tra hardware e software. Come il sistema operativo garantisce l‚Äôesecuzione di pi√π programmi contemporaneamente?\n\n\n\n                  \n                  la risposta \n                  \n                \nIl sistema operativo √® un vero e proprio software che ha il compito di fare da tramite tra l‚Äôutente e l‚Äôhardware, sopra di esso abbiamo una interfaccia detta GUI (Graphic User Interface) e viene usata dall‚Äôutente per interagire con il s.o.\ni software o l‚Äôutente effettuano chiamate di sistema che innescano delle procedure ad esempio comunicare con un controller di un dispositivo.\nil s.o. garantisce l‚Äôesecuzione di pi√π programmi contemporaneamente gestendo le risorse temporali e spaziali e applicando ad esempio algoritmi di scheduling e multiplexing alle varie risorse come la CPU\ntermporali: indicano quelle risorse che hanno un utilizzo che dipende dal tempo ad esempio la CPU con i suoi cicli di clock\nspaziali: quelle risorse che hanno un utilizzo in base a dello spazio come la memoria\n\n\nSi descriva il funzionamento del Direct Memory Access (DMA). Come il DMA migliora le prestazioni del sistema rispetto a un accesso gestito dalla CPU?\n\n\n\n                  \n                  la risposta \n                  \n                \nil DMA consente il trasferimento di informazioni e quindi un accesso in memoria diretto, senza rubare troppi cicli alla CPU che nel frattempo pu√≤ svolgere operazioni di diverso tipo\n\n\nSi inviti il candidato a illustrare il processo di avvio di un sistema operativo moderno, partendo dal BIOS fino al caricamento del kernel. Qual √® il ruolo della memoria flash nella motherboard?\n\n\n\n                  \n                  la risposta \n                  \n                \nil computer quando viene acceso avvia dalla memoria flash il bios che avr√† il compito di far eseguire le prime righe di codice del s.o.\n\n\nSi inviti il candidato a spiegare il funzionamento dei registri PSW (Program Status Word). Quali informazioni contengono e come vengono usati dal kernel?\n\n\n\n                  \n                  la risposta \n                  \n                \ni registri PSW contengono tutti quei flag e condizioni utilizzabili da un processo per effettuare delle operazioni logiche o simili. Il kernel le usa per eventualmente far riprendere il programma dove stava in precedenza\n\n\n\nDef sistema operativo\nIl sistema operativo √® uno strato di software della macchina ha lo scopo di fornire una semplificazione delle risorse hardware ai programmi\n\nIl s.o. maschera gli elementi sottostanti della macchina\nIl s.o. consente la gestione di esecuzioni in parallelo\nIl s.o. √® un gestore delle risorse e ne facilita l‚Äôutilizzo\n\nIn mezzo abbiamo un s.o. che traduce le operazioni dall‚Äôalto verso le componenti in basso\n\nLibrerie\nUna persona che vuole creare un software non si deve reinventare le interazioni con i livelli sottostanti bens√¨ utilizzer√† Librerie ovvero estratti di codice da implementare per accedere alle componenti sottostanti\nDifferenza principale tra normale software e sistema operativo\nEsistenza di un flag che differenzia del codice software o del codice software del s.o.\nIl s.o. accede a cose in pi√π\nCambio di contesto da software a modalit√† kernel\nIl s.o. deve saper gestire\n\npi√π utenti\npi√π programmi in esecuzione\nLa gestione delle risorse del sistema operativo include il discorso di Multiplexing(condivisione) fa dividere la gestione delle risorse in 2 modalit√†\ntemporale: quando una risorsa viene condivisa tra utenti o programmi a livello temporale ovvero che richiede del tempo per essere completata come una CPU spartita tra pi√π utenti o programmi e viene usata a giro da ognuno\nspaziale: i clienti(utenti o programmi) al posto di alternarsi prendono una parte della risorsa intesa come memoria\n\nCome sono nati?\nCi sono 5 generazioni\n\nanni 50 le macchine avevano solo uno scopo utilizzo di schede perforate e filamenti, se volevi cambiarne l‚Äôuso dovevi buttarla gi√π e ricostruirla, es: colossus\nanni 60 macchine anche chiamate mainframe con uso dei transistor che consentiva di cambiare le operazioni da far svolgere alla macchina attraverso dei programmi su schede forate e uso del sistema batch ovvero un insieme di job(programmi) ed un sistema che permetteva di eseguire le varie operazioni che necessitavano pi√π macchine con  una organizzazione simile a una pipeline\n\nanni 70 primi sistemi operativi come MULTICS e UNIX con multiprogrammazione, una macchina che consentiva pi√π programmi contemporaneamente cos√¨ da soddisfare i clienti ad esempio la 7094 della ibm 360 con strumenti scientifici e commerciali. POSIX chiamate a sistema che devono essere in ogni sistema operativo\nanni 80 i personal computer di oggi con le loro peculiarit√† e i loro sistemi operativi\nanni 90 i computer mobili di oggi come telefoni ecc\n\nPARTE HARDWARE\nOgni dispositivo ha un microprocessore che si interfaccia con il sistema operativo e viceversa\nil processore\nSono il cervello del computer prelevano le istruzioni dalla memoria e le eseguono in cicli contraddistinti\nRicordare almeno i registri:\n\nPC, Program Counter, contiene l‚Äôindirizzo di memoria della prossima istruzione da eseguire\nPSW, Program Status Word, contiene bit con il codice di condizione, impostati da istruzioni a confronto, la priorit√† della CPU, la modalit√† (utente o kernel) e altri diversi bit di controllo\nSP, Stack Pointer, punta alla cima dello stack\nConcetto di multiplexing delle operazioni nel tempo pipeline\nCache nella CPU\n\n\nmemorie\nPi√π  una memoria e‚Äô veloce pi√π costa e di solito e‚Äô meno capiente\n\ndispositivi di I/O\nSono costituiti da due parti un controller che gestisce il dispositivo e il dispositivo stesso\nIl controller fa da interfaccia per il sistema operativo\nLa CPU parla con un controller del disco che parla poi a sua volta con un controller e quest‚Äôultimo parla con la CPU\n\nDMA\nE‚Äô un chip che consente l‚Äôaccesso diretto tra un controller di un dispositivo e la memoria senza mettere in mezzo la CPU che dovr√† solo comunicare la dimensione di byte che si possono scambiare i due\nbus\nSono una serie di fili che consentono la comunicazione tra dispositivi, se il bus e‚Äô di scarsa qualit√† il sistema avr√† un collo di bottiglia\n\nAVVIO DEL SISTEMA\nOgni PC ha una motherboard con un BIOS ovvero un software di I/O di basso livello ora risiede in una piccola memoria flash non volatile nella mobo e gestisce varie cose del device"},"UNI/ANNO-2/SISTEMI-OPERATIVI/SISTEMI-OPERATIVI-LEZ.10":{"slug":"UNI/ANNO-2/SISTEMI-OPERATIVI/SISTEMI-OPERATIVI-LEZ.10","filePath":"UNI/ANNO 2/SISTEMI OPERATIVI/SISTEMI OPERATIVI LEZ.10.md","title":"SISTEMI OPERATIVI LEZ.10","links":[],"tags":[],"content":"Comunicazione tra processi\nI processi tra loro hanno bisogno di comunicare durante la loro esecuzione\n\nin particolare devono sincronizzarsi tra loro\n\nper evitare che si intralcino tra loro\nSe non sono sincronizzati in maniera adeguata possiamo incorrere nella RACE CONDITION\n\n\n\nRACE CONDITIONS\n\n\n                  \n                  esempio \n                  \n                \n\n\nIl processo A legge il valore in=7 e decide di usare quella posizione.\nPrima che A possa scrivere, viene sospeso.\nIl processo B legge lo stesso valore in=7, decide di usare quella posizione, e la occupa.\nQuando A riprende, sovrascrive il valore in posizione 7, ignorando che B aveva gi√† scritto l√¨.\nRisultato: errore o perdita di dati.\n\n\n\n\nper evitarle usiamo\nLE CRITICAL REGION\nsono una parte di codice che pu√≤ essere implementata in diversi modi(che poi vedremo)\ne che consente di isolare dei processi che vogliono condividere tra loro informazioni, seguendo delle regole\nLe regole:\n\nSolo un processo per volta pu√≤ trovarsi dentro una regione critica\nLa critical region deve essere indipendente dalle risorse come numero di CPU o velocit√†\n\nquindi deve funzionare in qualsiasi caso\n\n\nUn processo fuori dalla regione critica non pu√≤ impedire ad altri processi di accedervi\nUn processo pu√≤ aspettare per entrare in una regione critica ma non all‚Äôinfinito\n\nCOSA NON FARE\n\nDISABILITARE GLI INTERRUPT: disabiliti la possibilit√† di far riallocare la CPU, ovvero passare le proprie risorse di calcolo ad altri processi.\n\ncon INTERRUPT ci potrebbe essere una riallocazione che comporterebbe i problemi di prima\nquesta cosa ha senso solo con CPU singole\n\n\nBLOCCARE LE VARIABILI:\n\nQui si usano variabili per ‚Äúbloccare‚Äù l‚Äôaccesso alla Critical Region (es. variabili che indicano se una risorsa √® in uso).\nProblema: Questo sposta il problema delle Race Condition sulle variabili stesse, perch√© pi√π processi possono comunque interferire mentre leggono/scrivono la variabile di blocco.\n\n\n\n\nUna non soluzione, esclusione reciproca con BUSY waiting (Alternanza Rigorosa)\nabbiamo due codici uno per il processo1 e uno per il processo2\nCodiceprocesso0:\nwhile(TRUE){\n \nwhile(turn!=0);\ncritical_region();\nturn=1;\nnoncritical_region();\n}\nCodiceprocesso1:\nwhile(TRUE){\n \nwhile(turn!=1);\ncritical_region();\nturn=0;\nnoncritical_region();\n}\nCosa succede?\n\nla variabile turn √® in comune con entrambi i processi\nfaccio while(TRUE) perch√© altrimenti il processo finirebbe 1 volta il suo compito e si terminerebbe\nquando il while dentro √® verificato il processo entra in un loop di attesa che si sbloccher√† solo quando l‚Äôaltro processo avr√† finito\nuna volta fatto entrer√† nella regione critica(sotto forma di funzione)\ncambier√† turn in 0 o 1\nesce dalla zona critica\n\nProblemi\n\nNon puoi entrare 2 volte in una zona critica perch√© imposti turn all‚Äôopposto\nUn processo fuori dalla regione critica pu√≤ modificare turn\n\nAlgoritmo di Peterson\n\nAlice e Bob vogliono usare un unico computer ma ci sono delle regole\n\nsolo una persona per volta pu√≤ usare il computer\nse entrambi vogliono usarlo devono decidere chi va primo\n\n\nIdea dell‚Äôalgoritmo\n\nAlice o Bob devono segnalare il loro interesse a usare il computer\nSe l‚Äôaltro non √® interessato, la persona interessata pu√≤ usarlo subito\nse  una persona poi si interessa deve aspettare che l‚Äôaltro finisca\nse una persona segnala di aver finito l‚Äôaltra pu√≤ iniziare\nse entrambe vogliono usarlo sar√† in base all‚Äôordine di chi segnala ad esempio chi scrive prima su un foglio\n\n\n\nCODICE\n#define N 2                   /* numero di processi */\n \nint turn;                     /* A chi tocca? */\nint interested[N];            /* Tutti i valori inizialmente 0 (FALSE) */\n \nvoid enter_region(int process) {  /* process √® 0 o 1 */\n    int other;                  /* numero dell&#039;altro processo */\n    other = 1 - process;        /* 1&#039;opposto del processo */\n    interested[process] = TRUE; /* mostra che si √® interessati */\n    turn = process;             /* imposta il flag */\n    while (turn == process &amp;&amp; interested[other] == TRUE) /* istruzione null */;\n}\n \nvoid leave_region(int process) { /* process: chi esce */\n    interested[process] = FALSE; /* indica l&#039;uscita dalla regione critica */\n}\n\ncodice per entrare nella regione critica\n\nsi mette in input un processo o 0 o 1\nusiamo other per avere come riferimento gli opposti del processo\nponiamo il processo come interessato ad entrare\nmettiamo che turn diventa uguale a processo\nmettiamo in attesa se il processo √® interessato ma l‚Äôaltro processo other √® anche lui True\nipoteticamente dopo il while faccio la roba della regione\n\n\nabbandono della regione mette interesse a false\n\nCome evitare i Busy Waiting\n\n\n                  \n                  cosa sono? \n                  \n                \n\nCi si pu√≤ arrivare dalla sua etimologia, un processo o Thread che aspetta in maniera attiva|impegnata\n\ninfatti abbiamo un ciclo while con il true ecc‚Ä¶\n\n\n\nPer risolvere dobbiamo evitare lo spin lock e il busy waiting, ovvero non dobbiamo\nSPRECARE RISORSE\n\n\n                  \n                  spin lock? \n                  \n                \n\ntipo di meccanismo di sincronizzazione dove i processi condividono delle risorse tra loro e sono attivamente in attesa, quindi si usa la busy waiting\n\n\nla soluzione √® che mettiamo i processi che prima di trovare un modo erano in stato di wait ora saranno in fase di sleep quindi blocked, quindi quei processi cederanno le risorse alla CPU e per essere riattivate si far√† wakeup\nFunzione sleep()\nvoid sleep() {\n    set own state to BLOCKED;      // Imposta lo stato su &quot;bloccato&quot;\n    give CPU to scheduler;         // Rilascia la CPU\n}\n \nFunzione wakeup(process)\nvoid wakeup(process) {\n    set state of process to READY; // Imposta il processo su &quot;pronto&quot;\n    give CPU to scheduler;         // Scheduler assegna la CPU\n}\nquando fa sleep si toglie dalla lista d‚Äôattesa dello scheduler\nquando qualcuno gli chiama wakeup si sveglia e si rimette in lista dello scheduler\nCONCETTO DI PRODUTTORE CONSUMATORE\n\ndue processi che condividono tra loro un buffer fisso\n\nuno sar√† il produttore\n\nha lo scopo di produrre dati e metterli sul buffer, se il buffer √® pieno, dorme, viene risvegliato quando il consumatore legge i dati cos√¨ che pu√≤ riscriverli\n\n\nuno il consumatore\n\ndorme se il buffer √® vuoto e viene risvegliato quando il produttore inserisce dati\n\n\n\n\n\nCODICI\nCODICE PRODUTTORE\n#define N 100\nint count = 0;\n \nvoid producer(void) {\n    int item;\n    while (TRUE) {\n        item = produce_item();       // Produci un elemento\n        if (count == N) {\n            sleep();     // Se il buffer √® pieno, dormi\n        }\n        insert_item(item);           // Inserisci l&#039;elemento nel buffer\n        count++;                     // Incrementa il conteggio degli elementi\n        if (count == 1) wakeup(cons); // Risveglia il consumatore se era bloccato\n    }\n}\nCODICE CONSUMATORE\n#define N 100\nint count = 0;\n \nvoid consumer(void) {\n    int item;\n    while (TRUE) {\n        if (count == 0) {\n            sleep();      // Se il buffer √® vuoto, dormi\n        }\n        item = remove_item();         // Rimuovi un elemento dal buffer\n        count--;                      // Decrementa il conteggio degli elementi\n        if (count == N - 1) wakeup(prod); // Risveglia il produttore se era \n                                          // bloccato\n        consume_item(item);           // Consuma l&#039;elemento\n    }\n}\nProblema di questi due codici\n\nil consumatore sta per andare a dormire ma riceve un segnale di wakeup dal produttore, visto che sta per andare a dormire √® ancora sveglio e quindi poi continua ad andare a dormire\n\nil produttore non ha piena coscienza di chi ha davanti e semplicemente invia il segnale di wakeup quando ha finito di scrivere nel buffer\nil consumatore potrebbe averci messo pi√π tempo per leggere le cose e quindi non sta sincronizzato come il produttore\nil consumatore non si sveglier√† mai pi√π\n\n\n\nPossibili soluzioni di questi due codici\nc‚Äô√® un bit che si occupa di tenere conto dei vari wakeup mandati quando un processo sta per andare a dormire.\nse questo bit √® acceso il processo che sta per entrare in sleep si risveglia subito\n\n√® un porkaround\n\nLa mutua esclusione: I semafori\nconcetto di semaforo ideato da Dijkstra nel 1965\nSistema per gestire i vari wakeup citati in precedenza\nil semaforo pu√≤ avere 2 valori\n\n0 quando non ci sono wakeup\n1 quando ci sono dei wakeup in coda ad attendere\n\nOperazioni possibili\n\ndown se viene fatta su un processo e il valore del semaforo √® &gt;0 verr√† decrementato\n\nse il valore raggiunge 0 allora il processo che chiama down verr√† bloccato quindi andr√† a dormire in una coda di attesa\n\n\nup se il valore del semaforo √® 0 allora come abbiamo detto prima i processi sono in una coda di attesa\n\nuno di questi processi in attesa verr√† risvegliato e continuer√† la sua esecuzione\n\n\n\n\n\n                  \n                   Chi chiama down e chi up? Dipende dal ruolo dei processi:\n                  \n                \n\n\n\nIl produttore:\n\n\n\n\nChiama down per verificare se c‚Äô√® spazio libero nel buffer prima di produrre.\n\n\nChiama up per segnalare che ha aggiunto un elemento nel buffer (quindi c‚Äô√® un dato disponibile per il consumatore).\n\n\n\n\nIl consumatore:\n\n\n\nChiama down per verificare se ci sono dati disponibili nel buffer prima di consumare.\nChiama up per segnalare che ha liberato uno spazio nel buffer (quindi il produttore pu√≤ aggiungere un altro elemento).\n\n\n\n\n\n                  \n                  concetto di atomicit√† \n                  \n                \n\nle operazioni sui semafori sono indivisibili quindi ogni operazione √® a se evitando i conflitti\n\n\nDiversi tipi di semafori\n\nmutex, accesso esclusivo evita accessi simultanei\nfull, tutti i posti devono essere occupati\nempty, tutti i posti devono essere liberi\n\nCODICE\nCODICE PRODUTTORE\n#define N 100\n \ntypedef int semaforo;            // Definizione di tipo per i semafori\nsemaforo mutex = 1;              // Semaforo mutex inizializzato a 1 \nsemaforo empty = N, full = 0;    // Semafori per spazi vuoti e pieni \n \nvoid producer(void) {\n    int item;\n    while (TRUE) {\n        item = produce_item();      // Produce un elemento\n        down(&amp;empty);               // Aspetta uno spazio libero nel buffer\n        down(&amp;mutex);               // Accede al buffer in esclusiva\n        insert_item(item);          // Inserisce l&#039;elemento nel buffer\n        up(&amp;mutex);                 // Libera l&#039;accesso al buffer\n        up(&amp;full);                  // Segnala che un nuovo elemento √® disponibile\n    }\n}\n\ndown praticamente decrementa la variabile corrente\nup la aumenta\nla variabile empty indica quanti spazi liberi ci sono in questo caso 100\nla variabile mutex se vale 0 blocca l‚Äôaccesso agli altri se vale 1 lo rimette\n\n#define N 100\n \ntypedef int semaforo;            // Definizione di tipo per i semafori\nsemaforo mutex = 1;              // Semaforo mutex inizializzato a 1 \nsemaforo empty = N, full = 0;    // Semafori per spazi vuoti e pieni \n \nvoid consumer(void) {\n    int item;\n    while (TRUE) {\n        down(&amp;full);                // Segnala che un elemento √® stato rimosso\n        down(&amp;mutex);               // Accede al buffer in esclusiva\n        item = remove_item();       // Rimuove l&#039;elemento nel buffer\n        up(&amp;mutex);                 // Libera l&#039;accesso al buffer\n        up(&amp;empty);                 // Segnala che √® presente uno spazio in pi√π\n        consume_item(item);         // Consuma la risorsa\n    }\n}\nfa la stessa roba ma rimuove gli elementi\nUN‚ÄôALTRO PROBLEMA: LETTORI E SCRITTORI\n\nabbiamo R processi che vanno sul database e leggono\nabbiamo un processo che modifica il database\nposso avere pi√π lettori perch√© alla fine leggono e basta\nse ho lo scrittore in esecuzione tutti devono levarsi dal cazzo\n\nCODICE\nCodice reader\ntypedef int sema;            // Tipo per i semafori\nsema mutex = 1;              // Mutex per il contatore dei lettori\nsema db = 1;                 // Accesso esclusivo al database\nint rc = 0;                  // Contatore dei lettori attivi\n \nvoid reader() {\n    while (TRUE) {\n        down(&amp;mutex);        // Blocca l&#039;accesso al contatore dei lettori\n        rc++;                // Incrementa il numero di lettori\n        if (rc == 1)         // Se √® il primo lettore\n            down(&amp;db);       // Blocca l&#039;accesso al database per gli scrittori\n        up(&amp;mutex);          // Libera l&#039;accesso al contatore\n \n        read_db();           // Lettura dal database\n \n        down(&amp;mutex);        // Blocca l&#039;accesso al contatore\n        rc--;                // Decrementa il numero di lettori\n        if (rc == 0)         // Se √® l&#039;ultimo lettore\n            up(&amp;db);         // Sblocca il database per gli scrittori\n        up(&amp;mutex);          // Libera l&#039;accesso al contatore\n \n        use_data_read();     // Usa i dati letti\n    }\n}\n \n \n \nnel codice della reader\n\nalzo e abbasso il mutex quando vado a modificare il contatore rc\nalzo e abbasso il db quando vado a usare il database e se sono il primo o l‚Äôultimo dei readers\n\nCodice writer\ntypedef int sema;            // Tipo per i semafori\nsema mutex = 1;              // Mutex per il contatore dei lettori\nsema db = 1;                 // Accesso esclusivo al database\nint rc = 0;                  // Contatore dei lettori attivi\n \n \nvoid writer() {\n    while (TRUE) {\n        think_up_data();     // Pensa ai dati da scrivere\n        down(&amp;db);           // Blocca l&#039;accesso al database (esclusivo)\n        write_db();          // Scrive nel database\n        up(&amp;db);             // Sblocca l&#039;accesso al database\n    }\n}\nwrite abbassa e alza db\nPROBLEMA DI QUESTA COSA\n\nse ci sono troppi lettori, lo scrittore ci metter√† 90 anni per accedere\nUna soluzione potrebbe essere di creare una cosa e mettere in ordine lettori e scrittori in attesa\n"},"UNI/ANNO-2/SISTEMI-OPERATIVI/SISTEMI-OPERATIVI-LEZ.11":{"slug":"UNI/ANNO-2/SISTEMI-OPERATIVI/SISTEMI-OPERATIVI-LEZ.11","filePath":"UNI/ANNO 2/SISTEMI OPERATIVI/SISTEMI OPERATIVI LEZ.11.md","title":"SISTEMI OPERATIVI LEZ.11","links":[],"tags":[],"content":"I MUTEX\ncosa √®?\nServe per la sincronizzazione e gestione di risorse tra thread\nha due stati:\n\nbloccato\nsbloccato\nin teoria basterebbe una booleana ma si usa alcune volte\n0 bloccato\n&gt;1 sbloccato\nci sono due principali procedure\nmutex_lock, quando un thread vuole accedere e bloccare una regione critica\nmutex_unlock, quando vuole sbloccare e uscire da una regione critica\nnon √® contemplato il concetto di busy \\ waiting\nquando un thread non pu√≤ accedere a una regione critica con lock cede la cpu a un altro thread con thread_yield\n\nConsiderazioni aggiuntive\n\nI mutex possono essere implementati nello spazio utente con istruzioni come TSL o XCHG\nAlcuni pacchetti di thread offrono mutex_trylock, con cui si tenta di acquisire il lock o restituisce un errore, senza bloccare il processo corrente\ni mutex sono efficaci quando i thread operano in uno spazio di indirizzi comune\nla condivisione di memoria tra i processi pu√≤ essere gestita tramite kernel o con l‚Äôaiuto di sistemi operativi che permettono la condivisione di parti dello spazio degli indirizzi.\n\nPTHREAD E MUTEX\nPthread √® una libreria che ci consente di effettuare delle funzioni per sincronizzare i thread\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThread CallDescriptionpthread_mutex_initInizializza un oggetto mutex per l‚Äôuso, configurando le risorse necessarie.pthread_mutex_destroyDistrugge un oggetto mutex, liberando le risorse associate.Deve essere chiamato solo se il mutex non √® detenuto da alcun thread.pthread_mutex_lockBlocca un mutex, sospendendo l‚Äôesecuzione del thread chiamante se il mutex √® gi√† occupato da un altro thread.pthread_mutex_trylockTenta di bloccare un mutex senza sospendere l‚Äôesecuzione.Se il mutex √® gi√† bloccato, la funzione restituisce immediatamente con un codice di errore specifico.pthread_mutex_unlockSblocca un mutex, permettendo ad altri thread di acquisirlo.Deve essere chiamato solo dal thread che detiene il lock.\nLock vs Trylock\nUso lock quando il Thread deve assolutamente accedere alla regione critica, e se non riesce ad accedervi perch√© occupata si mette in attesa\nUso trylock quando il Thread se non entra nella regione critica con il mutex, va a fare altro.\nviene usato per controllare se il mutex √® bloccato senza avere troppe conseguenze\n\nquando si entra nella zona critica si attiva il mutex e poi si entra\n\nif (pthread_mutex_trylock(&amp;mutex) == 0) {\n \t  // Se otteniamo il lock, eseguiamo le operazioni protette\n \t   printf(&quot;Ho ottenuto il lock e sto eseguendo operazioni.\\n&quot;);\n \t   sleep(2); // Simuliamo qualche operazione lunga\n \t   printf(&quot;Ho terminato e rilascio il lock.\\n&quot;);\n \t   // Rilasciamo il lock\n \t   pthread_mutex_unlock(&amp;mutex);\n\t} else {\n \t   // Se il lock non √® disponibile, continuiamo con altre operazioni\n \t   printf(&quot;Non sono riuscito a ottenere il lock, continuo con altre \n \t           operazioni.\\n&quot;);\n\t}\nSemafori vs Mutex\n\nmutex\n\nviene usato per bloccare una determinata risorsa condivisa con la mutua esclusione(si/no)\nnon viene usato per la sincronizzazione\n\n\nsemaforo\n\nviene usato per bloccare una determinata risorsa condivisa\nviene usato per la sincronizzazione attraverso il decremento della variabile semaforo\nnon ha semantica di propriet√† quindi tutti possono andare a modificare la variabile del semaforo\n\n\n\n\n\n                  \n                  cosa sono le variabili condizionali? \n                  \n                \n\nconsente di sincronizzare l‚Äôaccesso a una risorsa dai thread\nquindi se ad esempio ho un thread nella regione critica ma che deve aspettare del tempo senza fare nulla, possono nel frattempo entrare gli altri nella regione critica\n\n\nVariabili condizionali\nCome detto prima, il mutex da solo non pu√≤ sincronizzare l‚Äôattesa su condizioni specifiche.\nPer farlo utilizziamo le variabili condizionali (phtread_cond).\npthread_cond serve per mettere i thread in attesa di eventi specifici\n\nun thread produttore pu√≤ notificare a un thread consumatore che √® stato prodotto qualcosa di nuovo che pu√≤ essere consumato\npthread_cond_wait() serve per mettere in attesa un thread rilasciando temporaneamente il mutex\npthread_cond_signal() pu√≤ servire ad esempio sei l produttore aggiunge un elemento al buffer e vuole risvegliare il consumatore\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThread CallDescriptionpthread_cond_initInizializza una variabile di condizione (pthread_cond_t) per consentire la sincronizzazione tra thread. La variabile di condizione viene associata a un mutex per coordinare l‚Äôaccesso a risorse condivise.pthread_cond_destroyDistrugge una variabile di condizione, liberando le risorse associate. Deve essere chiamata solo quando non ci sono thread in attesa sulla condizione.pthread_cond_waitBlocca il thread chiamante in attesa della segnalazione di una condizione. Il thread deve detenere un lock sul mutex associato, che viene rilasciato automaticamente durante l‚Äôattesa e riacquisito al termine.pthread_cond_signalRisveglia uno dei thread in attesa sulla variabile di condizione. Se nessun thread √® in attesa, la segnalazione viene persa. Questo √® utile per notificare il cambiamento di stato di una risorsa condivisa.pthread_cond_broadcastRisveglia tutti i thread in attesa sulla variabile di condizione. Questo √® utile quando un evento deve notificare pi√π thread contemporaneamente, ad esempio, quando una risorsa diventa disponibile per tutti.\nSENZA pthread_cond_wait USI IL BUSY-WAITING\npthread_mutex_lock(&amp;mutex);\nwhile (buffer == 0) { // Controllo continuo della condizione (inefficiente)\n    pthread_mutex_unlock(&amp;mutex);\n    usleep(1000); // Ritardo per ridurre il busy-waiting (non ottimale)\n    pthread_mutex_lock(&amp;mutex);\n}\nconsume(buffer);\npthread_mutex_unlock(&amp;mutex);\nIl consumatore controlla continuamente buffer == 0, sprecando risorse CPU\nCON pthread_cond_wait √à TUTTO PI√ô BELLO\npthread_mutex_lock(&amp;mutex);\nwhile (buffer == 0) {\n    // Attesa passiva finch√© il buffer non √® pieno\n    pthread_cond_wait(&amp;cond, &amp;mutex)\n}\nconsume(buffer);\npthread_mutex_unlock(&amp;mutex);\nIl consumatore si sospende senza consumare CPU finch√© il produttore non segnala                          (pthread_cond_signal) che il buffer non √® pi√π vuoto.\nESEMPIO DEL PROF\nfor (i = 1; i &lt;= MAX; i++) {\n    pthread_mutex_lock(&amp;the_mutex);\n\t\n    while (buffer != 0) {\n        pthread_cond_wait(&amp;condp, &amp;the_mutex);\n    }\n\t\n    // ... altre operazioni sulla risorsa condivisa ...\n}\nla cosa particolare √® pthread_cond_wait dove sostanzialmente viene\n\nmesso in attesa il thread che la chiama\nlo fa uscire dal mutex\n\nI MONITOR\nil problema dei semafori e dei mutex √® che non sono facili da implementare da parte di un programmatore\nHansen e Hoare hanno introdotto i monitor\n\ni monitor hanno lo scopo di semplificare l‚Äôimplementazione dei concetti di sincronizzazione\n\nun monitor raggruppa le varie procedure, variabili e strutture dati\ni vari processi interagiscono con il monitor senza entrare nelle implementazioni interne e complesse di esso\nun processo per volta pu√≤ accedere a un monitor\ni monitor proteggono i dati da eventuali problemi di concorrenza\n\n\n\nPer gestire le situazioni in cui i processi devono attendere, i monitor utilizzano variabili condizionali e le operazioni di wait e signal.\n\nse un segnale viene inviato e non c‚Äô√® nessuno in attesa il segnale viene perso\n\n\n\n                  \n                  Linguaggi come Java supportano i monitor consentendo la programmazione concorrente attraverso metodi dichiarate come synchronized\n                  \n                \n\nPSEUDOCODICE DI MONITOR PER PRODUTTORE-CONSUMATORE\ntorniamo a definire il problema produttore consumatore\nmonitor example\n    integer i;\n    condition c;\n\t\n    procedure producer();\n        ...\n    end;\n\t\n    procedure consumer();\n        ...\n    end;\n \nend monitor;\nMonitor: Produttore-Consumatore\nmonitor ProdCons {\n    condition full, empty;     // condizioni di buffer pieno e vuoto\n    int count = 0;             // elementi presenti nel buffer\n\t\n    void enter(int item) {     // PRODUTTORE\n        if (count == N) {      // se il buffer √® pieno\n\t        wait(full);        // si mette in attesa di un signal(full)\n        }\n        insert_item(item);     // inserisce l&#039;item\n        count++;               // incrementa il conteggio degli elementi\n        if (count == 1) {      // se l&#039;item inserito √® il primo\n\t        signal(empty);     // manda un segnale al consumatore\n\t    }\n    }\n\t\n    void remove(int *item) {   // CONSUMATORE\n        if (count == 0) {      // se il buffer √® vuoto\n\t        wait(empty);       // si mette in attesa di un signal(empty)\n        }\n        *item = remove_item(); // rimuove un item dal buffer\n        count--;               // crescrementa il conteggio degli elementi\n        if (count == N-1) {    // se ha rimosso un item\n\t        signal(full);      // manda un segnale al produttore\n\t    }\n    }\n}\n\nquesto codice definisce l‚Äôuso dei monitor\nfull e empty sono delle variabili condizionate che valgono tipo 0/1 le usiamo per definire sei il buffer √® libero o pieno\ncount contiamo gli elementi nel buffer per capire se √® full o empty\nenter immette gli elementi remove li toglie\npezzo di codice di enter\n\nwait(full) se il contatore √® uguale al massimo attiva la variabile condizionata full come vera\nuscita dall‚Äôattesa mette la variabile nell‚Äôitem\naumenta count di 1\nse il count √® uguale a 1 allora significa che sono il primo produttore a mettere qualcosa e devo segnalarlo\n\n\npezzo di codice remove\n\ncontrollo se il contatore √® zero, se √® zero aspetto che empty diventi false\nse finisce il controllo noi rimuoviamo un elemento e lo salviamo nel puntatore item\nscaliamo il contatore perch√© abbiamo tolto un elemento\nse il mio contatore √® meno 1 del massimo allora significa che non √® pi√π pieno e vado a modificare full che servir√† per il produttore\n\n\n\nFunzione produttore\nvoid producer() {\n    int item;\n    while (TRUE) {\n        item = produce_item();\n        ProdCons.enter(item);\n    }\n}\nFunzione consumatore\nvoid consumer() {\n    int item;\n    while (TRUE) {\n        ProdCons.remove(&amp;item);\n        consume_item(item);\n    }\n}\nsono codici che semplicemente attivano la funzione del monitor\n\nil produttore si salva da qualche parte il tutto\n\n\n\n                  \n                  Differenze tra sleep/wakeup e wait/signal\n                  \n                \n\nsleep/wakeup\n\nmeccanismi pi√π primitivi con il problema della race condition (il processo A vuole svegliare B ma B sta gi√† sotto le coperte)\n\nwait/signal\n\nSono protetti da mutua esclusione all‚Äôinterno del monitor\nuna volta che un processo/thread entra nella procedura attraverso il monitor ha l‚Äôesclusiva completa\n\n\n\n\n\n                  \n                  MONITOR e SEMAFORI \n                  \n                \n\nI monitor sono costrutti di linguaggio, riconosciuto dal compilatore per garantire la mutua esclusione.\nMolti linguaggi come C e Pascal non hanno monitor o semafori (ma possono essere aggiunti attraverso routine in assembly).\nI semafori sono pratici per risolvere la mutua esclusione in sistemi con memoria condivisa, ma non in sistemi distribuiti(client server).\nCONCLUSIONE:\n\nSEMAFORI, basso livello\nMONITOR, limitati ai linguaggi che li supportano\n\n\n\nSCAMBIO DI MESSAGGI\nLo scambio di messaggi √® una tecnica di comunicazione tra processi che avviene usando due funzioni primitive:\n\nsend\nreceive\n√à utilizzato in sistemi distribuiti ovvero sistemi che funzionano condividendo messaggi e non memoria\n\n\n\n                  \n                  problemi noti \n                  \n                \n\n\nperdita di pacchetti\nnecessit√† di avere acknowledgment ovvero un meccanismo che conferma la ricezione del messaggio\nAutenticazione per identificare il mittente ei l destinatario\ndenominazione dei processi, i processi che devono sapere a chi inviare e a chi ricevere\n\n\n\nScambio di messaggi: Produttore-Consumatore\nClassico problema Produttore-Consumatore con\nN messaggi e N posti nel buffer condiviso\n\nil consumatore invia N messaggi vuoti uno alla volta\nil produttore prende il messaggio vuoto e lo riempie poi lo invia\nil consumatore prende il messaggio lo svuota e lo rimanda\nil numero di messaggi rimane costante e garantisce efficienza di memoria condivisa\n\nCODICE\nPRODUTTORE\nvoid producer() {\n    int item;\n    message msg;\n\t\n    while (TRUE) {\n        item = produce_item();       // produce l&#039;item\n        receive(consumer, &amp;msg);     // riceve dal consumatore il messaggio (vuoto)\n        build_message(&amp;msg, item);   // costruisce il messaggio inserendo l&#039;item\n        send(consumer, &amp;msg);        // invia al consumatore il messaggio (pieno)\n    }\n}\nCONSUMATORE\n#define N 100\n \nvoid consumer() {\n    int item, i;\n    message msg;\n\t\n    for (i = 0; i &lt; N; i++) {\n        send(producer, &amp;msg);      // invia al produttore un messaggio vuoto (per \n                                   // volta)\n    }\n\t\n    while (TRUE) {\n        receive(producer, &amp;msg);   // riceve dal produttore il messaggio (pieno)\n        item = extract_item();     // estrare l&#039;item dal messaggio\n        send(producer, &amp;msg);      // riinvia al produttore il messaggio (vuoto)\n        consume_item(item);        // consuma l&#039;item\n    }\n}\n \n\n\n                  \n                  problematiche \n                  \n                \n\n\nse il produttore √® pi√π veloce i messaggi saranno pieno e quindi dovr√† aspettare chi li deve svuotare\nse il consumatore √® pi√π veloce dovr√† aspettare chi li scrive\nse ci sono pi√π macchine che si scambiano i messaggi allora dovr√† esserci un sistema che identifica chi invia e chi riceve\n\n\n\n\n\n                  \n                  soluzioni \n                  \n                \n\n\nOgni processo ha un indirizzo univoco che lo identifica\nInvece di inviare il messaggio direttamente al processo lo si invia a una Mailbox\n\ncos√¨ il mittente pu√≤ continuare a fare il suo lavoro senza dover aspettare il destinatario\n\n\n\n\n\nBARRIERE\nLe barriere sono utilizzate per sincronizzare i processi e per fare in modo che quando un processo raggiunge una barriera deve aspettare che tutti gli altri processi la raggiungano\n\nsi utilizzano per fare calcoli paralleli\n\n\nINVERSIONE DI PRIORIT√Ä READ-COPY-UPDATE\nIL MARS PATHFINDER\n\nIl mars pathfinder su Marte usava un sistema operativo real-time con 3 attivit√†\n\nattivit√† ad alta priorit√†: analizzava dati scientifici importanti\nattivit√† a media priorit√†: esegue le comunicazioni o altre operazioni\nattivit√† a bassa priorit√†: Gestiva compiti meno importanti come la registrazione di diagnostiche\n\n\n\n                  \n                  problema \n                  \n                \n\n\nil thread di bassa priorit√† ha bloccato una risorsa con il mutex\nil thread di media priorit√† supera quello di bassa priorit√† lasciando il mutex ancora bloccato\nquello ad alta priorit√† se vuole fare qualcosa si trova con il mutex bloccato\n\nquindi in poche parole le priorit√† non sono pi√π quelle, perch√© quello ad alta priorit√† dovrebbe aspettare gli altri ma non √® programmato per farlo e quindi si resetta\nQuesto caso viene descritto come inversione delle propriet√† (in pratica sono tutte sballate).\n\n\n\n\n                  \n                  SOLUZIONE \n                  \n                \n\nla NASA ha risolto il problema introducendo un protocollo di eredit√† delle priorit√†\nquando un thread ad alta priorit√† attende una risorsa bloccata, il sistema d√† al thread che ha quella risorsa la priorit√† pi√π alta cos√¨ da sbloccarla\n\n\n\n\n                  \n                  Una versione semplificata \n                  \n                \n\nIL PC √à UNO SOLO\n\nAndrea (alta priorit√†) deve giocare a GOW\nLuca (bassa priorit√†) √® nella lobby di fortnite\nSamuele (priorit√† media) sta vedendo un ep. di Blue Lock sul Tablet, ma sta continuamente interrompendo Luca chiedendogli di fargli vedere le skin che ha nel suo armadietto\n\nRISULTATO:\n\nLuca non riesce ad uscire dal gioco\nAndrea, che avrebbe priorit√† alta, aspetta inutilmente\n\nSOLUZIONE CON PROTOCOLLO DI EREDIT√Ä DELLE PRIORIT√Ä\n\nQuando Andrea aspetta Luca, Luca eredita temporaneamente la priorit√† di Andrea\nLuca pu√≤ andare su quit per poi uscire, ignorando completamente il povero Samuele che voleva solo vedere le skin üòî\nUna volta uscito dal gioco, Luca torna alla sua priorit√† normale (godo coglione)\n\n\n\nREAD-COPY-UPDATE\nl‚Äôidea √® di separare lettori e scrittori attraverso un meccanismo che non li blocca ma li lascia lavorare senza interferirsi\n\ni lettori accedono ai dati senza lock senza avere inconsistenze perch√© la struttura √® sempre completa\nla copia avviene quando uno scrittore deve modificare la struttura e la copia prima di modificarla cos√¨ non interferiscono con i lettori\nupdate aggiorna la struttura sostituendo la vecchia con la nuova in determinati nodi ecc‚Ä¶\n\nAGGIUNGERE UN NODO\n\n\ninizializzo X e connetto E a X cos√¨ A e E che si leggevano insieme\nQuando ho finito di mettere roba in X lo metto tra A e E, quelli che prima stavano leggendo leggeranno per un po‚Äô roba vecchia\n\nTOGLIERE NODI\n\n\naspettiamo che tutti i lettori smettano di leggere su B e C eliminando cos√¨ il tutto\n\n\n\n                  \n                  come capire quando una memoria √® liberata dai lettori? \n                  \n                \n\nil GRACE PERIOD √® un meccanismo utilizzato per determinare quanto una vecchia versione di dati pu√≤ essere liberata in sicurezza\n\nsi aspetta che tutti i lettori terminino\ndurante questo periodo i thread lettori non si bloccano e non vanno in sleep\n\n\n"},"UNI/ANNO-2/SISTEMI-OPERATIVI/SISTEMI-OPERATIVI-LEZ.12":{"slug":"UNI/ANNO-2/SISTEMI-OPERATIVI/SISTEMI-OPERATIVI-LEZ.12","filePath":"UNI/ANNO 2/SISTEMI OPERATIVI/SISTEMI OPERATIVI LEZ.12.md","title":"SISTEMI OPERATIVI LEZ.12","links":[],"tags":[],"content":"LO SCHEDULING\nIn un computer possono esserci n processi o thread che competono per utilizzare la CPU\n\n\n                  \n                  cosa fa lo scheduler? \n                  \n                \n\nlo scheduler ha il compito di decidere quale processo o thread deve essere eseguito successivamente seguento un determinato algoritmo\n\nCi sono due tipi di scheduler uno che lavora al livello utente uno kernel, lavorano in modo indipendente e quello kernel lavora per thread\n\n\n\nUN P√í DI STORIA\n\nI primi sistemi batch hanno uno scheduling lineare dove le istruzioni venivano eseguite in successione\ncon la multiprogrammazione lo scheduling divenne sempre pi√π complesso e si dovette ricorrere ad usare algoritmi per migliorare le prestazioni\nNei personal computer di solito la CPU non viene usata al 100% perch√© √® sempre in attesa dell‚Äôinput dell‚Äôutente.\n\nCOSTI DEI PROCESSI\nla cosa che costa tanto quando si ha un sistema con una CPU √® il il cambio di contesto e quando avviene succede questo:\n\nCambio la modalit√† da utente a kernel\nSalvo lo stato del processo interrotto cos√¨ da riprenderlo\nEseguo l‚Äôalgoritmo di scheduling\nCambio area di memoria su cui lavora il processo\nInvalidazione potenziale della memoria cache(poi lo vediamo alle prossime lezioni)\nIl cambio di contesto non deve essere per forza efficiente solo nell‚Äôambito di velocit√† ma anche di efficienza dei consumi tipo nei telefoni(IoT)(internet of things, quei dispositivi che funzionano attraverso la condivisione dei dati)\n\nI nostri processi sono caratterizzati da\n\nprocessi CPU bound stressano il processore al 100% tenendolo sempre occupato a fare qualcosa con un cpu-burst sempre all‚Äôattivo, in questi processi non hai bisogno di attendere input output quindi la CPU lavora a massimo regime\ni/o bound sono quei processi che ricevono input dall‚Äôesterno e quindi che devono fare attese frequenti avendo degli short burst\n\n\n\n                  \n                  cosa √® il cpu burst \n                  \n                \n\n(il cpu burst √® una unit√† di tempo che definisce quando la CPU √® in uso)\n\n\n\nPRECISAZIONI SULLO SCHEDULING\n\ncon CPU pi√π veloci i processi tendono a essere pi√π I/O bound\n\nperch√© spesso sono i processori ad attendere qualcun altro\n\n\nGli SSD possono un po‚Äô risolvere la cosa del I/O bound ma comunque i data center per un discorso di costo x bit sono ancora sugli HDD e usano algoritmi di scheduling per questo\nNon tutti gli scheduling funzionano su tutti i dispositivi\n\nGLI STATI DI UN PROCESSO\n\nun processo ha principalmente 3 stati:\n\nEsecuzione: sta eseguendo il codice e usa la CPU\nReady: √® pronto per eseguire il codice ma non lo fa\nBlocked: √® in attesa di qualche risorsa o comunque non √® pronto\nlo scheduler attraverso un algoritmo di scheduling capisce quale processo mettere in running\n\nLO SCHEDULER SERVE SEMPRE\n\n\n                  \n                  Quando interviene lo scheduler? \n                  \n                \n\n\nCreazione di un processo\n\nDecide chi eseguire se il genitore o il figlio\n\n\nUscita di un processo\n\nSe un processo esce allora deve decidere chi far partire\n\n\nBlocco del processo\n\nSe un processo si blocca se ne deve selezionare un altro\n\n\nInterrupt di I/O\n\nAlla fine di un interrupt il processo potrebbe andare su ready e essere eseguito\n\n\n\n\n\nEsistono due tipologie di scheduling\nNon preemptive(senza prelazione)\n\nse eseguo un processo devo aspettare che finisca da solo oppure che va in blocked in attesa di un i/o\n\nPreemptive(con prelazione)\n\nDefinisce un tempo e lascia eseguire quel processo in quel determinato quanto di tempo\nviene effettuato un interrupt del clock per far tornare il controllo allo scheduler una volta scaduto il tempo\n\n\n\n                  \n                  parentesi sulla prelazione \n                  \n                \n\nil croce dice:\n\n\n                  \n                  se  uno scheduler ha la prelazione ho una interruzione forzata, il processore dice al processo levati dal cazzo \n                  \n                \n\ncose importanti da dire sulla prelazione:\n\n√® davvero importante per mantenere il controllo e evitare processi lenti che intasano il sistema\n\n\n\n3 diversi ambienti di scheduling\n\nBatch\n\ndi solito SENZA PRELAZIONE\nviene usato spesso in contesti aziendali\nmassimizza il troughput, il numero di job completati in un dato tempo\nminimizzo il turnaround, il tempo che scorre dallo start all‚Äôend di un job\nmantiene la CPU sempre attiva\n\n\nInterattivo\n\nPrevedono la PRELAZIONE\nla CPU non viene monopolizzata\nAdatto per utenti multipli e server\nil tempo di risposta deve essere rapido\nla risposta deve essere adeguata in un tempo rapido, non luc ma luca\n\n\nSistemi Real-time\n\nNon devono avere pefforza la PRELAZIONE\nSe un processo impiega troppo tempo si interrompe\nEseguono programmi per specifiche applicazioni\nrispetto delle scadenze\nil funzionamento deve essere costante e non ci devono essere errori, tipo su applicativi che servono per la vita di persone\n\n\n\nObiettivi degli algoritmi di scheduling\ntutti i sistemi devono garantire:\n\nEquit√†: una equa condivisione della CPU tra tutti i processi\nImposizione della policy: applicare le definizioni della policy dette prima\nBilanciamento: mantenere tutti i componenti del sistema attivi\n\nSCHEDULING NEI SISTEMI BATCH\n1. FIRST COME FIRST SERVED (FCFS)\nChi prima arriva meglio alloggia\n\nnon ha prelazione\ni processi vengono assegnati alla CPU in base a come arrivano\nsi mettono tutti in una singola coda\ni processi bloccati vanno in fondo alla coda\n√® facile da programmare ed √® anche abbastanza equo\nnon √® troppo ottimale in scenari misti(sia CPU bound che I/O bound)\nsi pu√≤ incorrere in attese lunghe\n\n2. SHORTEST JOB FIRST (SFJ)\nIl pi√π corto alloggia prima\n\nalgoritmo senza prelazione\ni tempi di esecuzione si devono sapere prima\n\n\n√® ottimale per ridurre il tempo di turnaround quando tutti i job sono disponibili\nse alcuni arrivano dopo non √® ottimale perch√©\n\nil SFJ si ricorda solo il tempo di esecuzione di un processo solo iniziale\nquindi se un processo va in stato di blocco e gli mancano 0,1 secondi per essere eseguito, verr√† comunque trattato come se durasse tipo 10 ore, soluzione quello che vediamo dopo\n\n\n\n                  \n                  turnaround cosa significa? \n                  \n                \n\nsi riferisce al periodo totale impiegato per completare un‚Äôattivit√†\n\n\n3. SHORTEST REMAINING TIME NEXT (SRTN)\nquello che ha il tempo rimanente pi√π corto alloggia\n\nversione con prelazione di SJF\nseleziona il processo con il tempo rimanente pi√π breve\ntempo noto\nconfronta i job e vede il tempo rimanente pi√π basso\nse entra qualche nuovo processo che dura meno verr√† soddisfatto rapidamente\ntrasforma gli ambienti batch in circa preemptive\n\nSCHEDULING IN SISTEMI INTERATTIVI\nil tempo di risposta √© fondamentale e abbiamo diversi algoritmi:\n\n1. ROUND ROBIN (RR)\n\n√® il pi√π vecchio ma\n\nsemplice\nequo\nmolto utilizzato\n\n\nogni processo riceve un quanto se non lo rispetta va a casetta ed √® soggetto a prelazione\n√® prevista una lista di processi eseguibili(Ready)\nquando un processo termina un quanto si sposta alla fine della lista\n\n\nCose importanti del Round Robin\n\n√® importante scegliere un quanto perch√© se avviene troppo spesso avr√≤ troppi cambi di contesto e un overhead eccessivo, ovvero uno spreco della cpu sgravatus\nabbiamo un Trade-off sul quanto da definire e la reattivit√† del sistema\n√® consigliato un quanto tra 20 e 50 ms\n\n2. SCHEDULING A PRIORIT√Ä (SAP)\n\nil round robin vede tutti i processi uguali ma magari ce ne sono alcuni che hanno maggiore priorit√†\nogni processo ha una sua priorit√† e viene eseguito il processo con priorit√† pi√π alta\n\n\n\n\n                  \n                  gestione delle priorit√† \n                  \n                \n\nse una priorit√† viene subentrata da un altro processo\n\nil processo con la priorit√† maggiore lo supera\n\nfacendo avvenire un cambio\n\n\nla priorit√† pu√≤ essere\n\nstatica: la priorit√† non cambia nel tempo, usato tipo dai militari\ndinamica: la priorit√† cambia nel tempo, tipo in sistemi I/O bound\n\n\n\n\n\n\n\n                  \n                  se ho 3 processi con priorit√† 4 come li gestisco?\n                  \n                \n\nraggruppo i processi in gruppi in base alle priorit√†\npoi sul singolo gruppo posso usare tipo il round-robin\n\n\n\n3. SHORTEST PROCESS NEXT CON AGING(SPNCA)\nnoi vogliamo applicare shortest job first ai sistemi interattivi dove\n\nnon sappiamo a priori quanto ha da lavorare un job\nsoluzione\ncreiamo delle stime dando un peso a ogni volta che un processo viene eseguito\ncos√¨ facendo abbiamo una stima e non abbiamo bisogno di sapere prima i vari quanti\n\n\n4. GUARANTEED SCHEDULING(GS)\ncerca di creare una cosa pi√π equa possibile garantendo a tutti del tempo sulla CPU\nfacendo un rapporto tra\n\ntempo da quando ho creato processo x\nnumero di processi\nse un processo l‚Äôho creato da 100 secondi e ho 10 processi far√≤ 100/10 cos√¨ quel processo ha 10 secondi\nEsegue prima quello con il rapporto pi√π basso\n\n5. SCHEDULING A LOTTERIA(SAL)\n\n\ncreo dei biglietti della lotteria e li do randomicamente ad ogni processo\nchi vince si esegue e faccio n estrazioni al secondo\nse voglio creare una sorta di priorit√† posso dare pi√π biglietti a chi ha una priorit√† maggiore\nse ho processi figli posso fare in modo che il processo padre dia un po‚Äô dei suoi biglietti ai figli\n\n6. SCHEDULING FAIR-SHARE(SFS)\nL‚Äôidea √® dare una frazione predefinita di CPU ad ogni utente e si assicura che ogni utente riceva la sua frazione indipendentemente dal numero di processi posseduti. LETTERALMENTE DEFINIZIONE DI ‚ÄúEQUIT√Ä‚Äù\n\nSCHEDULING IN SISTEMI REAL-TIME\nvengono utilizzati in sistemi operativi che necessitano un tempo di risposta immediata\n\nESISTONO DUE TIPI DI SISTEMI REAL-TIME\n\nHard Real-Time: le scadenze devono obbligatoriamente essere rispettate\nSoft Real-Time: le scadenze devono essere rispettate ma in modo pi√π tollerabile\n\nTIPI DI EVENTI\n\nPeriodici : avvengono ad intervalli regolari\nnon Periodici : avvengono ad intervalli irregolari\n\nCONDIZIONE DI SCHEDULABILIT√Ä:\nLa CPU deve essere in grado di gestire la somma totale del tempo richiesto dai processi.\nPer esempio, se ci sono\n- m eventi periodici\n- ogni evento i avviene con un periodo di P_i\n- ogni evento richiede C_i secondi di tempo della CPU per essere gestito\nIl carico totale pu√≤ essere gestito SOLO SE \\sum_{i=1}^{m} \\frac{C_i}{P_i} \\leq 1\n\n\n                  \n                  da ricordare: Ci √® quanto tempo impiega l&#039;evento e Pi √® la periodicit√† \n                  \n                \n\nESEMPIO\n\nEVENTI PERIODICI: 100ms, 200ms, 500ms\nTEMPI RICHIESTI: 50ms, 30ms, 100ms\nAbbiamo quindi\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProcessiPeriodo (P_i)Tempi richiesti (C_i)CondizioneP1100ms50ms\\frac {C_i} {P_i} = \\frac {50} {100} = 0,5P2200ms30ms\\frac {C_i} {P_i} = \\frac {30} {200} = 0,15P3500ms100ms\\frac {C_i} {P_i} = \\frac {100} {500} = 0,2E QUINDI \\sum_{i=1}^{m} \\frac{C_i}{P_{i}} \\space \\space= \\space \\space 0,5 + 0,15 + 0,2 \\space \\space \\le \\space \\space 1\nGli algoritmi di scheduling possono essere\n\nStatici, in cui i requisiti di calcolo e periodicit√† sono ben definiti in anticipo (l‚Äôesempio appena visto era statico)\n√à limitato perch√© bisogna conoscere le esigenze e le scadenze a priori\nDinamici, in cui i requisiti cambiano durante l‚Äôesecuzione\n\nProcessi e Scheduling\ni processi non sono indipendenti bens√¨ possono esserci situazioni complesse dove un processo pu√≤ avere uno o pi√π figli sotto il suo controllo.\n(ad esempio un sistema di gestione di un database)\n\n\n                  \n                  i tradizionali scheduler trattano i processi come se fossero isolati e indipendenti tra loro, questo porta a delle complicanze e a delle decisioni non ottimali per il sistema \n                  \n                \n\nproprio per questa ragione nasce una separazione\nSeparazione tra meccanismo e politica di scheduling\n\nil meccanismo di scheduling riguarda tutte le varie implementazioni tecniche dell‚Äôalgoritmo nel kernel del sistema operativo\nle politiche di scheduling riguardano tutte quelle regole che decidono chi deve essere eseguito e quando\nci√≤ ci consente di far modificare eventuali politiche ai processi utente senza per√≤ modificare le tecniche implementative nel kernel\n\n\n\n                  \n                  un processo pu√≤ modificare la politica e dire &quot;i miei due processi figli devono avere priorit√† 2&quot; \n                  \n                \n\n\nnel frattempo il kernel sta ‚Äúsemplicemente‚Äù eseguendo un algoritmo di scheduling a priorit√†\n\n\n\nParallelismo\nIl parallelismo √® la capacit√† di un sistema di eseguire pi√π operazioni contemporaneamente.\nSi divide in due livelli principali\n\nlivello di processo, dove processi indipendenti vengono eseguiti in parallelo\nlivello di thread, in cui pi√π thread all‚Äôinterno dello stesso processo lavorano simultaneamente, condividendo memoria e risorse\nLo scheduling varia a seconda che si tratti di thread a livello utente o thread a livello kernel\n\nThread a livello utente\nil kernel non √® consapevole di ci√≤ che si cela dietro un processo e lo vede come un unico blocco\n\ni thread sono una cosa interna al processo ed √® il processo a gestirli\nlo scheduler assegner√† quantum di tempo a un processo e non a un singolo thread\n\n\nIn questo esempio un possibile ordine √® A1 ‚Üí A2 ‚Üí A3 ‚Üí (ricomincia il giro) A1 ‚Üí A2 ‚Üí A3\nCi√≤ che non pu√≤ MAI succedere √® questo A1 ‚Üí B1, perch√© prima eseguo SOLO A\nIl problema per√≤ si verifica se un thread consuma tutto il quanto di tempo, in quel caso gli altri thread dello stesso processo non verranno eseguiti fino al prossimo turno.\nThread a livello kernel\nQui i thread sono visibili dal kernel e possono essere scelti da esso per l‚Äôesecuzione\nSe un thread eccede il quanto viene sospeso\n\nQui i casi possibili sono\n\nA1 ‚Üí A2 ‚Üí A3 ‚Üí (ricomincia il giro) A1 ‚Üí A2 ‚Üí A3\nA1 ‚Üí B1 ‚Üí A2 ‚Üí B2\nQuesto approccio aumenta la flessibilit√† e sfrutta meglio il parallelismo, ma pu√≤ introdurre un overhead maggiore rispetto al livello utente, a causa dell‚Äôintervento pi√π frequente del kernel.\n\nDifferenze prestazionali tra livello utente e kernel\nLIVELLO UTENTE\nQui il passaggio da un thread all‚Äôaltro √® molto veloce, perch√© richiede solo poche istruzioni senza coinvolgere il kernel. Per√≤ in caso di blocco su operazioni di I/O, l‚Äôintero processo viene sospeso.\nLIVELLO KERNEL\nQui lo scambio di thread √® pi√π lento, ma se un thread si blocca su un‚Äôoperazione di I/O solo lui viene sospeso, mentre gli altri continuano ad essere eseguiti\nInoltre, il kernel pu√≤\n\nconsiderare i costi per passare da un thread all‚Äôaltro\ndare priorit√† ai thread dello stesso processo\n\nAlcune applicazioni hanno la possibilit√† di gestire direttamente lo scheduling dei propri thread, senza affidarsi completamente al kernel. In pratica, l‚Äôapplicazione implementa un sistema di scheduling personalizzato (chiamato scheduling specifico) per decidere come e quando i propri thread devono essere eseguiti."},"UNI/ANNO-2/SISTEMI-OPERATIVI/SISTEMI-OPERATIVI-LEZ.13":{"slug":"UNI/ANNO-2/SISTEMI-OPERATIVI/SISTEMI-OPERATIVI-LEZ.13","filePath":"UNI/ANNO 2/SISTEMI OPERATIVI/SISTEMI OPERATIVI LEZ.13.md","title":"SISTEMI OPERATIVI LEZ.13","links":[],"tags":[],"content":"ASTRAZIONE DI MEMORIA\nle memorie che considereremo si suddividono in\n\nmemoria principale (RAM)\n\ncostosa, poco capiente, veloce\n\n\nmemoria ‚Äúnormale‚Äù dischi ma non solo dischi\n\nmeno costosa, pi√π capiente, meno veloce(tranne ssd)\n\n\n\nIl ruolo del sistema operativo\ngestire questa gerarchia di memoria in un modello utile e astratto\n\nnon √® solo importante avere tanta memoria ma anche gestirla bene\n\n\n\n                  \n                  definizione di astrazione di memoria \n                  \n                \n\ni processi pensano che la memoria sia in un modo ma invece √® in un altro,\nquesta illusione la fa il s.o.\n\n\nLE ORIGINI\nMEMORIA SENZA ASTRAZIONE\nQui abbiamo un uso diretto della memoria fisica\nuso i registri e ci metto dentro byte di informazioni mov reg1,1000\n\n\n                  \n                  problemi di sovra scrizione e di accesso ai dati \n                  \n                \n\n9:40 sono cazzi\nquanti bit servono per fare riferimento a un numero\nda 0 a 32764\nla multiprogrammazione senza astrazione\ncon indirizzi assoluti posso avere problemi di sovrascrizione\nMODI DI ORGANIZZARE UNA MEMORIA NON ASTRATTA\nci sono tre modelli\n\na) OS in RAM(es. nei mainframe)\nb) OS in ROM(es. sistemi embedded)\nc) OS+ driver in ROM+RAM(es. primi pc)\n\n√® possibile scambiare i programmi in esecuzione attraverso uno swapping\nmetto il processo da togliere in una memoria non volatile\n\n\n\n                  \n                  esempio di conflitto di indirizzamenti \n                  \n                \n\n\n\nla memoria pi√π grande sar√† suddivisa da programma 1 e poi programma 2(figura c)\nil programma 1 fa un jump a riga 24 (freccia rossa)\nil programma 2 pu√≤ andare dove gli pare e quindi andr√† a intasare il programma 1 (freccia blu)\n\n\n\nASTRAZIONE\nad ogni processo viene assegnato un insieme unico di indirizzi separato dagli altri\n\nlo spazio degli indirizzi √® quell‚Äôinsieme unico di indirizzi che pu√≤ usare un processo per indirizzare la memoria\n\nUn vecchio esempio di astrazione\nlo spazio di indirizzi del processo veniva mappato e inserito in parti diverse di memoria fisica.\nquesto concetto prevede l‚Äôutilizzo di:\n\nregistro base(offset): contiene l‚Äôindirizzo fisico di ogni inizio programma\nregistro limite: contiene quanto √® lungo un programma\n\n\n\n                  \n                  se ad esempio un processo chiede indirizzo 1000 il s.o. gli assegner√† 1000+k \n                  \n                \n\n\nk rappresenta il registro base\nogni processo ha la sua base e se la sfora so cazzi\nil s.o. ha il compito di capire il limite delle richieste in memoria del processo\n\n\n\n\n\n                  \n                  IN POCHE PAROLE ogni volta che avviene un riferimento in memoria da parte di un programma \n                  \n                \n\n\nAggiunge il registro base all‚Äôindirizzo generato dal programma\nIl registro limite viene usato per non far superare eventuali limiti di accesso\n\n\n\n\n\n                  \n                  esempio diretto \n                  \n                \n\n\nriprendiamo l‚Äôesempio delle memorie non astratte\n\nstavolta effettuiamo dei controlli per verificare se rimaniamo nella nostra area di memoria\nil registro limit viene usato per definire il limite di dove pu√≤ stare il processo\n\n\n\n√® vero, ogni programma ha il suo spazio, ma calcolare tutte queste cose comporta un rallentamento del sistema\ncosa succede se sforo la memoria?\nse la memoria viene riempita faccio\n\nuno swapping, sposto le informazioni da memoria volatile a non volatile\n\nquesta tecnica si usa solo se necessario\n\n\nmemoria virtuale\n\ncerca di lasciare i processi in esecuzione lasciandogli parziali memorie disponibili\n\n\n\nFrammentazione della memoria\ni processi nel corso della loro esecuzione possono chiedere sempre pi√π memoria.\nper questo motivo il s.o. potrebbe assegnare pi√π del necessario per evitare problemi\n\n\n                  \n                  mi chiedi 10 ti do 14 dai ;) \n                  \n                \n\n\n\n\nla coperta per√≤ e corta quindi spreco memoria.\nSe termino la memoria faccio una di queste 3 cose\n\nlo swapping\ntrasferisco il processo\nuccido il processo\n\n\n\n                  \n                  quando tolgo un processo dalla memoria e ne metto altri potrei creare delle frammentazioni di memoria \n                  \n                \n\n\nla ricompattazione di quei frammenti di memoria che si creano provoca un rallentamento del sistema\nuna soluzione √® quella citata prima ma non √© troppo efficiente (quella del mi chiedi 10 ti do 14)\n\n\n\n\nGESTIONE DINAMICA DELLA MEMORIA\nCome gestisco la memoria libera?\ncerco di tenere traccia della memoria cercando di minimizzare il fenomeno della frammentazione\nho 2 metodi principali\n\nmetodo Bitmap tiene traccia di quali blocchi vengono allocati\nmetodo usando una lista collegata che tiene traccia della memoria non allocata\n\nprima di iniziare a spiegare i due metodi vorrei precisare una cosa:\n\n\n                  \n                  modi per scrivere una matrice di valori e rappresentarla \n                  \n                \n\nmatrice:\n\ndensa: memorizzo tutto cos√¨ com‚Äô√®\nsparsa: tolgo gli 0 inutili e le ripetizioni\n\nrappresentazione:\n\ndensa: rappresento tutto cos√¨ com‚Äô√®\nsparsa: tolgo gli 0 inutili e le ripetizioni\n\n\n\nmetodo Bitmap:\nQuesto metodo fa uso di una Bitmap per indicare dove sono presenti degli Hole(spazi vuoti) oppure dei Process(spazi pieni), si fa spesso uso anche di una linked list per rappresentarla\n\ncon la linked list possiamo vedere che non √© granch√© efficiente perch√© per arrivare alla fine dobbiamo scorrerla tutta\n\n\n\n√® suggerito l‚Äôuso di una lista collegata da ambe le parti per ottimizzare le cose\n\ntornare indietro √® figo perch√© consente di guardarsi alle spalle senza ricominciare\n\n\n\n\nMETODOLOGIE PER ANDARE AD ALLOCARE MEMORIA\n\nFirst fit: Seleziona il primo spazio disponibile (usata in MINIX3 molto semplice)\nNext fit: Seleziona il successivo spazio disponibile(pi√π lento)\nBest fit: Sceglie il pi√π adeguato\nWorst fit: Sceglie il meno adeguato\nQuick fit: Crea dei preset di spazi(le pi√π utilizzate)\nBuddy allocation: Migliora le performance del quickfit(lo vediamo subito dopo)\n\nPRECISAZIONI SUL Buddy allocation\n\nusato in linux\nLa memoria inizia come un singolo pezzo\nAd ogni richiesta la memoria viene divisa in una potenza di 2\nquando una allocazione di memoria viene rilasciata avviene una coalescenza e si riuniscono\n\n\n\n                  \n                  coalescenza? \n                  \n                \n\n√® tipo agar.io oppure il merge.\n\n\n\n\n\na) la memoria consiste in un unico pezzo da 64 blocchi\n\nappena un processo ha bisogno di tot blocchi di memoria li divide per 2 appena gli bastano\n\n\nb) 32 ti bastano? no\nc) 8 bastano? si va bene grazie ciao\nappena un processo termina viene ricompattata la cosa (h‚Üíi)\n\n\nFRAMMENTAZIONE NEL BUDDY\n\n\n                  \n                  Il problema del buddy algorithm e che ho delle piccole frammentazioni di memoria (caccolette) che si possono formare e che sono difficili da riunire \n                  \n                \n\n\nil buddy algorithm √® l‚Äôalgoritmo\nil buddy allocator √® il processo che fa avvenire l‚Äôallocazione\n\nUNA SOLUZIONE: SLAB ALLOCATOR\nSe io dovessi allocare 65 pagine con il buddy, dovrei richiederne 128 e 63 sarebbero inutilizzate\n\nLo slab allocator usa l‚Äôalgoritmo buddy per farsi allocare tot pagine di memoria e poi ci fa quello che vuole:\nse a un processo serve 1 pagina di scarto lo slab ne prende 2 e 1 la da a quel processo\n\ni piccoli blocchi di memoria vengono chiamati slabs suddivisi in chunk\n\n\n\n                  \n                  lo slab allocator e tipo un monnezzaio che prende tutte le caccolette e crea una memoria decente \n                  \n                \n\nOgni chunk corrisponde a un oggetto o una porzione pi√π piccola di memoria.\nGli slab sono classificati in 3 stati:\n\nFull: Tutti i chunk sono occupati.\nPartial: Alcuni chunk sono occupati, altri liberi.\nEmpty: Tutti i chunk sono liberi.\n\n\nIL CACHING\nQuando un oggetto viene deallocato non viene immediatamente restituito alla memoria libera\nviene mantenuto nella cache cos√¨ da soddisfare richieste nell‚Äôimmediato senza sprecare troppe risorse\nCosa contiene uno slab?\n\npuntatore che punta agli oggetti\nun indice che indica il prossimo slot libero\nbufctl √® un array con gli indici dei prossimi oggetti liberi\n\n\nConcetto di memoria virtuale\nogni programma ha un proprio spazio di indirizzi suddiviso in pagine\npage fault\n48 bit perche 48 sono gia un botto\n0k-4k 4k-8k...\nil programma chiede 32780\nho delle pagine che vanno a 4kb\nse mi chiedi 32k siamo nella pagina 8\nse non ha ancora puntato alla memoria vera, punta a una area vuota che soddisfa ad esempio il blocco n.1\n4096\ncalcolo logaritmo in base bho bisogna fare log_custom/lob_bho\n1:18\nun s.o. deve anche contenere la tabella delle pagine\nviene utilizzata una cache speciale sul processore per salvare queste tabelle\n1:25 compito per casa"},"UNI/ANNO-2/SISTEMI-OPERATIVI/SISTEMI-OPERATIVI-LEZ.14":{"slug":"UNI/ANNO-2/SISTEMI-OPERATIVI/SISTEMI-OPERATIVI-LEZ.14","filePath":"UNI/ANNO 2/SISTEMI OPERATIVI/SISTEMI OPERATIVI LEZ.14.md","title":"SISTEMI OPERATIVI LEZ.14","links":[],"tags":[],"content":"Problema\nI programmi nel tempo sono sempre cresciuti in termini di necessita di memoria\nquindi caricarli tutti in memoria √® sempre pi√π complesso\nsi iniziarono a creare delle soluzioni e negli anni 60 si introdussero gli overlay:\nla tecnica degli overlay consiste nel suddividere un programma in piu codici detti overlay\ndifficolta di implementazione e nessuna astrazione, erano letteralmente pezzi di codice\nMemoria virtuale\n√® una versione pi√π complessa e sicuramente astratta del metodo con base e limite\nconsiste nel suddividere spazi di indirizzi in pagine, ogni pagina rappresenta uno spazio contiguo di indirizzi.\nil programma avra l‚Äôillusione di puntare da una parte invece punter√† su una pagina che chiss√† dove cazzo sta\n\ntutto questo viene gestito dal s.o.\ntutte le pagine non devono stare in memoria\nesiste una mappa che tiene traccia di tutte le pagine e se non √® presente page fault e intervento del s.o.\nper ora prendiamo per scontato che siano tutte pagine da 4K\nsi vuole quindi creare una illusione per il programma di avere uno spazio di indirizzi pi√π esteso.\nse ad esempio abbiamo 48 bit possiamo rappresentare 2^{48} indirizzi virtuali\n\nCosa avviene al livello di processo?\nmettiamo caso di avere una memoria fisica da 32K, se ogni pagina effettiva occupa 4K avremo 8 frame (pagine fisiche)\n\nabbiamo poi 16 pagine, ma non tutte sono mappate fisicamente in memoria\nla mappatura avviene puntando all‚Äôindirizzo della pagina reale\nper effettuare la mappatura useremo la MMU memory managment unit(la vediamo poi)\n\npossiamo vedere come il processo crede che abbia pi√π memoria\n\nCosa succede se una pagina non √® mappata?\n\navviene un page fault\nsposto un frame usato raramente sul disco\nmetto al posto di quel frame la pagina virtuale\naggiorno la MMU(aggiungo alla tabella in quale pagina virtuale √® mappato il frame)\n\nESEMPIO PRATICO\n\nUn programma vuole scrivere nell‚Äôindirizzo 32780 che quindi √® compreso nella pagina 32K-36K\nquesta pagina per√≤ non √® mappata (ha la X)\nviene applicato un algoritmo che sposta una pagina secondo dei criteri, in memoria disco\nla pagina virtuale potr√† ora puntare al frame libero\n\n\nmettiamo di avere MOV REG,32780\nci posizioniamo nella pagina 8 che sar√† 2^{15} ovvero 32768\n\nla pagina √® un insieme di indirizzi e per capire dove posizionarci esattamente faremo\n32780-2^{15}=12  che rappresenta lo spazio nella singola pagina\npoi dobbiamo portare il tutto nella memoria fisica effettiva dei frame\nmettiamo che la pagina che si liberi √® la 1 quindi 4096 ci sommiamo lo spazio calcolato prima nella singola pagina e ci ritroviamo a scrivere su 4108\n\nFunzionamento interno della MMU Con lo stesso scenario di prima, ma questa volta vogliamo accedere all‚Äôindirizzo virtuale 8196. Per farlo dobbiamo tradurlo tramite la MMU, in un indirizzo fisico. La rappresentazione binaria di 8196 √® 0010 \\ 00000000100 Dove:\n\n\n\nI PRIMI 4 BIT rappresentano il numero di pagina virtuale\n\nCon 4 bit possiamo identificare fino a 2^{4} = 16 pagine virtuali (da 0 a 15)\n\n\n\nI RESTANTI 12 BIT rappresentano la posizione all‚Äôinterno della pagina (l‚Äôoffset)\n\nCon 12 bit possiamo rappresentare 2^{12} = 4096 byte (la dimensione di ogni pagina o frame fisico)\n\n\n\nAbbiamo quindi:\n\n0010 = 2\n000000000100 = 4\n\nQUINDI il dato si trova al quarto byte della pagina virtuale 2. Ora, tramite la tabella delle pagine:\n\n\nCerchiamo la pagina virtuale 2 nella tabella\n\n\nLa tabella indica che la pagina virtuale si trova nel frame fisico 110, ossia 6 (foto)\n\n\nLa MMU utilizza questa informazione per calcolare l‚Äôindirizzo fisico L‚Äôindirizzo fisico si calcola combinando\n\nLa base del frame fisico (frame \\times 4096)\nL‚Äôoffset (4) Quindi per il frame 6: Indirizzo \\ fisico = (6 \\times 4096) + 4 = 24580\n\n\n\n\nEVOLUZIONE DEGLI INDIRIZZI E TABELLA DELLE PAGINE\n32 BIT\n\nULTIMI 12 BIT = posizione nei 4096 byte della pagina\nPRIMI 20 BIT = possiamo avere nella tabella 2^{20} = 1.048.576 voci (UN BOTTO!!!!)\n\n64 BIT\n\nULTIMI 12 BIT = posizione nei 4096 byte della pagina\nPRIMI 52 BIT = possiamo avere nella tabella 2^{52} voci (sono talmente tante che che vengono usate solo 2^{48}).\n\nCome √® composta una voce della page table?\n\n\nnumero del frame quindi la posizione effettiva in memoria 12 bit negli esempi visti fino ad ora\nun bit che indica se la pagina √® in memoria oppure no(PRESENTE/ASSENTE)\nbit di protezione, quel classico bit che d√† ruoli di scrittura lettura esecuzione ecc‚Ä¶\nbit supervisor, se √® o meno eslusiva al livello supervisor\nBit modificato(M) o riferimento(R) viene soprattutto usato per gli algoritmi che vedremo dopo\n\nM se la pagina √® stata modificata\nR se la pagina √® stata acceduta\nun processo ha la sua tabella nel PTBR(Page Table Base Register) ovvero un registro\n\n\n\nCome si velocizza la paginazione?\n\nper non avere colli di bottiglia la ricerca di una pagina all‚Äôinterno di una tabella deve impiegare molto meno rispetto all‚Äôesecuzione dell‚Äôistruzione stesa\n\nes: una istruzione impiega 1 \\ ns la ricerca deve avvenire in 0,2 \\ ns\n\n\n\n\n\n                  \n                  1 singola voce indica, in teoria 1 singola pagina, questo significa che in una ipotetica tabella dovremmo avere 64 miliardi di voci,il che renderebbe la tabella estremamente pesante soprattuto perch√® ogni processo ha la sua tabella \n                  \n                \n\n\nsto tenendo in considerazione che con 48 bit di indirizzamento e 4KB ho 64 miliardi di pagine\nla soluzione la vedremo dopo con i TLB\n\n\n\nCome si salva una pagina?\n\n\nTabella delle pagine in Registri Hardware\n\nogni singola voce della tabella √® un registro\n√® facile da implementare \n√© lento perch√© ogni volta che cambio tabella devo ricaricare tutti i registri ad ogni cambio di contesto\n\n\n\nTabella delle pagine in Memoria Principale\n\nAbbiamo tutta la tabella nella RAM e un solo registro che punta al suo inizio(tipo una lista)\n√® facile da cambiare perch√© basta cambiare l‚Äôindirizzo del puntatore\n√® lento scorrere la lista\n\n\n\nEntrambi gli approcci fanno cacare la soluzione √® il TLB\nTLB=(Translation Lookaside Buffer)\nsoprattutto perch√© quando un processo viene eseguito di solito accede alle solite pagine\nil TLB √® un dispositivo hardware che mappa le recenti conversioni da indirizzi virtuali in fisici delle pagine.\n\nci consente di non accedere in memoria e quindi alla tabella delle pagine\n\nCom‚Äô√® strutturato il TLB?\n\nha un piccolo numero di voci\n\nuna variabile indica la validit√† o meno della pagina\nuna indica il numero della pagina nella memoria virtuale\nuna se √® stata modificata\nuna il tipo di accesso\ne una il corrispettivo frame in memoria fisica\n\n\n\n\nCome funziona il TLB?\n\nla MMU prima di fare una conversione da virtuale a fisico controlla la TLB\nse √® presente la prende senn√≤ no(TLB MISS) e la aggiunge alla TLB\n\nTIPOLOGIE DI TLB MISS\n\nSOFT MISS: √® quando non ho la pagina nel TLB ma nella tabella delle pagine\nHARD MISS: quando √® in memoria non volatile SSD,HDD‚Ä¶\npage table walk indica l‚Äôazione di ricerca nelle tabelle delle pagine\nse un accesso a un indirizzo non √® valido ho un segmentation fault\n\nSoluzione alle tabelle giga enormi (multi-level page table)\n\nqueste page table vengono attraversate dall‚Äômmu\n\n1. PAGE TABLE A 2 LIVELLI X86\n\nha due livelli di tabelle\n\nLa top level page table, contiene gli indirizzi che corrispondono alle tabelle di secondo livello\n\nCR3 √® un registro che punta alla radice del top level page table\n\n\nla second level page table, contiene gli indirizzi effettivi delle pagine\n\n2. PAGE TABLE A 4 LIVELLI X64\n\nLe sigle a sinistra sono dei campi che servono per ‚Äúnavigare‚Äù nei vari livelli di gerarchia:¬†\n\n\nPGD:¬†livello pi√π alto che contiene i puntatori al livello successivo¬†\n\n\nPUD:¬†contiene i puntatori al livello successivo¬†\n\n\nPMD:¬†contiene i puntatori al PTE¬†\n\n\nPTE:¬†contiene il numero del frame fisico, l‚Äôindirizzo finale viene calcolato aggiungendo l‚Äôoffset alla base del frame¬†\n\n\nQuello da ricordare qui √® che anche se il sistema √® a 64 bit ne utilizza solo 48 perch√© bastano e avanzano per qualsiasi cosa odierna\nALGORITMI DI SOSTITUZIONE DELLE PAGINE\nPAGE REPLACEMENT\nquando una pagina non √® in memoria e avviene un page fault, viene effettuato un page swap quando viene messa\nLISTA DI TUTTI GLI ALGORITMI\n1. Algoritmo Ottimaleüí©\n2. **Not Recently Used (NRU)**üëë\n3. **First-In, First-Out (FIFO)**üí©\n4. Second-Chance Algorithmüí©\n5. Clock Algorithmüëë\n6. **Least Recently Used (LRU)**üí©\n8. Not Frequently Used con AGING (NFUA) üëë\n9. Working Set Algorithmüí©\n10. WS Clock Algorithmüëë\n1. Algoritmo Ottimaleüí©\n\ndovrebbe prevedere quante volte viene utilizzata una pagina in un tot numero di istruzioni eseguite\nuna pagina non viene usata da 8 milioni di istruzioni e una da 6 milioni, viene tolta quella da 8 milioni\nimpossibile prevedere\n\n2. Not Recently Used (NRU) üëë\nutilizza i 2 bit di stato citati prima\nM(Modificato) e R(Referenziato) servono per identificare la pagina che deve essere eliminata\nscegliendola seguendo delle classi:\n\nad ogni clock viene azzerato il bit di referenza\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nclasseMR0[ ][ ]1[x][ ]2[ ][x]3[x][x]le scelte vanno in ordine da 0 a 3\n3. First-In, First-Out (FIFO) üí©\napplichi l‚Äôalgoritmo FIFO con le pagine\nil primo ad entrare sar√† il primo ad uscire\n\nelimina la pi√π vecchia ma potrebbe ancora essere la pi√π utilizzata\n\n4. Second-Chance Algorithm üí©\n√à tipo FIFO ma d√† una seconda chance a tutti prima di essere eliminati, la seconda chance la da modificando R\n\nR=1 hai ancora una chance\nR=0 non hai chance\n\n\nse tutte hanno R=1 non d√† seconda chance a nessuno e opera come FIFO\n5. Clock Algorithm üëë\nfunziona attraverso una lista collegata(che noi vediamo come un orologio)\ne un puntatore che punta a giro ad ogni elemento della lista collegata\nse R=0 elimina la pagina\nse R=1 azzera R\n+performante di seconda chance\n\n6. Least Recently Used (LRU) üí©\nmettiamo in una lista le pagine in ordine di utilizzo, in testa la pi√π usata in coda la meno usata e le tolgo cos√¨\nper√≤ non √® molto attendibile e molto costosa come operazione perch√© devi sempre aggiornare la lista\nuna piccola soluzione √® associare ad ogni pagina un contatore a 64 bit\nconto quante volte uso una pagina e basta(tua figlia con i giochi)\nil discorso √® che magari uso in modo concentrato la pagina per 1 giorno e poi non pi√π ma al livello di contatore sembra che la uso sempre\n7. Not Frequently Used con AGING (NFUA) üëë\nshifto di 1 bit in un ciclo di clock e inserisco 1 se utilizzata o 0 se non viene utilizzata\nquindi avr√≤ una sorta di et√† delle pagine\nelimino chi √® pi√π vecchio quindi chi ha numero pi√π basso\n\n9. Working Set Algorithmüí©\nHo il working Set che √® un ambiente aggiornato che tiene conto\n\ndell‚Äôet√† della singola pagina\nse √® stata o meno referenziata R\ndefinisco una variabile \\tau che rappresenta l‚Äôet√† massima per considerare una pagina nel working set\nSe avviene un page fault effettuo una ricerca per capire quale pagina togliere\nabbiamo 3 casi da analizzare per la singola pagina scelta in quel momento:\n\n\nR=1, aggiorno la tua et√† e anche la tua R\nR=0 e et√† della pagina&gt;\\tau la pagina viene rimossa dal working set\nR=0 e et√† della pagina \\leq \\tau questa viene salvata ma si va a prendere la pi√π vecchia per una possibile rimozioni\nse tutti sono salvi viene selezionata la pi√π vecchia con R=0 senn√≤ una pagina a caso\n\n10. WS Clock Algorithmüëë\n\nOgni pagina ha una et√† e un bit di Referenziazione\n\n\nSe il bit R=1, la pagina √® stata usata nel ciclo del clock. Il bit viene impostato a 0.¬†\n\nLa lancetta avanza ‚Üí figura b¬†\n\n\n\nSe R=0 (caso b dell‚Äôesempio) e l‚Äôet√† √® maggiore di¬†œÑ¬†si controlla M:¬†\n\n\nM=0: non ha subito modifiche, nessun problema per un rimpiazzo¬†\n\n\nM=1: ha subito modifiche, non pu√≤ essere rimpiazzata subito perch√© non ce n‚Äô√® ancora una copia in memoria¬†\n\n\n\n\n"},"UNI/ANNO-2/SISTEMI-OPERATIVI/SISTEMI-OPERATIVI-LEZ.15":{"slug":"UNI/ANNO-2/SISTEMI-OPERATIVI/SISTEMI-OPERATIVI-LEZ.15","filePath":"UNI/ANNO 2/SISTEMI OPERATIVI/SISTEMI OPERATIVI LEZ.15.md","title":"SISTEMI OPERATIVI LEZ.15","links":[],"tags":[],"content":"Sempre sulle pagine\nalgoritmi di paginazione locali o globali\n\nallocazione Locale\n\nogni processo riceve una porzione fissa della memoria, quindi tutte le pagine sono attaccate\npi√π facile da implementare\nmeno dinamica e meno inefficiente(si verifica troppo spesso il trashing)\n\n\nallocazione Globale\n\nogni processo pu√≤ distribuire dinamicamente le proprie pagine\nmeno facile da implementare (si usa soprattutto in processi che evolvono nel tempo)\npi√π dinamica e pi√π inefficiente(si verificano meno trashing ma non si azzerano)\nsi possono usare dei bit di aging per ottimizzare le cose\n\n\n\n\n\n                  \n                  cosa √® il trashing? \n                  \n                \n\nsi verifica quando il processore occupa pi√π tempo a fare operazioni di paging piuttosto che eseguire i processi stessi\n\n\nEsempio\n\nGestione memoria dei processi proporzionale o equa\n\nAllocazione equa\n\nad ogni processo assegno un quantitativo di frame prefissato\nproblema: un processo pu√≤ avere priorit√† diverse rispetto a un altro\n\n\nAllocazione proporzionale\n\nad ogni processo assegno un quantitativo di frame proporzionale\ndevo dare a un processo un limite minimo di pagine\ngestisco dinamicamente i frame aggiornando il loro quantitativo in base alle esigenze del processo\n\n\n\nCome capire quanta memoria allocare a un processo?\nPage Fault Frequency:\n\nse un processo causa molti page fault allora devo dargli tanta memoria senn√≤ no\n\nTrova un trade off del grafico tra una situazione in cui ho troppi page fault e troppi pochi\nquindi si tratta di una cosa dinamica\n\n\n\n                  \n                  il discorso non √® quale pagina togliere per metterne un&#039;altra ma quante pagine aggiungere \n                  \n                \n\ntante volte conviene assegnare piu pagine per ridurre eventuali overhead causati dagli eccesivi swap\n\n\nci sono due modi per mitigare il problema del trashing\n\nOut of memory killer\n\nprocesso che seleziona o termina un processo se richiede troppa memoria o √® poco importante\n\n\nswapping\n\ncome abbiamo gi√† visto con tutti quegli algoritmi\n\n\n\nCome ridurre queste uccisioni dei processi\ne se voglio evitare il trashing del mio processo\n\nscheduling a due livelli\n\nse ne ho uno in foreground(lo sto usando)\nmetto tutti gli altri in memoria non volatile\n\n\ngestione della multiprogrammazione\n\nusa delle caratteristiche per spostare i processi come:\n\nse √® I/O bound o CPU bound\nla dimensione e la frequenza di paginazione dei processi\n\n\n\n\naltre tecniche\n\noltre a uccidere o spostare potrei comprimere, compattare oppure deduplicare i processi\n\nper deduplicazione se ad esempio faccio il fork le istruzioni dei due processi saranno abbastanza identiche e quindi potrei farle puntare nelle stesse istruzioni\n\n\n\n\n\n\n\n                  \n                  per gli algoritmi di aging √® bene avere molte pagine libere cos√¨ che facciamo in modo che le varie pagine invecchino adeguatamente \n                  \n                \n\n\nutilizzo di un paging daemon\n\ndemon processo in background che viene risvegliato in modo sincrono, ad esempio nelle mail abbiamo un processo che ad ogni ciclo di clock refresha il server e controlla se ci sono mail\nogni tanto si risveglia e controlla come siamo messi in memoria e se stiamo messi bene sposta le pagine seguendo gli algoritmi visti in precedenza+\n\n\nScrittura in memoria non volatile\n\nQuando modifico una pagina mi salvo in memoria non volatile quelle informazioni\n\n\nclock a due lancette\n\nuna lancetta in senso anteriore ha un paging daemon che fa quello che deve fare\nla lancetta posteriore si ritrover√† ora pi√π pagine libere, eseguendo l‚Äôalgoritmo di clock\n\n\n\nDimensione delle pagine e bilancio dei fattori\nquale √® la migliore pagina da avere a disposizione?\n\navere pagine grandi √® un problema per la scrittura e lettura\navere pagine troppo piccole aumenta l‚Äôoverhead e le tabelle delle pagine saranno enormi\n\nsi cerca un trade off tra le due cose, consentendo dimensioni di pagine variabili\n\ntransparent huge pages, pagine estremamente grandi che occupano solo uno spazio nelle tabelle delle pagine\n\nCalcolare dimensione ottimale delle pagine\nParametri considerati:\n\nDimensione media del processo: s byte\nDimensione della pagina: p byte\nDimensione di ogni voce nella tabella: e byte\nPer capire quante pagine servono per ogni processo faccio: s/p\nPer capire quanto spazio occupa una voce nella tabella faccio: s* e/p byte\nla frammentazione interna si calcola facendo p/2\n\nCalcolo effettivo\nl‚Äôottimo si trova bilanciando questi due fattori  s* e/p$$+ p/2\n\n\n                  \n                  per trovare il punto massimo di una funzione uso la derivata \n                  \n                \n\nper farla prendiamo che la nostra x √® p\nESCE: -se/p^2-1/2\nper essere ottimale la nostra p=\\sqrt{2se}\n46:17\nProblemi di progettazione\nin passato alcuni sistemi avevano uno spazio di indirizzamento delle istruzioni separato da quello dei dati\n\nCondivisione delle pagine nei sistemi multiprogrammati\nEsiste un concetto di riutilizzo delle stesse risorse:\nper facilitarlo conviene dividerlo come detto prima in\nI-space: Instruction space\nD-space: Data space\n\n\n                  \n                  il processo usa dei puntatori per puntare a entrambe le cose e lo scheduler li sfrutta per impostare l&#039;MMU \n                  \n                \n\n\n\n                  \n                  se elimino un processo devo stare attento che altri non dipendano da esso, potrebbero avvenire diversi page fault \n                  \n                \n\n\n\nSe esistono delle pagine in sola lettura posso riciclarle,‚Äî ad esempio\n\nlibrerie riutilizzate\nquando si fa il fork\n\n\n\nse sono dei dati in scrittura di solito non si riciclano\n\ndipende tutto dall‚Äôutilizzo che se ne fa se entrambe condividono le stesse cose anche in scrittura. appena un processo inizia a scrivere qualcosa di diverso\n\nfaccio avvenire una trap e copio la pagina che √® stato modificato (copy on write)\n\n\n\n\n\nDLL- Dynamic Link Libraries‚Üí risparmio di spazio perch√© condivido librerie comuni\n\n\n\n                  \n                  per utilizzare questi meccanismi abbiamo bisogno di indirizzi relativi e non assoluti \n                  \n                \n\nusare un file mappato in memoria (slide stand-by)\nho dei processi che aggiornano in memoria eventuali cose in tempo reale\npotrei usarlo per far comunicare processi\nProblemi di implementazione della memoria virtuale\nscenari che deve gestire il s.o. per quanto riguarda la memoria virtuale abbiamo:\nCreazione di un processo:\n\ncapire quanto √® grande il processo\ncreare la tabella delle pagine\nDedicare uno spazio nella memoria non volatile allocando uno spazio per lo swapping\ninizializzare l‚Äôarea di scambio e registrare informazioni nella tabella dei processi\n\nEsecuzione di un processo(quando lo decide lo scheduler):\n\neventualmente azzero TLB e MMU\ncarico e attivo la tabella delle pagine\nfaccio una prepaginazione, ovvero aggiungo gi√† ora delle pagine del processo per ridurre page fault\n\nPage Fault(lo vedremo pi√π dettagliato dopo):\n\ncapire l‚Äôindirizzo virtuale che lo ha causato\ntrovare la pagina da inserire che prima era in memoria non volatile\nscegliere un frame disponibile, togliendo pagine vecchie\nCaricare la pagina nel frame e ripresa del processo\n\nChiusura del processo\n\nrilascio della tabella mettendola in memoria non volatile\ncontrolli eventuali dipendenze da altri processi e chiudi quelle pagine solo dopo che non servono pi√π a loro\n\nPage fault in 10 passi\n\nAvviene una trap nel kernel, l‚Äôhardware esegue una Trap e viene salvata l‚Äôultima posizione del registro Program Counter nello stack, tutte le info di quel processo vengono salvate nella CPU\nViene avviata una Routine in assembly che salva tutti i registri volatili e invoca il gestore dei page fault\nIl sistema operativo cerca di capire quale sia la pagina virtuale mancante e la recupera servendosi anche del Program Counter per capire l‚Äôistruzione che ha causato il page fault, e la fa riprendere una volta risolto\nFaccio un controllo per verificare la validit√† di un eventuale indirizzo, se non √® valido ritorno errori\nSe non ci sono frame liberi, applico algoritmi di swapping, se la pagina √® stata modificata avviene una fase di scrittura nella memoria non volatile e il processo viene sospeso\nLa pagina viene caricata dopo aver liberato il frame, se il processo √® ancora sospeso ne viene eseguito un altro finch√© non viene rimesso\nViene aggiornata la tabella delle pagine e viene reso disponibile il frame\nOra quell‚Äôistruzione che aveva causato page fault pu√≤ essere eseguita attraverso il PC che la puntava\nIl processo pu√≤ essere nuovamente schedulato\nIl controllo ritorna in modalit√† utente per continuare l‚Äôesecuzione\n\nBUG\nMettiamo caso che un processo richieda dei dati che vengono passati dal DMA(lo vedremo meglio poi)\n\nil processo viene messo in attesa\nil DMA mette il dato in memoria\nvisto che il processo √® in attesa ne arriva un altro\ncausa un page fault\nviene rimosso il dato da un algoritmo di gestione delle pagine\nil processo si attacca al cazzo\n\n\n\n                  \n                  come si risolve? \n                  \n                \n\nbit di pinning per dire all‚Äôalgoritmo che quella pagina √® pinnata e che non va tolta\n\n\nDMA √® una circuiteria che scrive in memoria\nArea di swap\n\n\n                  \n                  lo spazio swap √® ad uso e consumo del s.o. a differenza di file generici che possono essere spostati e letti da qualsisasi sistema che li supporta \n                  \n                \n\nl‚Äôarea di swap √® quello spazio, in memoria non volatile che ha al suo interno tutte quelle pagine che non sono in memoria volatile\nabbiamo anche l√¨ una tabella che ci dice dove sono posizionate queste pagine\nci sono due scenari di gestione di queste due realt√†:\nSCENARIO 1, rapporto 1:1\n\nAbbiamo un rapporto 1:1 tra area di swap e effettiva posizione delle pagine in memoria principale.\n\nOgni pagina ha la sua posizione e deve solo essere spostata nella sua Area di scambio\nQuando √® necessario ricaricarla, il sistema operativo pu√≤ ripristinarla direttamente dalla posizione specifica nello spazio di swap.\noccupa molta memoria\n\nSCENARIO 2, Dinamico\n\nUtilizzo una mappa del disco che mi dice le varie posizioni nell‚Äôarea di scambio\n\npi√π dinamica e leggera\npi√π difficile da implementare\n\nLA SEGMENTAZIONE\nSISTEMA DI MEMORIA MONODIMENSIONALE\n\n\nLa memoria √® vista come un unico blocco lineare, un unico spazio contiguo di indirizzi.\nOgni processo ha un solo segmento di memoria assegnato, che rappresenta tutto il suo spazio di esecuzione (codice, dati, stack, ecc.).\nGli indirizzi sono gestiti come una sequenza univoca (monodimensionale).\n\n\n\n                  \n                  potrei andare ad occupare altre aree di memoria virtuale con un programma \n                  \n                \n\n\n\n                  \n                  per risolvere creo dei segmenti, piu sequenze di indirizzi \n                  \n                \n\nSISTEMA DI MEMORIA A SEGMENTAZIONE\n\n\nL‚Äôidea del segmento consente ai processi di avere pi√π sequenze di indirizzi per evitare collisioni\nOgni segmento ha un suo spazio di indirizzi\nla loro dimensione √® variabile\nper raggiungere un indirizzo di memoria si usa\n\nnumero del segmento\nindirizzo nel segmento\n\n\nla segmentazione facilita la condivisione e la protezione delle risorse\n\nNoi fino ad ora abbiamo visto la memoria paginata e univoca che differenza c‚Äô√® con quella segmentata?\n\nla paginazione ha una dimensione prefissata(dovevamo calcolarla ecc)\nla segmentazione no, ha anche una logica\n\npuoi gestire l‚Äôaccesso, quindi puoi mettere sola lettura sola scrittura ecc‚Ä¶\npuoi dargli un ruolo, tipo puoi dire che quel segmento sono codici oppure dati ecc\noffre maggiore flessibilit√† ma √® pi√π difficile da implementare\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConsiderazionePaginazioneSegmentazioneIl programmatore deve sapere che questa tecnica √® in uso?NOS√åQuanti spazi di indirizzi lineari ci sono?1MoltiLo spazio degli indirizzi totale pu√≤ superare la dimensione della memoria fisica?S√åS√åLe procedure e i dati possono essere distinti e protetti separatamente?NOS√åLe tabelle la cui dimensione varia possono essere disposte facilmente?NOS√åLa condivisione delle procedure fra utenti √® facilitata?NOS√åPerch√© fu inventata questa tecnica?Per avere uno spazio degli indirizzi lineare grande senza dover acquistare ulteriore memoria fisica.Per consentire a programmi e dati di essere spezzati in spazi degli indirizzi logicamente indipendenti e per facilitare la condivisione e la protezione.\nESEMPIO\n\nMULTICS AVEVA LA SEGMENTAZIONE\nGli indirizzi funzionano a 34 bit\n\ni segmenti venivano trattati come spazi di memoria virtuali indipendenti\nogni programma poteva avere 2^{18} segmenti\nOgni segmento punta alle loro tabelle delle pagine\n\n\nCOME ERANO DIVISI I SEGMENTI\n\nc‚Äô√® una tabella dei segmenti che ha i vari descrittori dei segmenti\nCome √® fatto un descrittore del segmento?\nun descrittore ha 36 bit\nVero e proprio puntatore che punta alla tabella delle pagine(18 bit) che √® suddiviso a sua volta cosi ha un offset da sommare e il numero delle pagine\n\nla lunghezza di quel segmento\nun bit di protezione\naltre info\n\n\nConversione di un indirizzo\n\n\n\nTrovare il descrittore del segmento\n\nIl numero del segmento viene utilizzato per individuare il descrittore del segmento nella memoria.\n\n\n\nVerificare la tabella delle pagine\n\nSi controlla la presenza della tabella delle pagine relativa al segmento.\nQuesto passaggio √® fondamentale per prevenire eventuali errori.\n\n\n\nEsaminare la voce della pagina virtuale\n\nSe la pagina non √® in memoria: si verifica un page fault, e il sistema dovr√† caricare la pagina dalla memoria secondaria.\nSe la pagina √® in memoria: dalla voce della tabella delle pagine viene estratto l‚Äôindirizzo fisico della pagina nella memoria principale.\n\n\n\nCalcolare l‚Äôindirizzo fisico\n\nL‚Äôindirizzo fisico nella memoria principale viene calcolato aggiungendo l‚Äôoffset fornito all‚Äôindirizzo iniziale della pagina.\n\n\n\nAccedere alla memoria\n\nAvviene l‚Äôoperazione desiderata (lettura o scrittura) sulla posizione della memoria principale corrispondente.\n\n\n\nPer ottimizzare le prestazioni si usava una TLB personalizzata\nAddirittura gi√† si utilizzava una TLB se pur piccola:\n\nComando free\ncon -h li vediamo convertiti in formati decenti ci porta a vedere le informazioni sulla memoria ram e sullo swap\n\nNoi lo usiamo con -h cos√¨ vediamo le cose non in bit\n"},"UNI/ANNO-2/SISTEMI-OPERATIVI/SISTEMI-OPERATIVI-LEZ.16":{"slug":"UNI/ANNO-2/SISTEMI-OPERATIVI/SISTEMI-OPERATIVI-LEZ.16","filePath":"UNI/ANNO 2/SISTEMI OPERATIVI/SISTEMI OPERATIVI LEZ.16.md","title":"SISTEMI OPERATIVI LEZ.16","links":[],"tags":[],"content":"Problemi di memorizzazione:\n\ncome memorizzo i dati a lungo termine?\n\n\n\n                  \n                  non con la ram \n                  \n                \n\n\n\n                  \n                  con disco rigido o ssd (non volatili) \n                  \n                \n\n\npu√≤ essere visto come un insieme di blocchi di dimensione fissa\nsupporta operazioni di scrittura e lettura\npossono essere accessibili dai processi in modo simultaneo\n\n\n\n\ndobbiamo garantire l‚Äôesistenza di un arbitro che\n\nsalva i dati\ngarantisce la persistenza dei dati nel tempo\nfacilita l‚Äôaccessibilit√† ai dati e la protezione di essi\nquesto arbitro √® il file system\n\n\n\nil SO sfrutta i file systems\nSono un modo per memorizzare e organizzare le informazioni e sono:\n\norganizzate in file\ndirectory\nspesso chiamati NFTS, Ext4, APTFS\nAbbiamo delle astrazioni in termini di interfaccia utente e implementazione tecnica\nl‚Äôutente vedr√† solo le operazioni consentite e i file\nil progettista vedr√† tutte le strutture interne\n\nEsistono standard per garantire portabilit√† dei file system, cos√¨ le chiavette funzionano sulla maggior parte dei dispositivi ecc‚Ä¶\nRoadmap\nDescrive il processo di accesso ai file a un Sistema Operativo\n\n\npossiamo vedere qui un esempio dove lo user chiede un determinato file\nil sistema operativo interagisce con il file system per localizzare e leggere quel file\n\nil virtual file system ci consente di vedere ogni file system in modo virtuale cos√¨ che esso sia astratto e uguale per ogni implementazione\nuna page cache per velocizzare i lavori, salvando le varie pagine viste pi√π frequentemente\nesistono diversi driver per ogni tipologia di file system, convertono i comandi astratti del virtual file system in una cosa pi√π specifica\nbuffer cache per fare il trasferimento in modo ottimizzato e rapido delle informazioni\n\n\n\ndefinizione di file\nmetodo di astrazione per salvare e leggere informazioni su disco semplificando la lettura, altrimenti sarebbero tutti 0 e 1\n\nogni file ha un identificativo, un nome che per ogni SO deve rispettare dei criteri\n\nIn MS-DOS potevo avere 8 lettere per identificativo del file\n\nora possiamo mettere quello che ci pare con solo limiti nei formati(no caratteri speciali)(Case sensitivity),Linux e case sensitive\n\n\n\n\nil s.o. crea un ponte tra quel descrittore e quella sequenza di bit in disco\nEsistono due file\n\nbinari, non capibile a meno che sei matrix\ntestuali, sempre binario ma tradotto facilmente da un essere umano\n\n\nEstensione dei file, non necessaria in UNIX ma tipo .mp3, .txt ecc‚Ä¶\nLinux se ne fotte ed e a carico nostro aprire una app corrispondente a quel file\nGNOME esiste e consente di rimandare a una determinata estensione ma √® un software esterno\n\nABBIAMO 3 TIPI DI STRUTTURE FILE\n\na) Sequenza non strutturata di Byte che deve essere gestita e ricostruita dai software utente\n\n(non dal SO)\n\n\nb) una sequenza strutturata di Byte che andavano lette una alla volta in memoria(Nastri)\n\nsupporto in cui erano scritti i vari record\n\n\nc) Struttura organizzata, i dati venivano visti come record organizzati da una struttura ad albero, ogni record aveva le sue chiavi, principalmente usato nei mainframe\n\n\nDI COSA ABBIAMO BISOGNO PER GESTIRE TUTTA STA MERDA?\n\nfile e cartelle normali(Come ASCII e Binari)\n\nfile di uso comune dagli utenti come foto video ecc\ncartelle di uso comune che consentono la gestione dei vari file\n\n(anche le cartelle sono file in linux)\n\n\n\n\nTipi di file speciali\n\nA caratteri: usati per dispositivi che lavorano con byte, periferiche I/O ecc‚Ä¶\nA blocchi: File usati per astrarre i vari dispositivi che consentono l‚Äôaccesso ai dati come dischi ecc‚Ä¶\n\n\n\nFile eseguibili\nFile speciali che contengono una sequenza di byte eseguibile dal sistema operativo con formati specifici\nCome √® fatto?\n\n\nIntestazione (Header)\n\nNumero magico: specifica il tipo di file e se √® eseguibile o meno\nDimensioni varie (testo, dati, BSS, ecc.)\nPunto di ingresso: l‚Äôindirizzo da cui il SO deve iniziare l‚Äôesecuzione (main)\n\nFlag: varie propriet√† o comportamenti speciali del file\n\n\nTesto e dati\n\nTesto: parti del programma caricate e rilocate in memoria (il codice macchina eseguito dal processore)\nDati: contiene le variabili globali/statiche\n\n\nTabella dei simboli\n\nUtilizzata per il debug\n\n\n\n\n\nFile di archivio\nUn file di archivio come quelli creati con tar (acronimo di ‚Äútape archive‚Äù) √® un contenitore che raccoglie pi√π file e directory in un unico file\n\nIntestazioni dei moduli:¬†\n\nnome\ndata di creazione\nproprietario\ncodice di protezione\ndimensione¬†\nNon sono leggibili dall‚Äôutente perch√© sono in formato binario e stamparli produrrebbe caratteri incomprensibili\n\n\n\n                  \n                  Utility in UNIX sono una serie di euristiche che determinano il nome del file e tutte le sue info \n                  \n                \n\nCOME SI ACCEDE A UN FILE\nCi sono due modi:\n\nSequenziale, leggo i file in modo continuo, tipo su nastri(obsoleto)\nCasuale, Salto sul settore richiesto senza leggere sul tutto il file\n\nUtilizzo di seek che indica la posizione da cui iniziare a leggere\n\n\n\nATTributi dei file\nogni file ha i suoi attributi e metadati che indicano diverse informazioni\n\nOperazioni su file\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOperazioneDescrizioneCreateCreazione di un file senza dati. Principalmente per ¬´annunciare¬ª la presenza del file e impostare alcuni attributi. Non aggiunge dati ma lo registra nel file system (istanza vuota).DeleteEliminazione di un file per liberare spazio su disco. Dopo l‚Äôeliminazione, il file non √® pi√π accessibile.OpenApertura di un file per caricare in memoria gli attributi e gli indirizzi del disco. Facilita l‚Äôaccesso rapido in seguito.CloseChiusura del file per liberare spazio nelle tabelle interne del sistema operativo. Forza anche la scrittura dell‚Äôultimo blocco.ReadLettura dei dati da un file, generalmente dalla posizione corrente. Richiede un buffer per memorizzare i dati letti in RAM per velocit√†.WriteScrittura di dati nel file, alla posizione corrente. Pu√≤ ampliare il file o sovrascrivere i dati esistenti.AppendAggiunta di dati solo alla fine del file. Usata come forma limitata di scrittura in alcuni sistemi operativi.SeekRiposizionamento del puntatore del file a una posizione specifica (per accesso casuale). Permette lettura o scrittura dalla posizione scelta.Get AttributesLettura degli attributi di un file. Necessaria per processi come il comando make in UNIX per la gestione dei progetti software.Set AttributesModifica degli attributi di un file (es. modalit√† di protezione o flag), effettuata dopo la creazione del file.RenameRinominare un file. Utile come alternativa alla copia ed eliminazione, specialmente per file di grandi dimensioni.\nCome cazzo si scrive e legge un file?\nint fd=open(&quot;foo.txt&quot;,O_RDONLY);\nchar buf\nPrinta sullo stdout\nScrivere in binario e una sola perche dipende dal sistema operativo\nscfrivere in leggibile gode\n11_write and read posix\n\n0644 diritti di accesso\n\nCome cazzo si copia un file?\nle cartelle utilizzano i file\ndirectory di lavoro dove sono le cartelle\n3\nDIRECTORY\nSono file che tengono traccia di altri file in un file system\nDIVISIONE A DUE LIVELLI:\nA livello singolo:\n\nUna sola directory detta ROOT che contiene tutti i file\nusata nei dispositivi embedded\nMultilivello:\nPer motivi organizzativi si √® deciso di creare una struttura gerarchica con cartelle e sottocartelle cos√¨ da raggruppare e individuare meglio i file\nEsiste una ROOT directory che rappresenta l‚Äôinizio di ogni directory\n\nCome cazzo si trova una cartella?\nNomi di percorso assoluto Iniziano dalla root e conducono al file, sono unici per ogni file.\n\n\nUnix/LINUX: root = /\n\n/usr/hjb/mailbox, indica il file mailbox nella directory usr/hjb\n\n\n\nWindows: root = C:\n\nC:\\Users\\Samuele\\Documents\\sborra.txt, indica il file sborra.txt nella directory Documents\n\n\n\nNomi percorso relativi Non iniziano dalla root, il percorso √® basato sulla directory di lavoro dell‚Äôutente (corrente)\n\ncp /usr/hjb/mailbox /usr/hjb/mailbox.bak percorso assoluto\ncp mailbox mailbox.bak percorso relativo\n\nOgni processo ha una directory di lavoro indipendente che non influisce su altri processi o sul file system quando termina il suo lavoro. Le procedure di libreria impediscono il cambio di directory o la ripristinano (es. un file cambia temporaneamente directory e, una volta concluso, pu√≤ ritornare a quella originale). Per rappresenrare posizioni relative all‚Äôinterno della directory corrente si usa:\n\n\n.: directory corrente\n\n\n..: directory genitore\n\ncp ../lib/dictionary: copia il file dictionary della ../lib (genitore) alla directory corrente.\n\n\n\nOPERAZIONI SULLE DIRECTORY\nOperazioni di base\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOperazioneDescrizioneCREATECrea una directory con le voci . e .. predefinite.DELETEElimina una directory (possibile solo se la directory √® vuota).OPENDIRApre di una directory per leggerne il contenutoCLOSEDIRChiude una directory dopo la lettura per liberare risorse\nLettura e modifica\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOperazioneDescrizioneREADDIRRestituisce la prossima voce in una directory aperta senza esporre la struttura interna.RENAMERinomina una directory.\nLinking e Unlinking\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOperazioneDescrizioneLinkCrea un hard link (direttamente diretto a un file nel file system), collegando un file esistente a un nuovo percorso, condividendone l‚Äôi-nodeUnlinkingRimuove una voce dalla directory, cancellando il file se √® l‚Äôunico link.\n\n\n                  \n                  I-node (lo vedremo meglio poi) \n                  \n                \n\nUn I-node √® una struttura dato che rappresenta un file o una directory. Contiene informazioni essenziali sul file (metadati) e puntatori ai blocchi di dati sul disco\n\n\nLink simbolici: sono dei link speciali che puntano a diversi tipi di file e che vedremo meglio poi\nCREAZIONE DI ARCHIVI\nPer creare un nuovo archivio Usiamo il comando tar che ormai sempre si utilizza insieme a gz che consente di comprimere l‚Äôarchivio(tipo zip)\n\n\ntar -czvf nome-archivio.tar.gz /percorso/della/cartellabash\n\n\nc: Crea un nuovo archivio.¬†\n\n\nz: Comprimi l‚Äôarchivio usando gzip.¬†\n\n\nv: Visualizza un output dettagliato durante l‚Äôoperazione.¬†\n\n\nf: Specifica il nome del file di archivio.\n\n\n\n\nESTRAZIONE DI ARCHIVI\n\n\n`tar -xzvf nome-archivio.tar.gz¬†\n\n\nx: Estrai il contenuto dell‚Äôarchivio.¬†\n\n\nz: Decomprimi l‚Äôarchivio usando gzip.¬†\n\n\nv: Visualizza un output dettagliato durante l‚Äôestrazione.¬†\n\n\nf: Specifica il nome del file di archivio.\n\n\n\n\nEsistenza di ZIP\nZip √® pi√π veloce e supportato da windows e mac\nma Tar.GZ comprime di pi√π e mantiene le strutture interne meglio\nComandi con:¬†\n\n\nzip nome-archivio.zip file1 file2¬†\n\n\nunzip nome-archivio.zip\n\n"},"UNI/ANNO-2/SISTEMI-OPERATIVI/SISTEMI-OPERATIVI-LEZ.17":{"slug":"UNI/ANNO-2/SISTEMI-OPERATIVI/SISTEMI-OPERATIVI-LEZ.17","filePath":"UNI/ANNO 2/SISTEMI OPERATIVI/SISTEMI OPERATIVI LEZ.17.md","title":"SISTEMI OPERATIVI LEZ.17","links":[],"tags":[],"content":"Nella macchina viene avviato il BIOS, un piccolo sistema operativo che gestisce l‚Äôhardware.\n\ncontrolla che non ci siano errori\nche sia tutto ok ecc‚Ä¶\npoi bisogna far partire il vero s.o. con una serie di codici che lo fanno partire ‚Üí\nPer scegliere quale s.o. far eseguire delle varie partizioni si usa\nL‚ÄôMBR contiene una tabella con tutti i primi file di boot per ogni partizione\nnelle tabelle c‚Äô√® scritto da quale settore a quale settore √® scritta quella partizione\n\nPARTIZIONE\n\n\nOgni partizione deve essere contigua\nOgni partizione del disco √® strutturata come nella parte sotto della foto\nL‚ÄôMBR punta ad ognuno dei blocchi di boot, che contengono i primi codici per far eseguire il s.o.\nImmaginiamo di avere diverse partizioni di boot\nlinux\nwindows\nmacos\n\n\n\n                  \n                  L&#039;MBR tiene anche traccia delle partizioni senza s.o. ma lo specifica \n                  \n                \n\nUEFI\nIl BIOS vecchio √® stato abbandonato e sostituito da UEFI per diversi motivi:\n\nper problemi di flessibilit√†\nsupporto di architetture a 64 bit\nutilizzo di interfacce grafiche migliori e mouse\nintroduzione del Secure Boot(lo spieghiamo tra poco)\nrecupero del boot record precedente\nGPT and√≤ a sostituire MBR consentendo una gestione illimitata di partizioni e dischi con capienza maggiore(2,2TB)\n\nblocco 0, consente retrocompatibilit√† con vecchi MBR\nblocco 1, un sistema che descrive le info sulle varie partizioni\nblocco 2, lista di puntatori a partizioni\nvarie partizioni\npoi abbiamo il backup che ci consente di fare il recupero\n\nGUID PARTITION TABLE (GPT)\n\nSistema di gestione delle partizioni\nTutte le cose dette prima e in pi√π\nun controllo di integrit√† CRC\nEFI System Partition (ESP):\n√® una partizione speciale sui dischi GPT\narchivia file utili all‚Äôavvio come:\n\nbootloader, driver e utility di diagnostica\n\n\nUsa il file system FAT32\n\nParentesi sul Secure Boot\n\nAlcuni virus attaccano direttamente nella fase di boot\nil boot loader controlla le firme digitali dei vari boot, driver e utility\nriduce notevolmente la presenza di vari codici malevoli\nalcuni s.o. non la supportano a pieno e quindi bisogna disattivarla\n\nCome sono implementati i file nel file system\nCi sono due modi per memorizzare file\n1. Allocazione contigua\n\nOgni file √® memorizzato come un insieme di blocchi contigui\n\nproblema di frammentazione nel caso di una rimozione del file\nfacile implementazione\nnecessit√† di avere punto di inizio e fine del file\n\n2. Allocazione con liste concatenate\n\n\nogni file √® memorizzato come un insieme di blocchi che vengono collegati con puntatori\nogni directory deve solo salvarsi il puntatore di inizio e poi basta scorrerlo\ncon il sistema dei puntatori risolvo il problema della frammentazione\nProblema: devo scorrere blocco dopo blocco (seek) per arrivare in quella determinata posizione\nSoluzione\n\n3.Introduzione di FAT\nSistema ottimizzato delle liste concatenate\nUtilizzo la memoria RAM per avere una tabella che mi punta ad ogni blocco, dicendomi del singolo file, il suo rispettivo blocco successivo\n\nProblema:la FAT chiede un botto di RAM (1 TB di disco richiede 3GB di RAM)\n\nOra si USA NTFS ma per le schede SD e altra roba si usa ancora perch√© sono di dimensioni limitate\n\nI-NODE\nIntrodotti in Linux l‚ÄôI-node contiene tutte le info di un singolo file tranne il nome e il contenuto quindi avremo:\n\ndata creazione\nindirizzi di dove si trovano i vari blocchi\nil proprietario\ni permessi di accesso\nQuando apro un file solo l‚ÄôI-node di quel file viene messo in memoria\nSe un file supera il limite degli indirizzi da mettere in un I-node esso punter√† a un altro blocco che avr√† gli indirizzi aggiuntivi(per file enormi)\nGli I-node sono in una cache che viene gestita seguendo determinati algoritmi\ncome √® fatto un I-node:\n\nPer windows si usa NTFS usa tipo gli I-node ma pu√≤ mettere informazioni pi√π grandi\n\nLe cartelle\nLe cartelle sono un file che all‚Äôinterno ha la lista degli altri file che sono in essa\nLa singola riga che descrive il singolo file si dice voce\nCi sono due modi per organizzare le cartelle:\nCon voci fisse\nnegli anni 80 ogni directory aveva\n\nNome file\nattributi\n\nle solite cose\nindirizzi dei singoli blocchi\n\n\n\n\nDirectory con riferimento\nLa voce prevede\n\nnome del file\nI-Node\n\n\n\n\n                  \n                  Anche una cartella essendo un file e un I-node \n                  \n                \n\nCome gestisco i nomi dei file nelle directory(la parte a sx delle dir)\nOgni file ha un nome come detto in precedenza e di solito sono memorizzate con stringhe ovvero sequenze di caratteri\nCi sono due modi per memorizzare i nomi dei file\n1. Voci con lunghezza variabile\nOgni file ha il suo Header che mi dice quanto √® lunga la stringa del file\ne poi ho la stringa con il nome\n\n2. Gestione degli Heap\nHo una stringa enorme con tutti i nomi\nOgni voce ha un puntatore che punta all‚Äôinizio del suo nome e la scorro per la sua lunghezza dettata dall‚Äôheader\n\nRicerca all‚Äôinterno delle directory\nInizialmente avveniva la ricerca di un file confrontando tutte le voci nelle directory\nUtilizzo di una tabella che contiene tutti gli indirizzi dei file indicizzati attraverso una funzione di Hash, ne facilita la ricerca\nAnche qui si usa una cache che mette i file pi√π cercati cos√¨ da facilitarne l‚Äôaccesso\n\n\n                  \n                  se faccio ls -l non apro i file per vederli, apro solo le loro posizioni e le loro liste di I-node con tutti i metadati i nomi dei file vengono presi dalle liste delle directory\n                  \n                \n\nFile Condivisi e Link nei file system\nPosso condividere i file per fare in modo che pi√π utenti ci lavorino sopra\nPer farlo si usano i LINK\n1. Hard Link\nCondivido direttamente e brutalmente l‚ÄôI-Node\n\nUn file si elimina davvero solo se ogni suo Hard link viene eliminato\n\n\n\nCon il sistema Hard Link possiamo fare questo esempio che va da\na‚Üí c\ne vedere che un singolo file ha un contatore che conta quante directory puntano ad esso finch√© si azzera e muore\n2. Soft Link\nPunto solo al suo nome, se lo elimino il Soft non funziona pi√π\n\nes: crea collegamento su windows\n\nParentesi sui Link simbolici\nTu puoi fare un Hard link sullo stesso file system ma non su altri\ncon i link simbolici possiamo farlo\nQui devo crearmi il mio I-node che indicher√† poi il percorso all‚Äôaltro I-node sull‚Äôaltro file system\nIl sistema operativo deve farsi tutto il percorso\n\nse faccio un backup rischio di copiare anche i file dei symlink\nse ne ho pi√π di uno faccio 1000 copie\nho bisogno di software avanzati che capiscono che si tratta di un symlink\n"},"UNI/ANNO-2/SISTEMI-OPERATIVI/SISTEMI-OPERATIVI-LEZ.18":{"slug":"UNI/ANNO-2/SISTEMI-OPERATIVI/SISTEMI-OPERATIVI-LEZ.18","filePath":"UNI/ANNO 2/SISTEMI OPERATIVI/SISTEMI OPERATIVI LEZ.18.md","title":"SISTEMI OPERATIVI LEZ.18","links":["UNI/ANNO-1/ARCHITETTURA/LEZIONI/3.Le-memorie"],"tags":[],"content":"Spiegazione di come funziona l‚Äôesame:\n\nprova su form\nprogrammazione c su carta + domanda a risposta aperta\nOrale facoltativo o a meno di prove sospette\n\nin poche parole per tutto l‚Äôanno accademico si pu√≤ provare SISTEMI+RETI 3 volte\nGESTIONE DELLO SPAZIO SU DISCO\nCONTIGUA VS NON CONTIGUA\nCi sono due modi per memorizzare i file:\n\nALLOCAZIONE CONTIGUA\n\nIl singolo file occupa un insieme di blocchi contigui\nha un indirizzo di partenza iniziale e una lunghezza\nse esso cresce e supera il limite il file deve essere assegnato a un‚Äôaltra area di memoria\nse vengono eliminati dei blocchi allora potremmo incorrere in frammentazione\n\n\nBLOCCHI NON CONTIGUI\n\nIl file viene spezzettato in blocchi di dimensione fissa\nriduce la frammentazione\nogni blocco ha il riferimento del blocco successivo questo ci consente di metterli allocati dove ci pare\n\n\n\nOTTIMIZZAZIONE E LATENZA DEI BLOCCHI NON CONTIGUI\nc‚Äô√® una propriet√† che in sostanza ci dice\npi√π il blocco √® grande meno impiego nel cercare le varie informazioni di un file\n\nposso per√≤ incorrere in problemi di sovradimensionamento della memoria\npi√π √® piccolo pi√π impiego a cercare i blocchi ma risolvo la cosa detta prima\nOvviamente quando si parla di ricerca di un blocco si parla proprio di ‚Üí\nLatenza: tempo che perdi nel far girare la testina\n\n\nAvendo dischi da TB oggi si preferisce creare blocchi +grandi\nCome tracciamo i blocchi liberi?\nMetodo 1:potrei avere una lista di indici di blocchi liberi.\n\n\nha una rappresentazione sparsa(rivedi differenza tra sparso e denso)\nogni blocco pu√≤ contenere\n\nindirizzo di inizio del blocco libero\nlunghezza conto quanti blocchi avr√≤ liberi\n\n\nla free list ha i puntatori utilizzati nella memoria RAM\ngli altri nel disco\n\n\n\n                  \n                  Queste strutture sono caricate nel s.o. \n                  \n                \n\nMetodo 2: bitmap, 1 indica libero 0 indica pieno\nrimane sempre in memoria rispetto al metodo 1 che si svuota a secondo del numero dei blocchi pieni o liberi\n\ntutta la bitmap indica tutta la memoria\nogni rettangolo una sua porzione\n\n\n\nGestione e assegnazione delle quote nei sistemi multiutente\nL‚Äôamministratore assegna per ogni utente una quota\n\nsi intende un numero massimo di blocchi liberi e file\nil SO controlla se non si supera questa quota e tiene traccia di quanti file aperti ha un utente o un processo nella tabella dei file aperti ogni file aperto contiene:\ni suoi attributi(visti nella lez scorsa)\nindirizzi del disco(dove si trova il file)\nutente: l‚Äôutente che legge il file\npuntatore alla tabella delle quote\nLa tabella delle quote √® una tabella che tiene traccia delle quote di ogni utente e dei suoi file aperti\nAbbiamo due limitazioni\nsoft: io singolo utente posso superare quel limite di quota per poco tempo\nHard: se lo supero mi viene fatta una restrizione in termini di accesso\n\n\nCome √® organizzato Ext2\n\nExt2 viene usato principalmente in Linux ed √® un File System\n\nsuddiviso in gruppi di blocchi\nogni gruppo di blocchi ha\n\nsuper blocco\n\ncontiene i dettagli sui blocchi liberi e non del disco e il numero di I-node\n\n\ndescrittore del gruppo\n\ndettagli aggiuntivi sui blocchi liberi, I-node e posizione delle varie Bitmap\n\n\nBitmap\n\ntraccia i blocchi liberi e I-node liberi\n\n\nI-node i meta\n\ndati di un file\n\n\nblocchi di dati\n\ncontengono i file e le directory del file system, non sono necessariamente contigui sul disco\nnella scrittura di file Ext2 si tende a minimizzare la frammentazione cercando di scrivere il pi√π possibile nell‚Äôarea di blocchi della stessa directory genitore finch√© non si esaurisce lo spazio\n\n\n\n\nper determinare le aree libere Ext2 usa le bitmap\n\nuna voce di questi blocchi si legge cos√¨\n‚ÄúColossale‚Äù √® un file (Tipo, F)\ncon nome lungo 9\ncon numero I-Node 19.\nquando elimino un file esso viene marchiato come libero ma rimane presente in memoria in attesa di una eventuale riscrittura\nper accedere ai file uso soft e hard link, inoltre uso anche eventuali comandi di open\nviene sfruttata una cache che migliora l‚Äôaccesso agli ultimi file visitati o in base ad altre caratteristiche\n\nPerformance(tecniche per migliorarle)\nVelocit√† di accesso:\ntutto il computer √® molto pi√π veloce del disco quindi bisogna ottimizzare le cose in modo che il File system sia veloce\nAll‚Äôinterno del sistema operativo vengono usate delle cache\n\nbuffer cache: memorizza i blocchi del disco in RAM per ridurre gli accessi ai blocchi in disco\npage cache: prima di essere blocchi ovviamente in modo pi√π virtuale e astratto sono pagine dei file, qui in questo caso vengono salvate le pagine pi√π utilizzate collegate al VFS virtual file system(spiego sotto)\n\n\nPrecisazione sulla cache\n√® sempre la stessa struttura dove ho dei blocchi con uso di hash per identificare rapidamente se un blocco √® nella cache\nse si cerca un file nella cache e non c‚Äô√® viene messo dal disco alla cache\nOgni elemento della cache viene messo in questa lista doppiamente collegata\n\nSe ho la memoria cache piena che faccio?\napplico degli algoritmi come quelli gi√† visti con dei vantaggi e svantaggi\nse ad esempio volessi usare LRU potrei avere limiti di inconsistenza in caso di crash\nPer prevenire la perdita di dati faccio sync dove ogni volta scrivo il ‚Äúbackup‚Äù su disco\nil sistema viene sempre basato sul fatto che pu√≤ sempre saltare la corrente\nCache buffer e Cache delle pagine sono entrambe da sincronizzare\nAvremo un virtual file system\nche punta a tutti i file system e fa da intermediario\nQuando dei file system vengono implementati devono avere un vettore da dare ai virtual file system\nRitorniamo alle slide prima\nPage Cache Buffer cache\ntutte e due sono nella ram e quindi devo gestirle entrambi cercando di ottimizzare la loro allocazione\nComandi gi√† visti e non\nfree\n\ngi√† visto\ndefrag\ncerca di scansionare tutti i blocchi di memoria e metterli vicini cos√¨ da evitare spazi piccoli non contigui di memoria\nimpiega molto tempo\nin Ext4 √® ottimizzato preallocando dei blocchi contigui cos√¨ da ridurre la frammentazione\n\ndeduplicazione e compressione\nAlcuni File System possono comprimere i file ad esempio sostituendo sequenze ripetute in modo da ridurre il peso di un file\n\nNFTS\nZFS\nInoltre altri possono ridurre le duplicazioni di file creando ad esempio Hard link e avere una sola copia in memoria\nper scoprire duplicazioni si fa durante la creazione del file inline oppure\nPost process in\nbackground un processo scansiona il tutto\n\nAFFIDABILIT√Ä\nPossono incorrere errori al File System di diverso tipo\n\numano\nsoftware\nhardware\n\nper risolvere si fanno i Backup\nci sono due tipi di backup\n\nfisici\n\ncopio i byte bit a bit 1:1\n\n\nlogici\n\ncopio in base alle ultime modifiche apportate all‚Äôalbero dei file\noppure uno specifico file\nsi effettua una copia ad alto livello basandosi su database o strutture dati astratte\n\nwayback machine di apple fatta bene\n\n\n\nStrumento rsync sincronizza una volta i file e poi modifica alle prossime sincronizzazioni solo i file cambiati\n\nmolto versatile\nconsente anche accessi da remoto\ncon a manteniamo i permessi e la struttura precedente\ncon v ci ritorna i dettagli sul trasferimento\nnormale:\n\nrsync -av /sorgente/cartella /destinazione/cartella\nda remoto:\nrsync -av /sorgente/cartella utente@remoto:/destinazione/cartella\nCoerenza dei file\nIMPORTANTE\nse avviene un crash potrebbe avvenire la perdita di informazioni\nuso delle utility per verificare la coerenza dei dati\n\nvengono eseguite all‚Äôavvio dopo un crash\nJournaling\nprima di eseguire una modifica sul file sysem si salvano le operazioni da fare in un registro journal.\nsi controllano\n\nse salta la corrente posso capire cosa non e stato fatto e posso ripristinarlo\nVirtual File System(VFS)\nil VFS consente di utilizzare diversi File System in un‚Äôunica macchina virtualizzandoli\n\nNFTS\nFAT-32\nExt2\necc‚Ä¶\nIl VFS ha due livelli principali:¬†\nSuperiore:¬†\n\nInteragisce con le chiamate di sistema POSIX come OPEN, READ E WRITE¬†\n\n\nInferiore:¬†\n\nDecine di funzioni che il VFS invia ai file system sottostanti\n\n\n\n\nStruttura del VFS\n\n\nSuperblock:¬†tipo di file system, nome, dimensione e dove si trova\n\n\nV-NODE:¬†\n\nrappresenta ogni file o directory del VFS, contiene i metadati (permessi, propriet√†, dimensione del file e riferimenti ai dati sul disco).\n√à usato dal VFS per rendere l‚Äôaccesso ai file indipendente dal tipo di file system.¬†\n\n\n\nDirectory del FS:\n\npermette al VFS di mappare i nomi dei file ai loro v-node indipendentemente dal FS in cui questi file si trovano.\nfacilita la navigazione e l‚Äôaccesso ai file.\n\nQuando viene aggiunto un nuovo file system questo deve registrarsi al VFS fornendo un serie di funzioni specifiche (lettura, scrittura, montaggio, ecc‚Ä¶ )\n\n\n\nQuando viene montato un nuovo file system (es. USB), il VFS crea un v-node per i file presenti e mappa le operazioni richieste a quel file system.¬†\nIl VFS poi tiene traccia dei file aperti e utilizza il v-node per sapere quale file system deve gestire una specifica richiesta.\nRAID\nDisaster recovery: backup in un altro posto\n√® decisamente a basso livello legato all‚Äôhardware\nlezione RAID\nFILE SYSTEM V7 UNIX\n\nHa reso UNIX famoso con una gestione con il numero di i-node e il nome del file\nDa notare che per ogni i-node vi era un contatore incrementato o decrementato in base al numero di link con esso.¬†\nAnche in questo file system era possibile muoversi attraverso\n\npercorsi assoluti(parto dalla radice)\nrelativi(parto da una generica cartella)\n\nIl passaggio a EXT avvenne soprattutto per\n\naver introdotto il VFS\nsuperare i limiti di 2GB\n2 e 3 introdussero blocchi di dimensione variabile\ncon Ext3 venne introdotto il journaling\ncon BTFRS venne introdotto il copy on write\n\nUNA CARRELATA DI COMANDI\nVisualizzazione delle partizioni¬†¬†\nComando¬†lsblk¬†¬†\nMostra un elenco dei dispositivi a blocco dove per blocco si intendono proprio i blocchi del disco, mi permette di vedere anche dischi e partizioni.¬†\nComando¬†fdisck -l¬†\nElenca tutte le partizioni su disco comprese quelle non montate¬†¬†\nComando¬†mount -l¬†\nElenco dei file system appena montati con le loro opzioni di montaggio ed etichette¬†\nComando per fare il mount di una partizione su file system\nmount [opzioni] &lt;dispositivo&gt; &lt;directory&gt;\ntipo\nsudo mount /dev/sda1 /mnt/mydisk\nquindi dev monta mnt\n"},"UNI/ANNO-2/SISTEMI-OPERATIVI/SISTEMI-OPERATIVI-LEZ.19":{"slug":"UNI/ANNO-2/SISTEMI-OPERATIVI/SISTEMI-OPERATIVI-LEZ.19","filePath":"UNI/ANNO 2/SISTEMI OPERATIVI/SISTEMI OPERATIVI LEZ.19.md","title":"SISTEMI OPERATIVI LEZ.19","links":[],"tags":[],"content":"PRINCIPI DELL‚ÄôHARDWARE DI I/O\nil mondo dell‚ÄôI/O √® un mondo vastissimo\nPer gestire al meglio hardware il sistema operativo deve avere delle funzionalit√† importantissime\n\ninvio dei comandi\nintercettazione di interrupt\ngestione degli errori\nusare una interfaccia che funzioni con + dispositivi e +sistemi\n\nci sono due punti di vista\n\nquello degli ingegneri elettronici\n\nche vedono la scheda come una vera e propria scheda fisica\n\n\nquello dei programmatori\n\ninteressati alle interfacce che permettono di utilizzare gli hardware con comandi ecc‚Ä¶\n\n\n\nDISPOSITIVI I/O\nCi sono due macro categorie di dispositivi di I/O:\n1. dispositivi a blocchi\nAstraggono i dati in forma di blocchi di dati di dimensioni fisse e che prevedono l‚Äôesistenza di indirizzi\n\nHDD, SSD e  nastri\nogni blocco viene scritto e letto indipendentemente\n\n2. dispositivi a caratteri\nflusso di caratteri senza struttura a blocchi\n\nmi limito a inviare e ricevere dati senza gestirli in modo indirizzabile o effettuando ricerche\nstampanti interfacce di rete mouse\n\nalcuni non fanno parte completamente di uno o dell‚Äôaltro\nschermi mappati in memoria\nalcuni dispositivi per semplificazione vengono messi nel file system dal sistema operativo\nVelocita dei dispositivi che hanno impatti importanti\n\npanoramica generale dei dispositivi e i vari controller\nil s.o. comunica con i controller dei dispositivi\n\ncontroller integrato nella scheda madre\n\nLa scheda madre √® divisa in northbridge e southbridge\nnorthbridge √® il piu veloce e interagisce con il pci-e\nil southbridge √® il piu lento e interagisce con le cose pi√π lente\n\nStandard delle interfacce\ntipo sata scsi thunderbolt ecc‚Ä¶\nconsentono di utilizzare dispositivi da diverse aziende\ninterfacce di basso livello\nsono le ultime interfacce possibili e si occupano della gestione dei veri e propri bit\neffettuano verifiche e controlli per gli errori dei bit con ad esempio ECC(Error Correction Code)\nUna vecchia porta parallela\n\n\nvecchia interfaccia per stampanti ecc\n8 spinotti per scambiare i dati\n8 per i comandi effettivi\naltri per la gnd e alimentazione\nporta usb\n\nla vecchia porta usb √® una interfaccia standardizzata per effettuare una connessione con il computer e i dispositivi\n\n2 pin per alimentazione e 2 per i dati\nin base alle onde positive o negative si codifica e decodifica il segnale\n\ndiverse versioni di usb portano una forte retrocompatibilit√† e sono plug-play\ntabella di porte usb\n\nun disco hdd come √® fatto\nPCB √® il circuito che ha\n\nal centro una MCU (micro controller unit)\ncache una ram usata per una cache\nVCM controlla la rotazione del motore del disco\n\n\nCome comunicano dispositivi e CPU\nogni dispositivo ha un controller che fa da intermediario tra cpu e dispositivo\nquesto controller ha dei registri dove scrivere e leggere le informazioni\nmolti hanno una area detta buffer dove vengono conservati i dati mentre vengono letti o scritti\nCome avviene? importante\nuso due approcci per inviare i dati\n\nI/O port-mapped\nI/O memory-mapped\nversione ibrida\n\nPort mapped I/O\nper rappresentare un dispositivo hardware uso ad esempio port mapped I/O\nogni porta √® un collegamento con quel dispositivo definito attraverso un indirizzo\nogni porta a 8 o 16 bit\nuso istruzioni differenti dal solito assembly\n\nIN REG, PORT  per la lettura di port e salva in reg\nOUT PORT,REG per scrivere\ndue spazi di indirizzi uno per la ram e uno per i dispositivi di I/O\n\n\nMemory mapped I/O\n\nma perch√© non mettiamo tutto insieme?\nogni dispositivo viene mappato in memoria insieme alle altre cose con degli indirizzi univoci\ni registri hardware sono accessibili solo dal kernel, garantisce maggiore sicurezza\nAttraverso la gestione delle pagine di memoria, il sistema pu√≤ controllare dispositivi in modo selettivo.\npotrebbe esserci un problema relativo all‚Äôutilizzo della cache\ndove un registro viene salvato in cache e non subisce cambiamenti dal dispositivo e quindi il dato non si aggiorna\n\ndi questo sistema c‚Äô√® una problematica che prevede 2 soluzioni\nil sistema non sa se ha a che fare con un indirizzo in memoria o che appartiene a un dispositivo hardware\n\nprima soluzione a tentativi lenta ma facile da scrivere\nbus snooping come seconda soluzione che monitora quali sono i dispositivi di I/O e determina se un indirizzo √® associato a un dispositivo hardware o alla memoria principale.\nnecessit√† di bilanciare prestazioni e efficienza\n\nIBRIDO\n\nsi usano entrambi i metodi uno per operazioni pi√π rapide l‚Äôaltro per operazioni pi√π lente\nPMIO e MMIO, il primo per fare roba pi√π lenta l‚Äôaltro roba pi√π veloce\nDirect memory access\nDMA VS SENZA\nIl controller DMA consente lo scambio di dati dei dispositivi senza uso della CPU\n\nsenza DMA il controller del disco legge i dati e li memorizza nel suo buffer e li invia al SO\ncon DMA la CPU dice al DMA attivati e dice al controller del disco attivati e li fa lavorare\n\nIl controller DMA pu√≤ essere\nsemplice(1 trasferimento per volta)\ncomplesso(+ trasferimenti)\n\ninoltre possono essere pi√π personalizzabili\ngestiscono pi√π controller di dispositivi\n\n\n\nCome trasferisco i dati?\ntutti i blocchi citati riguardano un conflitto di bus\n\ncycle stealing: invio un pacchetto alla volta rubando cicli alla cpu, perch√© ogni volta la interpello\nmodalit√† burst: invia tutto con una botta rubando il bus per quel tempo\nfly by mode: trasferisce direttamente alla memoria principale senza cpu usando semafori mutex o roba cosi\n\nCome arriva l‚Äôinterrupt\n\ntrap, azione deliberata, expected\nfault, azione non deliberata, unexpected\ninterrupt hardware segnali inviati da dispositivi come stampanti alla CPU\nl‚Äôinterrupt viene gestito da un controller\nse ho piu interrupt li gestisco con delle code e algoritmi\n\n\nSTEP interrupt\n\nun dispositivo richiede attenzione alla CPU inviando un interrupt alla CPU, il controller assegna un numero a quel dispositivo per identificarlo\nla CPU interrompe ci√≤ che fa e ha un vettore degli interrupt dove ad ogni numero corrisponde un indirizzo di quello che deve eseguire a seconda dell‚Äôinterrupt. Quando un dispositivo corrisponde a un numero la CPU prende quel numero e lo confronta con l‚Äôarray e esegue quella determinata riga di codice\nsfrutta il vettore degli interrupt, per eseguire una procedura puntando alla sua base\nuna volta eseguita tutta la routine quindi procedura ecc‚Ä¶ la cpu scrive nel controller degli interrupt per dire che ha finito questo √® utile per evitare race conditions ovvero conflitti\nil program counter deve essere salvato per far riprendere la CPU ci√≤ che stava facendo\nle informazioni dai dispositivi di I/O viene salvato nei registri interni o sullo stack\nci sono due tipi di stack, uno nel kernel uno invece che appartiene al processo utente, con quello utente si possono creare errori, quello del kernel richiede cambi di contesto che rallentano un po‚Äô le cose\n\ninterrupt precisi vs imprecisi\n\nla CPU grazie a pipeline pu√≤ gestire pi√π processi senza che debbano per forza finire\nquesto complica la gestione degli interrupt\nabbiamo due tipi di interrupt:\n\ninterrupt precisi: il sistema quando avviene un interrupt pu√≤ determinare con esattezza quali istruzioni sono state completate\ninterrupt imprecisi: salviamo gli stati di completamento degli interrupt non sapendo effettivamente lo stato del programma\ncon gli interrupt precisi:\n\n\nforzo che le istruzioni terminino\ntutte le istruzioni prima del program counter sono state eseguite\nla CPU annulla tutti gli effetti transitori eseguiti dopo il PC, per evitare azioni non prevedibili\nquando avviene un interrupt vengono completate tutte le istruzioni prima di quella che stava per fare la CPU cos√¨ si ha uno stato definito\ncon gli interrupt imprecisi:\nogni istruzione viene lacciata con uno stato di completamento\nsalvare tutti questi stati rallenta il computer\nnon tutti gli effetti sono completamente annullati\n"},"UNI/ANNO-2/SISTEMI-OPERATIVI/SISTEMI-OPERATIVI-LEZ.2":{"slug":"UNI/ANNO-2/SISTEMI-OPERATIVI/SISTEMI-OPERATIVI-LEZ.2","filePath":"UNI/ANNO 2/SISTEMI OPERATIVI/SISTEMI OPERATIVI LEZ.2.md","title":"SISTEMI OPERATIVI LEZ.2","links":[],"tags":[],"content":"\n\n                  \n                  lista di domande \n                  \n                \n\nDOMANDE\n\nSi analizzi il concetto di multiplexing in un sistema operativo. Come si differenziano le modalit√† di condivisione temporale e spaziale delle risorse? Si forniscano esempi pratici.\n\n\n\n                  \n                  la risposta \n                  \n                \nl‚Äôho spiegato alla domanda prima\n\n\nSi illustri il ciclo di vita di un processo in un sistema operativo moderno. Quali sono le transizioni di stato principali e come vengono gestite dal kernel?\n\n\n\n                  \n                  la risposta \n                  \n                \nun processo viene:\n\n\ngenerato\neseguito\nviene messo in fase di blocco\nsi riprende\nsi pu√≤ clonare\npu√≤ interrompersi\ninoltre ha 3 stati principali : bloccato, esecuzione, pronto\nse un processo viene messo in stato di blocco i suoi registri vengono salvati per poi essere riusati\n\n\n\n\nSi fornisca una spiegazione del funzionamento delle chiamate di sistema, con particolare attenzione al passaggio dalla modalit√† utente alla modalit√† kernel. Qual √® il ruolo delle istruzioni trap?\n\n\n\n                  \n                  la risposta \n                  \n                \nil processo pu√≤ avere cambi di contesto dove passa dallo spazio utente allo spazio kernel, con esso vengono salvati tutti i registri di quel processo e vengono spostati nello spazio di memoria kernel, le istruzioni trap hanno lo scopo di prendere il processo nella sua interezza catturandolo a seconda di determinate condizioni che la innescano\n\n\nSi inviti il candidato a spiegare il funzionamento di una pipe in Linux. Qual √® l‚Äôimportanza delle pipe nella comunicazione tra processi? Si fornisca un esempio pratico.\n\n\n\n                  \n                  la risposta \n                  \n                \nuna pipe √® uno pseudo-file utilizzato dai processi per comunicare tra loro, la pipe ha una sezione di input e una di output e funziona attraverso una logica di tipo FIFO\n\n\nSi definisca il ruolo del Program Counter (PC) e dello Stack Pointer (SP) nella gestione di un processo. Come il sistema operativo utilizza questi registri durante il cambio di contesto?\n\n\n\n                  \n                  la risposta \n                  \n                \nquesti registri sono in ogni processo\nil program counter ha lo scopo di puntare all‚Äôistruzione successiva che deve essere eseguita dal processo\nlo stack pointer punta alla cima dello stack del processo, infatti ogni processo ha uno stack dove vengono salvate le informazioni utilizzate nel corso del codice\nil s.o. li usa per il cambio di contesto per far riprendere l‚Äôesecuzione del codice senza causare problemi di alcun tipo\n\n\nSi descriva il funzionamento di un file system montato in un sistema UNIX. Quali sono le implicazioni della formattazione del dispositivo per il sistema operativo?\n\n\n\n                  \n                  la risposta \n                  \n                \nun file system in un sistema UNIX ha una gerarchia ad albero molto organizzata e che si dirama a partire dalla root / ogni file come anche cartelle sono strettamente collegate in qualche modo ad essa, quando andiamo ad inserire un dispositivo esterno di memorizzazione che ha un suo file system lo aggiungiamo a quello del nostro s.o. attraverso il mount, esso verr√† adeguatamente messo nella gerarchia\n\n\n\nQUANTI NE ESISTONO\nTanti ma ci sono famiglie\n\nSistemi per mainframe(grandi computer per banche)\n\ngestiscono pi√π transazioni quindi concetto di gestione simultanea e Multiplexing\nnon √® richiesta l‚Äôinterazione dall‚Äôutente\ntransazione una sequenza di operazioni con garanzia che vengano eseguite con successo\n\n\nSistemi per Server\n\ncomputer con funzionalit√†, risorse e operazioni complesse\npossono accedervi pi√π utenti\n\n\nSistemi per personal computer\n\nsupportano un singolo utente\nhanno una interfaccia facilitata\n\n\nSistemi per Smartphone e Tablet\n\nprevedono un solo utente e ottimizzazione delle librerie per uso di app di terze parti software e hardware\n\n\nSistemi per IoT e embedded(dispositivi perfetti per svolgere un solo compito)\n\ncomponenti di circuito hardware come frigoriferi, lavatrici ecc‚Ä¶\nnon general purpose e leggeri e limitate\n\n\nSistemi real-time\n\nquando deve rispettare scadenze rigide con quanti temporali da dover rispettare e che non venga mai rimandato\n\n\nSistemi operativi per Smart Card:\n\nSistemi estremamente recenti come carte con contatti ecc\ntante volte si usa Java\n\n\n\nCOSA Hanno in comune?\n\nExtended machine\n\nestraggono nascondono e estendono funzionalit√† hardware e cose complicate\n\n\nResource manager\n\nl‚Äôuso simultaneo con condivisione equa delle risorse e eventuali limitazioni\n\n\n\nConcetti base di un sistema operativo\n\nil s.o. offre le sue funzionalit√† attraverso delle chiamate di sistema\nil s.o. ha dei servizi ovvero n chiamate di sistema es(file system,Process management Service)\nOgni processo ha il proprio spazio di indirizzamento\nUn processo non avr√† uno spazio di memoria dedicato fisico ma avr√† una partizione della memoria: esempio con mattonella dando una piccola porzione di mattonella dinamicamente\nI file persistono rispetto ai processi\n\nCos‚Äô√® un processo?\nIl processo √® un programma in esecuzione\n\n√® associato a uno spazio di indirizzi e a una serie di risorse come registri e file aperti\nIl s.o. deve salvare i vari SP,PC ecc per poi farlo riprendere durante l‚Äôalternarsi\nil processo pu√≤ essere visto come il contenitore di tutte le informazioni necessarie per l‚Äôesecuzione del determinato programma\n\nIL LAYOUT DI UN PROCESSO\n\n\n                  \n                  Quante linee sono FFFF? \n                  \n                \n\n\nF sono 4 bit\ncon 4 bit puoi rappresentare fino al numero 15 1111\nabbiamo 4 F quindi 16 bit\n1 byte sono 8 bit\nquindi sono 2 byte\n\n\n\n\n\n                  \n                  come viene rappresentato in memoria il processo? \n                  \n                \n\n\n\nStack: le Active call data √® una porzione di memoria che viene usata da un processo per metterci dentro informazioni durante la sua esecuzione, come risultati di funzioni che poi una volta finito il processo vengono eliminate\nData: vengono messe le variabili del programma e possono essere locali e globali\nText: viene messo il codice del programma\n\n\n\nCICLO DI VITA DI UN PROCESSO(generazione di un processo)\nIl s.o. ha una tabella con tutte le info sui processi\n\nquando un processo √® sospeso potr√† riprendere l‚Äôesecuzione grazie alle informazioni e registri salvati nella tabella dei processi e anche grazie al suo spazio di indirizzi di memoria\nun processo pu√≤:\ncrearsi\nterminarsi\nsospendersi\nriprendersi\ncreare un‚Äôaltro sotto processo come ‚Äúfiglio‚Äù\nOgni processo pu√≤ clonarsi quindi c‚Äô√® bisogno di un PID(Process-Id) per identificare i\nprocessi\n\nStati di un processo\n\n\n\n                  \n                  Un albero di processi composto da processi e processi figli \n                  \n                \n\n\n\n\nCHI POSSIEDE UN PROCESSO?\nOgni processo e‚Äô collegato a un UserId\n\n\n                  \n                  su Unix un processo figlio ha stesso UId di un processo padre \n                  \n                \n\nOgni utente pu√≤ essere in un gruppo identificati con GUid\nPoi c‚Äô√® super-user root con pi√π privilegi\nFILE\nAstrazione di un dispositivo di memorizzazione reale e non tipo un disco\nOgni file non ha continuit√† di bit ma frammentazioni\nRisorsa=File=sequenza di 1,0\nSTRUTTURAZIONE PER CERCARE FILE\nCon win abbiamo c: ‚Ä¶\nCon UNIX abbiamo nodo radice e sotto nodi che sono risorse ecc\n\nla directory principale root √® /\nci sono Absolute Path come /home/ast/todo-list\npercorsi a partire dalla directory dove siamo ../courses/slides1.pdf\naltri filesystem(CD,DVD,USB‚Ä¶) possono essere montati nella root /mnt/windows\n\n\n\n                  \n                  Cartella e&#039; un file? \n                  \n                \n\nSiüëç\n\n\npropriet√† file con metadati\n\n\n                  \n                  I file sono protetti da tre bit che corrispondono a diverse entit√† di una macchina, ogni bit consente o meno determinate attivit√† sul file \n                  \n                \n\n\n\nr=read\nw=write\nx=execute\nRosso=Owner Verde=Group Blu=Other\n14492 sono l‚Äôunione di tutti i frammenti di questo file in memoria che formano una serie di byte\n\n\n\nIl sistema operativo non decide nulla quindi fa le cose in base allo user che lo usa\nEsempio di organizzazione di un file system\nUn file system viene organizzato in una certa struttura arborea\n\n\n                  \n                  Fotoesempio\n                  \n                \n\n\n\n\nQuando eseguiamo un montaggio di un dispositivo nel s.o. la sua organizzazione deve essere riconciliata come quella del s.o.\nNon √® scontato questo cambiamento di struttura poich√© il s.o. potrebbe non riconoscere il tipo di formattazione della chiavetta\n\n\na) Prima del mount la USB non √® accessibile\nb)dopo la mount la USB si √® collegata nei file\n\nESEMPIO ACCESSO AI FILE\nESERCIZIO PER CASA\nTUTTO √® un file\nIn Linux i device hardware vengono visti come dei file\n\nBlock special file per I dischi\nCharacter special file per le porte seriali\n\nFILE A PIPE\nProcessi comunicano tra loro con le pipe, ovvero pseudo file che viaggiano su un canale FIFO\nScrivere un processo che comunica con altri processi attraverso pipe(chiede a esame)\n\nCHIAMATE DI SISTEMA\nUna chiamata di sistema permette ai programmi in user space (spazio utente) di richiedere servizi o risorse direttamente al kernel del sistema operativo. √à uno dei meccanismi fondamentali che consentono ai programmi di interagire con l‚Äôhardware e le risorse di sistema in modo controllato e sicuro.\nQuando un programma ha bisogno di un servizio che solo il kernel pu√≤ fornire (ad esempio leggere un file), deve effettuare una chiamata di sistema.\n\n\nDevono essere estremamente veloci\nTrap blocca il processo e lo sposta facendogli fare il cambio di contesto\nle chiamate di sistema variano a seconda del s.o. come soluzione si sono create delle chiamate di sistema generiche per ogni s.o. POSIX\n\nquali sono le chiamate di sistema per la gestione dei processi che vedremo?\n\nil programma prepara i parametri della procedura che deve chiamare read(fd, buffer, nbytes)\nil programma chiama la procedura nella libreria (4)\nin un registro RAX viene immesso il numero che identifica il tipo di funzione del kernel che bisogna eseguire(read, write,open‚Ä¶), spesso questi numeri vengono messi in una tabella(5)\npassaggio a modalit√† kernel che avviene attraverso una istruzione trap verso il kernel(6)\nil gestore di chiamate di sistema viene eseguito(8)\nviene ridato il controllo alla procedura utente(10)\n\n"},"UNI/ANNO-2/SISTEMI-OPERATIVI/SISTEMI-OPERATIVI-LEZ.20":{"slug":"UNI/ANNO-2/SISTEMI-OPERATIVI/SISTEMI-OPERATIVI-LEZ.20","filePath":"UNI/ANNO 2/SISTEMI OPERATIVI/SISTEMI OPERATIVI LEZ.20.md","title":"SISTEMI OPERATIVI LEZ.20","links":["UNI/ANNO-2/SISTEMI-OPERATIVI/SISTEMI-OPERATIVI-LEZ.14"],"tags":[],"content":"Nella scorsa lezione abbiamo parlato dei dispositivi di I/O ora parleremo dei software che li gestiscono\nCome deve essere il software di I/O\n\nindipendente dal dispositivo\n\nun programma che legge un file deve funzionare se uso ssd o usb\n\n\ndenominazione uniforme\n\ni nomi dei file devono essere indipendenti dal dispositivo e devono essere stringhe o numeri\nad esempio in UNIX per andare su un file non ci indirizziamo al dispositivo con ST6NM04 ma usiamo ad esempio /mnt/movies rispettando la gerarchia del file system\n\n\nGestione degli errori\n\nil software di I/O deve gestire gli errori piu vicino possibile all‚Äôhardware al livello di controller per gestirlo adeguatamente\n\nerrori transitori: errori di fisica del mondo delay roba elettronica ecc‚Ä¶\n\n\n\n\ntrasferimenti sincroni o asincroni\n\nI/O fisico √® quasi sempre asincrono, i dati arrivano come arrivano.\n\nsiamo noi con i software che li trattiamo in modo bloccante dandogli del tempo\nil sistema operativo deve rendere sincrone e bloccanti le cose asincrone\nil DMA viene gestito dal s.o.\n\n\n\n\nbuffering dal software\n\nnon tutto pu√≤ essere trasmesso subito e bisogna sfruttare un buffer temporaneo per spostare tutto poi interamente\ncon dispositivi che hanno vincoli real-time ce ne accorgiamo perch√® ci sono vincoli sulle prestazioni, un buffer potrebbe comportare a delle attese maggiori\n\n\ndispositivi condivisibili o dedicati\n\ni dischi sono  a volte condivisi da pi√π utenti\nstampanti o scanner sono dedicati per la maggior parte dei casi\nil sistema operativo deve evitare deadlock\n\n\n\nTipologie di software per I/O\nI/O programmato\nLa CPU gestisce tutto il processo di trasferimento dei dati\nI/O viene gestito dal programma\nESEMPIO:\n\nun utente vuole stampare ‚ÄúABCDEFGH‚Äù\nabbiamo questa stringa in un buffer nello spazio utente\neffettuo la chiamata di sistema per stamparlo\ncopio questa stringa nello spazio kernel\ninvio i caratteri uno per volta alla stampante aspettando che sia pronta a riceverne uno nuovo\n\nPOLLING O BUSY WAITING\nQuesta attesa data dal fatto che il s.o. deve andare a controllare il registro di stato della stampante per vedere se pu√≤ inviare un nuovo carattere si dice\n\nciclo di polling\n\ncontrollo periodico dello stato di un dispositivo o di una condizione\nprevede delle pause quindi non ruba tutta la CPU\noppure\n\n\nbusy waiting\n\nsimile a quello sopra ma non prevede pause senza per√≤ rilasciare la CPU\n\n\n\n\n\n                  \n                  differenza tra busy waiting e cycle stealing \n                  \n                \n\n\nil busy waiting riguarda il controllo di variabili o dispositivi\nil cycle stealing riguarda un dispositivo che ruba cicli alla CPU per accedere ai bus di trasferimento dati al posto di farlo usare dalla CPU\n\n\n\n\nCodice che usa stampante 1\n\n\ndevo copiare dal buffer utente al buffer kernel copy_from_user()\ncontrollo e attendo disponibilita della stampante con un while che confronta il registro\ninvio i vari caratteri al registro della stampante\n\n\n\n                  \n                  problema del codice: \n                  \n                \n\nil while crea un busy waiting\n\n\nCodice che usa stampante 2\n\n\nQuesto codice ottimizza le cose\n\ncopio il buffer utente in uno del kernel\nabilito gli interrupt che verranno utilizzati dalla stampante\nattendiamo che il registro della stampante sia pronto\nscrivo il primo carattere in assoluto\npasso il controllo a un altro processo chiamando lo scheduler\nla stampante invia un interrupt al processo  quando ha finito di scrivere il primo carattere e riprende l‚Äôesecuzione del processo\n\nin sostanza gli dice ‚Äúne hai altri?‚Äù\n\n\nil processo lo verifica con count\n\nse sono finiti sblocca il processo utente ‚Äúpadre‚Äù ovvero quello che chiama il processo di stampa\nviene sbloccato con unblock_user()\n\n\nse count non √® 0\n\nscrive la posizione i del buffer nel registro della stampante *printer_data_register\ndecrementa count perch√© inserisce un elemento\nincrementa l‚Äôindice del buffer\n\n\nakcknowledge_interrupt() serve per dire alla stampante quindi a chi ha inviato l‚Äôinterrupt che esso √® stato gestito correttamente\nreturn_from_interrupt() fa riprendere alla CPU altre operazioni\nogni volta la stampante invier√† interrupt il che √® un problema\n\naltrimenti uso il DMA gli invio tutto a lui e gli dico ‚Äúcazzi tuoi‚Äù\nil DMA riduce significativamente il numero di interrupt\nla CPU fa un interrupt al DMA e gli dice che se la deve gestire lui\nscambia le informazioni con la stampante\nil DMA prende il buffer dal kernel\nrestituisce allo scheduler()\nil DMA invia un interrupt una volta finito\nfa i vari unblock ecc‚Ä¶\n\n\n\n                  \n                  chiarimento spicciolo \n                  \n                \n\nin poche parole questo processo sposta il buffer nel kernel e fa fare tutto al DMA una volta che il DMA ha finito dice al processo che l‚Äôha chiamato e restituisce tutto il controllo alla CPU\n\n\nStruttura del software di I/O\n\nho quattro livelli che caratterizzano il software di I/O\nora studieremo i gestori degli interrupt ‚Üí\nGestori degli interrupt\n\ndevo bloccare i driver fino al completamento dell‚ÄôI/O\n\ni driver devono essere usati da un dispositivo alla volta, c‚Äô√® una sorta di semaforo\nl‚Äôaltra cosa √® che ci deve essere la possibilit√† di bloccarli per sincronizzare lo scambio di informazioni\n\n\ngestione degli interrupt complesso\n\npoich√© bisogna salvare vari registri per poi riprendere quella determinata esecuzione, impostare contesti e usare controller degli interrupt\n\n\nimpatto sulla memoria virtuale bisogna gestire TLB MMU e cache per i dispositivi che le usano\n\nvedi SISTEMI OPERATIVI LEZ.14\ngestirli aumenta l‚Äôuso della CPU\n\n\ntutta questa roba richiede numerosi cicli della cpu\n\nCosa succede al software quando arriva un interrupt\npunti molto generali\n\nsalvo tutti i registri\nimposto il contesto con tabelle TLB MMU ecc‚Ä¶\n\nimposto il contesto significa che mi preparo per gestire l‚Äôinterrupt\n\n\nimpostare lo stack, vado a posizionare il program counter sulle istruzioni per eseguire la procedura\nconfermo al controller degli interrupt e riabilito l‚Äôinterrupt\n\ncos√¨ posso mandare altri interrupt tipo CTRL+C\naltrimenti non potrei inviare l‚Äôinterrupt di terminazione della procedura\nconfermo al controller che l‚Äôinterrupt √® stato preso in carico\n\n\nvisto che il processo √® interrotto copiamo i suoi registri ecc‚Ä¶ nella tabella dei processi\neseguo la procedura di servizio dell‚Äôinterrupt\n\nora finalmente eseguo il codice dell‚Äôinterrupt\nAd esempio, invia un nuovo carattere alla stampante\n\n\ndetermina quale processo eseguire come successivo o con alta priorit√† o quello che era stato bloccato dall‚Äôinterrupt chiamato prima\nreimposto il nuovo contesto del processo con le varie tabelle MMU TLB ecc‚Ä¶\nCarico i nuovi registri come il PSW che contiene i bit di condizione ecc‚Ä¶\navvio il nuovo processo\n\nDRIVER DEI DISPOSITIVI\nOra ci troviamo ad un livello superiore quello dei driver dei dispositivi\ni driver sono dei codici specifici per ogni dispositivo, lo gestiscono tramite i suoi registri.\nAl pi√π i driver gestiscono una classe di dispositivi correlati tra loro ma spesso sono unici per ogni dispositivo.\nTecnologie come USB utilizzano una pila di driver per gestire vari dispositivi\nI DRIVER della tecnologia USB sono divisi in 3 livelli\n\nLivello base: Gestisce I/O seriale e questioni hardware\nLivelli superiori: trattano pacchetti per lo scambio di dati e funzionalit√† comuni\nAPI di alto livello: le varie interfacce dei dispositivi\n\nPosizionamento nel Kernel\nI driver di solito sono al livello Kernel per accedere meglio ai vari registri del controller del dispositivo\n\n\n                  \n                  Se fossero messi nello spazio utente? \n                  \n                \n\n\npi√π facili da installare e mettono meno a rischio il sistema operativo\nMA sono pi√π lenti (devono passare allo spazio Kernel per ogni operazione)\n\n\n\nFunzionalit√† e interfaccia dei driver dispositivo\n\nI driver per essere installati vengono visti come dei veri e propri dispositivi\ne vengono classificati in:\n\nA BLOCCHI: si leggono sequenzialmente, contengono blocchi di dati, e spesso sono dischi\nA CARATTERI: generano o accettano flussi di caratteri tipo stampanti o tastiere\nalcuni driver nel passato erano caricati direttamente in binario nel s.o. ora vengono caricati in modo dinamico\n\nImplementazione e complessit√† dei driver di dispositivo\nFunzioni\nI driver svolgono diverse funzioni tra cui\n\ngestioni di lettura e scrittura\ninizializzazione del dispositivo\ngestione dell‚Äôalimentazione\nregistrazione degli eventi e attivit√†\n\nProcesso generale\nPer assicurare una corretta comunicazione tra hardware e software, il driver esegue una serie di operazioni\n\nverifica la validit√† dei parametri di input ricevuti dal SO o dall‚Äôutente\ntraduce i parametri in comandi compatibili col dispositivo\ngestisce l‚Äôutilizzo del dispositivo\n\nGestione di I/O e errori\nI driver devono anche gestire efficientemente l‚ÄôI/O e prevenire errori critici, aspettando in alcuni casi un interrupt per completare l‚Äôoperazione.\nComplessit√† e rientranza\nPer supportare un ambiente multitasking e garantire stabilit√†, i driver devono essere progettati con caratteristiche specifiche\n\ndevono essere RIENTRANTI, ossia poter gestire pi√π richieste simultaneamente (quelli di ‚ÄúRETI‚Äù sono cos√¨)\ndevono permettere la connessione e disconnessione dinamica dei dispositivi (HOT-PLUGGING)\n\nse un nuovo dispositivo viene aggiunto, deve inizializzarlo correttamente\nse un dispositivo viene rimosso improvvisamente deve interrompere TUTTE le operazione e evitare tentativi di accesso\n\n\n\nSoftware di I/O indipendente dal dispositivo\nSaliamo ancora di livello e arriviamo a dei software dal dispositivo\n√à un software universale per standardizzare la comunicazione tra hardware e applicazione utente\nfungendo da intermediario e interfaccia.\nLe sue funzioni chiave includono:\n\nFornire un‚Äôinterfaccia uniforme per diversi driver\nottimizzare il trasferimento dei dati attraverso il buffering\ngestire e segnalare errori di comunicazione\nassegnare e rilasciare dispositivi dedicati agli utenti o ai processi\nstandardizzare la dimensione dei blocchi di dati, indipendentemente dal dispositivo.\n\n\n\n                  \n                  Perch√© √® utile avere uniformit√† con questo software? \n                  \n                \n\nL‚Äôuniformit√† evita di dover modificare il SO ogni volta che viene introdotto un nuovo dispositivo.\nAvere un‚Äôinterfaccia standard aumenta notevolmente l‚Äôefficienza.\n\n(a) INTERFACCE DIVERSE\n(b) INTERFACCE UNIFORMI\n\n\n\n\nImplementazione e gestione dell‚Äôinterfaccia dei driver\nsono fondamentali per la comunicazione tra SO e dispositivi hardware\ni driver contengono una tabella che ha riferimenti a funzioni specifiche\n\nquesta tabella viene usata dal SO per facilitare le chiamate indirette\n\nle chiamate indirette esistono perch√© il SO non fa chiamate a funzioni direttamente al driver ma si serve di un puntatore quindi le fa in modo indiretto\nOgni dispositivo ha un nome simbolico (es. /dev/disk0 in UNIX)\n\n\nper garantire la sicurezza vengono usati permessi tipo quelli dei file\nil SO fornisce una interfaccia standard per i driver facilitando l‚Äôintegrazione con nuovi dispositivi\n\nBuffering\n\nDiversi scenari\nil buffering √® fondamentale e lo capiamo dall‚Äôesempio\nBuffering visto in prospettiva di input\na) Esempio di lettura dati da un modem VDSL senza uso di buffer richiede un riavvio del processo\nutente per ogni carattere ricevuto\nb) Miglioramento con buffer nello spazio utente il processo fornisce un buffer, questo processo si\nriavvia solo quando il buffer risulta pieno\nc) Problemi di paginazione e soluzione con buffer nel kernel, stavolta il buffer √® nel kernel\nd) Doppio Buffer nel Kernel hai due buffer, uno accumula input mentre l‚Äôaltro √® in copia nello spazio utente\nBuffering visto in prospettiva di output\ngli esempi a e b sono analoghi poi ci sono\n\nsoluzione con buffer nel kernel copia nel buffer del kernel e sblocco immediato del processo utente\nIl buffering multiplo pu√≤ creare problemi in termini prestazionali\nSi creano troppe copie del buffer prima al kernel poi al controller poi sulla rete ecc‚Ä¶\ntrasmettere tutti questi pacchetti pu√≤ rallentare la velocit√† di trasferimento di essi\n\nGestione degli errori di I/O del sistema operativo\nsi utilizzano codici di errori hardware o software\n\nper quelli software si intendono quelli di programmazione che ritornano un codice d‚Äôerrore al chiamante del processo\nper quelli hardware li gestiscono i driver\nEsistono azioni che possono dipendere dal contesto\ndi tipo interattivo se c‚Äô√® un utente con cose tipo (riprova, ignora, termina‚Ä¶) per il croce sono inutili al cazzo\nnon interattivi ritornano semplicemente il codice d‚Äôerrore\nper strutture critiche se succede qualcosa si hanno dei codici d‚Äôerrore\n\nGestione dei dispositivi dedicati o esclusivi\n\nesclusivi ad esempio la stampante che pu√≤ essere in teoria usata da un solo processo alla volta\n\nEsiste un sistema che gestisce le richieste di uso del dispositivo\n\n\n\nmetodi di allocazione e rilascio\n\napproccio tradizionale\n\nun processo fa open su file speciali che indicano il dispositivo e close per chiudere il dispositivo\n\n\napproccio alternativo\n\nse la open non va a buon fine si mettono i richiedenti su una coda\n\n\n\nSistema di Spooling\n\n\n                  \n                  cosa significa \n                  \n                \n\n√® una tecnica per gestire i dispositivi dedicati in ambienti multiprogrammati evitando blocchi da parte di un solo processo\n\nin poche parole serve per sincronizzarli in modo armonioso\nin modo pratico uso un daemon e una directory di spooling per ordinare e gestire i lavori di stampa\n\ntutti questi sono i livelli del sistema di I/O\nle frecce indicano i flussi di controllo che attraversano i livelli\n\n\n\nUniformit√† nella dimensione dei blocchi dei dispositivi\nle dimensioni fisiche variano a seconda dei dispositivi\n\nper questo usiamo un software che astrae la memoria cos√¨ tutti risultano uniformi\nAstrazione dei dispositivi in unici blocchi logici\ni dispositivi che lavorano a caratteri trasmettono quantit√† di dati differenti, attraverso software si occulta questa cosa aumentando l‚Äôuniformit√†\n\nLibrerie di I/O nell‚Äôambito utente\nci sono librerie che facilitano le chiamate di sistema tipo write in c\npoi ci sono printf e scanf per facilitare le chiamate di sistema di input e output\nqueste librerie semplificano di molto la programmazione di I/O per lasciare ai programmatori spazio per pensare alla logica delle applicazioni e non perdere tempo su dettagli a basso livello"},"UNI/ANNO-2/SISTEMI-OPERATIVI/SISTEMI-OPERATIVI-LEZ.3":{"slug":"UNI/ANNO-2/SISTEMI-OPERATIVI/SISTEMI-OPERATIVI-LEZ.3","filePath":"UNI/ANNO 2/SISTEMI OPERATIVI/SISTEMI OPERATIVI LEZ.3.md","title":"SISTEMI OPERATIVI LEZ.3","links":[],"tags":[],"content":"\n\n                  \n                  lista di domande \n                  \n                \n\nDOMANDE\n\nSi definisca il concetto di memoria virtuale e si descriva il ruolo del sistema operativo nella gestione delle pagine di memoria. Qual √® l‚Äôeffetto di un page fault sulle prestazioni del sistema?\n\n\n\n                  \n                  la risposta \n                  \n                \n\n\nSi esamini la struttura di un sistema operativo monolitico. Quali sono i vantaggi e gli svantaggi rispetto a un microkernel?\n\n\n\n                  \n                  la risposta \n                  \n                \nun sistema operativo monolitico √® usato ad esempio nei sistemi UNIX, esso presenta un unico codice, √® molto veloce ma allo stesso tempo √® decisamente contorto poich√© si trova tutto in un unico posto, ci√≤ causa problematiche di manutenzione e aggiornamento. un sistema monolitico viene spesso usato quando √® difficile disaccoppiare i vari codici, quindi ognuno di loro √® strettamente dipendente da altro.\nnei sistemi monolitici abbiamo le librerie condivise, in windows sono le DDL in UNIX si chiamano shared library, che consentono di non riscrivere mille volte lo stesso codice. il microkernel ha come vantaggio quello di essere molto pi√π sicuro poich√© si basa su un sistema client-server dove le varie chiamate di sistema avvengono attraverso dei messaggi condivisi tra le varie parti, il kernel ha l‚Äôessenziale per funzionare e tutto il resto √® su pi√π livelli, ci√≤ aumenta di molto la sicurezza ma rallenta la velocit√† e l‚Äôimplementazione √® pi√π difficile\n\n\nSi analizzi il concetto di containerizzazione. In che modo i container differiscono dalle macchine virtuali e quali sono i vantaggi di questa tecnologia?\n\n\n\n                  \n                  la risposta \n                  \n                \ni container sono una sorta di mini sistema operativo che ha l‚Äôessenziale per far funzionare un determinato software, essi hanno un gestore dei container che √® in grado di farci eliminare o modificare i container a nostro piacimento. Il container gi√† in fase di installazione ha tutto il necessario per far eseguire quel software e sono molto pi√π leggeri di una normale macchina virtuale che invece spesso √® di tipo general purpose\n\n\nSi spieghi il concetto di least authority in un sistema operativo. Come questo principio migliora la sicurezza del sistema?\n\n\n\n                  \n                  la risposta \n                  \n                \nil concetto di least authority prevede che un processo ha accesso e pu√≤ controllare solo ci√≤ di cui ha bisogno per funzionare, ci√≤ aumenta la sicurezza di molto\n\n\nSi analizzi il concetto di hypervisor in un contesto di virtualizzazione. Quali sono le principali differenze tra un hypervisor di tipo 1 e uno di tipo 2?\n\n\n\n                  \n                  la risposta \n                  \n                \ngli hypervisor sono degli applicativi che mettiamo per tradurre le operazioni di un sistema operativo in modo che le possano comprendere i livelli sottostanti\nci sono due tipi di hypervisor uno con e l‚Äôaltro senza\n\n\ndi tipo 1 √® un software direttamente collegato all‚Äôhardware e traduce le istruzioni dei sistemi operativi soprastanti per rimandarle all‚Äôhardware. √® molto pi√π veloce ma √® pi√π difficile da implementare\ndi tipo 2 √® senza hypervisor effettivo, √® un software che si esegue al di sopra di un s.o. general purpose, questo software prende le istruzioni dei s.o. sopra e le traduce in modo che il s.o. sottostante le comprenda, poi sar√† lui a eseguirle comunicando con l‚Äôhardware. Alcuni di questi tipi presentano dei collegamenti diretti con il kernel\n\n\n\n\nSi inviti il candidato a discutere il ruolo e l‚Äôimportanza delle librerie condivise in un sistema operativo UNIX. Come le librerie dinamiche riducono l‚Äôuso della memoria e migliorano l‚Äôefficienza del sistema?\n\n\n\n                  \n                  la risposta \n                  \n                \nho risposto prima\n\n\n\nChiarimento prima della lezione\nPrima di iniziare a riassumere la lezione 3 volevo spiegare una volta per tutte e in modo corretto cosa √® il kernel\n\n\n                  \n                  definizioni e chiarimenti \n                  \n                \n\nIl kernel √® un codice che consente attraverso le sue funzioni(chiamate di sistema) di gestire le risorse hardware e fare da intermediario con i software che stanno al di sopra\n\nIl s.o. aggiunge oltre alle cose del kernel eventuali interfacce grafiche, driver e varie utility\nIl s.o. raccoglie anche il kernel al suo interno\n\n\n\nSTRUTTURA DI UN SISTEMA OPERATIVO DI TIPO MONOLITICO\nQui il s.o. viene eseguito come un singolo programma in modalit√† kernel\n\n\n                  \n                  quando un kernel si dice monolitico? \n                  \n                \n\nQuando tutte le funzionalit√† del kernel sono scritte in un unico spazio di indirizzamento, tutte le funzioni sono connesse tra loro e possono chiamarsi a vicenda, ci√≤ permette maggiori performance ma porta difficolt√† in termini di\n\nmanutenzione\ndimensioni del kernel\n\n\n\n\n\n                  \n                  Perch√© i sistemi monolitici sono stati fatti cos√¨ in modo contorto? \n                  \n                \n\nPerch√® √® molto complicato disaccoppiare un software, processo ecc..\nDisaccoppiare significa creare un codice che non abbia dipendenze da altre risorse del sistema e che quindi sia modulare\n\n\nQuesto sistema monolitico crea un Trade-off tra complessit√† e flessibilit√†\nUna via di mezzo tra cattive implementazioni e buone implementazioni\nRicordare che se viene aggiunto un pacchetto al kernel √® necessario il riavvio della macchina, alcune volte no ma per la maggior parte delle cose si\nConsiderazioni sulla struttura monolitica\n\nSe ci sono dei moduli che dipendono uno dall‚Äôaltro si ha comunque un sistema operativo monolitico, anche se non sono per forza scritti in un unico spazio di indirizzamento\nmancata presenza di isolamento delle diverse parti del sistema\nPresenza di una struttura a tre strati con il trap che consente la comunicazione tra questi livelli\n\nuser mode\nkernel mode\nHardware\n\n\nEstensioni caricabili, carichi dinamicamente roba come driver ecc, funziona anche in un sistema monolitico\nPer aggiornare alcuni driver bisogna riavviare, poich√© alcuni sono bloccati fino al riavvio per evitare modifiche che apportano a danni\nPresenza di Librerie condivise tra pi√π programmi riduce copie multiple dello stesso codice in memoria\n\nWindows: DDL(Dynamic Link Libraries)\nUNIX: Librerie condivise\n\n\n\nSTRUTTURA DI UN SISTEMA OPERATIVO MONOLITICO\nPer rappresentare un sistema monolitico con gerarchia venne usato il sistema THE\ncon livelli che gestivano l‚Äôallocazione del processore, la memoria, la comunicazione, l‚ÄôI/O, I dispositivi e gli utenti\n\n\n                  \n                  di solito il singolo livello pu√≤ parlare solo con chi gli sta sopra e chi sotto senn√≤ sarebbe un puttanaio \n                  \n                \n\n\nQuesto sistema venne usato da MULTICS anche se ideato per uno scopo educativo, aveva pi√π programmi che lavoravano singolarmente senza darsi fastidio tra loro e usava degli anelli per definire i privilegi(pi√π eri dentro agli anelli pi√π avevi privilegi)\nCon queste strutture si definivano meglio I compiti e aumentava la protezione delle risorse\nRAPPRESENTAZIONE MENO STILIZZATA DI UN S.O. MONOLITICO\n\n\nKernel Unificato: tutte le funzionalit√† sono centralizzate in un unico kernel\nInterconnessione: Ogni componente pu√≤ chiamare qualsiasi altro componente\nScalabilit√†: eccessivamente contorto al livello di codice e quindi un po‚Äô rognoso da scalare\n\nMACCHINE VIRTUALI\n\n\n                  \n                  cos&#039;√® una macchina virtuale? \n                  \n                \n\nPermette l‚Äôesecuzione di pi√π sistemi operativi su un unico hardware fisico, simulando un\nambiente separato per ciascuno di essi\n\n\nVirtualizzare una macchina significa aggiungere uno strato aggiuntivo per cui chi √® sopra pensa di parlare con l‚Äôhardware ma invece sotto sono presenti altri elementi\n\ntipo 1.a sotto c‚Äô√® un hypervisor software direttamente attaccato all‚Äôhardware che esegue e traduce direttamente le istruzioni di un sistema e gestisce le macchine virtuali superiori, una volta che viene eseguito si prende lui la briga di fare tutto\ntipo 2 senza hypervisor, uso un sistema operativo nato per essere generalista e sopra metto una app che esegue e traduce le operazioni sopra o sotto\n\nb. √à un software che traduce semplicemente le istruzioni in un linguaggio che puo‚Äô capire il s.o. sottostante, questa cosa √® pi√π lenta dell‚Äôhypervisor di tipo 1 ma √® piu‚Äô semplice da applicare\nc. Molto simile al tipo b ma ha un accesso diretto al livello kernel con un modulo e quindi molte risorse le prende direttamente senza essere schermato dal s.o. sottostante, ci√≤ gli consente di fare chiamate di sistema direttamente al livello kernel\n\n\n\n\nOvviamente aggiungere uno strato porta a una diminuzione delle performance\n\n\n                  \n                  consiglio dal prof per scegliere una versione di un sistema operativo \n                  \n                \n\nLTS=Long Term Service, versioni affidabili e durature\n\n\nCONTAINER\nI container √® un metodo di virtualizzazione che permette di eseguire applicazioni in ambienti isolati e condividere il kernel e le librerie con il sistema operativo host\n√à un processo a s√© e contiene solo ci√≤ di cui si necessita senza avere un completo s.o.\nInfatti I container possono eseguire dei ‚Äúmini sistemi operativi‚Äù ovvero istanze di un sistema operativo\nInvece di installare sulla macchina app che richiedono librerie da scaricare ecc appesantendo il s.o. basta prendere questo container preassemblato con tutto ci√≤ di cui si ha bisogno\nSi usano i container poich√© sono istanze complete gi√† con librerie per eseguire l‚Äôapp\nEsiste il gestore del container che gestir√† tutti i container che possono esplodere con un click\nQuasi tutte le funzionalit√† di Google si installano con container di tipo docker\n\nEXOKERNEL\nNon emula l‚Äôhardware sottostante ma d√† accesso diretto alle macchine virtuali al di sopra per√≤ limitando e gestendo notevolmente le risorse in modo che siano spartite nel modo corretto\nGarantisce maggiore sicurezza e maggiori performance\nUna GPU pu√≤ usare solo 8 GB di Vram\nUNIKERNEL\nSono sistemi minimi basati su LibOS progettati per eseguire solo un‚Äôapplicazione su una macchina virtuale\nNon sono general purpose, ma mettono a disposizione poche funzionalit√† per la singola applicazione\nHa completo accesso almeno all‚Äôutente del server\nVengono spesso usati per app come server web\nTogliendo funzionalit√† al s.o. potrei renderlo pi√π sicuro e leggero\nSTRUTTURA DI UN SISTEMA OPERATIVO BASATO SU CLIENT-SERVER MICROKERNEL\nLe chiamate di sistema si basano su dei messaggi inviati tra le componenti del kernel\nKernel semplificato\nLe Service procedure vengono chiamate non nel kernel ma al livello utente\n\n\n                  \n                  concetto di least autority \n                  \n                \n\nOgni processo del s.o. pu√≤ fare solo ci√≤ che serve per svolgere il compito\n\n\nQueste comunicazioni non avvengono in una rete ma all‚Äôinterno del s.o.\n\nVisto che nella struttura interna del kernel c‚Äô√® poco e niente ed √® tutto al livello user si aumenta di molto la sicurezza del sistema poich√© √® difficile accedere alla parte sottostante che ha poco e niente\nIl passaggio di messaggi √® pi√π lento"},"UNI/ANNO-2/SISTEMI-OPERATIVI/SISTEMI-OPERATIVI-LEZ.4-5-6-7":{"slug":"UNI/ANNO-2/SISTEMI-OPERATIVI/SISTEMI-OPERATIVI-LEZ.4-5-6-7","filePath":"UNI/ANNO 2/SISTEMI OPERATIVI/SISTEMI OPERATIVI LEZ.4-5-6-7.md","title":"SISTEMI OPERATIVI LEZ.4-5-6-7","links":["UNI/ANNO-2/SISTEMI-OPERATIVI/SISTEMI-OPERATIVI-LEZ.2"],"tags":[],"content":"\n\n                  \n                  lista di domande \n                  \n                \n\nDOMANDE\n\nSi descriva il concetto di file system, con particolare attenzione alla struttura ad albero tipica di UNIX. Come vengono gestiti i percorsi assoluti e relativi nel file system?\n\n\n\n                  \n                  la risposta \n                  \n                \n\n\nSi inviti il candidato a spiegare la differenza tra memoria cache e memoria principale. Come il sistema operativo ottimizza l‚Äôuso della cache?\n\n\n\n                  \n                  la risposta \n                  \n                \n\n\nSi inviti il candidato a descrivere i comandi fondamentali di gestione dei file in Linux, come cat, grep, sort, e uniq. Si fornisca un esempio d‚Äôuso combinato di questi comandi.\n\n\n\n                  \n                  la risposta \n                  \n                \n\n\nSi definisca il concetto di processo orfano in un sistema operativo. Come il kernel gestisce i processi orfani e li assegna al processo init?\n\n\n\n                  \n                  la risposta \n                  \n                \n\n\n\n(INTRODUZIONE A LINUX E BASH)\nSTORIA DI LINUX\n\nLinux √® una copia di UNIX, scritto da Linus Torvalds\nil 64% dei server nel mondo sono con varianti di Unix o Linux\nUnix ha una serie di programmi che funzionano da soli ma altri sono molto complessi e danno il meglio di se quando sono con altri programmi\n\nBash √® il linguaggio di scrittura per la gestione dei sistemi operativi come Linux e Unix.\nOltre a essere un linguaggio di scripting √® anche una Shell ovvero un software su riga di comando che esegue gli script\nCarrellata di comandi\nMan serve per mostrare il manuale di Linux di un determinato comando o tutto il manuale\nMan comando\n\nCosa fanno tutti i comandi?\nQuesti comandi prendono n byte in input e mandano fuori n byte in stream di output:\n\nstandard output, un tipo di output usato per le normali operazioni\noutput con errori standard error, consente di inviare solo i messaggi preoccupanti che contengono errori problemi da risolvere ecc..\n\n\n\n                  \n                  cosa sono gli stream? \n                  \n                \n\nsono dei flussi astratti al livello software gestiti dal sistema operativo e bisogna vederli come degli spazi in memoria su cui ci si scrivono sopra le informazioni da streammare\n\n\nCarrellata di comandi\nQuesti comandi mettono a disposizione alcune chiamate di sistema che non si possono usare su software che devono fare trap cambi di contesto ecc\nQuindi, abbiamo visto questi comandi.\n\n\n                  \n                   AWK ‚Üí serve per l&#039;elaborazione di file in particolare di testo, CSV e log usando piccoli script\n                  \n                \n\nin awk si pu√≤ usare un carattere separatore con -F\n\n\n\n\n\n                  \n                   GREP‚Üí cerca una stringa specifica all&#039;interno di un testo.\n                  \n                \n\nla stringa si dice pattern e avremo la possibilit√† di modificare ci√≤ che fa GREP usando dei comandi predefiniti\n-i stampa senza fare distinzioni tra maiusc e minusc\n-v stampa tutto tranne quella riga di quella parola\n-n indica il numero della riga\n\n\n\n\n\n                  \n                   CAT ‚Üí il comando che accede ad un file per esempio, e lo invia allo standard output.\n                  \n                \n\nil comando CAT viene spesso usato con simboli di redirect come &gt;  e &gt;&gt;\n\n‚Äù&gt;‚Äù indirizza una cosa da una parte all‚Äôaltra in questo caso potrebbe sovrascrivere da un file a un altro\n‚Äù&gt;&gt;‚Äú√® essenzialmente un append quindi aggiunge alla fine del file senza sovrascrivere\n\n\n\n\n\n\n                  \n                   CUT ‚Üí ti permette di selezionare alcuni campi, colonne all&#039;interno di un file usando delle opzioni di comando.\n                  \n                \n\n\nf1 consente di specificare la colonna in cui siamo creata da eventuali delimitatori o specificatori\nd √® un delimitatore che divide le righe in colonne basandosi su un carattere\nc specifica i caratteri da estrarre tipo -c 1-4 per i primi 4 caratteri\n\n\n\n\n\n\n                  \n                   DIFF ‚Üí √® la fantastica applicazione che permette di confrontare due file. Con DIFF puoi evidenziare tutte le modifiche che sono state fatte al file\n                  \n                \n\n\nw ignora gli spazi bianchi come caratteri di differenza\ni ignora maiusc e minusc\nq ti dice solo se i file sono diversi\n\n\n\n\n\n\n                  \n                   HEAD‚Üí  ti permette di vedere le prime righe di un file\n                  \n                \n\n\ndefault 10 righe\n-n 5 si usa per indicare ad esempio le prime 5 righe\n\n\n\n\n\n\n                  \n                   TAIL ‚Üí ti permette di vedere le ultime righe di un file\n                  \n                \n\n\n-n indica il numero delle righe\n-f refresha le ultime righe in real-time utile per analizzare eventuali log\n\n\n\n\n\n\n                  \n                   LESS ‚Üí √® un visualizzatore di file che visualizza i file in base ai limiti del nostro display,\n                  \n                \n\nquindi non carica tutto in memoria(in questo caso di tipo ram) a differenza di cat e altri comandi.\nquindi se ad esempio il nostro schermo visualizza 5 righe lui dinamicamente caricher√† in\nmemoria il punto dove siamo e toglier√† dalla memoria alcune cose che non vediamo\n\n-N indica il numero di righe\n\n\n\n\n\n                  \n                   OD ‚Üí visualizza i file in diversi formati\n                  \n                \n\n\n-x converte in esadecimale\n-c converte in ASCII\n-n specifica il numero di righe da visualizzare\n\n\n\n\n\n\n                  \n                   SED ‚Üí √® un file editor che manipola i file\n                  \n                \n\n\nsostituendo determinate porzioni di testo\neliminando righe o parti di testo specifiche\ninserendo testo in porzioni specifiche\ntrasformando il testo mettendo maiuscole o minuscole\nfiltrare righe in base a dei criteri\n\n\n\n\n\n\n                  \n                   SORT dovrebbe prendere l&#039;intero oggetto in memoria e ordinarlo.\n                  \n                \n\nle opzioni per ordinarlo di default in ordine alfabetico\n\n-n in ordine numerico\n-r in ordine decrescente\n-k indica la colonna\n-u rimuove duplicati\n-o manda in output in un file specifico\n\n\n\n\n\n\n                  \n                   SPLIT‚Üí lo uso se ho un file di grandi dimensioni e voglio dividerlo in file pi√π piccoli\n                  \n                \n\n\n-l indica il numero di n righe ciascuno\n-b indica il peso in kilobyte (K), megabyte (M) o gigabyte (G).\n-a poi un numero che indica il numero del suffisso di ogni file, creer√† ad esempio con\n-a 3 far√† tutti piccoli file come ‚Äúoutput_aaa, output_aab, ecc.\n\n\n\n\n\n\n                  \n                   TR ‚Üí ci permette di sostituire un singolo carattere ovunque vogliamo.\n                  \n                \n\n\n-d per eliminare i file sostituiti\nuso dei redirect per salvare e mandare al comando tr il file da modificare\n\n\n\n\n\n\n                  \n                   UNIQ ‚Üí toglie le ripetizioni da un file e fa tante altre cose\n                  \n                \n\nFunziona generalmente insieme al comando sort, poich√© uniq elimina solo le righe duplicate adiacenti. IL SORT NON MODIFICA IL FILE, quindi se voglio salvare le modifiche dovr√≤ inserirle in un altro file e ogni volta devo aspettare che il sort finisca\n\n-c conta il numero di elementi\n-d mostra solo i duplicati\n\n\n\n\n\n\n\n                  \n                   WC ‚Üí  utilizzato per contare righe, parole e byte (o caratteri) in file o input.\n                  \n                \n\n-l conta solo il numero di righe\n-w conta solo il numero di parole\n-c conta il numero di byte\n-m conta il numero di caratteri\n-L mostra la lunghezza della riga pi√π lunga.\n\n\n\nPrecisazione sul significato di console\nConsole √® un modo generico per definire tutti quei tipi di shell come bash sh zsh ecc... ovvero i vari software terminali\nCOMANDI FONDAMENTALI CHE SI USANO PER UN FILE\nConosciamo bene Open, Read e Write ma esiste anche il comando di seek\n\n\n                  \n                  cosa f√† il comando di seek? \n                  \n                \n\nil comando di seek √® quel comando che ci consente di muoverci all‚Äôinterno di un file.\nquesto serve perch√® i file non vengono scritti in modo sequenziale e quindi abbiamo bisogno di spostarci\n\n\nSpiegazione della pipe\nsignificato di pipe a SISTEMI OPERATIVI LEZ.2\nin termini di linguaggio bash le pipe si scrivono con | e sono utilizzate per collegare l‚Äôoutput di un comando all‚Äôinput di un altro, permettendo la creazione di catene di comandi.\n\nil comando esegue prima il comando a sinistra del |\n\n\n\n                  \n                  ESEMPIO \n                  \n                \n\n\naltro esempio:\ncat nomefile |grep&quot;-file&quot;|sort|uniq -c|sort -k 1 -n -r\n\n\nCome prendere dalla riga 17 alla 23\nLe funzioni sono ESTREMAMENTE ottimizzate\nCi sono alcune funzioni che sono un collo di bottiglia operazionale come il sort\nLa shell\nLa shell √® un ambiente di scripting che ci consente di creare file con una serie di comandi da eseguire in modo sequenziale e nella Shell introducono degli elementi condizionali(if,for ecc‚Ä¶)\nVisto che ho dei condizionali posso fare molte computazioni\n\n\n                  \n                  Definizione di Script \n                  \n                \n\nScript sequenza di tutti i comandi necessari per eseguire quel compito\n\n\nScript di tipo Bash\nIl nostro script si chiamer√† Bash‚Üí ‚ÄúBourne again-shell‚Äù\nVariabili d‚Äôambiente\nLe variabili d‚Äôambiente servono per memorizzare alcune informazioni utili che possono servire a processi o applicazioni.\nUn esempio tra queste variabili d‚Äôambiente √® PATH, una stringa che contiene tutte le directory di tutti i comandi da eseguire\nPATH al suo interno ha anche percorsi privilegiati con comandi eseguibili solo da super-user\n\n\n                  \n                  Tip\n                  \n                \n\nGeneralmente il sistema operativo PRIMA cerca il comando all‚Äôinterno della cartella in cui ci troviamo e se lo trova lo esegue; se non lo trova va a cercare in questi percorsi privilegiati e se riesce a trovarlo lo esegue altrimenti restituisce comando non trovato.\n\n\n\n\n                  \n                  come si stampa una variabile d&#039;ambiente? \n                  \n                \n\n\n\n\n\nPrintenv stamper√† tutte le variabili del sistema\n\n\n\n                  \n                  Possibilit√† di creare variabili personali oltre alle variabili di sistema \n                  \n                \n\n\n\n\nQueste variabili personali sono temporanee perch√© ogni volta che apro un terminale avvio un processo che si inizializza e poi esegue I comandi di base contenuti nel file bash.rc\nPer creare una variabile per sempre bisogna scrivere in questo file .bashrc per farle leggere ogni volta che si avvia una shell\n\nil file .bashrc si modifica ad esempio con vim\nBash esegue e interpreta comandi che gli diamo su riga\nComandi come whoami hostname ecc ti danno informazioni sul sistema\n\n\n\n                  \n                  Esercizio per creare uno script che ti saluta con il tuo nome con vim \n                  \n                \n\nMIONOME=$(whoami)\necho &quot;CIAO&quot; $MIONOME  \n\nper fare il return di uno standard output di un comando bisogna fare $(nome comando)\nper eseguirla bisogna fare bash nomefile\n\n\n\nComandi per usare history e semplici editing per comandi\n\nCTRL+R per fare una ricerca inversa con i suggerimenti di quello che abbiamo nella history con completamento\nfreccia su e freccia gi√π per muoverti nella history\nse fai history ti stampa tutta la history\n\nCOMANDI DI AIUTOüõü\nabbiamo due comandi\n\nhelp, viene anche lui usato per aiuto su comandi ecc\nman, accede al manuale e usa less in fase di display\n\nCarrellata di informazioni sparse che non fanno male\n\nINVENTORE DI HTML E WEB Tim Berners-Lee\n\n\n\n                  \n                  Differenza tra Markdown e Markup \n                  \n                \n\n\nUn linguaggio di markup √® un insieme di regole per annotare un documento in un modo che √® leggibile sia per gli esseri umani che per le macchine.\nIl markdown √® un linguaggio di markup leggero creato per formattare testo in modo semplice e leggibile. √à progettato per essere facilmente convertito in HTML e altre formattazioni.\n\n\n\nDiff tra HTML e XML e JSON\n\nhtml viene usato per strutturare pagine web visualizzabili\nxml viene usato per strutturare e scrivere descrizioni su dati\njson √® pi√π semplice ed utilizzato per app web client-server per rappresentare dati in modo chiaro\nPoi esiste anche Yaml, un nuovo modo per scrivere in markup\nHTML‚ÜíXML‚ÜíJSON‚ÜíYAML\n\nPrecisazione su man\nman √® soltanto un programma che dato un comando va dentro la cartella con tutte le guide e usa il comando less per mostrare il contenuto\nw √® un comando ti dice chi √® loggato\n\nL‚Äôestensione di un file √® una nostra cosa che aggiungiamo ma in realt√† √® una convenzione perch√© sar√† sempre una stringa in Linux, quindi ci sar√† un file che semplicemente ha una stringa come ‚Äúpippo.txt‚Äù ma quel txt serve solo per noi utenti umani e non per il s.o. UNIX\nStruttura del file system\nLa struttura di un file system √® ad albero e serve a noi per organizzare al meglio le varie cartelle e file\n\nogni directory ha una directory genitore eccetto la root\nLinux a differenza di Windows e altri ha solo un file system, infatti ogni disco in windows √® una cosa a se\n\ntutte le linee pi√π scure indicano le directory di primo livello che sono accessibili solo dall‚Äôamministratore eccetto TMP che contiene tutti i file temporanei che al riavvio verranno eliminati\nHOME: √® una directory con tutte sotto-directory che corrispondono alle home dei vari utenti es: /home/Luca /home/paolo\nDEV: riprendendo il concetto everything is a file qui avremo i file dei vari dispositivi ad es la stampante\nLIB: contiene i file delle librerie essenziali che servono per eseguire i comandi di base, dentro ci sono anche le varie chiamate di sistema del kernel come read ecc‚Ä¶\nMNT: Qua dentro avremo le cartelle dei dispositivi esterni di archiviazione come cd,usb,hdd ecc‚Ä¶\nROOT cartella Home ma per il root user sei proprio megalomane, il prof suggerisce di lavorare raramente su queste cartelle poich√© si rischia grosso\nOPT i software che non installi nella tua home li metti qui ‚Äúaccessibili a tutti‚Äù con ogni programma che ha una sua cartella\nBOOT: Contiene tutti i file di cui ha bisogno il sistema in fase di accensione(boot) come il kernel\nUSR: contiene tutti i file che possono usare tutti gli utenti del sistema ma non modificare\n\nSHARE:Contiene ad esempio MAN\nINCLUDE:Ha le librerie usate dai compilatori tipo gcc\nBIN: contiene la maggior parte dei comandi usati dagli utenti\nSBIN: contiene i comandi di amministrazione di sistema infatti S sta per Superuser\n\n\nBIN E SBIN: contengono comandi utili\nVAR: Ho file che cambiano nel tempo come cache log ecc‚Ä¶\nETC: Contiene i file di configurazione e controllo del sistema\nMEDIA: Tutti i file per gestire i dispositivi del MNT\n\n\n\n                  \n                  cosa sono i file di log \n                  \n                \n\nfile che si generano indicano il comportamento di un software, un sistema o un processo rimandando errori ecc\n\n\nComandi per navigare nel file system\n\n\n                  \n                   pwd stampa la working directory\n                  \n                \n\n\n\n\n\n\n                  \n                   cd cambia la directory su cui lavorare\n                  \n                \n\n\n\n                  \n                   ls: si usa per mostrare la lista dei file\n                  \n                \n\nha dei sotto comandi che si possono concatenare tipo ls -la:\n\n-a mostra i file nascosti che di solito sono indicati con . all‚Äôinizio\n\n-ld mostra i dettagli dei file come i ruoli ecc senza mostrare i nomi\n\n-F aggiunge alla fine di ogni directory / questo carattere\n\n-lR mostra i file e i loro dettagli in modo ricorsivo quindi andando a fondo\n\n\n-lh mette le dimensioni dei file in modo che possa leggerli anche un umano con conversioni utili\n\n-lS sorting in base alla dimensione di un file\n\n-lt sorta in base al tempo di modifica\n\n-lrth fa una lista dettagliata‚Üí ordina al contrario(z-a) ‚Üí sorta in base al tempo di modifica ‚Üí mostra cambiando i dati in modo umano\n\n\n\nTool da usare per definire delle cartelle e file\ni pathname si dividono in due tipi:\n\nassoluti quando esprimi un indirizzo partendo dalla root /\nrelativi quando non lo fai\n~ indica la tua home directory\n. current directory\n.. indica la directory genitore\n* autocompletamento di un nome di un file *.txt\n? completa un carattere tipo file?.txt\nTAB prova a completare un filename\n\nEnnesima serie di comandi\n\n\n                  \n                  cp serve per copiare \n                  \n                \n\ncopia byte a byte\n\n\n\n\n\n                  \n                  mv sposta un file in una destinazione \n                  \n                \n\nmv crea una copia nella destinazione che scegliamo e poi cancella il file nella destinazione originale\n\n\n\n\n                  \n                  file identifica il tipo di file \n                  \n                \n\n\n\n\n\n\n                  \n                  tac il contrario di cat quindi stampa al contrario \n                  \n                \n\n\n\n\n\n\n                  \n                  ln vedremo poi \n                  \n                \n\n\n\n                  \n                  touch cambia il tempo di modifica di un file \n                  \n                \n\n\n\n\n\n\n                  \n                  echo serve per stampare e un utilizzo √® con il redirect \n                  \n                \n\n\n\n\nPermessi di accesso a un file\nCome gi√† detto in precedenza ogni file ha ruoli di lettura scrittura ed esecuzione\nsi possono modificare con\n\n\n                  \n                   chmod facendo tipo chmod u+x nomefile\n                  \n                \n\n\n\nu=owner\n\n\ng= group\n\n\no=other\n\n\na=all\nDEFINIZIONI\n\n\nr=read\n\n\nw=write\n\n\nx= execute\nChmod funziona anche con le seguenti mappature\n\n\nread = 4\n\n\nwrite = 2\n\n\nexecute = 1\n\n\nSe voglio che un file possa essere letto e scritto da owner e group chmod 660 CARTELLA\nTABELLA BASE\n\n\nGestione dei processi\ninteragendo con Linux creiamo una serie di istanze di programmi dette processi che hanno ognuno il loro PID\n\n\n                  \n                  usiamo il comando ps per vedere le liste di processi in esecuzione\n                  \n                \n\n\n-ef in aggiunta a ps e mostra i processi non solo della tua sessione f mostra pi√π dettagli ad albero\n\nps mostra solo i processi in esecuzione nel terminale corrente\nf (forest): visualizza i processi in una struttura ad albero, utile per vedere le relazioni tra processi (genitore e figli).\nu (user): mostra i processi associati all‚Äôutente corrente con un livello di dettaglio aggiuntivo, inclusi l‚Äôutente che ha avviato il processo e il tempo CPU utilizzato.\nx (no controlling terminal): include anche i processi che non hanno un terminale di controllo associato (come i processi di sistema o demoni).\ne (every): mostra tutti i processi del sistema, non solo quelli associati all‚Äôutente corrente.\n\nps -ef lo uso per vedere tutti i processi sul sistema\nps -ef | grep NOME serve per vedere tutti i processi posseduti da me e da altri membri del gruppo top per vedere chi consuma pi√π CPU\n\n\n\nInterazione tra processi\nin questa parte parleremo in modo approfondito dei processi e della loro gestione\ncome eseguire una applicazione?\n\nper applicazioni si intendono ad esempio quei comandi messi a disposizione dal sistema operativo che sono nel path\nun programma √® una applicazione che viene eseguita\n\nper eseguire uno script in bash fai\nbash √® anche un linguaggio di scripting che ci permette di formalizzare su pi√π righe un codice fatto da comandi bash bash nomescript\noppure ./nomefile.sh\n\n\n                  \n                  che succede se eseguo senza shebang? \n                  \n                \n\nnon si sa il compilatore e quindi non funziona\nusiamo shebang possiamo specificare all‚Äôinizio del file con quale interprete leggere lo script\n\nper specificare un file bash user√≤ #! /bin/bash\nper python io scrivo #!/usr/bin/python3 dove specifico dove sia l‚Äôinterprete\n\nposso scrivere ./my_script.py cos√¨ so che questo script verr√† eseguito dall‚Äôinterprete python.\n\n\n\n\n\nGestione dei permessi per eseguire uno script\nper modificare i permessi si deve usare chmod come fatto in precedenza e bisogna mettere\n\nse si vuole eseguire in file con ./ bisogna mettere x al file\nse si vuole eseguire il file con un interprete quindi bash nomefile bisogna mettere la lettura al file e l‚Äôesecuzione al compilatore\n\nBackground vs Foreground\nForeground\nquando eseguo un processo e lo lascio eseguire sul terminale(bash), lo faccio di default\nnon hai possibilit√† di mandare altri input alla shell finch√© non termina il processo che abbiamo eseguito in foreground(qualche piccola eccezione per comandi di interrupt particolari)\nBackground\nlo mando in background con la &amp;\n./nomescript &amp;\n\n\n                  \n                  la fregatura \n                  \n                \n\nse io ho uno standard output nello script che stampa gli elementi a schermo viene comunque\nstampata quella roba ma avr√≤ la riga di comando libera per scrivere cose, per ovviare questo\nproblema devo mettere lo standard output da qualche parte ad esempio con un redirect su un txt\nper stampare il codice bash\nquando facciamo bash nome file &gt;temp.txt passera gli output al txt e non sulla bash\ntail -f per leggere l‚Äôoutput del file txt in real time\n\n\nI job\n\nIl job indica una unit√† di lavoro intesa come un processo\nOgni job ha un suo identificativo, per usarlo bisogna mettere il simbolo %\njobs tratta i processi come delle attivit√†\nposso attivare un job in background o in foreground\n\nfg per foreground\nbg per background\nSe faccio il comando jobs mi stampa tutti i jobs e anche i vari processi perch√® sotto potrebbero avere dei jobs\n\n\nmi stampa ad ogni Job un identificativo che va da 1 a n con un + o -\nil + indica che se faccio fg senza specificare nulla mi mander√† il processo con il + in foreground, di solito lo hanno i processi che spesso richiedono input da tastiera\nil - indica il processo che una volta concluso il + ricever√† il + come suo successore\n\n\nI segnali ai processi\nper comunicare tra processi e ai processi abbiamo due cose\n\nsegnali inviati da un processo a un altro\ninterrupt causati da hardware\nOgni segnale ha un nome\nCtrl+c=segnale di interruzione\nCtrl+z=segnale del terminale di stop\nOgni processo ha un handler che gestisce il processo e lo termina\n\nNohup\nComando nohup sgancia il programma dal processo padre e lo mette alla root\nanche i processi sono un file e quindi vengono messi alla root se si fa nohup\nvisto che stacchiamo il processo non sar√† pi√π dipendente dalla bash\n\nnohup manda tutto lo stdoutput e error brutalmente su un file di output chiamato nohup.out, se non viene specificato diversamente\nLa bash se viene chiusa manda un segnale che chiude tutti i suoi processi figli\ninvece con i normali processi se hanno un padre e il padre viene ucciso vengono inizializzati e gestiti per fargli continuare l‚Äôesecuzione\n\nSCREEN\ne se devo interagire? che succede? il processo ora √® staccato quindi √® fuori\npossiamo ricorrere all‚Äôoperativo screen ci permette di simulare la bash\n\nda bash ho aperto screen e screen ha aperto un processo bash\nctrl a d esco dalla bash vecchia e ritorno alla bash principale\ne posso creare altre screen\nsono finestre virtuali che simulano pi√π bash\nuccidere un processo padre non ammazza i figli\nil processo figlio se viene ammazzato non ammazza il padre\nsuggerimento: uccidere prima i pap√† e poi i figli\nscreen se devo interagire\nnohup se non devo interagire\n57\nusare sudo ma MAI usare l‚Äôutente root\n\ncreazione di un utente\nuseradd fa il minimo indispensabile manco crea la home\n\nla riga di comando che gli si assegna di default √® sh e fa cagare e dobbiamo dare il path della bash\n-d dove deve essere la home -m per crearla\n-G assegnare un gruppo tipo sudo ovvero della gente che puo fare il sudo\nusername ma senza password\nsettare la password sudo passwd username\ndove vengono messe le password\nle password sono cifrate\nil metodo piu semplice e usare una funzione di ash che non la rende invertibile ma che possiamo conoscere con pass predefinite\nquindi si legge il file cryptato ma si sanno i significati e si fa bruteforce\n\nmd5 1h 9?\ncambiare i due hash ti permette di modificare la password\nper grep esistono le regex tipo il cappelletto\nsbin"},"UNI/ANNO-2/SISTEMI-OPERATIVI/SISTEMI-OPERATIVI-LEZ.8":{"slug":"UNI/ANNO-2/SISTEMI-OPERATIVI/SISTEMI-OPERATIVI-LEZ.8","filePath":"UNI/ANNO 2/SISTEMI OPERATIVI/SISTEMI OPERATIVI LEZ.8.md","title":"SISTEMI OPERATIVI LEZ.8","links":[],"tags":[],"content":"Introduzione ai processi\nIl processo √® una cosa che ha degli stati\nhanno dei limiti come il cambio di contesto nella sostituzione tra processi che ha un costo\nsi cerca di optare in una versione alleggerita dei processi i thread\ncome comunicano tra loro questi processi?\nil s.o. come li deve gestire?\nLo scheduling attore fondamentale di una lezione prossima e decide chi deve andare in esecuzione\nDefinizione di processo\nnon √® solo un programma in esecuzione ma anche una serie di programmi in un processo\ne una astrazione il processo\nper fare l‚Äôastrazione abbiamo bisogno di un sistema operativo che\n\nastrae risorse\ncontabilizza risorse\nlimita le risorse\nIl sistema operativo mantiene informazioni sulle risorse e sullo stato interno di ogni singolo processo del sistema, e tutte queste informazioni sono contenute in una tabella.\n\nIl modello di un processo\n\n\n                  \n                  Quando abbiamo pi√π processi da dover eseguire il SO, tramite la CPU, √® in grado di passare da un processo all&#039;altro in maniera molto repentina, dando l&#039;idea che questi avvengano in parallelo. \n                  \n                \n\nIllusione come al cinema ovvero n fotogrammi che ci fanno sembrare che siano in movimento\nfoto con processi al fly\n\n\nOgni processo ha una porzione specifica di memoria assegnata.\nLe frecce indicano il process switch, ossia il passaggio da un processo ad un altro. In questo modo noi abbiamo l‚Äôillusione che tutti i processi vengano svolti simultaneamente ma in realt√† c‚Äô√® un continuo switch repentino gestito dalla CPU.\nIn questo esempio il PC(Program Counter) √® uno solo.\n\n\nProcessi concorrenti\nTutti i processi sono indipendenti e ognuno di loro ha una sua memoria separata astratta\nogni processo avr√† a sua volta sotto processi\nQuindi servono dei meccanismi per farli interagire tra loro e si va a creare una sorta di gerarchia(visibile con il comando ps fux)\nLa CPU, per poter switchare da un processo all‚Äôaltro ha bisogno di salvarsi il PC e lo stato del processo corrente (quello che sta per finire) e ripristinarlo quando vuole riprenderlo.\nCos√¨ tutti i processi possono progredire ma solo uno √® attivo in un dato momento\nGerarchie di processi\nIl s.o. quando viene avviato crea solo un processo chiamato init che rimane attivo fino allo spegnimento della macchina, questo processo init avr√† a cascata tutti sotto processi\n\nCreazione di un processo\nci sono degli eventi particolari che generano un processo\n\ninizializzazione del sistema\nUn processo in esecuzione che avvia una chiamata di sistema per creare un processo\nfork() chiamata di sistema per generare processi\nRichiesta dall‚Äôutente di creare un nuovo processo\nAvvio di un job in modalit√† bash\n\n\n\n                  \n                  spiegazione migliore di fork \n                  \n                \n\nil comando fork() √® una chiamata di sistema che permette a un processo (detto processo\npadre) di creare una copia esatta di se stesso, creando cos√¨ un nuovo processo (detto processo\nfiglio), il quale ha una copia del contesto del processo padre (inclusi i file aperti e l‚Äôambiente).\nTuttavia, il figlio ha un proprio spazio di indirizzamento, quindi le modifiche alle variabili fatte dal\nfiglio non influenzano il processo padre, e viceversa; e anche un PID diverso.\n\n\nTermine di un processo\nEventi tipici che terminano un processo in prospettiva di un processo\n\nUscita normale(volontaria), semplicemente il processo termina di eseguirsi tipo alla fine di un main return 0\nA causa di un errore(volontario), si trova un errore e il processo decide di chiudersi\nA causa di un errore Fatale(involontario), Segmentation fault errori di programmazione esterni\nUcciso da un altro proceso(involontario), Tipo ctrl+c che chiude il processo\n\nComandi di gestione dei processi\nSono chiamate di sistema\n\nfork\n\nconcetto parent-child astrazione solo concettuale √® una clonazione vera e propria che fa in modo che i processi siano uguali tranne alcune cose tipo il PID, non condividono informazioni tra loro per motivi di sicurezza(nei Thread invece lo fanno e si creano un po‚Äô di casini da gestire)\n\n\nexec\n\nci fa eseguire nuovi processi usando fork\n\n\nexit\n\ncausa terminazione volontaria del processo\n\n\nkill\n\ninvia un segnale, uno dei pochi meccanismi che fa comunicare tra processi\nil segnale senza dettagli termina involontariamente il processo\n\n\n\nGli stati del processo\nTutto quel discorso che i processi si eseguono velocemente e si alternano ci rimanda agli stati di un processo\nRappresenta il modo in cui il s.o. gestisce in modo ottimale i processi con uno scheduler, ci sono tre stati:\n\nrunning, quando un processo √® in esecuzione\nready, quando √® pronto per essere eseguito ma deve ancora essere messo in running\nblocked, quando √® in blocco perch√© magari attende eventuali risorse\n\n\n\n                  \n                  concetto di quanto di tempo \n                  \n                \n\nrappresenta l‚Äôintervallo massimo di tempo assegnato a ciascun processo o thread in un sistema multitasking\n\n\n\nInformazioni per un singolo processo\nUn singolo processo ha queste informazioni memorizzate nella tabella dei processi del SO:\n\nPID, UID, GID\nSpazio degli indirizzi di memoria\nRegistri hardware (program counter)\nFile aperti\nSegnali Interrupt\n\nComunicazione tra processi\nl‚Äôunico modo che i processi hanno di comunicare √® attraverso i segnali o gli interrupt\ndifferenza tra i due\n\n\ni segnali sono eventi di natura software generati da un processo o dal s.o.\n\ngestione personalizzata o comportamenti predefiniti\nil fatto che siano gestibili facilmente posso creare delle cose eccezionali ovvero fuori dalla volont√† del processo e asincroni(arrivano in ogni momento)\ni segnali sono una modalit√† di comunicazione\nci sono questi signal handler che dicono a un determinato processo come si deve comportare in base a un determinato segnale (anzich√© dire chiuditi e basta)\n\n\n\ninterrupt indica quei segnali al livello hardware\n\nspesso hanno alta priorit√†\nil s.o. li gestisce\nviene chiamato lo scheduler che toglie dalle palle il processo in esecuzione e da priorit√† al processo che gestisce l‚Äôinterrupt\nfrequenza del clock necessaria per implementare interazioni\n\n\n\nasincrono quando voglio lo faccio\n\n\nsincrono devo farlo subito\n\n\nCome funzionano questi interrupt?\nOgni volta che avviene un interrupt c‚Äô√® un gestore degli interrupt al livello hardware che controlla periodicamente se si sta generando un input hardware e fornisce l‚Äôinformazione allo scheduler per deallocare la CPU e metterla a lavorare sul processo generato da un interrupt\nTabella interrupt vector\nun vettore che contiene tutte le varie informazioni di ciascun dispositivo di I/O e le varie linee di interrupt(dove sono posizionate)\n\nL‚Äôinterrupt vector √® parte della tabella dei descrittori di interrupt(IDT)\n\nal suo interno abbiamo il primo indirizzo della prima procedura che dice al s.o. come gestire l‚Äôinterrupt\n\n\ngestore di interrupt o interrupt handler che continua l‚Äôesecuzione\n\nPassaggi che fa un s.o. ad un livello basso per gestire un interrupt\n\nUN PROCESSO NON PUO CEDERE LA CPU A UN ALTRO PROCESSO DEVE FARLO SOLO DELLO SCHEDULER NEL S.O.\nTipi di segnali:\nci sono due tipi di  segnali hardware e software\n\nse premo x mi chiede di salvare\nse premo termina attivit√† esplode tutto\nPassaggi di un segnale\n\nil kernel invia un segnale(come abbiamo detto i segnali sono software)\nviene interrotto il codice in esecuzione perch√© cos√¨ si gestisce il segnale\nSalvo il contesto, ovvero il punto in cui mi sono fermato nel codice\nViene eseguito il codice di gestione del segnale\nSi ritorna al contesto originale\n\nquindi ci sono segnali che chiedono di chiudere invece altri che fanno esplodere tutto\n\ninterruzione immediata\nterminazione controllata\n\nThread\n\n√® una parte astratta del processo\nprendi un precesso e lo spezzi in sotto processi che hanno compiti\nper ora abbiamo visto:\nun processo‚Üí1 thread\nora per√≤ approfondiremo invece multithread execution:\n1 processo‚Üí N thread\n\nlightweight processes, consentono una maggiore efficienza alleggerendo i singoli sottoprocessi(Thread)\n\nun thread gestisce una tastiera\nun thread il disco\ne uno il software\nProblema di eseguire queste istruzioni cos√¨ al fly senza dividere in pi√π processi e che possono esserci sovrascrizioni di variabili, questa cosa va a discapito del programmatore\nESEMPIO SERVER CON MULTITHREAD\n\ni thread condividono stessa tabella del processo?\nIl cambio di contesto costa un botto √® il male assoluto\n\nCaratteristiche sui thread\n\nogni thread sar√† nello stesso spazio degli indirizzi di un singolo processo\nGli scambi di informazioni avvengono tramite i dati condivisi tra thread\nOgni thread ha\n\nil proprio stack\ni propri registri hardware\nil proprio stato\n\n\nTabella dei thread con anche la sua tabella degli interrupt\nCiascun Thread pu√≤ chiamare qualsiasi chiamata di sistema supportata dal sistema operativo per conto del processo di cui √® figlioccio\nOgni Thread ha i suoi elementi privati(Stack) e i suoi elementi condivisi(Variabili globali)\n\n\nI THREAD IN POSIX\nCHIEDE A ESAME\n\nIl thread e addestrato per fare un lavoro quindi praticamente esegue una funzione tipo in c\nImplementazione dei thread nello spazio utente\nun thread potrebbe essere definito o gestito nello spazio utente, oppure pu√≤ gestirli il kernel quando magari deve fare particolari chiamate di sistema\n\n\n\n                  \n                  approfondimento sui thread al livello utente \n                  \n                \n\nPRO:\n\nsono gestiti dal kernel come dei processi a singolo thread anche se sono pi√π thread\ngestiti tramite libreria e possono anche essere eseguiti da s.o. che non supportano i thread\nOgni processo che usa thread a livello utente necessita di una propria tabella dei thread per tracciare lo stato e altre cose\nNon √® richiesto un cambiamento di contesto completo perch√© sono tutti sotto lo stesso processo\nOffrono maggiore scalabilit√† e personalizzazione dell‚Äôalgoritmo di scheduling\nContro:\nse uno fa una chiamata di sistema bloccante tutti i Thread vengono fermati, questa cosa accade anche in caso di errori, perch√© vengono visti come un singolo individuo e quindi il s.o. potrebbe fermarli tutti\nI thread nello spazio utente non hanno interrupt del clock quindi non possono fare round robin\nSebbene pi√π veloci i Thread al livello utente non sono adatti per applicazioni che si bloccano spesso come i web server\n\n\n\n\n\n                  \n                  approfondimento su Thread nello spazio kernel \n                  \n                \n\n\nIl kernel che gestisce i thread elimina la necessit√† di avere un sistema run-time per processo\n\nper sistema run-time si intende un sistema che compila e interpreta esegue ecc‚Ä¶ se ho\ntutto nel kernel non ho bisogno di avere sistemi particolari per fare chiamate di sistema\nperch√© siamo gi√† vicini al kernel\n\n\nLe chiamate che potrebbero bloccare un thread vengono implementate come chiamate di\nsistema e quindi non avr√≤ pi√π quei blocchi\nRiciclo dei thread per ridurre i costi\nProgrammazione con thread richiede cautela per evitare errori\n\n\n\n\n\n                  \n                  approfondimento su Thread con sistema ibrido \n                  \n                \n\nAlcuni sistemi effettuano un multiplexing dei thread utente su thread del kernel (praticamente\nsceglie chi usare)\nMaggiore flessibilit√† per i programmatori che possono scegliere quanti thread usare in spazio\nutente e quanti in spazio kernel\nIl kernel √® a conoscenza solo dei suoi thread nello spazio kernel\nOgni thread del kernel pu√≤ gestire per√≤ i thread a livello utente anche se il kernel non li conosce\n\n\n\nProblemi sui thread: conflitti, sovrascrizione, problemi di implementazione anche di buffer ecc‚Ä¶"},"UNI/ANNO-2/SISTEMI-OPERATIVI/SISTEMI-OPERATIVI-LEZ.9":{"slug":"UNI/ANNO-2/SISTEMI-OPERATIVI/SISTEMI-OPERATIVI-LEZ.9","filePath":"UNI/ANNO 2/SISTEMI OPERATIVI/SISTEMI OPERATIVI LEZ.9.md","title":"SISTEMI OPERATIVI LEZ.9","links":["UNI/ANNO-2/SISTEMI-OPERATIVI/SISTEMI-OPERATIVI-LEZ.4-5-6-7"],"tags":[],"content":"iniziamo vedendo C\nC nasce da Ritchie nel 1972 per sviluppare programmi UNIX\n\nricordiamo che alcune caratteristiche di UNIX sono ancora in circolazione come everything is a file\nQuando avviamo un processo, in modo predefinito si aprono questi 3 file(stream)\nsono numerati, e sono dei file descriptor\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNomeNome abbreviatoNumero del fileDescrizioneStandard instdin0Input dalla tastieraStandard outstdout1Output alla consoleStandard Errorstderr2Errore di outputPer illustrare il concetto di chiamate di sistema, possiamo stampare ‚ÄúHello World!‚Äù utilizzando diversi metodi:\nMetodo 1(il classico)\nUsando printf:\n#include &lt;stdio.h&gt;\n \nint main(int argc, char **argv) {\n   printf(&quot;Hello World!\\n&quot;);\n   return 0;\n}\nper eseguire un programma in c faremmo\n./programma arg1 arg2 arg3\noppure\n./programma ciao a tutti\n\nargc(argument count), conta quante parole(argomenti) scriviamo su riga di comando contando anche la chiamata del programma stesso ./programma\n**argv (argument vector), √® un array di puntatori dove ogni puntatore punta a una stringa di ciascun argomento\n\nargv[0] sar√† ./programma (nome del programma).\nargv[1] sar√† ciao.\nargv[2] sar√† a.\nargv[3] sar√† tutti.\n\n\n\nBuild Process\nAbbiamo 4 principali step\n\nHo i miei file c e le mie librerie e le do in input al pre preprocessore C\nIl compilatore C riceve dal preprocessore un file dopo aver fatto una rapida lettura e aver interpretato(condizioni, librerie, costanti ecc‚Ä¶) per evitargli intoppi\nIl compilatore dopo aver compilato il codice butter√† in output dei file in linguaggio macchina\nQuesti file saranno tutti uniti da un linker che creer√† il vero e proprio eseguibile prendendo e mettendo in comune funzioni, variabili ecc‚Ä¶\n\n\nMetodo 2(usando chiamate di sistema in modo astratto)\nUsando la chiamata di sistema write:\n#include &lt;unistd.h&gt;\n#define STDOUT 1\nint main(int argc, char **argv) {\n   char msg[] = &quot;Hello World! \\n&quot;;\n   write(STDOUT,msg,sizeof(msg));\n   return 0;\n}\n\nper fare chiamate di sistema usiamo unistd.h una libreria che consente di gestire operazioni a basso livello\ndefiniamo una costante STDOUT per un uso pi√π semplice nella write\ncreiamo una stringa di caratteri per mettere hello world...\ndefiniamo la funzione write che scrive in un determinato file, accetta 3 parametri fondamentali\n\nil file descriptor, ovvero un intero che identifica un determinato file, i primi 3 sono gi√†\npredefiniti e ogni file ha il suo, in questo caso usiamo 1 perch√© vogliamo scrivere alla console\nil secondo √® la stringa o la cosa che vogliamo stampare\nla terza √® la dimensione specifica che ha il messaggio che vogliamo stampare\n\n\n\nMetodo 3(usando chiamate di sistema ma in modo meno astratto)\nutilizziamo una libreria per effettuare delle syscall in modo diretto\nunistd.h vs syscall.h\nsembra che facciano le stesse cose solo che unistd.h √® pi√π astratto e meno diretto e semplice\n\nin unistd.h avr√≤ read write ecc come funzioni\nin syscall.h devo usare il numero di chiamata di sistema e sar√† pi√π diretto\n\n#include &lt;unistd.h&gt;\n#include &lt;stdio.h&gt;\n#include &lt;sys/syscall.h&gt;\n#define STDOUT 1\n \nint main(int argc, char **argv) {\n   char msg[] = &quot;Hello World! \\n&quot;;\n   int nr = SYS_write;\n   syscall(nr, STDOUT, msg , sizeof(msg));\n   return 0;\n}\nsenza che ripetiamo le altre cose arriviamo al dunque\n\nincludiamo la libreria syscall.h\ndefiniamo nr, sar√† il numero di chiamata di sistema da fare, ci sono tipo read open write..\neffettuo la syscall che accetta di solito i seguenti argomenti:\n\nnumero di chiamata di sistema in questo riguarda write\nil descrittore di file da utilizzare\nil messaggio\nla dimensione\n\n\n\n\n\n                  \n                  piccola nota sui descrittori \n                  \n                \n\nda quello che ho capito i descrittori identificano su quale file fare operazioni in stream\ncome read write ecc‚Ä¶\n\nstream tipo una porzione di file continua dove passiamo le informazioni\n\n\n\nLibc e Syscall\nLibc √® una libreria standard del linguaggio C che fornisce molte funzionalit√† per facilitare lo sviluppo di programmi; include dei wrapper per semplificare l‚Äôuso delle syscall.\nI wrapper sono funzioni che ‚Äúimpacchettano‚Äù la chiamata a basso livello alle syscall per permetterti di usarle in un modo pi√π semplice e leggibile.\nQuando non si usa Libc √® necessario fare uso diretto delle syscall. Ci sono due modi:\n\nUtilizzare la funzione syscall().\nUsare l‚Äôistruzione int 0x80, che √® un‚Äôistruzione in linguaggio assembly specifica per effettuare una syscall in sistemi Linux a 32 bit.\n\nSyscall note\nclicca qui per vederle tutte\n\nDifferenza tra i 3\n\n\n                  \n                  ma quindi cosa cambia tra queste 3 cose? \n                  \n                \n\nRiepilogo della Differenza:\n\n\nlibc: √® una libreria che contiene varie funzioni standard in c come malloc, printf... e anche chiamate POSIX\n\n\nunistd.h: √® un file di intestazione(un file che ha delle funzioni costanti ecc‚Ä¶) che dichiara funzioni POSIX come write, read e fork, √® un sottoinsieme di libc che serve solo per semplificare alcune chiamate POSIX\n\n\nsyscall.h: consente di effettuare delle chiamate di sistema direttamente  al kernel senza passaggi, √® decisamente pi√π a basso livello delle altre\n\n\n\n\n\n\n                  \n                  cosa √® un file di intestazione? \n                  \n                \n\nun file di intestazione ha al suo interno prototipi di funzioni di altre librerie e costanti.\nconsente di fare da intermediario tra il codice scritto dal programmatore e le varie librerie.\n\nmostra solo quali strutture e funzioni sono disponibili\nLa dichiarazione in un header √® essenziale per il compilatore perch√© gli permette di verificare la correttezza dei parametri e fare in modo che il codice venga compilato senza errori.\nci permette di leggere funzioni e parametri senza andare a leggere il codice\ndobbiamo dichiarare le librerie comunque\n\n\n\n\n\n                  \n                  cosa sono i wrapper? \n                  \n                \n\nNon sono dei cantanti xD\nsi chiamano cos√¨ quelle funzioni che implementano altre funzioni ma le migliorano ‚Äúaggiungendo‚Äù cose\n\nin pratica, un wrapper √® una sorta di ‚Äústrato‚Äù di codice che si trova intorno a un‚Äôaltra funzione\nun esempio √® tipo una funzione che fa delle equazioni e tu gli aggiungi una funzione che fa da wrapper e magari stampa il log di quella funzione con tutti i passaggi che fa\n\n\n\nLa ATTRAVERSATA del Croce\nCome abbiamo detto in precedenza syscall √® la versione pi√π a basso livello delle altre funzioni che abbiamo visto, ora vedremo dei passaggi da read della libreria libc‚Üí syscall\n\nelenco dei passaggi\nalcuni punti saranno approssimati per rendere l‚Äôidea\n\nTutti i passaggi da read() a sys_read()\n\n\nFunzione read() in glibc\n\nAll‚Äôinterno della libreria glibc(implementazione della libc) √® presente un wrapper chiamato read().\n\nLa sua implementazione si trova nel file read.c all‚Äôinterno della libreria glibc.\n\n\n\n\n\nMacro SYSCALL_CANCEL\n\nDentro la funzione read(), per effettuare effettivamente la chiamata di sistema, viene utilizzata una macro chiamata SYSCALL_CANCEL, garantisce che una syscall possa essere ‚Äúcancellata‚Äù senza compromettere il comportamento del programma.\n\nLa sua implementazione si trova nel file sysdep.h.\nsi chiama con il #define ed √® tipo una funzione\n\n\n\n\n\nMacro INTERNAL_SYSCALL\n\nLa macro SYSCALL_CANCEL utilizza a sua volta INTERNAL_SYSCALL, che si occupa di configurare i registri del processore, per fare il passaggio di parametri al kernel quando chiamiamo syscall\n\nLa definizione di questa macro si trova anch‚Äôessa in sysdep.h.\n\n\n\n\n\nPunto di ingresso nel kernel (entry_SYSCALL_64)\n\nQuando l‚Äôistruzione syscall viene eseguita, il processore cambia modalit√†(cambio di contesto), passando dall‚Äôesecuzione in spazio utente a quella in spazio kernel. Il primo punto in cui il kernel gestisce questa richiesta √® la funzione entry_SYSCALL_64, scritta in assembly e definita nel file entry_64.S.\n\n\n\nFunzione do_syscall_64\n\nDopo essere entrati nel kernel tramite entry_SYSCALL_64, la funzione do_syscall_64 prende in carico la richiesta. Questa funzione, scritta in C, ha il compito di determinare quale funzione specifica del kernel deve essere chiamata, basandosi sul numero della syscall che √® stato passato (ad esempio, il numero 0 corrisponde alla syscall read).\n\nLa definizione di questa funzione si trova nel file common.c.\n\n\n\n\n\nTabella delle syscall (sys_call_table)\n\nPer sapere quale funzione del kernel deve essere eseguita, do_syscall_64 consulta la tabella delle syscall, chiamata sys_call_table. Questa tabella mappa i numeri delle syscall alle rispettive funzioni. Per la syscall read, il numero √® 0, e la tabella lo collega alla funzione __x64_sys_read.\n\nLa tabella si trova nel file syscall_64.tbl.\n\n\n\n\n\nFunzione __x64_sys_read\n\nQuesta funzione √® un wrapper per la logica vera e propria della syscall read, implementata internamente in un‚Äôaltra funzione chiamata ksys_read, che contiene il codice che interagisce con il file system per leggere effettivamente i dati richiesti.\n\nLa funzione __x64_sys_read √® implementata nel file read_write.c.\n\n\n\n\n\n\nCREAZIONE DEI PROCESSI\nCerchiamo attraverso delle funzioni in librerie di creare una shell minimale\n\nquali sono le funzionalit√† BASILARI di una shell?\n\nAttende un comando: La shell interagisce con l‚Äôutente e aspetta un input.\nCrea un processo: Quando l‚Äôutente digita un comando, la shell utilizza una chiamata di sistema, come fork(), per creare un nuovo processo.\nEsegue e attende: Il processo esegue il comando (usando execv()) e la shell aspetta che termini (con wait()).\n\n\n\nintanto vediamo il 2 e il 3\n1.Creazione di un processo e wait\nabbiamo due funzioni\n\npid_t fork, duplica il processo corrente e ritorna 0 se √® il figlio oppure il pid del figlio se √® il padre\n\nil fatto che ci sia 0 o il pid serve per differenziare le due cose\n\n\npid_t wait, monitora un processo figlio modificando una variabile status che gli passiamo noi, quest‚Äôultima verr√† letta dal processo padre\n\nCODICE DI ESEMPIO\nvoid main(void){\n\tint pid, child_status;\n\t\n\tif (fork() == 0){\n\t\tfai_qualcosa_nel_figlio(); // una funzione non implementata ma esplicita\n\t}\n\telse{\n\t\twait(&amp;child_status); // il padre aspetta che il figlio cambi stato\n\t}\n}\n\nvediamo il codice in c come se venisse eseguito da entrambe le parti, ovvero sia dal padre che dal figlio\nentrambi fanno la chiamata fork\nil processo padre usa wait e passa la variabile child status con &amp; per farla modificare\n\n2.Creazione di un processo, wait e execv\nexecv crea un nuovo processo sostituendolo a quello precedente facendolo cessare di esistere, eliminando le mappature in memoria del vecchio mettendo quelle del nuovo\nNon ritorna mai se ha successo:\n\nSe execv() ha successo, il nuovo programma viene eseguito immediatamente e execv() non ritorna mai al chiamante.\nSe fallisce (ad esempio, se il file indicato da path non esiste), restituisce un valore negativo e imposta errno.\n\nCODICE DI ESEMPIO\nvoid main(void){\n    int pid, child_status;\n    char *args[] = {&quot;/bin/ls&quot;, &quot;-l&quot;, NULL}; // Argomenti per execv()\n \n    if (fork() == 0) { // Creazione del processo figlio\n        execv(args[0], args); // Nel figlio: carica ed esegui il programma \n\t\t\t\t\t\t      ///bin/ls con argomenti &quot;-l&quot;\n    } \n    else {\n        wait(&amp;child_status); // Nel genitore: aspetta che il figlio termini\n    }\n}\n \n\nper far funzionare execv doppiamo negli argomenti\n\npassare il path del programma da eseguire(in questo caso quello in args)\noltre a passare il path passiamo direttamente l‚Äôarray di puntatori con le relative opzioni del comando\nl‚Äôultima posizione di args deve essere NULL per definire la fine\n\n\n\n3. Creazione di un processo, wait, execv e attesa di un comando\nEsempio di shell minimale\nIl seguente codice mostra il funzionamento di una shell minimale, ossia un programma che:\nCODICE DI ESEMPIO\nwhile (1) {\n    char cmd[256], *args[256]; // Buffer per il comando e i suoi argomenti\n    int status; // Per memorizzare lo stato del processo figlio\n    pid_t pid; // Per memorizzare il PID del processo figlio\n \n    read_command(cmd, args); // Legge il comando e gli argomenti dalla riga di \n                             // comando\n \n    pid = fork(); // Crea un nuovo processo figlio\n \n    if (pid == 0) { // Nel processo figlio\n        execv(cmd, args); // Sostituisce il processo figlio con il programma \n                          // specificato\n        exit(1); // Esce con errore se execv fallisce\n    } \n    else {\n        wait(&amp;status); // Nel processo genitore: aspetta che il figlio termini\n    }\n}\n\nl‚Äôunica cosa nuova √® read_command che legge dalla riga di comando e modifica le variabili cmd e args,\ncmd ricever√† il path del programma da eseguire\nargs le opzioni con il NULL\n\nse scrivo tipo ls -l\nls verr√† convertito in un path da mettere in cmd /bin/ls\nil path poi -l con NULL verr√† messo in args\n\n\n\nCome terminare i programmi?\nUSO CTRL+C che sostanzialmente invia un segnale\nI segnali\n\n\n                  \n                  Cos&#039;√® un segnale? \n                  \n                \n\n\nI segnali sono un meccanismo di comunicazione utilizzato in Unix/Linux per notificare ai processi eventi asincroni.\nUn segnale √® come un messaggio che viene inviato al processo per avvisarlo di un evento specifico, ad esempio:\n\nterminazione\ninterruzzione\nerrori vari\n\n\n\n\n\n\nogni processo ha un suo signal handler che gestisce la ricezione dei segnali indirizzati ad esso\n\nSignal, Alarm, Kill\nsono in signal.h\nvedremo tutti prototipi in questo file header\nsignal()\nsighandler_t signal(int signum, sighandler_t handler);\n\nCosa fa: Registra un gestore di segnali (signal handler) per un segnale specifico.\nsignum intero che identifica il tipo di segnale, ad esempio\n\nSIGINT(interruzione)\nSIGTERM (richiesta di terminazione)\nSIGKILL (terminazione forzata)\n\n\nhandler\n\ndato di tipo sighandler_t un tipo di dato specifico per rappresentare un puntatore a funzione che pu√≤ gestire un segnale.\ncolleghiamo un handler al tipo di segnale definito\n\n\n\nalarm()\nunsigned int alarm(unsigned int seconds);\n\nCosa fa: Imposta un timer che invia il segnale SIGALRM al processo dopo un certo numero di secondi.\nArgomenti:\n\nseconds: Numero di secondi dopo i quali inviare il segnale.\n\n\nComportamento:\n\nDopo che il timer scade, il processo riceve SIGALRM.\nPuoi gestire SIGALRM con un handler personalizzato o lasciare il comportamento predefinito.\nSe chiami alarm(0), annulli il timer.\n\n\n\n\n\n                  \n                  ESEMPIO \n                  \n                \n\n#include &lt;stdio.h&gt;\n \n#include &lt;signal.h&gt;\n#include &lt;unistd.h&gt;\n#include &lt;stdlib.h&gt;\n \nvoid alarm_handler(int signal) {\n   printf(&quot;In signal handler: caught signal %d!\\n&quot;, signal);\n   exit(0); // Termina il programma\n}\n \n \nint main(int argc, char **argv) {\n   signal(SIGALRM, alarm_handler); // Associa SIGALRM al gestore custom\n   alarm(1); // Imposta un timer: SIGALRM sar√† inviato dopo 1 secondo\n \n   while (1) {\n       printf(&quot;I am running!\\n&quot;); // Stampa &quot;I am running!&quot; continuamente\n   }\n \n   return 0;\n}\n\nunsigned int indica un int con solo valori positivi\ndichiariamo una funzione che gestir√† alarm con un determinato segnale\nnel main signal\n\n\n\nkill()\nint kill(pid_t pid, int sig);\n\nCosa fa: Invia un segnale specifico a un processo identificato dal suo PID.\nArgomenti:\n\npid: Il PID del processo al quale inviare il segnale.\n\npid &gt; 0: Il segnale viene inviato al processo con quel PID.\npid == 0: Il segnale viene inviato a tutti i processi nel gruppo del chiamante.\npid &lt; 0: Il segnale viene inviato a tutti i processi nel gruppo identificato da |pid|.\n\n\nsig: Il segnale da inviare (es., SIGTERM, SIGKILL, SIGUSR1).\n\n\nNota:\n\nkill() non sempre ‚Äúuccide‚Äù il processo. Il segnale inviato pu√≤ essere gestito dal processo in modo personalizzato, a meno che non sia un segnale non ignorabile (come SIGKILL).\n\n\n\nComunicazione tra processi attraverso PIPE\nOPEN,CLOSE,DUP\nopen()\nint open(const char *pathname, int flags);\n\nCosa fa: Apre un file specificato dal percorso pathname e restituisce un file descriptor (fd), un identificatore unico per il file.\nArgomenti:\n\npathname: Il percorso al file da aprire.\nflags: Specifica come aprire il file (es., sola lettura, scrittura, o entrambe). Esempi di flag:\n\nO_RDONLY: Apre il file in sola lettura.\nO_WRONLY: Apre il file in sola scrittura.\nO_RDWR: Apre il file in lettura e scrittura.\nO_CREAT:\n\n\n\n\nValore restituito:\n\nUn intero positivo (il file descriptor) se l‚Äôapertura √® riuscita.\n-1 in caso di errore, e errno contiene il codice dell‚Äôerrore.\n\n\n\nclose()\nint close(int fd);\n\nCosa fa: Chiude il file associato al file descriptor fd.\nArgomenti:\n\nfd: Il file descriptor da chiudere.\n\n\nValore restituito:\n\n0 se la chiusura √® riuscita.\n-1 in caso di errore, e errno contiene il codice dell‚Äôerrore.\n\n\nDopo la chiusura, il sistema operativo libera il file descriptor e lo rende disponibile per essere riassegnato ad altri file o risorse in futuro.\n\n\n\n                  \n                  piccola parentesi sui file descriptor da francesco totti \n                  \n                \n\nAh reg√†, ce sto! Allora, se chiudi er file col file descriptor, ‚Äòsto numero magico va a farsi na vacanza, capito? In pratica, quanno usi close(fd);, er file descriptor sparisce, nun lo puoi pi√π us√†. Se provi a farce operazioni tipo legge o scrive, te becca er sistema e te dice ‚ÄúA Fra‚Äô, che stai a fa‚Äô?‚Äù.\nEr file descriptor mo √® libero come ‚Äòn uccellino, pronto a esse riassegnato. Quindi, se apri n‚Äôantra risorsa, pu√≤ pure capit√† che usi lo stesso numero de file descriptor. Insomma, chiudi er file e nun ce pensi pi√π, sta storia √® chiusa!\n\n\npipe()\nint pipe(int pipefd[2]);\n\nCosa fa: Crea una pipe, un canale di comunicazione unidirezionale tra processi.\nla pipe funziona con processo1 | processo2\nLa pipe ha due estremit√†:\n\npipefd[0]: quando scrivo 0 intendo lettura\npipefd[1]: quando scrivo 1 intendo scrittura\n\n\nquando un processo deve inviare dei file al processo che si trova a destra della | allora deve fare una scrittura\ncaso opposto lettura\nArgomenti:\n\npipefd: Un array di due file descriptor, dove:\n\npipefd[0] √® usato per leggere dalla pipe.\npipefd[1] √® usato per scrivere nella pipe.\n\n\n\n\nValore restituito:\n\n0 se la pipe √® stata creata correttamente.\n-1 in caso di errore, e errno contiene il codice dell‚Äôerrore.\n\n\n\ndup()\nint dup(int oldfd);\n\nCosa fa: Crea una copia del file descriptor oldfd e restituisce il file descriptor pi√π basso disponibile come copia\nin pratica se io ho i file descriptor 0, 1, 2 (stdin, stdout, stderr) e un file aperto fd = 3, se chiamo int new_fd = dup(3) il sistema assegner√† il valore 4 a new_fd perch√© √® il file descriptor pi√π basso disponibile.\nArgomenti:\n\noldfd: Il file descriptor da copiare.\n\n\nValore restituito:\n\nUn nuovo file descriptor (la copia) se l‚Äôoperazione √® riuscita.\n-1 in caso di errore, e errno contiene il codice dell‚Äôerrore.\n\n\n\n\n\n                  \n                  Differenze tra dup e dup2\n                  \n                \n\n\ndup(oldfd):\n\n\nFa una copia di un file descriptor.\nTi restituisce il numero pi√π basso disponibile tra i file descriptor non usati.\n\n\nEsempio: Se oldfd √® 3 e il file descriptor 4 √® libero, dup() restituir√† 4.\n\n\n\n\n\ndup2(oldfd, newfd):\n\n\nTi permette di scegliere esattamente quale numero usare come copia (newfd).\nSe il numero newfd √® gi√† occupato, lo chiude automaticamente prima di riassegnarlo.\n\nEsempio: Se vuoi che il file descriptor 3 diventi anche il numero 1 (stdout), userai dup2(3, 1).\n\n\n\nPerch√© sono utili?\nImmagina che tu voglia:\n\nReindirizzare l‚Äôoutput di un programma:\n\nNormalmente tutto ci√≤ che stampi (con printf) va al terminale.\nCon dup2, puoi ‚Äúagganciare‚Äù l‚Äôoutput (stdout) a un file. Cos√¨ tutto quello che il programma stampa finir√† nel file invece che sul terminale.\n\n\nUsare una pipe tra processi:\n\nIn una pipeline (ls | grep txt), il comando ls deve mandare il suo output non al terminale, ma all‚Äôinput di grep.\nQuesto si fa con dup2 per collegare i file descriptor.\n\n\n\n\n\nESEMPI CON CODICI\nESEMPIO1\nint file_fd = open(&quot;output.txt&quot;, O_WRONLY | O_CREAT, 0644);\ndup2(file_fd, STDOUT_FILENO);\nprintf(&quot;Questo va in output.txt\\n&quot;);\nclose(file_fd);\n\nopen prende un file in un path e sceglie di aprirlo in sola lettura oppure crearlo, mettiamo 0644 se in caso lo creiamo mettiamo quei ruolivedi qui la cosa dei ruoli\nmettiamo il file descriptor ritornato da open infile_fd\ndup2 sostituisce il file_fd con uno standard output con``FILENO\nprint stampiamo\nclose chiudiamo\n\nESEMPIO2\nint fd[2];           // Array per i file descriptor: fd[0] (lettura), fd[1] (scrittura)\npipe(fd);            // Creazione della pipe\n \nif (fork() == 0) {   // Processo figlio\n    close(fd[0]);    // Chiude l&#039;estremit√† di lettura (non usata dal figlio)\n    dup2(fd[1], STDOUT_FILENO);  // Reindirizza stdout nella pipe\n    execlp(&quot;ps&quot;, &quot;ps&quot;, &quot;aux&quot;, NULL); // Esegue il comando `ps aux`\n} else {             // Processo genitore\n    close(fd[1]);    // Chiude l&#039;estremit√† di scrittura (non usata dal genitore)\n    dup2(fd[0], STDIN_FILENO);   // Reindirizza stdin dalla pipe\n    execlp(&quot;grep&quot;, &quot;grep&quot;, &quot;httpd&quot;, NULL); // Esegue il comando `grep httpd`\n}\n\n\nmette lo standard output della bash dentro lo stream di scrittura.\n\n\nil padre prende lo standard input e ci mette lo stream della pipe in lettura\n\n\nexeclp: funziona come execv solo che\n\naccetta le stringhe singolarmente senza creare array di stringhe\ncon p diciamo che tutti i processi da prendere sono nel path e quindi non bisogna specificare tipo /bin/ps ecc‚Ä¶\n\n\n\n\n\n                  \n                  esempio di codice con execlp o execv\n                  \n                \n\nexecv\nchar *args[] = {&quot;ls&quot;, &quot;-l&quot;, &quot;-a&quot;, NULL};\nexecv(&quot;/bin/ls&quot;, args);\nnotare come devo specificare il path e usare la stringa di array\nexeclp\nexeclp(&quot;ls&quot;, &quot;ls&quot;, &quot;-l&quot;, &quot;-a&quot;,NULL);\n\n\nESEMPIO3\nif (fork() == 0) {                     // Processo figlio\n    int log_fd = open(&quot;logfile.txt&quot;, O_WRONLY | O_CREAT | O_APPEND, 0644);\n    dup2(log_fd, STDOUT_FILENO);       // Reindirizza stdout verso il file\n    close(log_fd);                     // Chiude il file descriptor\n    execlp(&quot;ls&quot;, &quot;ls&quot;, &quot;-l&quot;, NULL);    // Esegue il comando `ls -l`\n}\nuniche cose da ricordare\ntrattiamo quel file descriptor come\n\nO_WRONLY sola scrittura\nO_CREAT se non esiste lo crea\nO_APPEND se il file esiste tutto quello che scrive lo mette in append\n\nESEMPIO4 (THE PIPE EXAMPLE)\n#include &lt;stdio.h&gt;\n#include &lt;stdlib.h&gt;\n#include &lt;unistd.h&gt;\n#include &lt;sys/types.h&gt;\n#include &lt;sys/wait.h&gt;\n \n#define STDIN 0\n#define STDOUT 1\n#define PIPE_RD 0\n#define PIPE_WR 1\n \nint main(int argc, char** argv) {\n    pid_t cat_pid, sort_pid;\n    int fd[2];\n    \n    pipe(fd);\n \n    // Primo processo figlio: `cat names.txt`\n    cat_pid = fork();\n    if (cat_pid == 0) { // Processo figlio per `cat`\n        close(fd[PIPE_RD]);          // Chiude l&#039;estremit√† di lettura (non usata)\n        close(STDOUT);               // Chiude lo standard output\n        dup(fd[PIPE_WR]);            // Reindirizza stdout verso la pipe\n        execl(&quot;/bin/cat&quot;, &quot;cat&quot;, &quot;names.txt&quot;, NULL); // Esegue `cat names.txt`\n    }\n    \n    \n    // Secondo processo figlio: `sort`\n    sort_pid = fork();\n    if (sort_pid == 0) { // Processo figlio per `sort`\n        close(fd[PIPE_WR]);          // Chiude l&#039;estremit√† di scrittura (non usata)\n        close(STDIN);                // Chiude lo standard input\n        dup(fd[PIPE_RD]);            // Reindirizza stdin verso la pipe\n        execl(&quot;/usr/bin/sort&quot;, &quot;sort&quot;, NULL); // Esegue `sort`\n    }\n    \n    \n    // Processo genitore: chiude entrambe le estremit√† della pipe\n    close(fd[PIPE_RD]);\n    close(fd[PIPE_WR]);\n    \n    // Attende che i processi figli terminino\n    waitpid(cat_pid, NULL, 0);\n    waitpid(sort_pid, NULL, 0);\n    \n    return 0;\n}\nCosa succede se non chiudo una pipe? spiegata da Totti\nAh√≥, mo‚Äô te spiego come Francesco Totti, co‚Äô parole semplici, sto discorso delle ‚Äúchiusure‚Äù.\n√à importante, perch√© le pipe s√≤ tipo i passaggi della palla. Se nun chiudi bene ‚Äòsti passaggi, succede un casino, capito?\n\nEvitare Blocchi: √à come quando passi ‚Äòa palla e nun te muovi. Se lasci aperta la pipe, quello che scrive rimane ‚Äúbloccato‚Äù perch√© aspetta. Devi chiude la fine de lettura, cos√¨ tutto fila liscio. Ricezione\nEOF: Sort aspetta er fischio finale (EOF) per cap√¨ che tutto √® finito. Devi chiude la pipe de scrittura, senn√≤ lui rimane l√† fermo, aspettando ‚Äòna palla che nun arriva.\nEvitare Letture Accidentali: Se c‚Äôhai una pipe aperta e non la chiudi, ‚Äòna lettura inaspettata potrebbe fa‚Äô un casino, tipo uno che prende la palla quando nun deve.\nReindirizzamento di STDOUT in cat: √à come dire a ‚Äòcat‚Äô di passare ‚Äòa palla solo nella pipe, niente dribbling extra. Chiudi er vecchio passaggio e fallo passare solo dove serve.\nReindirizzamento di STDIN in sort: Dopo il setup, devi fa‚Äô in modo che sort guardi solo ‚Äòna direzione, cio√® la pipe. Quindi chiudi er vecchio ingresso.\nDescriptor nel Processo Padre: Dopo er fork, il processo padre deve chiude le estremit√† della pipe, come un allenatore che lascia spazio ai giocatori sul campo.\nCapito? √à tipo gioca‚Äô a pallone: se nun chiudi i passaggi che non servono, tutto se incasina!\n\n\n\n                  \n                  ALTRI ESEMPI DI CODICI SUL SUO TEAMS NEI FILE CODING \n                  \n                \n\nESERCIZIO PER CASA\n"},"UNI/ANNO-2/SISTEMI-OPERATIVI/TICKET-TO-RIDE":{"slug":"UNI/ANNO-2/SISTEMI-OPERATIVI/TICKET-TO-RIDE","filePath":"UNI/ANNO 2/SISTEMI OPERATIVI/TICKET TO RIDE.md","title":"TICKET TO RIDE","links":[],"tags":[],"content":"PROCESSI\n\nDefinizione\nstati di un processo\nlayout di un processo\ncpu bound\ni/o bound\ncpu burst\nThread\n\nspazio utente spazio kernel\nrace condition\nregione critica\natomico\n\n\nComunicazione tra processi\n\npipe\ninterrupt\n\nprecisi imprecisi\n\n\nsegnali\n\n\nscheduler\n\nsistemi e algoritmi\nprelazione no\n\n\naltro sulla sincronizzazione\n\nbarriere\nread copy update\n\n\n\nMEMORIA\n\nsenza astrazione\n\nindirizzamenti diretti no spazio indirizzi\n\n\nastrazione\n\nreg base + limite\nswapping(intero)\navvantaggio crescita\nspazi liberi\n\nbitmap\nliste\n\n\nalgoritmi di allocazione\nbuddy allocator\nslab\n\n\nmemoria virtuale\n\npagine\n\npage fault\nspazi di swap\ntabelle\n\nsingola\n2 o 4\n\n\nTLB MMU\nsoft miss hard miss\ndimensione delle pagine\nframmentazione interna\npage fault frequency\ntrashing\nalgoritmi di paging\nallocazione globale locale\nequa proporzionale\nout of memory killer e demon\n\n\nI SPACE D SPACE\n\nread copy on write\n\n\nsegmentazione\n\nmultics\nha anche una TLB\nframmentazione esterna\n\n\n\n\n\nFILE E FILE SYSTEM\n\nproblema memorizzazione(volatile)\ndefinizione di file\n\n3 modi struttura file\ntipi di file\n\nnormali,\nspeciali(caratteri, blocchi),eseguibili, archivio\n\n\naccesso sequenziale casuale\n\n\ndirectory\n\ndue tipi di directory\nsingolo livello o gerarchico\nconcetto di root\nnomi dei file\n\n\nfile system\n\ndefinizione\nallocazione blocchi contigua o liste\nfat\n\nram\n\n\next2\n\ni-node, gruppi\n\n\nhard link soft link symbol link\nroadmap\nvirtual file system\n\n\ndisco\n\ntracciare blocchi liberi\n\nbitmap liste\n\n\nquote utente\nbackup e raid\n\n\n\nDispositivi I/O\n\ndefinizione\nblocchi o caratteri\nmemory mapped port mapped\n\nproblema cache\n\ntentativi sequenziali o snooping\n\n\n\n\nSOFTWARE\n\nregole\n\nbuffering\nindipendente\nerrori\nsincroni asincroni\n\n\nprogrammato\ninterrupt\n\ngestore\n\n\nDMA\ndriver\n\nkernel o utente\n3 livelli\na caratteri o blocchi\n\n\nsoftware indipendente\n\nbuffering\nspooling\nerrori con interazione\n\n\n\n\n\nS.O.\n\n\ndefinizione\n\n\nkernel\n\nunikernel\nexokernel\nmicrokernel\n\n\n\nsyscall\n\n\nvirtualizzazione\n\ncontainer\nhypervisor\n\n\n"},"UNI/ANNO-3/ALGORITMI-PER-I-BIG-DATA/BIG-DATA-INDICE":{"slug":"UNI/ANNO-3/ALGORITMI-PER-I-BIG-DATA/BIG-DATA-INDICE","filePath":"UNI/ANNO 3/ALGORITMI PER I BIG DATA/BIG DATA INDICE.md","title":"BIG DATA INDICE","links":[],"tags":[],"content":""},"UNI/ANNO-3/ALGORITMI-PER-I-BIG-DATA/BIG-LEZ-1":{"slug":"UNI/ANNO-3/ALGORITMI-PER-I-BIG-DATA/BIG-LEZ-1","filePath":"UNI/ANNO 3/ALGORITMI PER I BIG DATA/BIG LEZ 1.md","title":"BIG LEZ 1","links":[],"tags":[],"content":"\nsketch numero su una data pagina che questo random walker abbia una certa prob\n"},"UNI/ANNO-3/CRITTOGRAFIA/CRITTOFOTO/LEZ-1":{"slug":"UNI/ANNO-3/CRITTOGRAFIA/CRITTOFOTO/LEZ-1","filePath":"UNI/ANNO 3/CRITTOGRAFIA/CRITTOFOTO/LEZ 1.md","title":"LEZ 1","links":[],"tags":[],"content":""},"UNI/ANNO-3/CRITTOGRAFIA/CRITTOGRAFIA-INDICE":{"slug":"UNI/ANNO-3/CRITTOGRAFIA/CRITTOGRAFIA-INDICE","filePath":"UNI/ANNO 3/CRITTOGRAFIA/CRITTOGRAFIA INDICE.md","title":"CRITTOGRAFIA INDICE","links":["UNI/ANNO-3/CRITTOGRAFIA/INTRODUZIONE"],"tags":[],"content":"INTRODUZIONE"},"UNI/ANNO-3/CRITTOGRAFIA/INTRODUZIONE":{"slug":"UNI/ANNO-3/CRITTOGRAFIA/INTRODUZIONE","filePath":"UNI/ANNO 3/CRITTOGRAFIA/INTRODUZIONE.md","title":"INTRODUZIONE","links":[],"tags":[],"content":"TUTTO IL CAPITOLO 1 DEL LIBRO\nIntroduzione alla crittografia\nIl capitolo presenta una panoramica dei principali problemi studiati nella crittografia e delle tecniche utilizzate per risolverli.\nL‚Äôobiettivo √® introdurre, in modo non tecnico, i concetti fondamentali che saranno approfonditi nei capitoli successivi.\n\n1.1 ‚Äì Crittosistemi e strumenti di base\nCrittosistemi a chiave segreta\n√à il modello pi√π antico: due persone (Alice e Bob) condividono una chiave segreta usata per cifrare (encryption) e decifrare (decryption) i messaggi.\nIl messaggio originale (plaintext) diventa un testo cifrato (ciphertext) leggibile solo con la chiave corretta.\nLa sicurezza dipende dal segreto della chiave e dalla sua lunghezza: pi√π ampio √® lo spazio delle chiavi, pi√π difficile √® un attacco per forza bruta.\nL‚Äôinsieme delle tecniche usate per tentare di ‚Äúrompere‚Äù un sistema cifrato si chiama crittanalisi.\nOltre alla protezione dei dati trasmessi, la crittografia moderna viene impiegata anche per proteggere i dati memorizzati, come file su dischi, database o cloud.\nIl limite principale di questo modello √® la distribuzione della chiave: Alice e Bob devono accordarsi sulla chiave in modo sicuro prima di comunicare, il che pu√≤ essere complesso se si trovano in luoghi diversi.\nCrittosistemi a chiave pubblica\nIntrodotti negli anni ‚Äô70 da Diffie e Hellman, prevedono due chiavi diverse:\n\n\nuna pubblica (nota a tutti) per cifrare;\n\n\nuna privata (nota solo al destinatario) per decifrare.\nEsempio classico: RSA.\nQuesto elimina la necessit√† di una chiave condivisa, ma introduce un nuovo problema: come garantire che una chiave pubblica sia autentica?\nLa soluzione √® l‚Äôuso di certificati digitali, firmati da autorit√† di fiducia.\n\n\nCifrari a blocchi e a flusso\n\n\nBlock cipher: divide il testo in blocchi fissi (es. 128 bit) e li cifra uno per volta.\n\n\nStream cipher: genera un flusso continuo di bit (keystream) combinato con il messaggio tramite XOR.\nI sistemi a chiave pubblica sono sempre a blocchi; quelli a chiave segreta possono essere di entrambi i tipi.\n\n\nCrittografia ibrida\nCombina i vantaggi dei due modelli:\nAlice genera una chiave segreta casuale per cifrare il messaggio con un algoritmo veloce, poi cifra quella chiave con la chiave pubblica di Bob.\nBob decifra prima la chiave segreta e poi il messaggio.\n√à il principio alla base dei protocolli HTTPS/TLS.\n\n1.2 ‚Äì Integrit√† dei messaggi\nLa cifratura garantisce la riservatezza, ma non l‚Äôintegrit√†: un avversario attivo pu√≤ modificare o falsificare messaggi.\nPer questo, oltre all‚Äôencryption, servono strumenti che assicurino che i dati non siano stati alterati e che provengano davvero dal mittente.\nAvversario passivo e avversario attivo\n\n\nUn avversario passivo (eavesdropper) pu√≤ intercettare i messaggi ma non li altera.\nIl suo obiettivo √® leggere informazioni riservate, e la crittografia serve a difendersi da questo tipo di minaccia. FIGURA 1.1\n\n\nUn avversario attivo pu√≤ invece modificare, falsificare o dirottare i messaggi durante la trasmissione.\nPu√≤ alterare i dati, fingere di essere un altro mittente o redirigere la comunicazione verso terzi.\nContro questi attacchi servono strumenti che garantiscano autenticit√† e integrit√†, come MAC e firme digitali. FIGURA 1.2\n\n\n\nUn esempio di vulnerabilit√† a un attacco attivo √® il bit-flipping attack nei cifrari a flusso: se un avversario modifica alcuni bit del ciphertext, i corrispondenti bit del plaintext vengono cambiati in modo prevedibile, anche senza conoscere la chiave.\nCodici di autenticazione dei messaggi (MAC)\nRichiedono una chiave segreta condivisa.\nAlice genera un tag (una breve firma) sul messaggio usando la chiave; Bob lo ricrea per verificare l‚Äôautenticit√†.\nUn avversario senza chiave non pu√≤ creare tag validi.\nSchema comune: encrypt-then-MAC (prima cifrare, poi firmare).\nFirme digitali\nUsano la chiave privata del mittente per firmare e la chiave pubblica per verificare.\nChiunque pu√≤ controllare la firma, ma solo il titolare pu√≤ crearla.\nEsempio pratico: aggiornamenti software firmati.\nSchema combinato: sign-then-encrypt (prima firmare, poi cifrare).\nNon ripudio\nLe firme digitali permettono di dimostrare che un messaggio √® stato firmato da un individuo, impedendogli di negarlo in seguito (non-repudiation).\nI MAC non offrono questa garanzia, perch√© la chiave √® condivisa tra entrambe le parti, e nessuno pu√≤ provare chi ha creato il tag.\nI MAC sono quindi ‚Äúdeniable‚Äù, utili in comunicazioni ‚Äúoff the record‚Äù.\nCertificati\nServono a verificare l‚Äôautenticit√† delle chiavi pubbliche.\nSono firmati da autorit√† di fiducia (CA), il cui certificato √® preinstallato nei browser.\nUsati in TLS per stabilire connessioni sicure tra client e server.\nFunzioni di hash\nTrasformano messaggi di lunghezza arbitraria in un digest di lunghezza fissa.\nServono a firmare messaggi lunghi (hash-then-sign) e per derivare chiavi.\nDevono essere resistenti alle collisioni (impossibile trovare due messaggi con lo stesso hash).\nNon possono essere usate per cifrare, perch√© non sono invertibili n√© basate su chiavi.\n\n1.3 ‚Äì Protocolli crittografici\nI protocolli combinano vari strumenti (cifratura, firme, hash) per creare sistemi pi√π complessi.\nEsempi:\n\n\nSchemi di identificazione: provano l‚Äôidentit√† di un utente (es. password, challenge‚Äìresponse).\n\n\nDistribuzione e accordo di chiavi: permettono a due parti di stabilire una chiave segreta, con o senza l‚Äôintervento di un‚Äôautorit√† fidata (es. protocollo Diffie-Hellman).\n\n\nSecret sharing: un segreto √® diviso in pi√π parti (‚Äúshare‚Äù) e pu√≤ essere ricostruito solo da un numero minimo di esse, secondo uno schema (k, n).\n\n\n\n1.4 ‚Äì Sicurezza\nUn sistema √® ‚Äúsicuro‚Äù se un avversario non pu√≤ violarlo con le risorse disponibili.\nLa sicurezza si analizza considerando tre aspetti:\n\n\nModello di attacco: quali informazioni ha l‚Äôavversario (ciphertext, plaintext, messaggi scelti, ecc.).\n\n\nObiettivo: cosa vuole ottenere (chiave, contenuto, o solo distinguere due messaggi).\n\n\nLivello di sicurezza: quante risorse e quanto tempo servono per riuscirci.\n\n\nModelli di attacco principali\n\n\nCiphertext-only attack: l‚Äôattaccante ha solo testi cifrati.\n\n\nKnown-plaintext attack: conosce alcune coppie plaintext‚Äìciphertext.\n\n\nChosen-plaintext attack: pu√≤ scegliere i messaggi da cifrare.\n\n\nChosen-ciphertext attack: pu√≤ chiedere la decifrazione di testi a sua scelta.\nI modelli 3 e 4 sono pi√π forti, perch√© offrono all‚Äôavversario pi√π informazioni.\n\n\nTipi di sicurezza\n\n\nComputazionale: il sistema √® sicuro perch√© richiederebbe risorse o tempo eccessivi per essere violato.\n\n\nDimostrabile (provable): la sua sicurezza √® ridotta a un problema matematico difficile (es. fattorizzazione, logaritmo discreto).\n\n\nIncondizionata: l‚Äôattacco √® impossibile anche con risorse illimitate, come nel One-Time Pad.\n\n\nUn esempio storico √® il caso RSA del 1977: una sfida pubblica proponeva un messaggio cifrato con una chiave di 512 bit, che si credeva indecifrabile per ‚Äúmilioni di anni‚Äù. Fu risolta nel 1994 grazie a computer pi√π veloci, nuovi algoritmi e la cooperazione via Internet ‚Äî dimostrando che la sicurezza computazionale cambia nel tempo.\nAttacchi pratici e implementativi\nAnche un sistema matematicamente sicuro pu√≤ essere vulnerabile se mal implementato.\nEsempi:\n\n\nPadding oracle attack: sfrutta errori nella gestione del padding nei cifrari a blocchi.\n\n\nSide-channel attacks: analizzano informazioni fisiche (tempi di esecuzione, consumo energetico, cache, errori hardware) per estrarre chiavi o dati segreti.\nQuesti attacchi dimostrano che la sicurezza deve considerare anche l‚Äôimplementazione fisica, non solo la teoria.\n\n"},"UNI/ANNO-3/CRITTOGRAFIA/LEZ-1":{"slug":"UNI/ANNO-3/CRITTOGRAFIA/LEZ-1","filePath":"UNI/ANNO 3/CRITTOGRAFIA/LEZ 1.md","title":"LEZ 1","links":[],"tags":[],"content":"2.1.1\n2.1.2\n2.2.1\n2.2.2\nüîπ Obiettivo della crittografia\nLo scopo principale della crittografia √® permettere a due persone (tradizionalmente Alice e Bob) di comunicare in modo sicuro su un canale insicuro (come Internet o una linea telefonica).\n\nAlice vuole inviare un messaggio (plaintext) a Bob.\nUsa una chiave segreta e un algoritmo di cifratura per trasformarlo in ciphertext (testo cifrato).\nBob riceve il ciphertext e, usando la stessa chiave (o una chiave corrispondente), lo decifra per recuperare il messaggio originale.\nUn avversario (Oscar), anche se intercetta il ciphertext, non √® in grado di capire il contenuto.\n\n\nüîπ Definizione formale di un crittosistema\nUn crittosistema √® definito matematicamente come una cinquina:\n(P, C, K, E, D)\ndove:\n\nP √® l‚Äôinsieme dei plaintexts (tutti i possibili messaggi originali);\nC √® l‚Äôinsieme dei ciphertexts (tutti i possibili messaggi cifrati);\nK √® lo spazio delle chiavi, cio√® l‚Äôinsieme di tutte le chiavi possibili;\nPer ogni chiave K \\in K:\n\nesiste una funzione di cifratura e_K : P \\to C\ned una funzione di decifratura d_K : C \\to P\ntali che:\n\n\n\nd_K(e_K(x)) = x \\quad \\text{per ogni } x \\in P\n(cio√®, se cifri e poi decifri, ottieni di nuovo il messaggio originale).\n‚û°Ô∏è In altre parole, la cifratura e la decifratura sono funzioni inverse l‚Äôuna dell‚Äôaltra per una data chiave.\n\nüîπ Il processo di comunicazione\n\nAlice e Bob concordano una chiave K in modo sicuro (di persona o tramite un canale protetto).\nAlice vuole inviare un messaggio x = x_1x_2 \\dots x_n, composto da n simboli.\nOgni simbolo x_i viene cifrato con la funzione e_K:\ny_i = e_K(x_i)\nottenendo il ciphertext y = y_1y_2 \\dots y_n.\nAlice invia y a Bob tramite il canale insicuro.\nBob applica la funzione di decifratura d_K su ogni simbolo:\nx_i = d_K(y_i)\ne ricostruisce cos√¨ il messaggio originale x.\n\nOscar, anche se intercetta y, non pu√≤ risalire a x senza conoscere la chiave K.\n\nüìä Figura 2.1 ‚Äì Il canale di comunicazione\nL‚Äôimmagine descrive graficamente questo processo:\n\n\nüîπ Propriet√† fondamentali\n\n\nCifratura iniettiva (one-to-one):\nOgni plaintext deve corrispondere a uno e un solo ciphertext.\nSe due plaintext diversi dessero lo stesso ciphertext:\ne_K(x_1) = e_K(x_2), \\quad x_1 \\neq x_2\nallora Bob non potrebbe sapere quale messaggio decifrare ‚Üí il sistema non funzionerebbe.\n\n\nSe P = C (cio√® se l‚Äôinsieme dei plaintext e quello dei ciphertext coincidono):\nogni funzione di cifratura e_K √® una permutazione degli elementi dell‚Äôinsieme.\n‚Üí In questo caso, cifrare significa semplicemente riordinare (permutare) gli elementi del messaggio in modo controllato dalla chiave.\n\n\n\nüîπ Esempio intuitivo: il Cifrario di Cesare\nUn esempio pratico di questo modello √® il Shift Cipher (Cifrario di Cesare):\n\nP = C = \\{ A, B, C, \\dots, Z \\}\nK = \\{ 0, 1, 2, \\dots, 25 \\}\ne_K(x) = (x + K) \\bmod 26\nd_K(y) = (y - K) \\bmod 26\n\nQui:\n\nCifratura e decifratura sono inversi.\nOgni e_K √® una permutazione dell‚Äôalfabeto.\nOscar pu√≤ vedere il ciphertext, ma senza la chiave K non pu√≤ sapere di quanto √® stato ‚Äúspostato‚Äù ogni simbolo.\n\nüîπ 2.1.1 ‚Äì Il Cifrario a Scorrimento (Shift Cipher)\nIl Shift Cipher √® uno dei pi√π semplici esempi di crittosistema.\nFunziona applicando uno spostamento numerico costante a ogni lettera del messaggio, utilizzando le regole dell‚Äôaritmetica modulare.\n\n‚öôÔ∏è Ripasso di aritmetica modulare\nPrima di descrivere il cifrario, il testo ricorda alcuni concetti fondamentali.\nDefinizione di congruenza modulo m\nPer interi a, b e un intero positivo m, diciamo che:\na \\equiv b \\pmod{m}\nse e solo se m divide (b - a).\nIn altre parole, a e b lasciano lo stesso resto quando divisi per m.\nEsempio:\n101 \\bmod 7 = 3, \\quad (-101) \\bmod 7 = 4\n(perch√© -101 = 7 \\times (-15) + 4)\n\nüî∏ Nota: in matematica il resto a \\bmod m √® sempre non negativo, compreso tra 0 e m - 1.\nIn molti linguaggi di programmazione, invece, pu√≤ avere il segno di a.\n\n\nüßÆ L‚Äôinsieme \\mathbb{Z}_m\nSi definisce:\n\\mathbb{Z}_m = \\{ 0, 1, 2, \\dots, m-1 \\}\ncon due operazioni:\n\nAddizione modulo m: (a + b) \\bmod m\nMoltiplicazione modulo m: (a \\times b) \\bmod m\n\nEsempio:\n11 \\times 13 = 143, \\quad 143 \\bmod 16 = 15 \\Rightarrow 11 \\times 13 \\equiv 15 \\pmod{16}\n\nüß© Propriet√† di \\mathbb{Z}_m\n\n√à chiuso per addizione e moltiplicazione.\nLe operazioni sono commutative e associative.\nEsiste l‚Äôelemento neutro:\n\nper l‚Äôaddizione: 0\nper la moltiplicazione: 1\n\n\nOgni elemento ha un inverso additivo:\na + (m - a) \\equiv 0 \\pmod{m}\n\nLe operazioni soddisfano la distributivit√†.\n\nIn termini algebrici:\n\n(\\mathbb{Z}_m, +) √® un gruppo abeliano\n(\\mathbb{Z}_m, +, \\times) √® un anello finito (finite ring)\n\nEsempio:\nIn \\mathbb{Z}_{31},\n11 - 18 = -7 \\Rightarrow (-7) \\bmod 31 = 24\n\nüîê Definizione del Shift Cipher\nIl Cifrario a Scorrimento √® definito come segue:\nP = C = K = \\mathbb{Z}_{26}\nperch√© ci sono 26 lettere nell‚Äôalfabeto inglese.\nLe funzioni di cifratura e decifratura sono:\ne_K(x) = (x + K) \\bmod 26\nd_K(y) = (y - K) \\bmod 26\ndove:\n\nx √® il plaintext (una lettera convertita in numero)\ny √® il ciphertext (la lettera cifrata)\nK √® la chiave (lo ‚Äúspostamento‚Äù)\n\n√à facile verificare che:\nd_K(e_K(x)) = (x + K - K) \\bmod 26 = x\n‚Üí quindi il sistema soddisfa la definizione formale di crittosistema.\n\nüèõÔ∏è Il Cifrario di Cesare\nPer la chiave K = 3, il sistema prende il nome di Cifrario di Cesare, perch√© secondo la tradizione fu usato da Giulio Cesare per le comunicazioni militari.\n\nüî† Corrispondenza lettere‚Äìnumeri\n\n\n‚úâÔ∏è Esempio 2.1\n\nüîç Sicurezza e crittoanalisi\nPerch√© un sistema sia pratico, deve avere:\n\nCifratura e decifratura efficienti\nDifficolt√† di determinare la chiave K osservando solo il ciphertext\n\nMa il Shift Cipher non √® sicuro, perch√©:\n\nil numero di chiavi possibili √® solo 26;\nun avversario pu√≤ provare tutte le chiavi (metodo exhaustive key search).\n\n\nüß© Esempio 2.2 ‚Äì Attacco per forza bruta\nCiphertext:\nJBCRCLQRWCRVNBJENBWRWN\nSi prova ogni chiave K = 0, 1, 2, \\dots, 25.\nDopo alcuni tentativi, si ottiene:\nastitchintimesavesnine\nQuindi il plaintext √® ‚Äúa stitch in time saves nine‚Äù\ne la chiave √® K = 9.\nIn media, basta provare \\frac{26}{2} = 13 chiavi per trovare quella giusta.\n\n‚ö†Ô∏è Conclusione sulla sicurezza\nIl Cifrario a Scorrimento mostra che:\n\nun crittosistema √® insicuro se il suo spazio delle chiavi √® troppo piccolo;\nma un grande keyspace, da solo, non garantisce sicurezza (servono anche buone propriet√† matematiche).\n\nüîπ 2.1.2 ‚Äì Il Cifrario a Sostituzione\nIl Substitution Cipher √® un sistema in cui ogni lettera dell‚Äôalfabeto viene sostituita da un‚Äôaltra lettera, secondo una permutazione casuale.\nIn altre parole, la chiave √® una riorganizzazione dell‚Äôalfabeto.\nQuesto sistema √® molto pi√π flessibile del Cifrario di Cesare, perch√© non si limita a ‚Äúspostare‚Äù tutte le lettere di una quantit√† fissa, ma consente qualunque corrispondenza.\n\nüîê Definizione formale (Cryptosystem 2.2)\nP = C = \\mathbb{Z}_{26}\n(cio√® le 26 lettere dell‚Äôalfabeto inglese rappresentate dai numeri da 0 a 25).\nLa chiave K √® costituita da tutte le possibili permutazioni dell‚Äôinsieme:\n\\{ 0, 1, 2, \\dots, 25 \\}\nPer ogni permutazione \\pi \\in K:\nCifratura:\ne_\\pi(x) = \\pi(x)\nDecifratura:\nd_\\pi(y) = \\pi^{-1}(y)\ndove \\pi^{-1} √® la permutazione inversa, cio√® quella che ‚Äúannulla‚Äù la cifratura.\n\nüß† Significato intuitivo\nOgni lettera del plaintext viene sostituita da una lettera diversa secondo la chiave (cio√® la permutazione).\nPer decifrare, si applica la permutazione inversa, che riporta ogni lettera al suo valore originale.\n\nüî§ Esempio di permutazione\nLa tabella seguente mostra una possibile chiave casuale (cio√® una permutazione dell‚Äôalfabeto):\n\nEsempi:\ne_\\pi(a) = X, \\quad e_\\pi(b) = N, \\quad e_\\pi(c) = Y, \\quad e_\\pi(z) = I\n\nüîÅ Permutazione inversa (decifratura)\nPer decifrare, bisogna invertire la mappa.\nLa seconda tabella mostra la permutazione inversa:\n\nEsempi:\nd_\\pi(A) = d, \\quad d_\\pi(B) = l, \\quad d_\\pi(X) = a, \\quad d_\\pi(Z) = i\n\nüîì Esercizio di decrittazione (dal testo)\nCiphertext:\nMGZVYZLGHCMHJMYXSSFMNHAHYCDLMHA\nUsando la permutazione inversa qui sopra, si pu√≤ risalire al plaintext sostituendo ogni lettera cifrata con la corrispondente lettera in chiaro.\nüëâ (Posso mostrarti la decrittazione completa, se vuoi che la risolviamo passo per passo.)\n\nüìè Spazio delle chiavi\nLa chiave del Substitution Cipher √® una permutazione dell‚Äôalfabeto di 26 lettere.\nQuindi il numero di chiavi possibili √®:\n26! = 26 \\times 25 \\times 24 \\times \\dots \\times 1 \\approx 4.03 \\times 10^{26}\nSi tratta di un numero enorme, quindi una ricerca esaustiva (brute-force) √® impraticabile, anche per un computer moderno.\n\n‚ö†Ô∏è Ma‚Ä¶ non √® sicuro\nNonostante l‚Äôenorme spazio delle chiavi, il Substitution Cipher √® facile da rompere con tecniche di crittanalisi statistica, perch√©:\n\nOgni lettera del plaintext viene sempre cifrata nello stesso modo\n(es. se ‚ÄúE‚Äù diventa ‚ÄúQ‚Äù, sar√† sempre ‚ÄúQ‚Äù).\nQuindi, la frequenza delle lettere nel testo cifrato rispecchia quella del linguaggio originale.\n(es. in inglese la ‚ÄúE‚Äù √® la lettera pi√π comune ‚Üí la lettera pi√π frequente nel ciphertext sar√† probabilmente la ‚ÄúE‚Äù cifrata.)\n\nLe tecniche di frequency analysis furono sviluppate gi√† nel Medioevo e bastano per decifrare messaggi cifrati con questo metodo.\nüîπ 2.2.1 ‚Äì Cryptanalysis of the Affine Cipher\nüß© Contesto\nOscar (l‚Äôavversario) intercetta un messaggio cifrato con un Affine Cipher:\ne_K(x) = (a x + b) \\bmod 26\ndove:\n\nx √® la lettera del plaintext (convertita in numero tra 0 e 25);\na, b sono i parametri della chiave segreta;\na deve essere invertibile modulo 26, cio√® \\gcd(a, 26) = 1.\n\nLa decifratura corrispondente √®:\nd_K(y) = a^{-1} (y - b) \\bmod 26\n\nüìú Esempio 2.10 ‚Äì Ciphertext intercettato\nFMXVEDKAPHFERBNDKRXRSREFMORUDSDKDVSHVUFEDKAPRKDLYEVLRHHRH\nTotale: 57 lettere\nüìä Analisi delle frequenze\nIl testo fornisce la frequenza di ciascuna lettera nel messaggio:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLetteraFreqLetteraFreqLetteraFreqLetteraFreqA2B1C0D7E5F4G0H5I0J0K5L2M2N1O1P2Q0R8S3T0U2V4W0X2Y1Z0\nLe lettere pi√π frequenti nel ciphertext sono:\n\nR (8)\nD (7)\nE, H, K (5)\nF, S, V (4)\n\n\nüéØ Ipotesi iniziale basata sulle frequenze\nOscar sa che, in inglese, le lettere pi√π comuni sono:\n\ne (pi√π frequente)\nt (seconda pi√π frequente)\n\nQuindi ipotizza:\nR \\rightarrow e, \\quad D \\rightarrow t\n\nüßÆ Costruzione del sistema di equazioni\nIn forma numerica:\ne = 4, \\quad t = 19, \\quad R = 17, \\quad D = 3\nDalla definizione del cifrario affine:\ne_K(x) = a x + b \\pmod{26}\notteniamo due equazioni:\n4a + b \\equiv 17 \\pmod{26}\n19a + b \\equiv 3 \\pmod{26}\n‚úèÔ∏è Risoluzione\nSottraiamo le due equazioni:\n(19a - 4a) \\equiv (3 - 17) \\Rightarrow 15a \\equiv -14 \\Rightarrow 15a \\equiv 12 \\pmod{26}\nRisolvendo in \\mathbb{Z}_{26}, otteniamo a = 6, \\ b = 19.\nMa:\n\\gcd(6, 26) = 2 \\neq 1\n\ngcd √® MCD\n\n‚Üí quindi a = 6 non √® invertibile modulo 26 ‚Üí chiave illegale.\nL‚Äôipotesi √® sbagliata.\n\nüîÅ Secondi tentativi\nOscar prova nuove ipotesi:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIpotesiRisultatoR \\to e, E \\to ta = 13 ‚ùå (illegale, \\gcd(13, 26) = 13)R \\to e, H \\to ta = 8 ‚ùå (illegale)R \\to e, K \\to ta = 3, b = 5 ‚úÖ (legale, \\gcd(3, 26) = 1)\n\nüîì Determinazione della chiave\nAbbiamo quindi:\na = 3, \\quad b = 5\n‚Üí Chiave K = (3, 5)\n\nüîÅ Funzione di decifratura\nServe ora l‚Äôinverso moltiplicativo di a = 3 modulo 26.\nPoich√©:\n3 \\times 9 = 27 \\equiv 1 \\pmod{26}\nl‚Äôinverso √®:\na^{-1} = 9\nLa funzione di decifratura diventa:\nd_K(y) = 9 (y - 5) \\bmod 26\nche si pu√≤ riscrivere come:\nd_K(y) = 9y - 45 \\equiv 9y - 19 \\pmod{26}\n\nüß© Risultato finale (plaintext)\nApplicando:\nd_K(y) = 9y - 19 \\bmod 26\nal ciphertext, si ottiene:\nalgorithmsarequitegeneraldefinitionsofarithmeticprocesses\n‚û°Ô∏è Plaintext:\n‚ÄúAlgorithms are quite general definitions of arithmetic processes.‚Äù\n‚úÖ Il testo √® coerente e leggibile in inglese ‚Üí la chiave trovata √® corretta.\n\nüîç Cosa abbiamo imparato\nQuesto esempio mostra che:\n\nAnche senza conoscere la chiave, un avversario pu√≤ dedurla analizzando le frequenze delle lettere.\nAnche cifrari apparentemente complessi come l‚ÄôAffine Cipher possono essere rotti facilmente se il testo √® abbastanza lungo e se si conoscono le statistiche del linguaggio.\n\nüîπ 2.2.2 ‚Äì Cryptanalysis of the Substitution Cipher\nüß© Contesto\nAbbiamo un messaggio cifrato con un Substitution Cipher, cio√® ogni lettera del plaintext √® stata sostituita da una diversa lettera dell‚Äôalfabeto secondo una permutazione sconosciuta (la chiave).\nLo scopo √® determinare la chiave (cio√® la mappatura lettere ‚Üí lettere) e ricostruire il testo originale.\n\nüìú Ciphertext intercettato (Esempio 2.11)\nYIFQFMZRWQFYVECFMDZPCVMRZWNMDZVEJBTXCDDUMJ\nNDIFEFMDZCDMQZKCEYFCJMYRNCWJCSZREXCHZUNMXZ\nNZUCDRJXYYSMRTMEYIFZWDYVZVYFZUMRZCRWNZDZJJ\nXZWGCHSMRNMDHNCMFQCHZJMXJZWIEJYUCFWDJNZDIR\nyaml\nCopy code\n\nüìä Analisi delle frequenze\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLetteraFrequenzaOsservazioneZmolto frequentepi√π comuneC, D, F, J, M, R, Yfrequentialtremeno frequenti\nQuindi, come prima ipotesi:\nd_K(Z) = e\npoich√© ‚Äúe‚Äù √® la lettera pi√π comune in inglese.\n\nüß© Analisi dei digrammi (coppie di lettere)\nPer confermare o smentire l‚Äôipotesi, si studiano i digrammi che contengono la lettera Z.\nSe Z \\to e, allora coppie come DZ, ZW, NZ, ZU potrebbero corrispondere a digrammi comuni in inglese (‚Äúre‚Äù, ‚Äúed‚Äù, ‚Äúhe‚Äù, ‚Äúer‚Äù, ecc.).\n\nDZ e ZW compaiono 4 volte ciascuno\nNZ e ZU compaiono 3 volte\naltri (HZ, XZ, RZ, ecc.) solo 1‚Äì2 volte\n\n\nüß† Prima ipotesi ragionata\nPoich√© ZW √® frequente ma WZ no ‚Üí probabilmente W \\to d\n(il digramma ‚ÄúZW‚Äù corrisponde a ‚Äúed‚Äù, comune in inglese).\nPoich√© DZ compare spesso ‚Üí D \\to r, s o t (ma non ancora certo).\n\nüîç Nuove deduzioni osservando il testo\nNel ciphertext compaiono sequenze come:\nZRW\nyaml\nCopy code\nPoich√© Z \\to e e W \\to d, abbiamo ‚Äúed‚Äù.\nC‚Äô√® una R prima: ‚ÄúRZ‚Äù ‚Üí ‚Äúne‚Äù √® un digramma molto comune.\nQuindi R \\to n.\n\nüí¨ Situazione parziale\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCipherPlainZeWdRn\nApplicando queste sostituzioni, nel testo compaiono frammenti come:\n------end---------e----ned---e------------\nyaml\nCopy code\n‚Üí gi√† si intravede la parola ‚Äúend‚Äù, segno che le ipotesi sono buone.\n\nüß† Nuove osservazioni\nIl digramma ‚ÄúNZ‚Äù (cio√® ‚Äúhe‚Äù) √® molto comune, mentre ‚ÄúZN‚Äù no ‚Üí N \\to h.\nLa sequenza ‚Äúne‚Äìndhe‚Äù suggerisce che C \\to a.\nAggiornamento:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCipherPlainZeWdRnNhCa\nApplicando queste sostituzioni:\n---end---a---e-a‚Äînedh‚Äîe---\nyaml\nCopy code\n\nüßÆ Analisi successiva\nLa lettera M √® frequente ‚Üí probabilmente rappresenta una vocale.\nAbbiamo gi√† a ed e, quindi M pu√≤ essere i oppure o.\nPoich√© il digramma ‚ÄúCM‚Äù (cio√® ‚Äúai‚Äù) √® comune, si prova M \\to i.\nAggiornamento:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCipherPlainZeWdRnNhCaMi\nOra nel testo emergono parole parziali come:\n‚Ä¶inedhi‚Ä¶\nyaml\nCopy code\n‚Üí potrebbe essere ‚Äúfinished‚Äù o ‚Äúend hi‚Ä¶‚Äù ‚Äî plausibile.\n\nüî† Ipotesi sulla lettera Y\nRestano le vocali mancanti: o, u.\nSi nota che Y √® frequente e, se Y \\to o, si evitano sequenze di vocali innaturali come ‚Äúaoi‚Äù.\n‚Üí quindi Y \\to o.\n\nüîÅ D, F, J come possibili consonanti\nLe lettere pi√π frequenti rimaste sono D, F, J ‚Üí probabilmente corrispondono a r, s, t (in qualche ordine).\nOsservazioni:\n\nIl trigramma ‚ÄúNMD‚Äù ‚Üí con N = h, M = i ‚Üí ‚Äúhi_\\_‚Äù ‚Üí suggerisce D \\to s\nIl gruppo ‚ÄúHNCMF‚Äù ‚Üí con N = h, C = a, M = i ‚Üí ‚Äúha_i_\\_‚Äù\nSe fosse ‚Äúchair‚Äù, allora F \\to r e H \\to c\n‚Üí Rimane J \\to t per esclusione.\n\n\n‚úÖ Chiave parziale trovata\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCipherPlainCipherPlainZeDsWdFrRnHcNhJtCaMiYo\n\nüß© Risultato del testo parziale\nDopo tutte le sostituzioni, il messaggio diventa chiaramente leggibile:\n\n‚ÄúOur friend from Paris examined his empty glass with surprise, as\nif evaporation had taken place while he wasn‚Äôt looking.\nI poured some more wine and he settled back in his chair,\nface tilted up towards the sun.‚Äù\n\n‚úÖ Plaintext finale:\n\n‚ÄúOur friend from Paris examined his empty glass with surprise, as if evaporation had taken place while he wasn‚Äôt looking. I poured some more wine and he settled back in his chair, face tilted up towards the sun.‚Äù\n\n\nüß† Cosa abbiamo imparato\nAnche senza formule matematiche, il Substitution Cipher pu√≤ essere rotto analizzando:\n\nle frequenze delle lettere\ni digrammi (coppie)\ni trigrammi (triplette)\nil contesto linguistico\n\nSi parte da ipotesi plausibili (es. ‚ÄúZ \\to e‚Äù) e si confermano con la coerenza del testo.\nMan mano che si identificano parole, le altre lettere vengono dedotte per esclusione.\n\nüí° In sintesi\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConcettoDescrizioneCifrarioSubstitution Cipher (sostituzione monoalfabetica)Metodo di attaccoAnalisi statistica: frequenze, digrammi, contesto linguisticoChiave trovataPermutazione parziale (es. Z \\to e, W \\to d, R \\to n, ‚Ä¶)RisultatoPlaintext completamente recuperatoConclusioneAnche con un enorme spazio di chiavi (26!), il Substitution Cipher √® debole perch√© mantiene la struttura linguistica del testo.\n\nüîì Conclusione:\nIl Substitution Cipher non √® sicuro, perch√© la frequenza delle lettere nel ciphertext riflette quella del linguaggio naturale.\nUn attaccante pu√≤, con abbastanza testo, ricostruire la chiave a mano usando logica e statistica"},"UNI/ANNO-3/CRITTOGRAFIA/LEZ-2":{"slug":"UNI/ANNO-3/CRITTOGRAFIA/LEZ-2","filePath":"UNI/ANNO 3/CRITTOGRAFIA/LEZ 2.md","title":"LEZ 2","links":[],"tags":[],"content":"2.1.4,\n2.2.3, e\n3.3\n2.1.3"},"UNI/ANNO-3/INGEGNERIA-DEL-SOFTWARE/IS-INDICE":{"slug":"UNI/ANNO-3/INGEGNERIA-DEL-SOFTWARE/IS-INDICE","filePath":"UNI/ANNO 3/INGEGNERIA DEL SOFTWARE/IS INDICE.md","title":"IS INDICE","links":["UNI/ANNO-3/INGEGNERIA-DEL-SOFTWARE/IS-LEZ.1","UNI/ANNO-3/INGEGNERIA-DEL-SOFTWARE/IS-LEZ.2"],"tags":[],"content":"IS LEZ.1\nIS LEZ.2"},"UNI/ANNO-3/INGEGNERIA-DEL-SOFTWARE/IS-LEZ.1":{"slug":"UNI/ANNO-3/INGEGNERIA-DEL-SOFTWARE/IS-LEZ.1","filePath":"UNI/ANNO 3/INGEGNERIA DEL SOFTWARE/IS LEZ.1.md","title":"IS LEZ.1","links":[],"tags":[],"content":"üê∑DEFINIZIONE DI INGEGNERIA DEL SOFTWARE\n\nleggibile a IEEE Std 610.12\nApplicazione di un approccio sistematico, disciplinato‚Ä¶\nha lo scopo di rispondere a domande di ottimizzazione e manutenzione del software\n\nü´ö IL SOFTWARE\n\nva ingegnerizzato e non solo scritto\ninsieme totale di tutti i vari processi e procedimenti nella creazione del prodotto, non solo codice\nla legge di Brooks ci dice che se sono in ritardo nella consegna, se aggiungo nuovi programmatori rallento ancora di pi√∫\n\nüßÆ DRE (Defect Removal Efficiency)\n\nFornisce una misura quantitativa di quanto un processo di sviluppo riesce a identificare e correggere i difetti.\n\n\n‚öôÔ∏è Caratteristiche essenziali di Brooks\n\nComplesso\n\nNumero di stati possibili del software decisamente elevato.\n\n\nConformit√†\n\nIl software deve conformarsi al contesto di quel dato ambiente operativo.\n\n\nCambiabilit√†\n\nIl software viene costantemente modificato e aggiornato.\n\n\nInvisibilit√†\n\nNon abbiamo sempre la visuale su ci√≤ che avviene nella parte back del software.\n\n\n\n\nüí∞ Costo del prodotto software\n\nDiversi aspetti:\n\nDimensione\n\nIl costo in soldini √® proporzionale al quadrato della dimensione:\nC = aS¬≤\n\n\nRepliche\n\nGrazie alle piattaforme online, il costo di distribuzione √® quasi nullo.\n\n\nAmpiezza di mercato\n\nQuante persone sono disposte ad acquistare o utilizzare un determinato prodotto.\n\n\n\n\n\n\nüìò Carrellata di definizioni\n\nProdotto software\n\nCodice + Documentazione.\n\n\nArtefatto\n\nProdotto software intermedio con vari documenti:\n\nDocumento dei requisiti\nDocumento di specifica\nDocumento di progetto\n\n\n\n\nCodice\n\nProdotto software finale.\n\n\nSistema software\n\nInsieme organizzato di prodotti software (es. Office, Adobe, ecc‚Ä¶).\nOppure pu√≤ significare hardware + software con un hardware custom.\n\n\nCliente\n\nColui che commissiona il prodotto software.\n\n\nSviluppatore\n\nSoggetto che lo produce.\n\n\nUtente\n\nSoggetto che lo usa.\n\n\nSoftware interno\n\nCliente e sviluppatore coincidono.\n\n\nSoftware a contratto\n\nCliente e sviluppatore sono soggetti differenti.\n\n\nEmbedded\n\nSoftware integrato in dispositivi hardware specifici.\n\n\n\n\nüß© Affidabilit√† del software\n\nInformalmente\n\nCredibilit√† del prodotto.\n\n\nFormalmente\n\nProbabilit√† che il software lavori correttamente in un determinato intervallo temporale (detto mission time).\n\n\n\n\nü™≤ Difetti, guasti ed errori\n\nDifetto o bug\n\nAnomalia nel prodotto software.\nTanti difetti = poca affidabilit√†.\n\n\nGuasto\n\nComportamento anomalo del prodotto software dovuto a uno o pi√π difetti.\n\n\nErrore\n\nAzione errata di chi, per ignoranza o distrazione, introduce un difetto nel prodotto software.\n\n\n\n\nüîÅ Regression false\n\nTrovo un difetto, lo risolvo‚Ä¶ e ne spuntano altri due.\nSe elimino un difetto non per forza migliora l‚Äôaffidabilit√†.\n\n\n‚è±Ô∏è Regola 10‚Äì90\n\nIl 90% del tempo di esecuzione totale √® speso eseguendo solo il 10% delle istruzioni.\nQuesto 10% √® detto nucleo, e rappresenta gran parte dell‚Äôaffidabilit√†.\n\n\nüìä Operational profile\n\nPercentuale quantitativa che indica con quale probabilit√† si usano le varie parti del prodotto.\n\nLa classe 1 usa una certa % del prodotto.\nLa classe 2 un‚Äôaltra %, e cos√¨ via.\n\n\nL‚Äôaffidabilit√† dipende dagli utenti e da come utilizzano il software.\n\n\n‚öñÔ∏è Guasti hardware e software\n\nSoftware\n\nDifetti nei programmi.\nNon si consumano.\nSi correggono con attenzione, perch√© si pu√≤ incorrere in ulteriori problemi.\nREGRESSION FAULT\n\n\nHardware\n\nProdotti che si deteriorano o si rompono.\nPer ripararli bisogna sostituire la componente.\n√à definito un MTTF (Mean Time To Failure) ‚Üí indica dopo quanto tempo una certa componente potrebbe fallire.\n\n\n\n‚öôÔ∏è Frequenza difetti hardware\n\n\n‚ÄúVasca da bagno‚Äù letteralmente.\n\n\nFailure rate alto nei primi tempi ‚Üí mortalit√† infantile.\n\n\nPoi si stabilizza nel tempo.\n\n\nAumenta di nuovo nei tempi di usura con il prolungarsi del tempo.\n\n\n\nüíæ Frequenza difetti software\n\n\nCurva idealizzata: decrescente.\n\n\nCurva reale: differente, con una leggera ricrescita dovuta a particolari aggiornamenti.\n\n\nSecondo alcuni studiosi di software rejuvenation, nei software grandi nel tempo possono esserci ‚Äúdanni di usura‚Äù.\n\n\nPer risolvere, dicono che basta fare manutenzione periodica (es. una volta all‚Äôanno).\n\n\nSecondo il prof, √® ‚Äúabbastanza una cazzata‚Äù: basta spegnere e riaccendere.\n\n\n\n\n\nüñ•Ô∏èSoftware availability\n\n\n√à la percentuale di tempo in cui il software √® utilizzabile.\n\n\nDipende da:\n\n\nNumero di guasti.\n\n\nTempo necessario a ripararli.\n\n\n\n\nLe interruzioni comportano perdite:\n\n\nEconomiche.\n\n\nSociali.\n\n\nDi produttivit√†.\n\n\n\n\n\nüß™ Tecniche di testing\n\n\nTesting statistico\n\n\nDispendioso in tempi e risorse.\n\n\nSi prende un lasso di tempo prefissato.\n\n\nAd ogni fallimento si registra l‚Äôistante di fallimento.\n\nIl prodotto viene corretto e si ricomincia il testing per lo stesso intervallo.\n\n\n\n\n\nModello pi√π usato: modello del frakkone.\nc\n\n"},"UNI/ANNO-3/INGEGNERIA-DEL-SOFTWARE/IS-LEZ.2":{"slug":"UNI/ANNO-3/INGEGNERIA-DEL-SOFTWARE/IS-LEZ.2","filePath":"UNI/ANNO 3/INGEGNERIA DEL SOFTWARE/IS LEZ.2.md","title":"IS LEZ.2","links":[],"tags":[],"content":""},"UNI/ANNO-3/INTELLIGENZA-ARTIFICIALE/IA-INDICE":{"slug":"UNI/ANNO-3/INTELLIGENZA-ARTIFICIALE/IA-INDICE","filePath":"UNI/ANNO 3/INTELLIGENZA ARTIFICIALE/IA INDICE.md","title":"IA INDICE","links":[],"tags":[],"content":""},"UNI/ANNO-3/INTELLIGENZA-ARTIFICIALE/IA-LEZ.2":{"slug":"UNI/ANNO-3/INTELLIGENZA-ARTIFICIALE/IA-LEZ.2","filePath":"UNI/ANNO 3/INTELLIGENZA ARTIFICIALE/IA LEZ.2.md","title":"IA LEZ.2","links":[],"tags":[],"content":"\ndifferenza tra un software tradizionale e un software AI\n\nil software AI √© un software che non lavora in isolamento, lavora in un ambiente che agisce in autonomia, lui riceve segnali dall‚Äôambiente e ne risponde\n\n√® piu simile a un S.O rispetto a un software classico\nl‚Äôagente non puo sapere prima le domande\nl‚Äôagente puo avere degli effettori, coloro che consentono a lui di effettuare azioni fisiche\nsensori, apparati in grado di vedere l‚Äôambiente e riconoscerlo adeguatamente\nCiclo dell‚Äôagente\n\npercepire una azione mediante i sensori\ndecido\nagisco con una azione\nsi aggiorna\n\n\ngli agenti hanno obiettivi e una percezione adeguata ma anche parziale del mondo esterno\n\nil mondo esterno non √® per√≤ una copia 1:1 bensi una copia senza tutte le informazioni, che vengono aggiunte in modo dinamico e astratto una volta che mi accorgo della loro necessit√†\n\n\n\n\n\n\n\nPERCEZIONI E AZIONI\n\nPercezione\nSequenza\nl‚Äôazione √® esclusivamente dopo una Percezione\n\nAgenti Razionali\n\nUn agente ha una razionalita\n\nscopo o scopi del singolo agente\nUn agente intelligente=Un agente razionale\ngli agenti lavorano su un criterio approssimato che cerca l‚Äôottimalita su diverse scelte\n\nci sono piu vie\nvado a approfondire la cosa se ogni scelta ha probabilit√† identiche\n\n\n\n\n\nValutazione della prestazione\n\nho diverse metodologie per dare una valutazione a una prestazione attuabile\n\ndevono funzionare su ambienti diversi, non una sola partita ma tutte le istanze possibili\n\n\n\nUn agente razionale\n\nla razionalit√† relativa a\n\nla misura di prestazioni che hanno successo\nle conoscenze pregresse dell‚Äôambiente\nle percezioni presenti e passate\nle capacita dell‚Äôagente\n\n\nper ogni percezione deve compiere l‚Äôazione che massimizza il valore atteso della misura delle prestazioni, sfruttando percezioni passate e la conoscenza passata\n\ndiff tra percez passate e conoscenza passata\n\n\nnon deve sempre fare le cose giuste per essere razionale\n\nse non sa deve apprendere da risorse dati ecc, comunque dall‚Äôambiente esterno\n\n\n\nAgenti autonomi\n\nlavorano in autonomia\n\nmentre decide deve essere autonomo, possiamo pero manipolarlo perche cmq e un collaboratore\n\n\n\nAMBIENTE E CODIFICA PEAS\nun ambiente √® caratterizzato da una dimensione di 4 cose\n\nPrestazioni\n\nobiettivi\n\n\nAmbiente\n\ndescrizione\n\n\nAttuatori\n\ncomponenti da usare per fare azioni\n\n\nSensori\n\ncomponenti per percepire dall‚Äôambiente\nESEMPIO DI AMBIENTE CHAT GPT\n\n\nvedi slide\n\nProblema P dell‚Äôagente\n\nun problema P per un agente parte sicuramente da una caratterizzazione adeguata dell‚Äôambiente\n\nUN ambiente e il problema hanno diverse proprieta\n\ncompletamente o parzialmente osservabile\nagente singolo o multiplo\n\nagente non indicava multiple ia?\n\n\ndeterministico, stocazzo, non deterministico\n\nil primo e se sono sicuro al 100% di cosa succede\nstocazzo se ho una certa prob\nnon det se ho difficolta a determinare cosa deve avvenire\n\n\nepisodico vs sequenziale\n\nepisodico quando decisioni sono prese singolarmente\nsequenziale decisioni in sequenza\n\n\nstatico o dinamico\n\ndefiniti da un cambiamento ambientale o meno\nstatico quando l‚Äôagente va piu veloce dei cambiamenti quindi non cambia l‚Äôambiente ecc\ndinamico quando le scelte vanno di paripasso ai cambiamenti dell‚Äôambiente\n\ntipo taxi autonomo\n\n\nsemi dinamico, l‚Äôambiente non cambia ma la valutazione dell‚Äôagente si\n\n\ndiscreto o continuo\n\ndiscreti, ambienti di esame\n\nmodificano ogni tot tick o scansioni e transizioni temporali\ncontinuo quando le variabile vengono descritte da numeri reali\n\n\n\n\n\nOsservabilit√† dell‚Äôambiente\n\ncompletamente osservabile\nparzialmente osservabile\n\nCome automatizzare un ambiente\n\nattraverso uno strumento software che vuole:\n\ngenerare stimoli per gli agenti\nraccogliere le azioni in risposta\naggiornare il proprio stato\nattivare altri processi implicati dal cambiamento effettuato\nvalutare le prestazioni degli agenti\n\n\n\nAGENTE\narchitettura+programma\nfunzione che prende percezioni e manda in output azioni\nuna funzione di un agente prende in input una percezione\nmanda in output una azione\nha una memoria che deve aggiornare\neffettua una azione scegliendo la migliore\naggiorna la memoria a seguito di una azione\nrestituisco l‚Äôazione\n"},"UNI/ANNO-3/INTELLIGENZA-ARTIFICIALE/IA-LEZIONE-1":{"slug":"UNI/ANNO-3/INTELLIGENZA-ARTIFICIALE/IA-LEZIONE-1","filePath":"UNI/ANNO 3/INTELLIGENZA ARTIFICIALE/IA LEZIONE 1.md","title":"IA LEZIONE 1","links":[],"tags":[],"content":"\nIA disciplina\nAgenti plurale di pi√π IA\nUna IA\n\nosserva, comprende\nriproduce comportamenti intelligenti\n\n\nIA si dice forte se tende a essere razionale come l‚Äôuomo\n\nnon deve fornire solo l‚Äôoutput ma deve eseguire gli step simulando il tutto come se li facesse un uomo\n\n\nCriterio di successo dell‚ÄôIA\n\ndevo misurare il successo in % a paragone dell‚Äôuomo\n\n\nuna IA pu√≤ seguire i pensieri e le azioni umane oppure razionali\n\ntipo un robot non pensa e non esegue azioni come una persona che pulisce\nl‚Äôuomo di per se non √® razionale sempre, quindi potrebbe portare a soluzioni non ottimizzate al 100%\nquesto detto sopra non va in contrapposizione a quanto detto prima? come definizione di IA?\nforse umanit√† e razionalit√† vanno di pari passo\n\n\nUNA IA come chat gpt lavora su quello che √®\n\nil question answering\nsequenze di regole context free radicate\nSentiment analysis o recognition\n\nobiettivi con un certo sentiment\nper ognuno di questi obiettivi assegna un certo sentiment\n\n\n\n\ninstruction tuning\npremessa+domanda\n\navvia un processo dinamico dove la macchina itera fino a che non termina\nsuccessivamente recuperano le informazioni on the fly tipo sul web\ne poi forniscono una risposta basato sul contesto che ha derivato da premessa+domanda\n\n\nprompt\n\nporzione di premessa e domanda +contesto prelevato da parti diverse\n\n\nfondamenti dell‚ÄôIA\n\npsicologia\nmatematica‚Ä¶\n\n\nTest di Turing\n\nsto parlando con una macchina o una persona?\n\n\n"},"UNI/ANNO-3/ORGANIZZAZIONI-ESAMI":{"slug":"UNI/ANNO-3/ORGANIZZAZIONI-ESAMI","filePath":"UNI/ANNO 3/ORGANIZZAZIONI ESAMI.md","title":"ORGANIZZAZIONI ESAMI","links":[],"tags":[],"content":"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMateriaAppello Gennaio-FebbraioAppello Giugno-LuglioAppello SettembreLING 1‚úÖLING 2‚úÖFOND.‚úÖGEOMETRIA‚úÖINTELLIGENZA ARTIFICIALE‚úÖINGEGNERIA DEL SOFTWARE‚úÖALGORITMI PER I BIG DATA‚úÖJAVA PER DISPOSITIVI MOBILI‚úÖPROGRAMMAZIONE WEB‚úÖINFORMATION RETRIEVAL‚úÖFISICA/CALCOLO/CRITTO‚úÖ\nDAMMI LA PAZIENZA"},"UNI/Excalidraw/Drawing-2024-10-26-15.09.58.excalidraw":{"slug":"UNI/Excalidraw/Drawing-2024-10-26-15.09.58.excalidraw","filePath":"UNI/Excalidraw/Drawing 2024-10-26 15.09.58.excalidraw.md","title":"Drawing 2024-10-26 15.09.58.excalidraw","links":["Pasted-Image-20250303174307_434.png"],"tags":["excalidraw"],"content":"‚ö†  Switch to EXCALIDRAW VIEW in the MORE OPTIONS menu of this document. ‚ö†\nText Elements\nEmbedded files\n24ff07f2638bb107a2cb45f846e46857946d6e2f: Pasted Image 20250303174307_434.png"},"index":{"slug":"index","filePath":"index.md","title":"index","links":["UNI/ANNO-3/CRITTOGRAFIA/CRITTOGRAFIA-INDICE","UNI/ANNO-3/INGEGNERIA-DEL-SOFTWARE/IS-INDICE","UNI/ANNO-3/INTELLIGENZA-ARTIFICIALE/IA-INDICE","UNI/ANNO-3/ALGORITMI-PER-I-BIG-DATA/BIG-DATA-INDICE","UNI/ANNO-1/ANALISI-1/ANALISI-1-INDICE","UNI/ANNO-1/PROGRAMMAZIONE/Programmazione-INDICE","UNI/ANNO-1/DISCRETA/Discreta-INDICE","UNI/ANNO-1/LOGICA/Logica-INDICE","UNI/ANNO-1/ARCHITETTURA/Architettura-INDICE","UNI/ANNO-1/GEOMETRIA/GEOMETRIA-INDICE","UNI/ANNO-2/ALGORITMI-1/ALGORITMI-INDICE","UNI/ANNO-2/ALGORITMI-2/ALGORITMI-2-INDICE","UNI/ANNO-2/FONDAMENTI/FONDAMENTI-DI-INFORMATICA-INDICE","UNI/ANNO-2/LINGUAGGI/LINGUAGGI-INDICE","UNI/ANNO-2/SISTEMI-OPERATIVI/SISTEMI-OPERATIVI-E-RETI-INDICE","UNI/ANNO-2/BASE-DI-DATI/BASI-DI-DATI-INDICE","UNI/ANNO-2/PROBABILIT√Ä/PROBABILIT√Ä-INDICE","ALTRO/ONE-PIECE-EPISODI","ALTRO/COSA-FARE-SE-TI-SENTI-IL-CERVELLO-ANNEBBIATO"],"tags":[],"content":"Chi sono?üë®üèª‚Äçüíª\nMi chiamo Luca Gugliotta e studio presso l‚Äôuniversit√† di Tor Vergata informatica\n\nGli esami:\nCRITTOGRAFIA üîí\nappunti del corso: CRITTOGRAFIA INDICE\nINGEGNERIA DEL SOFTWARE\nIS INDICE\nINTELLIGENZA ARTIFICIALE\nIA INDICE\nBIG DATA\nBIG DATA INDICE\n\n\n                  \n                  anno 1 \n                  \n                \n\nAnalisiüìà\necco qua:ANALISI 1 INDICE\n\nriassunti‚ùå\nesercizi‚ùå\n\nProgrammazioneüíª\neccoci qua:Programmazione INDICE\n\nriassunti ‚úÖ\nesercizi ‚ùå\n\nDiscreta üßÆ\neccoci qua:Discreta INDICE\n\nriassunti‚ùå\nesercizi ‚ùå\n\nLogica e Reti Logicheüß†\neccolo qui:Logica INDICE\n\nriassunti ‚úÖ\nesercizi ‚ùå\n\nArchitettura dei sistemi di elaborazioneüéõ\neccolo qua:Architettura INDICE\n\nriassunti ‚úÖ\nesercizi ‚úÖ\n\nGeometria üìê\nesercizi meccanici:GEOMETRIA INDICE\n\nriassunti‚ùå\nesercizi ‚úÖ\n\n\n\n\n\n                  \n                  anno 2 \n                  \n                \n\nALGORITMI üéØ\nappunti del corso:ALGORITMI INDICE\n\nriassunti‚úÖ\nesercizi ‚ùå\npdf commentati di algoritmi 2:\nALGORITMI 2 INDICE\n\nFONDAMENTI DI INFORMATICA ü§ñ\nappunti del corso:FONDAMENTI DI INFORMATICA INDICE\n\nriassunti‚ùå\nesercizi ‚ùå\n\nLINGUAGGI &lt;/&gt;\nappunti del corso:LINGUAGGI INDICE\n\nriassunti‚úÖ\nesercizi ‚ùå\n\nSISTEMI OPERATIVI E RETI ‚öôÔ∏è\nappunti del corso:SISTEMI OPERATIVI E RETI INDICE\n\nriassunti‚úÖ\nesercizi ‚úÖ\n\nBASI DI DATI ùÑú\nappunti del corso:BASI DI DATI INDICE\n\nriassunti‚ùå\nesercizi ‚ùå\n\nProbabilit√† e Statistica üé≤\nappunti del corso:PROBABILIT√Ä INDICE\n\nriassunti‚ùå\nesercizi ‚ùå\n\n\n\nALTRO\nONE PIECE EPISODI\nCOSA FARE SE TI SENTI IL CERVELLO ANNEBBIATO\nOrganizzazione\n\n"}}